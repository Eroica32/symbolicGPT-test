{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "467e4132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b3b16f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make deterministic\n",
    "from mingpt.utils import set_seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c38c2fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec44808b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "629b5749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "embeddingSize=768\n",
    "numPoints=30\n",
    "numVars=1\n",
    "numYs=1\n",
    "paddingToken='<PAD>'\n",
    "padId=0\n",
    "extractAttributes = False\n",
    "block_size = 500 # spatial extent of the model for its context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39d95800",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, block_size, extractAtt=False):\n",
    "        chars = sorted(list(set(data)))\n",
    "        data_size, vocab_size = len(data), len(chars)\n",
    "        print('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
    "        \n",
    "        self.stoi = { ch:i for i,ch in enumerate([paddingToken]+chars if extractAtt else chars) } \n",
    "        self.itos = { i:ch for i,ch in enumerate([paddingToken]+chars if extractAtt else chars) }\n",
    "        self.block_size = block_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.data = data\n",
    "        self.attributes = extractAtt\n",
    "        self.threshold = [-1000,1000]\n",
    "        \n",
    "        if self.attributes:\n",
    "            self.dataList = self.data.split('\\n') #TODO: remove later?\n",
    "\n",
    "            self.blockIdx = []\n",
    "            summation = 0\n",
    "            for d in self.dataList:\n",
    "                s = summation\n",
    "                e = s + len(d)\n",
    "                self.blockIdx.append((s,e))\n",
    "                summation = e+1\n",
    "    \n",
    "    def __len__(self):\n",
    "        if self.attributes:\n",
    "            return len(self.dataList) - 1\n",
    "        else:\n",
    "            return len(self.data) - self.block_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # grab a chunk of (block_size + 1) characters from the data\n",
    "        #chunk = self.data[idx:idx + self.block_size + 1]\n",
    "        if not self.attributes:\n",
    "            chunk = self.data[idx:idx + self.block_size + 1]\n",
    "            dix = [self.stoi[s] for i,s in enumerate(chunk)]\n",
    "            inputs = torch.tensor(dix[:-1], dtype=torch.long).contiguous()\n",
    "            outputs = torch.tensor(dix[1:], dtype=torch.long).contiguous()\n",
    "            return inputs, outputs\n",
    "        else:\n",
    "            chunk = self.data[self.blockIdx[idx][0]:self.blockIdx[idx][1]]\n",
    "        \n",
    "            # extracts other attributes\n",
    "            points = None\n",
    "            if self.attributes:\n",
    "                dic = json.loads(chunk)\n",
    "                points = []\n",
    "                for xy in zip(dic['X'], dic['Y']):\n",
    "                    x = xy[0] + [self.stoi[paddingToken]]*(max(numVars-len(xy[0]),0)) # padding\n",
    "                    y = [xy[1]] if type(xy[1])== float else xy[1]\n",
    "                    y = y + [self.stoi[paddingToken]]*(max(numYs-len(y),0)) # padding\n",
    "\n",
    "                    p = x + y #x.extend(y)\n",
    "                    p = torch.tensor(p)\n",
    "\n",
    "                    #replace nan and inf\n",
    "                    p = torch.nan_to_num(p, nan=0.0, \n",
    "                                         posinf=self.threshold[1], \n",
    "                                         neginf=self.threshold[0])\n",
    "\n",
    "                    points.append(p)\n",
    "                chunk = '\"'+dic['EQ']+'\"'\n",
    "\n",
    "            # encode every character to an integer\n",
    "            dix = [self.stoi[s] for i,s in enumerate(chunk) if i<self.block_size]\n",
    "            paddingSize = max(self.block_size-len(dix),0)\n",
    "\n",
    "            mask = [1] + [1 for s in dix]\n",
    "            #dixX = dix + [self.stoi[paddingToken]]*paddingSize # padding\n",
    "            dix += [self.stoi[paddingToken]]*paddingSize # padding\n",
    "            mask += [0]*paddingSize\n",
    "\n",
    "            inputs = torch.tensor(dix[:-1], dtype=torch.long).contiguous()\n",
    "            mask = torch.tensor(mask[:-1], dtype=torch.long).contiguous()\n",
    "            mask = mask.unsqueeze(0)\n",
    "            mask = mask.T @ mask\n",
    "\n",
    "            \"\"\"\n",
    "            arrange data and targets so that the first i elements of x\n",
    "            will be asked to predict the i-th element of y. Notice that\n",
    "            the eventual language model will actually make block_size\n",
    "            individual predictions at the same time based on this data,\n",
    "            so we are being clever and amortizing the cost of the forward\n",
    "            pass of the network. So for example if block_size is 4, then\n",
    "            we could e.g. sample a chunk of text \"hello\", the integers in\n",
    "            x will correspond to \"hell\" and in y will be \"ello\". This will\n",
    "            then actually \"multitask\" 4 separate examples at the same time\n",
    "            in the language model:\n",
    "            - given just \"h\", please predict \"e\" as next\n",
    "            - given \"he\" please predict \"l\" next\n",
    "            - given \"hel\" predict \"l\" next\n",
    "            - given \"hell\" predict \"o\" next\n",
    "\n",
    "            In addition, because the DataLoader will create batches of examples,\n",
    "            every forward/backward pass during traning will simultaneously train\n",
    "            a LOT of predictions, amortizing a lot of computation. In particular,\n",
    "            for a batched input of integers X (B, T) where B is batch size and\n",
    "            T is block_size and Y (B, T), the network will during training be\n",
    "            simultaneously training to make B*T predictions, all at once! Of course,\n",
    "            at test time we can paralellize across batch B, but unlike during training\n",
    "            we cannot parallelize across the time dimension T - we have to run\n",
    "            a forward pass of the network to recover the next single character of the \n",
    "            sequence along each batch dimension, and repeatedly always feed in a next\n",
    "            character to get the next one.\n",
    "\n",
    "            So yes there is a big asymmetry between train/test time of autoregressive\n",
    "            models. During training we can go B*T at a time with every forward pass,\n",
    "            but during test time we can only go B at a time, T times, with T forward \n",
    "            passes.\n",
    "            \"\"\"        \n",
    "\n",
    "            outputs = torch.tensor(dix[1:], dtype=torch.long).contiguous()\n",
    "\n",
    "            #assert mask.shape==outputs.shape==inputs.shape, 'M:{}-O:{}-I:{}'.format(mask.shape,outputs.shape,inputs.shape)\n",
    "            assert len(mask) == self.block_size, 'Wrong mask shape: {}'.format(mask.shape)\n",
    "            assert len(inputs) == self.block_size-1, 'Wrong inputs shape: {}'.format(inputs.shape)\n",
    "            assert len(outputs) == self.block_size-1, 'Wrong y shape: {}'.format(outputs.shape)\n",
    "            assert len(points) == numPoints, 'Wrong #points: {}'.format(len(points))\n",
    "\n",
    "            return inputs, outputs, points, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16b9ac32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "def processDataFiles(files):\n",
    "    text = ''\"\"\n",
    "    for f in tqdm(files):\n",
    "        with open(f, 'r') as h: \n",
    "            lines = h.read() # don't worry we won't run out of file handles\n",
    "            text += lines #json.loads(line)                \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b08ce5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.49it/s]\n"
     ]
    }
   ],
   "source": [
    "path = 'D:\\Datasets\\Symbolic Dataset\\Datasets\\Mesh_Simple_GPT2_Sorted\\TrainDatasetFixed\\*.json'\n",
    "files = glob.glob(path)\n",
    "text = processDataFiles([files[0]]) #[files[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7164d622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avgBlockSize = 0\n",
    "# upNum = 100\n",
    "# for i in tqdm(range(0,upNum)):\n",
    "#     avgBlockSize += len(text.split('\\n')[i])\n",
    "# avgBlockSize /= upNum\n",
    "# print('avg block size is {}'.format(avgBlockSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4598793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 243072217 characters, 43 unique.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CharDataset(text, block_size, extractAtt=extractAttributes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e95f9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:tensor([ 1, 28, 11,  9, 13, 12, 29,  7,  1, 28, 12,  9, 16, 16, 29,  7,  1, 28,\n",
      "        11,  9, 12, 29,  7,  1, 28, 12,  9, 17, 17, 29,  7,  1, 28, 11,  9, 11,\n",
      "        29,  7,  1, 28, 12,  9, 18, 17, 29,  7,  1, 28, 12,  9, 19, 17, 29,  7,\n",
      "         1, 28, 12,  9, 20, 18, 29,  7,  1, 28, 13,  9, 11, 18, 29,  7,  1, 28,\n",
      "        13,  9, 12, 18, 29,  7,  1, 28, 13,  9, 13, 19, 29,  7,  1, 28, 13,  9,\n",
      "        14, 19, 29,  7,  1, 28, 13,  9, 15, 19, 29,  7,  1, 28, 13,  9, 16, 20,\n",
      "        29,  7,  1, 28, 13,  9, 17, 20, 29,  7,  1, 28, 13,  9, 18, 20, 29,  7,\n",
      "         1, 28, 13,  9, 20, 29,  7,  1, 28, 14,  9, 11, 29, 29,  7,  1,  2, 27,\n",
      "         2, 21,  1, 28,  8, 12,  9, 11,  7,  1,  8, 12,  9, 11,  7,  1,  8, 11,\n",
      "         9, 20, 20,  7,  1,  8, 11,  9, 20, 19,  7,  1,  8, 11,  9, 20, 18,  7,\n",
      "         1,  8, 11,  9, 20, 16,  7,  1,  8, 11,  9, 20, 15,  7,  1,  8, 11,  9,\n",
      "        20, 12,  7,  1,  8, 11,  9, 19, 20,  7,  1,  8, 11,  9, 19, 17,  7,  1,\n",
      "         8, 11,  9, 19, 14,  7,  1,  8, 11,  9, 18, 20,  7,  1,  8, 11,  9, 18,\n",
      "        18,  7,  1,  8, 11,  9, 18, 13,  7,  1,  8, 11,  9, 17, 19,  7,  1,  8,\n",
      "        11,  9, 17, 14,  7,  1,  8, 11,  9, 17,  7,  1,  8, 11,  9, 16, 15,  7,\n",
      "         1,  8, 11,  9, 15, 15,  7,  1,  8, 11,  9, 14, 14,  7,  1,  8, 11,  9,\n",
      "        13, 14,  7,  1,  8, 11,  9, 12, 13,  7,  1, 11,  9, 11,  7,  1, 11,  9,\n",
      "        12, 12,  7,  1, 11,  9, 13, 13,  7,  1, 11,  9, 14, 14,  7,  1, 11,  9,\n",
      "        15, 15,  7,  1, 11,  9, 16, 14,  7,  1, 11,  9, 17, 14,  7,  1, 11,  9,\n",
      "        18, 12, 29,  7,  1,  2, 22, 24,  2, 21,  1,  2,  8, 38, 31, 34,  3, 12,\n",
      "         9, 12,  5, 40, 12,  6, 11,  9, 17, 15,  4,  2,  7,  1,  2, 25, 32, 30,\n",
      "        33, 30, 39, 35, 34,  2, 21,  1,  2, 38, 31, 34,  3, 13,  5, 40, 12,  4,\n",
      "         2, 42,  0, 41,  2, 26,  2, 21,  1, 28, 28, 11,  9, 11, 29,  7,  1, 28,\n",
      "        11,  9, 12, 29,  7,  1, 28, 11,  9, 13, 12, 29,  7,  1, 28, 11,  9, 14,\n",
      "        12, 29,  7,  1, 28, 11,  9, 15, 12, 29,  7,  1, 28, 11,  9, 16, 13, 29,\n",
      "         7,  1, 28, 11,  9, 17, 13, 29,  7,  1, 28, 11,  9, 18, 13, 29,  7,  1,\n",
      "        28, 11,  9, 19, 14, 29,  7,  1, 28, 11,  9, 20, 14, 29,  7,  1, 28, 12,\n",
      "         9, 11, 14, 29,  7,  1, 28, 12,  9, 12, 15, 29,  7,  1])\n",
      "y:tensor([28, 11,  9, 13, 12, 29,  7,  1, 28, 12,  9, 16, 16, 29,  7,  1, 28, 11,\n",
      "         9, 12, 29,  7,  1, 28, 12,  9, 17, 17, 29,  7,  1, 28, 11,  9, 11, 29,\n",
      "         7,  1, 28, 12,  9, 18, 17, 29,  7,  1, 28, 12,  9, 19, 17, 29,  7,  1,\n",
      "        28, 12,  9, 20, 18, 29,  7,  1, 28, 13,  9, 11, 18, 29,  7,  1, 28, 13,\n",
      "         9, 12, 18, 29,  7,  1, 28, 13,  9, 13, 19, 29,  7,  1, 28, 13,  9, 14,\n",
      "        19, 29,  7,  1, 28, 13,  9, 15, 19, 29,  7,  1, 28, 13,  9, 16, 20, 29,\n",
      "         7,  1, 28, 13,  9, 17, 20, 29,  7,  1, 28, 13,  9, 18, 20, 29,  7,  1,\n",
      "        28, 13,  9, 20, 29,  7,  1, 28, 14,  9, 11, 29, 29,  7,  1,  2, 27,  2,\n",
      "        21,  1, 28,  8, 12,  9, 11,  7,  1,  8, 12,  9, 11,  7,  1,  8, 11,  9,\n",
      "        20, 20,  7,  1,  8, 11,  9, 20, 19,  7,  1,  8, 11,  9, 20, 18,  7,  1,\n",
      "         8, 11,  9, 20, 16,  7,  1,  8, 11,  9, 20, 15,  7,  1,  8, 11,  9, 20,\n",
      "        12,  7,  1,  8, 11,  9, 19, 20,  7,  1,  8, 11,  9, 19, 17,  7,  1,  8,\n",
      "        11,  9, 19, 14,  7,  1,  8, 11,  9, 18, 20,  7,  1,  8, 11,  9, 18, 18,\n",
      "         7,  1,  8, 11,  9, 18, 13,  7,  1,  8, 11,  9, 17, 19,  7,  1,  8, 11,\n",
      "         9, 17, 14,  7,  1,  8, 11,  9, 17,  7,  1,  8, 11,  9, 16, 15,  7,  1,\n",
      "         8, 11,  9, 15, 15,  7,  1,  8, 11,  9, 14, 14,  7,  1,  8, 11,  9, 13,\n",
      "        14,  7,  1,  8, 11,  9, 12, 13,  7,  1, 11,  9, 11,  7,  1, 11,  9, 12,\n",
      "        12,  7,  1, 11,  9, 13, 13,  7,  1, 11,  9, 14, 14,  7,  1, 11,  9, 15,\n",
      "        15,  7,  1, 11,  9, 16, 14,  7,  1, 11,  9, 17, 14,  7,  1, 11,  9, 18,\n",
      "        12, 29,  7,  1,  2, 22, 24,  2, 21,  1,  2,  8, 38, 31, 34,  3, 12,  9,\n",
      "        12,  5, 40, 12,  6, 11,  9, 17, 15,  4,  2,  7,  1,  2, 25, 32, 30, 33,\n",
      "        30, 39, 35, 34,  2, 21,  1,  2, 38, 31, 34,  3, 13,  5, 40, 12,  4,  2,\n",
      "        42,  0, 41,  2, 26,  2, 21,  1, 28, 28, 11,  9, 11, 29,  7,  1, 28, 11,\n",
      "         9, 12, 29,  7,  1, 28, 11,  9, 13, 12, 29,  7,  1, 28, 11,  9, 14, 12,\n",
      "        29,  7,  1, 28, 11,  9, 15, 12, 29,  7,  1, 28, 11,  9, 16, 13, 29,  7,\n",
      "         1, 28, 11,  9, 17, 13, 29,  7,  1, 28, 11,  9, 18, 13, 29,  7,  1, 28,\n",
      "        11,  9, 19, 14, 29,  7,  1, 28, 11,  9, 20, 14, 29,  7,  1, 28, 12,  9,\n",
      "        11, 14, 29,  7,  1, 28, 12,  9, 12, 15, 29,  7,  1, 28])\n",
      "\n",
      "x: [0.21], [1.55], [0.1], [1.66], [0.0], [1.76], [1.86], [1.97], [2.07], [2.17], [2.28], [2.38], [2.48], [2.59], [2.69], [2.79], [2.9], [3.0]], \"Y\": [-1.0, -1.0, -0.99, -0.98, -0.97, -0.95, -0.94, -0.91, -0.89, -0.86, -0.83, -0.79, -0.77, -0.72, -0.68, -0.63, -0.6, -0.54, -0.44, -0.33, -0.23, -0.12, 0.0, 0.11, 0.22, 0.33, 0.44, 0.53, 0.63, 0.71], \"EQ\": \"-sin(1.1*x1+0.64)\", \"Skeleton\": \"sin(2*x1)\"}\n",
      "{\"X\": [[0.0], [0.1], [0.21], [0.31], [0.41], [0.52], [0.62], [0.72], [0.83], [0.93], [1.03], [1.14], \n",
      "\n",
      "y:[0.21], [1.55], [0.1], [1.66], [0.0], [1.76], [1.86], [1.97], [2.07], [2.17], [2.28], [2.38], [2.48], [2.59], [2.69], [2.79], [2.9], [3.0]], \"Y\": [-1.0, -1.0, -0.99, -0.98, -0.97, -0.95, -0.94, -0.91, -0.89, -0.86, -0.83, -0.79, -0.77, -0.72, -0.68, -0.63, -0.6, -0.54, -0.44, -0.33, -0.23, -0.12, 0.0, 0.11, 0.22, 0.33, 0.44, 0.53, 0.63, 0.71], \"EQ\": \"-sin(1.1*x1+0.64)\", \"Skeleton\": \"sin(2*x1)\"}\n",
      "{\"X\": [[0.0], [0.1], [0.21], [0.31], [0.41], [0.52], [0.62], [0.72], [0.83], [0.93], [1.03], [1.14], [\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(min(train_dataset.__len__(),1000))\n",
    "sample = train_dataset.__getitem__(idx)\n",
    "batch = sample\n",
    "if extractAttributes:\n",
    "    x,y,p,m = batch\n",
    "    print('XS:{}\\nMS:{}\\nyS:{}\\nPointsS:{}'.format(x.shape,m.shape,y.shape,len(p)))\n",
    "    print('X:{}\\nM:{}\\ny:{}\\nPoints:{}'.format(x,m,y,p))\n",
    "else:\n",
    "    x,y = batch\n",
    "    print('X:{}\\ny:{}\\n'.format(x,y))\n",
    "    xc = ''.join([train_dataset.itos[int(i)] for i in x]).strip('\"')\n",
    "    yc = ''.join([train_dataset.itos[int(i)] for i in y]).strip('\"')\n",
    "    print('x:{}\\n\\ny:{}'.format(xc,yc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd24bc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 331.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 901208 characters, 43 unique.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path = 'D:\\Datasets\\Symbolic Dataset\\Datasets\\Mesh_Simple_GPT2_Sorted\\TestDataset\\*.json'\n",
    "files = glob.glob(path)\n",
    "textTest = processDataFiles([files[0]])\n",
    "test_dataset = CharDataset(textTest, block_size, extractAtt=extractAttributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91efc174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b60ca8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/13/2021 23:23:40 - INFO - mingpt.model -   number of parameters: 5.715456e+07\n"
     ]
    }
   ],
   "source": [
    "from mingpt.model import GPT, GPTConfig, PointNetConfig\n",
    "pconf = PointNetConfig(embeddingSize=embeddingSize, \n",
    "                       numberofPoints=numPoints, \n",
    "                       numberofVars=numVars, \n",
    "                       numberofYs=numYs)\n",
    "mconf = GPTConfig(train_dataset.vocab_size, train_dataset.block_size-1 if extractAttributes else train_dataset.block_size,\n",
    "                  n_layer=8, n_head=8, n_embd=embeddingSize, grad_norm_clip=1.0,\n",
    "                  padToken=paddingToken, padId=padId)\n",
    "model = GPT(mconf)#, pconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "735e789d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (tok_emb): Embedding(43, 768)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): CausalSelfAttention(\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "        (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): CausalSelfAttention(\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "        (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): CausalSelfAttention(\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "        (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): CausalSelfAttention(\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "        (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): CausalSelfAttention(\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "        (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): CausalSelfAttention(\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "        (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): CausalSelfAttention(\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "        (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): CausalSelfAttention(\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "        (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (head): Linear(in_features=768, out_features=43, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3f752a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 123: train loss 1.05662. lr 5.000000e-04:   0%|               | 124/15191983 [01:04<1609:47:58,  2.62it/s]"
     ]
    }
   ],
   "source": [
    "from mingpt.trainer import Trainer, TrainerConfig\n",
    "\n",
    "# initialize a trainer instance and kick off training\n",
    "tconf = TrainerConfig(max_epochs=150, batch_size=16, learning_rate=5e-4,\n",
    "                      lr_decay=True, warmup_tokens=512*20, final_tokens=2*len(train_dataset)*block_size,\n",
    "                      num_workers=0)\n",
    "trainer = Trainer(model, train_dataset, test_dataset, tconf)\n",
    "\n",
    "try:\n",
    "    trainer.train()\n",
    "except KeyboardInterrupt:\n",
    "    print('KeyboardInterrupt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4366a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a safe wrapper for numpy math functions\n",
    "from numpy import *\n",
    "import numpy as np\n",
    "\n",
    "def divide(x, y):\n",
    "  x = np.nan_to_num(x)\n",
    "  y = np.nan_to_num(y)\n",
    "  return np.divide(x,y+1e-5)\n",
    "\n",
    "def sqrt(x):\n",
    "  x = np.nan_to_num(x)\n",
    "  return np.sqrt(np.abs(x)) \n",
    "\n",
    "# Mean square error\n",
    "def mse(y, y_hat):\n",
    "    y_hat = np.reshape(y_hat, [1, -1])[0]\n",
    "    y_gold = np.reshape(y, [1, -1])[0]\n",
    "    our_sum = 0\n",
    "    for i in range(len(y_gold)):\n",
    "        our_sum += (y_hat[i] - y_gold[i]) ** 2\n",
    "\n",
    "    return our_sum / len(y_gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d86f2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alright, let's sample some character-level symbolic GPT\n",
    "from mingpt.utils import sample\n",
    "#from gp_model import Genetic_Model\n",
    "#from mlp_model import MLP_Model\n",
    "    \n",
    "loader = torch.utils.data.DataLoader(\n",
    "                                test_dataset, \n",
    "                                shuffle=False, \n",
    "                                pin_memory=True,\n",
    "                                batch_size=1,\n",
    "                                num_workers=0)\n",
    "\n",
    "testRange = [3.1,6.0]\n",
    "numTestPoints = 10\n",
    "#test = np.linspace(3.1,6.0,numTestPoints)\n",
    "\n",
    "# gpm = Genetic_Model(n_jobs=-1)\n",
    "# mlp = MLP_Model()\n",
    "    \n",
    "fName = 'res.txt'\n",
    "resultDict = {}\n",
    "with open(fName, 'w', encoding=\"utf-8\") as o:\n",
    "    textTestList = textTest.split('\\n')\n",
    "    modelName = 'SymbolicGPT'\n",
    "    resultDict[fName] = {modelName:[]}\n",
    "    \n",
    "    for i, (x,y,p,m) in enumerate(loader):\n",
    "        \n",
    "        print('Test Case {}.'.format(i))\n",
    "        o.write('Test Case {}/{}.'.format(i,len(textTestList)))\n",
    "        \n",
    "        t = json.loads(textTestList[i])\n",
    "        \n",
    "        if model.pointNetConfig:\n",
    "            x = x[:,0:1].to(trainer.device)\n",
    "            p = [e.to(trainer.device) for e in p]\n",
    "            yHat = sample(model, x, 50, points=p, \n",
    "                          temperature=1.0, sample=True, \n",
    "                          top_k=10)[0]\n",
    "        else:\n",
    "            sos_eq_loc = 1 # pass everything (x,y) to the model except the equations\n",
    "            x = x[:,0:sos_eq_loc].to(trainer.device)\n",
    "            yHat = sample(model, x, block_size, points=None, \n",
    "                          temperature=1.0, sample=True, \n",
    "                          top_k=10)[0]\n",
    "        \n",
    "        target = ''.join([train_dataset.itos[int(i)] for i in y[0]]).strip('\"')\n",
    "        target = target.strip(paddingToken)\n",
    "        o.write('{}'.format(target))\n",
    "        \n",
    "        predicted = ''.join([train_dataset.itos[int(i)] for i in yHat])\n",
    "        # filter out predicted\n",
    "        predicted = predicted.split('\"')[1]\n",
    "        predicted = predicted.strip(paddingToken)\n",
    "        \n",
    "        print('Target:{}\\nPredicted:{}'.format(target, predicted))\n",
    "        \n",
    "        Ys = [] #t['YT']\n",
    "        Yhats = []\n",
    "        for xs in t['XT']:\n",
    "            try:\n",
    "                eqTmp = target + '' # copy eq\n",
    "                eqTmp = eqTmp.replace(' ','')\n",
    "                eqTmp = eqTmp.replace('\\n','')\n",
    "                for i,x in enumerate(xs):\n",
    "                    # replace xi with the value in the eq\n",
    "                    eqTmp = eqTmp.replace('x{}'.format(i+1), str(x))\n",
    "                    if ',' in eqTmp:\n",
    "                        assert 'There is a , in the equation!'\n",
    "                YEval = eval(eqTmp)\n",
    "                YEval = 0 if np.isnan(YEval) else YEval\n",
    "                YEval = 10000 if np.isinf(YEval) else YEval\n",
    "            except:\n",
    "                YEval = 0\n",
    "            Ys.append(YEval)\n",
    "            try:\n",
    "                eqTmp = predicted + '' # copy eq\n",
    "                eqTmp = eqTmp.replace(' ','')\n",
    "                eqTmp = eqTmp.replace('\\n','')\n",
    "                for i,x in enumerate(xs):\n",
    "                    # replace xi with the value in the eq\n",
    "                    eqTmp = eqTmp.replace('x{}'.format(i+1), str(x))\n",
    "                    if ',' in eqTmp:\n",
    "                        assert 'There is a , in the equation!'\n",
    "                Yhat = eval(eqTmp)\n",
    "                Yhat = 0 if np.isnan(Yhat) else Yhat\n",
    "                Yhat = 10000 if np.isinf(Yhat) else Yhat\n",
    "            except:\n",
    "                Yhat = 0\n",
    "            Yhats.append(Yhat)\n",
    "        mseErr = mse(Ys,Yhats)\n",
    "        \n",
    "        if type(mseErr) is np.complex128:\n",
    "            mseErr = mseErr.real\n",
    "        elif mseErr < 0.00005:\n",
    "            mseErr = 0\n",
    "            \n",
    "        resultDict[fName][modelName].append(mseErr)\n",
    "        \n",
    "        o.write('{}:{}\\n{}'.format(modelName, \n",
    "                               mseErr,\n",
    "                               predicted))\n",
    "        \n",
    "        print('MSE:{}\\n'.format(mseErr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8498966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the error frequency for model comparison\n",
    "from matplotlib import pyplot as plt\n",
    "num_eqns = len(resultDict[fName]['SymbolicGPT'])\n",
    "num_vars = pconf.numberofVars\n",
    "\n",
    "models = list(resultDict[fName].keys())\n",
    "lists_of_error_scores = [resultDict[fName][key] for key in models]\n",
    "linestyles = [\"-\",\"dashdot\",\"dotted\",\"--\"]\n",
    "\n",
    "eps = 0.00001\n",
    "y, x, _ = plt.hist([np.log([x+eps for x in e]) for e in lists_of_error_scores],\n",
    "                   label=models,\n",
    "                   cumulative=True, \n",
    "                   histtype=\"step\", \n",
    "                   bins=2000, \n",
    "                   density=\"true\")\n",
    "y = np.expand_dims(y,0)\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for idx, m in enumerate(models): \n",
    "    plt.plot(x[:-1], \n",
    "           y[idx] * 100, \n",
    "           linestyle=linestyles[idx], \n",
    "           label=m)\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.title(\"{} equations of {} variables\".format(num_eqns, num_vars))\n",
    "plt.xlabel(\"Log of Mean Square Error\")\n",
    "plt.ylabel(\"Normalized Cumulative Frequency\")\n",
    "\n",
    "name = '{}.png'.format('results')\n",
    "plt.savefig(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db9676c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
