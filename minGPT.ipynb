{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "educational-liberty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "weighted-victim",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make deterministic\n",
    "from mingpt.utils import set_seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "experienced-filing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fifth-cancellation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "postal-match",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, block_size, extractAtt=False):\n",
    "        chars = sorted(list(set(data)))\n",
    "        data_size, vocab_size = len(data), len(chars)\n",
    "        print('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
    "        \n",
    "        self.stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "        self.itos = { i:ch for i,ch in enumerate(chars) }\n",
    "        self.block_size = block_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.data = data\n",
    "        self.attributes = extractAtt\n",
    "        \n",
    "        if self.attributes:\n",
    "            self.dataList = self.data.split('\\n') #TODO: remove later?\n",
    "\n",
    "            self.blockIdx = []\n",
    "            summation = 0\n",
    "            for d in self.dataList:\n",
    "                s = summation\n",
    "                e = s + len(d)\n",
    "                self.blockIdx.append((s,e))\n",
    "                summation = e+1\n",
    "    \n",
    "    def __len__(self):\n",
    "        if self.attributes:\n",
    "            return len(self.dataList)\n",
    "        else:\n",
    "            return len(self.data) - self.block_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # grab a chunk of (block_size + 1) characters from the data\n",
    "        #chunk = self.data[idx:idx + self.block_size + 1]\n",
    "        chunk = self.data[self.blockIdx[idx][0]:self.blockIdx[idx][1]]\n",
    "        \n",
    "        # extracts other attributes\n",
    "        points = None\n",
    "        if self.attributes:\n",
    "            dic = json.loads(chunk)\n",
    "            points = []\n",
    "            for xy in zip(dic['X'], dic['Y']):\n",
    "                x = xy[0]\n",
    "                y = xy[1]\n",
    "                x.extend([y])\n",
    "                x = torch.tensor(x)\n",
    "                points.append(x)\n",
    "            chunk = '\"'+dic['EQ']+'\"'\n",
    "        \n",
    "        # encode every character to an integer\n",
    "        dix = [self.stoi[s] for s in chunk]\n",
    "        \"\"\"\n",
    "        arrange data and targets so that the first i elements of x\n",
    "        will be asked to predict the i-th element of y. Notice that\n",
    "        the eventual language model will actually make block_size\n",
    "        individual predictions at the same time based on this data,\n",
    "        so we are being clever and amortizing the cost of the forward\n",
    "        pass of the network. So for example if block_size is 4, then\n",
    "        we could e.g. sample a chunk of text \"hello\", the integers in\n",
    "        x will correspond to \"hell\" and in y will be \"ello\". This will\n",
    "        then actually \"multitask\" 4 separate examples at the same time\n",
    "        in the language model:\n",
    "        - given just \"h\", please predict \"e\" as next\n",
    "        - given \"he\" please predict \"l\" next\n",
    "        - given \"hel\" predict \"l\" next\n",
    "        - given \"hell\" predict \"o\" next\n",
    "        \n",
    "        In addition, because the DataLoader will create batches of examples,\n",
    "        every forward/backward pass during traning will simultaneously train\n",
    "        a LOT of predictions, amortizing a lot of computation. In particular,\n",
    "        for a batched input of integers X (B, T) where B is batch size and\n",
    "        T is block_size and Y (B, T), the network will during training be\n",
    "        simultaneously training to make B*T predictions, all at once! Of course,\n",
    "        at test time we can paralellize across batch B, but unlike during training\n",
    "        we cannot parallelize across the time dimension T - we have to run\n",
    "        a forward pass of the network to recover the next single character of the \n",
    "        sequence along each batch dimension, and repeatedly always feed in a next\n",
    "        character to get the next one.\n",
    "        \n",
    "        So yes there is a big asymmetry between train/test time of autoregressive\n",
    "        models. During training we can go B*T at a time with every forward pass,\n",
    "        but during test time we can only go B at a time, T times, with T forward \n",
    "        passes.\n",
    "        \"\"\"\n",
    "        x = torch.tensor(dix[:-1], dtype=torch.long)\n",
    "        y = torch.tensor(dix[1:], dtype=torch.long)\n",
    "        \n",
    "        return x, y, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "weird-rubber",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "def processDataFiles(files):\n",
    "    text = ''\"\"\n",
    "    for f in tqdm(files):\n",
    "        with open(f, 'r') as h: \n",
    "            lines = h.read() # don't worry we won't run out of file handles\n",
    "            text += lines #json.loads(line)                \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "wireless-terrorist",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.35it/s]\n"
     ]
    }
   ],
   "source": [
    "path = 'D:\\Datasets\\Symbolic Dataset\\Datasets\\Mesh_Simple_GPT2_Sorted\\TrainDatasetFixed\\*.json'\n",
    "files = glob.glob(path)\n",
    "text = processDataFiles([files[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "vital-singing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avgBlockSize = 0\n",
    "# upNum = 100\n",
    "# for i in tqdm(range(0,upNum)):\n",
    "#     avgBlockSize += len(text.split('\\n')[i])\n",
    "# avgBlockSize /= upNum\n",
    "# print('avg block size is {}'.format(avgBlockSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "increasing-atlantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 500 # spatial extent of the model for its context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "sexual-punishment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 243072217 characters, 43 unique.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CharDataset(text, block_size, extractAtt=True) # one line of poem is roughly 50 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closed-navigator",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "rotary-billion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:tensor([ 2,  8, 38, 31, 34,  3, 12,  9, 12,  5, 40, 12,  6, 11,  9, 17, 15,  4])\n",
      "y:tensor([ 8, 38, 31, 34,  3, 12,  9, 12,  5, 40, 12,  6, 11,  9, 17, 15,  4,  2])\n",
      "Points:[tensor([ 0.8300, -1.0000]), tensor([ 0.9300, -1.0000]), tensor([ 0.7200, -0.9900]), tensor([ 1.0300, -0.9800]), tensor([ 0.6200, -0.9700]), tensor([ 1.1400, -0.9500]), tensor([ 0.5200, -0.9400]), tensor([ 1.2400, -0.9100]), tensor([ 0.4100, -0.8900]), tensor([ 1.3400, -0.8600]), tensor([ 0.3100, -0.8300]), tensor([ 1.4500, -0.7900]), tensor([ 0.2100, -0.7700]), tensor([ 1.5500, -0.7200]), tensor([ 0.1000, -0.6800]), tensor([ 1.6600, -0.6300]), tensor([ 0.0000, -0.6000]), tensor([ 1.7600, -0.5400]), tensor([ 1.8600, -0.4400]), tensor([ 1.9700, -0.3300]), tensor([ 2.0700, -0.2300]), tensor([ 2.1700, -0.1200]), tensor([2.2800, 0.0000]), tensor([2.3800, 0.1100]), tensor([2.4800, 0.2200]), tensor([2.5900, 0.3300]), tensor([2.6900, 0.4400]), tensor([2.7900, 0.5300]), tensor([2.9000, 0.6300]), tensor([3.0000, 0.7100])]\n"
     ]
    }
   ],
   "source": [
    "sample = train_dataset.__getitem__(0)\n",
    "print('X:{}\\ny:{}\\nPoints:{}'.format(sample[0], sample[1], sample[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "needed-contemporary",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 334.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 901208 characters, 43 unique.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path = 'D:\\Datasets\\Symbolic Dataset\\Datasets\\Mesh_Simple_GPT2_Sorted\\TestDataset\\*.json'\n",
    "files = glob.glob(path)\n",
    "textTest = processDataFiles([files[0]])\n",
    "test_dataset = CharDataset(textTest, block_size, extractAtt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "exceptional-sunrise",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/11/2021 00:42:35 - INFO - mingpt.model -   number of parameters: 2.552013e+07\n"
     ]
    }
   ],
   "source": [
    "from mingpt.model import GPT, GPTConfig, PointNetConfig\n",
    "embeddingSize=512\n",
    "pconf = PointNetConfig(embeddingSize=embeddingSize, \n",
    "                       numberofPoints=30, \n",
    "                       numberofVars=1, \n",
    "                       numberofYs=1)\n",
    "mconf = GPTConfig(train_dataset.vocab_size, train_dataset.block_size,\n",
    "                  n_layer=8, n_head=8, n_embd=embeddingSize)\n",
    "model = GPT(mconf, pconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "juvenile-offer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 67: train loss 2.19714. lr 7.177734e-05:   0%|                      | 68/500001 [00:03<8:06:31, 17.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from mingpt.trainer import Trainer, TrainerConfig\n",
    "\n",
    "# initialize a trainer instance and kick off training\n",
    "tconf = TrainerConfig(max_epochs=2, batch_size=1, learning_rate=6e-4,\n",
    "                      lr_decay=True, warmup_tokens=512*20, final_tokens=2*len(train_dataset)*block_size,\n",
    "                      num_workers=0)\n",
    "trainer = Trainer(model, train_dataset, None, tconf)\n",
    "\n",
    "try:\n",
    "    trainer.train()\n",
    "except KeyboardInterrupt:\n",
    "    print('KeyboardInterrupt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-pharmacology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0:\n",
      "Target:-sin(1.1*x1+0.64)\n",
      "Predicted:-sin(1.1*x1+0.64)\n",
      "MSE:0.00011463910705842355\n",
      "\n",
      "Sample 1:\n",
      "Target:-1.42*x1+sqrt(x1+0.53)\n",
      "Predicted:-1.42*x1+sqrt(x1+0.53)\n",
      "MSE:0.00015629388692434343\n",
      "\n",
      "Sample 2:\n",
      "Target:sqrt(-sin(0.2*x1))\n",
      "Predicted:sqrt(-sin(0.2*x1))\n",
      "MSE:3.4483289580975676e-05\n",
      "\n",
      "Sample 3:\n",
      "Target:sin(sqrt(x1))\n",
      "Predicted:sin(sqrt(x1))\n",
      "MSE:7.747989464006532e-06\n",
      "\n",
      "Sample 4:\n",
      "Target:0.86*x1**2-0.59*x1+1.36\n",
      "Predicted:0.86*x1**2-0.59*x1+1.368\n",
      "MSE:0.007778901333333281\n",
      "\n",
      "Sample 5:\n",
      "Target:0.28*sqrt(-x1**2)\n",
      "Predicted:0.28*sqrt(-x1**2)\n",
      "MSE:0.000407333333333339\n",
      "\n",
      "Sample 6:\n",
      "Target:sin(0.07*x1**2+0.28*x1)\n",
      "Predicted:sin(0.07*x1**2+0.28*x1)\n",
      "MSE:0.008675065163676714\n",
      "\n",
      "Sample 7:\n",
      "Target:sin(x1)\n",
      "Predicted:sin(x1)\n",
      "MSE:7.36144468968795e-06\n",
      "\n",
      "Sample 8:\n",
      "Target:0.81*sqrt(-x1**2-0.95*x1+0.12)\n",
      "Predicted:0.81*sqrt(-x1**2-0.95*x1+0.12)\n",
      "MSE:0.00045791611437728623\n",
      "\n",
      "Sample 9:\n",
      "Target:sin(x1+0.37)\n",
      "Predicted:sin(x1+0.37)\n",
      "MSE:1.0393529956063066e-05\n",
      "\n",
      "Sample 10:\n",
      "Target:-0.68*x1**2+1.77*x1\n",
      "Predicted:-0.68*x1**2+1.77*x1\n",
      "MSE:38224.126941625334\n",
      "\n",
      "Sample 11:\n",
      "Target:sqrt(x1)+0.51*x1**2-0.17*x1\n",
      "Predicted:sqrt(x1)+0.51*x1**2-0.17*x1\n",
      "MSE:0.00041937720667757476\n",
      "\n",
      "Sample 12:\n",
      "Target:1.25*x1+0.85*sqrt(-0.68*x1-1)\n",
      "Predicted:1.25*x1+0.85*sqrt(-0.68*x1-1)\n",
      "MSE:1.263758850430321e-05\n",
      "\n",
      "Sample 13:\n",
      "Target:sin(x1**2-0.11*x1)\n",
      "Predicted:sin(x1**2-0.11*x1)\n",
      "MSE:0.00010647095516902854\n",
      "\n",
      "Sample 14:\n",
      "Target:0.7*sqrt(x1-0.51)\n",
      "Predicted:0.7*sqrt(x1-0.51)\n",
      "MSE:6.595742457912719e-05\n",
      "\n",
      "Sample 15:\n",
      "Target:sqrt(x1**2+0.31*x1)\n",
      "Predicted:sqrt(x1**2+0.31*x1)\n",
      "MSE:5.799335656226982e-06\n",
      "\n",
      "Sample 16:\n",
      "Target:4*x1-0.25\n",
      "Predicted:4*x1-0.25*x1\n",
      "MSE:0.8344791666666668\n",
      "\n",
      "Sample 17:\n",
      "Target:1.64*x1**2-0.31*x1-0.13\n",
      "Predicted:1.64*x1**2-0.31*x1-0.13\n",
      "MSE:4.766800000002734e-05\n",
      "\n",
      "Sample 18:\n",
      "Target:sqrt(-sin(0.37*x1-0.65))\n",
      "Predicted:sqrt(-sin(0.37*x1-0.65))+0.69496*sqrt(*x1*x1\n",
      "MSE:3152.8312199999987\n",
      "\n",
      "Sample 19:\n",
      "Target:1.48*x1**2+0.55\n",
      "Predicted:1.48*x1**2+0.55*x1+0.92\n",
      "MSE:11266.896171065333\n",
      "\n",
      "Sample 20:\n",
      "Target:0.56*x1**2+0.69*x1+0.82\n",
      "Predicted:0.56*x1**2+0.69*x1+0.82\n",
      "MSE:0.004320254666666895\n",
      "\n",
      "Sample 21:\n",
      "Target:0.93*sqrt(0.62*x1+1)\n",
      "Predicted:0.93*sqrt(0.62*x1+1)\n",
      "MSE:3.8405954015868104e-05\n",
      "\n",
      "Sample 22:\n",
      "Target:2*x1+sin(x1)-0.89\n",
      "Predicted:2*x1+sin(x1)-0.895*x1+0.1\n",
      "MSE:10.127601529526066\n",
      "\n",
      "Sample 23:\n",
      "Target:0.93*x1*sin(0.85*x1+0.49)\n",
      "Predicted:0.93*x1*sin(0.85*x1+0.49)\n",
      "MSE:0.0018961861286526348\n",
      "\n",
      "Sample 24:\n",
      "Target:-sin(sin(0.4*x1+0.16))\n",
      "Predicted:-sin(sin(0.4*x1+0.16))\n",
      "MSE:1.9478000245147868e-05\n",
      "\n",
      "Sample 25:\n",
      "Target:0.1*x1**3\n",
      "Predicted:0.1*x1**3)\n",
      "MSE:135.42903001383166\n",
      "\n",
      "Sample 26:\n",
      "Target:0.8*sqrt(x1)\n",
      "Predicted:0.8*sqrt(x1)\n",
      "MSE:0.00010282316087073881\n",
      "\n",
      "Sample 27:\n",
      "Target:0.83*sqrt(x1)+x1\n",
      "Predicted:0.83*sqrt(x1)+x1\n",
      "MSE:0.00012125526293398072\n",
      "\n",
      "Sample 28:\n",
      "Target:1.83*x1-1.34\n",
      "Predicted:1.83*x1-1.34*x1\n",
      "MSE:23.9368905\n",
      "\n",
      "Sample 29:\n",
      "Target:1.79*x1**2\n",
      "Predicted:1.79*x1**2\n",
      "MSE:9148.555081519668\n",
      "\n",
      "Sample 30:\n",
      "Target:-0.53*x1-0.76*sin(x1-0.43)\n",
      "Predicted:-0.53*x1-0.76*sin(x1-0.43)\n",
      "MSE:18.03687110229448\n",
      "\n",
      "Sample 31:\n",
      "Target:sqrt(sin(x1-0.76))\n",
      "Predicted:sqrt(sin(x1-0.76))7)\n",
      "MSE:11.871779199919605\n",
      "\n",
      "Sample 32:\n",
      "Target:0.34*x1**2-0.05*x1-0.08\n",
      "Predicted:0.34*x1**2-0.05*x1-0.084-1*2\n",
      "MSE:3.953294847999996\n",
      "\n",
      "Sample 33:\n",
      "Target:sqrt(2)*sqrt(x1)\n",
      "Predicted:sqrt(2)*sqrt(x1)\n",
      "MSE:9.599322996606103e-06\n",
      "\n",
      "Sample 34:\n",
      "Target:x1**2+0.09*x1+0.69\n",
      "Predicted:x1**2+0.09*x1+0.6944*x1\n",
      "MSE:6.396429437600007\n",
      "\n",
      "Sample 35:\n",
      "Target:0.97*sqrt(-x1)\n",
      "Predicted:0.97*sqrt(-x1)\n",
      "MSE:2.448219581839937e-05\n",
      "\n",
      "Sample 36:\n",
      "Target:-sin(0.14*x1**2-0.53*x1)\n",
      "Predicted:-sin(0.14*x1**2-0.53*x1)\n",
      "MSE:0.003148099652276536\n",
      "\n",
      "Sample 37:\n",
      "Target:0.85*sqrt(0.1*x1-1)\n",
      "Predicted:0.85*sqrt(0.1*x1-1)\n",
      "MSE:0.0009246660170773401\n",
      "\n",
      "Sample 38:\n",
      "Target:sin(0.56*sqrt(x1))\n",
      "Predicted:sin(0.56*sqrt(x1))\n",
      "MSE:9.740779869475872e-06\n",
      "\n",
      "Sample 39:\n",
      "Target:1.99*x1+0.57\n",
      "Predicted:1.99*x1+0.576)\n",
      "MSE:77.59761914035444\n",
      "\n",
      "Sample 40:\n",
      "Target:sqrt(sin(0.06*x1+0.44))\n",
      "Predicted:sqrt(sin(0.06*x1+0.44))-08\n",
      "MSE:0.027771745059872018\n",
      "\n",
      "Sample 41:\n",
      "Target:0.45*x1**2\n",
      "Predicted:0.45*x1**2-sqrt(sin(1)+0.0.6*x\n",
      "MSE:89.51101514626501\n",
      "\n",
      "Sample 42:\n",
      "Target:x1**2-0.65*x1-0.02\n",
      "Predicted:x1**2-0.65*x1-0.02\n",
      "MSE:38155.51419916667\n",
      "\n",
      "Sample 43:\n",
      "Target:0.97*sqrt(x1**2-0.28*x1-0.35)\n",
      "Predicted:0.97*sqrt(x1**2-0.28*x1-0.35)\n",
      "MSE:0.0001372001885950608\n",
      "\n",
      "Sample 44:\n",
      "Target:(x1-0.15)**(1/4)\n",
      "Predicted:(x1-0.15)**(1/4)\n",
      "MSE:7.269789081182164e-06\n",
      "\n",
      "Sample 45:\n",
      "Target:-sin(0.11*x1)\n",
      "Predicted:-sin(0.11*x1)\n",
      "MSE:0.0002992943256549858\n",
      "\n",
      "Sample 46:\n",
      "Target:2*x1-1.48\n",
      "Predicted:2*x1-1.48\n",
      "MSE:3.944304526105059e-31\n",
      "\n",
      "Sample 47:\n",
      "Target:0.73*sqrt(x1)\n",
      "Predicted:0.73*sqrt(x1)\n",
      "MSE:7.726101376121307e-05\n",
      "\n",
      "Sample 48:\n",
      "Target:0.14*x1\n",
      "Predicted:0.14*x1*x1+0.85\n",
      "MSE:28.99782620133334\n",
      "\n",
      "Sample 49:\n",
      "Target:0.88*(-x1)**(1/4)\n",
      "Predicted:0.88*(-x1)**(1/4)\n",
      "MSE:(-0.6868422012481864-0.6669309310443149j)\n",
      "\n",
      "Sample 50:\n",
      "Target:0.82*x1**2-0.84*x1+0.22\n",
      "Predicted:0.82*x1**2-0.84*x1+0.225\n",
      "MSE:6.709199999999774e-05\n",
      "\n",
      "Sample 51:\n",
      "Target:sqrt(sin(0.03*x1))\n",
      "Predicted:sqrt(sin(0.03*x1))*2+0.94)\n",
      "MSE:591.5124250000002\n",
      "\n",
      "Sample 52:\n",
      "Target:(x1+0.54)**(1/4)\n",
      "Predicted:(x1+0.54)**(1/4)\n",
      "MSE:7.409684000378301e-06\n",
      "\n",
      "Sample 53:\n",
      "Target:1.8*x1-0.56\n",
      "Predicted:1.8*x1-0.56\n",
      "MSE:0.00048333333333332347\n",
      "\n",
      "Sample 54:\n",
      "Target:sin(0.62*sqrt(0.63*x1+1))\n",
      "Predicted:sin(0.62*sqrt(0.63*x1+1))\n",
      "MSE:1.2534572422431235e-05\n",
      "\n",
      "Sample 55:\n",
      "Target:sqrt(x1-0.89)\n",
      "Predicted:sqrt(x1-0.89)\n",
      "MSE:9.666683574491232e-06\n",
      "\n",
      "Sample 56:\n",
      "Target:sin(0.08*x1**2-0.04*x1)\n",
      "Predicted:sin(0.08*x1**2-0.04*x1)*2)\n",
      "MSE:2.04779529604768\n",
      "\n",
      "Sample 57:\n",
      "Target:-0.70\n",
      "Predicted:-0.70.43*x1*x1\n",
      "MSE:4.314775126525856\n",
      "\n",
      "Sample 58:\n",
      "Target:sin(sin(x1))\n",
      "Predicted:sin(sin(x1))*x1)\n",
      "MSE:8.16297187385847\n",
      "\n",
      "Sample 59:\n",
      "Target:x1**3+0.71*x1\n",
      "Predicted:x1**3+0.71*x1\n",
      "MSE:171.51340426666658\n",
      "\n",
      "Sample 60:\n",
      "Target:sin(sqrt(x1+0.83))\n",
      "Predicted:sin(sqrt(x1+0.83))\n",
      "MSE:9.899350495589201e-06\n",
      "\n",
      "Sample 61:\n",
      "Target:0.92*x1+0.09*sin(0.37*x1-0.48)\n",
      "Predicted:0.92*x1+0.09*sin(0.37*x1-0.48)**2*x1+0.9*x1\n",
      "MSE:23.17993541759368\n",
      "\n",
      "Sample 62:\n",
      "Target:sqrt(sin(x1-0.86))\n",
      "Predicted:sqrt(sin(x1-0.86))\n",
      "MSE:1.3340531606266179e-05\n",
      "\n",
      "Sample 63:\n",
      "Target:sqrt(-sin(0.11*x1))\n",
      "Predicted:sqrt(-sin(0.11*x1))\n",
      "MSE:5.911095855003078e-05\n",
      "\n",
      "Sample 64:\n",
      "Target:2*x1-0.16\n",
      "Predicted:2*x1-0.16**(15**x1+sqrt(x1)\n",
      "MSE:69.53302551887683\n",
      "\n",
      "Sample 65:\n",
      "Target:(x1-0.76)**(1/4)\n",
      "Predicted:(x1-0.76)**(1/4)\n",
      "MSE:6.46521495315213e-06\n",
      "\n",
      "Sample 66:\n",
      "Target:2.64*x1+0.2\n",
      "Predicted:2.64*x1+0.2*x1*sqrt(x1)\n",
      "MSE:3.3918525808753146\n",
      "\n",
      "Sample 67:\n",
      "Target:-0.93*x1+sqrt(x1-0.91)\n",
      "Predicted:-0.93*x1+sqrt(x1-0.91)***x1)\n",
      "MSE:445.46891217407926\n",
      "\n",
      "Sample 68:\n",
      "Target:0.91*sqrt(x1)+x1**2-0.86*x1\n",
      "Predicted:0.91*sqrt(x1)+x1**2-0.86*x1-0.4\n",
      "MSE:0.15020656798566215\n",
      "\n",
      "Sample 69:\n",
      "Target:sin(sin(x1))\n",
      "Predicted:sin(sin(x1))\n",
      "MSE:8.24399355069689e-06\n",
      "\n",
      "Sample 70:\n",
      "Target:0.78*x1**2\n",
      "Predicted:0.78*x1**2+0.5*2*x1\n",
      "MSE:21.76749303866667\n",
      "\n",
      "Sample 71:\n",
      "Target:sin(0.68*sqrt(-x1))\n",
      "Predicted:sin(0.68*sqrt(-x1))\n",
      "MSE:6.880450293542013e-06\n",
      "\n",
      "Sample 72:\n",
      "Target:-sin(0.8*x1)*sin(x1-0.87)\n",
      "Predicted:-sin(0.8*x1)*sin(x1-0.87)\n",
      "MSE:1.602972013189666e-05\n",
      "\n",
      "Sample 73:\n",
      "Target:x1**(1/4)\n",
      "Predicted:x1**(1/4)\n",
      "MSE:9.067667546166463e-06\n",
      "\n",
      "Sample 74:\n",
      "Target:0.41*sqrt(x1**2+0.94*x1)\n",
      "Predicted:0.41*sqrt(x1**2+0.94*x1)\n",
      "MSE:8.92655020178408e-06\n",
      "\n",
      "Sample 75:\n",
      "Target:0.5*x1**2-0.43*x1-0.57\n",
      "Predicted:0.5*x1**2-0.43*x1-0.573*x1**x1\n",
      "MSE:56623818.23032143\n",
      "\n",
      "Sample 76:\n",
      "Target:0.62*sqrt(0.87*x1+1)\n",
      "Predicted:0.62*sqrt(0.87*x1+1)\n",
      "MSE:0.0003498140878656724\n",
      "\n",
      "Sample 77:\n",
      "Target:0.97*x1**2+0.54*x1+1.11\n",
      "Predicted:0.97*x1**2+0.54*x1+1.11+0.4\n",
      "MSE:0.13586726366666546\n",
      "\n",
      "Sample 78:\n",
      "Target:-0.33*x1**2-0.29*x1+0.89*sqrt(-x1)\n",
      "Predicted:-0.33*x1**2-0.29*x1+0.89*sqrt(-x1)\n",
      "MSE:0.014565437345197276\n",
      "\n",
      "Sample 79:\n",
      "Target:0.18*x1**2-0.27*x1\n",
      "Predicted:0.18*x1**2-0.27*x1\n",
      "MSE:0.013389258666666687\n",
      "\n",
      "Sample 80:\n",
      "Target:0.88*x1-0.64\n",
      "Predicted:0.88*x1-0.64*2\n",
      "MSE:40.28365133333333\n",
      "\n",
      "Sample 81:\n",
      "Target:-0.04*x1*sin(0.74*x1+0.23)+0.42\n",
      "Predicted:-0.04*x1*sin(0.74*x1+0.23)+0.42*(x1*x1)\n",
      "MSE:96.18847803138968\n",
      "\n",
      "Sample 82:\n",
      "Target:0.95*x1**2*sqrt(-x1)-0.12*x1\n",
      "Predicted:0.95*x1**2*sqrt(-x1)-0.12*x1)\n",
      "MSE:1214.518549041026\n",
      "\n",
      "Sample 83:\n",
      "Target:-sin(0.87*x1-0.58)\n",
      "Predicted:-sin(0.87*x1-0.58)\n",
      "MSE:0.00019796688285845626\n",
      "\n",
      "Sample 84:\n",
      "Target:-sin(0.25*x1-0.4)\n",
      "Predicted:-sin(0.25*x1-0.4)\n",
      "MSE:0.00012153002046109276\n",
      "\n",
      "Sample 85:\n",
      "Target:sin(2*x1)\n",
      "Predicted:sin(2*x1)\n",
      "MSE:8.885294420179668e-06\n",
      "\n",
      "Sample 86:\n"
     ]
    }
   ],
   "source": [
    "# alright, let's sample some character-level symbolic GPT\n",
    "from mingpt.utils import sample\n",
    "from gp_model import Genetic_Model\n",
    "from mlp_model import MLP_Model\n",
    "    \n",
    "loader = torch.utils.data.DataLoader(\n",
    "                                test_dataset, \n",
    "                                shuffle=False, \n",
    "                                pin_memory=True,\n",
    "                                batch_size=1,\n",
    "                                num_workers=0)\n",
    "\n",
    "gpm = Genetic_Model(n_jobs=-1)\n",
    "mlp = MLP_Model()\n",
    "    \n",
    "fName = 'res.txt'\n",
    "resultDict = {}\n",
    "with open(fName, 'w', encoding=\"utf-8\") as o:\n",
    "    textTestList = textTest.split('\\n')\n",
    "    resultDict[fName] = {'SymbolicGPT':[],\n",
    "                         'MLP':[],\n",
    "                         'GP':[]}\n",
    "    for i, (x,y,p) in enumerate(loader):\n",
    "        print('Sample {}:'.format(i))\n",
    "        t = json.loads(textTestList[i])\n",
    "        x = x.to(trainer.device)\n",
    "        p = [x.to(trainer.device) for x in p]\n",
    "        yHat = sample(model, x, 20, points=p, \n",
    "                      temperature=1.0, sample=True, \n",
    "                      top_k=10)[0]\n",
    "        predicted = ''.join([train_dataset.itos[int(i)] for i in yHat])\n",
    "        # filter out predicted\n",
    "        predicted = predicted.split('\"')[1]\n",
    "        target = ''.join([train_dataset.itos[int(i)] for i in y[0]]).strip('\"')\n",
    "        print('Target:{}\\nPredicted:{}'.format(target, predicted))\n",
    "        \n",
    "        Ys = t['YT']\n",
    "        Yhats = []\n",
    "        for xs in t['XT']:\n",
    "            try:\n",
    "                eqTmp = predicted + '' # copy eq\n",
    "                eqTmp = eqTmp.replace(' ','')\n",
    "                eqTmp = eqTmp.replace('\\n','')\n",
    "                for i,x in enumerate(xs):\n",
    "                    # replace xi with the value in the eq\n",
    "                    eqTmp = eqTmp.replace('x{}'.format(i+1), str(x))\n",
    "                    if ',' in eqTmp:\n",
    "                        assert 'There is a , in the equation!'\n",
    "                Yhat = eval(eqTmp)\n",
    "                Yhat = 0 if np.isnan(Yhat) else Yhat\n",
    "                Yhat = 10000 if np.isinf(Yhat) else Yhat\n",
    "            except:\n",
    "                Yhat = 10000 if np.isinf(Yhat) else Yhat\n",
    "            Yhats.append(Yhat)\n",
    "        mseErr = mse(Ys,Yhats)\n",
    "        \n",
    "        \n",
    "        print('MSE:{}\\n'.format(mseErr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "atomic-karaoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a safe wrapper for numpy math functions\n",
    "from numpy import *\n",
    "import numpy as np\n",
    "\n",
    "def divide(x, y):\n",
    "  x = np.nan_to_num(x)\n",
    "  y = np.nan_to_num(y)\n",
    "  return np.divide(x,y+1e-5)\n",
    "\n",
    "def sqrt(x):\n",
    "  x = np.nan_to_num(x)\n",
    "  return np.sqrt(np.abs(x)) \n",
    "\n",
    "# Mean square error\n",
    "def mse(y, y_hat):\n",
    "    y_hat = np.reshape(y_hat, [1, -1])[0]\n",
    "    y_gold = np.reshape(y, [1, -1])[0]\n",
    "    our_sum = 0\n",
    "    for i in range(len(y_gold)):\n",
    "        our_sum += (y_hat[i] - y_gold[i]) ** 2\n",
    "\n",
    "    return our_sum / len(y_gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "front-question",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
