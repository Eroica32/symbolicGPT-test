{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "773d97b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f22a467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make deterministic\n",
    "from mingpt.utils import set_seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73c28909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "496e2860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca721c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "embeddingSize=504\n",
    "numPoints=30\n",
    "numVars=1\n",
    "numYs=1\n",
    "paddingToken='P'\n",
    "padId=0\n",
    "block_size = 60 # spatial extent of the model for its context\n",
    "batchSize = 256 if block_size < 100 else 16\n",
    "pointsAsList = False\n",
    "padding = True\n",
    "method = 'outputConcat' # GPT/FirstToken/Summation/Concat/outputConcat/outputSummation\n",
    "extractAttributes = True # use the pointNET if it is true\n",
    "extractAttributes = False if method=='GPT' else extractAttributes\n",
    "dataInfo = 'Mesh_XYSorted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29ee291e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, files=None, block_size=50, extractAtt=False, \n",
    "                 chars=None, stoi=None, itos=None, testTime=False,\n",
    "                 pointsAsList=False, padding=False):\n",
    "        self.chars = sorted(list(set(data))+['T','<','>']) if chars==None else chars\n",
    "        data_size = len(data)\n",
    "        print('data has %d characters, %d unique.' % (data_size, len(self.chars)))\n",
    "        \n",
    "        self.stoi = { ch:i for i,ch in enumerate([paddingToken]+self.chars if extractAtt else self.chars) } if stoi==None else stoi\n",
    "        self.itos = { i:ch for ch,i in self.stoi.items() } if itos==None else itos\n",
    "        self.block_size = block_size\n",
    "        self.vocab_size = len(self.stoi)\n",
    "        \n",
    "        self.files = files\n",
    "#         if self.files == None:\n",
    "        self.data = data # this is memory expensive\n",
    "        \n",
    "        self.attributes = extractAtt\n",
    "        self.threshold = [-1000,1000]\n",
    "        self.testTime = testTime\n",
    "        self.pointsAsList = pointsAsList\n",
    "        self.padding = padding\n",
    "        \n",
    "        if self.attributes or self.testTime:\n",
    "            self.dataList = self.data.split('\\n') #TODO: remove later?\n",
    "\n",
    "            self.blockIdx = []\n",
    "            summation = 0\n",
    "            for d in self.dataList:\n",
    "                s = summation\n",
    "                e = s + len(d)\n",
    "                self.blockIdx.append((s,e))\n",
    "                summation = e+1\n",
    "    \n",
    "    def __len__(self):\n",
    "        if self.attributes or self.testTime:\n",
    "            return len(self.dataList) - 1\n",
    "        else:\n",
    "            return len(self.data) - self.block_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # grab a chunk of (block_size + 1) characters from the data\n",
    "        #chunk = self.data[idx:idx + self.block_size + 1]\n",
    "        if not self.attributes:\n",
    "            if self.testTime:\n",
    "                chunk = self.data[self.blockIdx[idx][0]:self.blockIdx[idx][1]]\n",
    "            else:\n",
    "                chunk = self.data[idx:idx + self.block_size + 1]\n",
    "                \n",
    "            dix = [self.stoi[s] for i,s in enumerate(chunk)]\n",
    "            inputs = torch.tensor(dix[:-1], dtype=torch.long).contiguous()\n",
    "            outputs = torch.tensor(dix[1:], dtype=torch.long).contiguous()\n",
    "            return inputs, outputs\n",
    "        else:\n",
    "            chunk = self.data[self.blockIdx[idx][0]:self.blockIdx[idx][1]]\n",
    "        \n",
    "            # extracts other attributes\n",
    "            points = None\n",
    "            if self.attributes:\n",
    "                dic = json.loads(chunk)\n",
    "\n",
    "                if self.pointsAsList:\n",
    "                    points = []\n",
    "                else:\n",
    "                    points = torch.zeros(numVars+numYs, numPoints)\n",
    "                    \n",
    "                for idx, xy in enumerate(zip(dic['X'], dic['Y'])):\n",
    "                    x = xy[0] + [self.stoi[paddingToken]]*(max(numVars-len(xy[0]),0)) # padding\n",
    "                    y = [xy[1]] if type(xy[1])== float else xy[1]\n",
    "                    y = y + [self.stoi[paddingToken]]*(max(numYs-len(y),0)) # padding\n",
    "                    \n",
    "                    #print('x:{},y:{}\\n'.format(x,y))\n",
    "\n",
    "                    p = x+y # because it is only one point \n",
    "                    p = torch.tensor(p)\n",
    "\n",
    "                    #replace nan and inf\n",
    "                    p = torch.nan_to_num(p, nan=0.0, \n",
    "                                         posinf=self.threshold[1], \n",
    "                                         neginf=self.threshold[0])\n",
    "                    \n",
    "                    if self.pointsAsList:\n",
    "                        points.append(p)\n",
    "                    else:\n",
    "                        points[:,idx] = p\n",
    "                        \n",
    "                chunk = '<'+dic['EQ']+'>'\n",
    "\n",
    "            # encode every character to an integer\n",
    "            dix = [self.stoi[s] for i,s in enumerate(chunk) if i<self.block_size]\n",
    "            dixInput = dix[:-1]\n",
    "            dixOutput = dix[1:]\n",
    "            \n",
    "           \n",
    "            if self.padding:\n",
    "                paddingSize = max(self.block_size-len(dixInput),0)\n",
    "                paddingList = [self.stoi[paddingToken]]*paddingSize\n",
    "                dixInput += paddingList # padding\n",
    "                dixOutput += paddingList # padding\n",
    "            else:\n",
    "                paddingSize = max(self.block_size-len(dixInput),0)\n",
    "                # instead of padding use the same tokens repetitive\n",
    "                dixInput += dixInput * (int(paddingSize/len(dixInput))+1) \n",
    "                dixOutput += dixOutput * (int(paddingSize/len(dixOutput))+1) \n",
    "                \n",
    "            dixInput = dixInput[:self.block_size-1] # make sure the size is correct\n",
    "            dixOutput = dixOutput[:self.block_size-1] # make sure the size is correct\n",
    "                \n",
    "            outputs = torch.tensor(dixOutput, dtype=torch.long).contiguous()\n",
    "            inputs = torch.tensor(dixInput, dtype=torch.long).contiguous()\n",
    "\n",
    "            mask = [1 for s in dix]\n",
    "            mask += [0]*paddingSize\n",
    "\n",
    "            mask = torch.tensor(mask[:-1], dtype=torch.long).contiguous()\n",
    "            mask = mask.unsqueeze(0)\n",
    "            mask = mask.T @ mask\n",
    "            #mask = mask.T # transpose the output mask\n",
    "\n",
    "            assert len(mask) == self.block_size, 'Wrong mask shape: {}'.format(mask.shape)\n",
    "            assert len(inputs) == self.block_size-1, 'Wrong inputs shape: {}'.format(inputs.shape)\n",
    "            assert len(outputs) == self.block_size-1, 'Wrong y shape: {}'.format(outputs.shape)\n",
    "\n",
    "            return inputs, outputs, points, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d70bbb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "def processDataFiles(files):\n",
    "    text = ''\"\"\n",
    "    for f in tqdm(files):\n",
    "        with open(f, 'r') as h: \n",
    "            lines = h.read() # don't worry we won't run out of file handles\n",
    "            text += lines #json.loads(line)                \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9d029d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:10<00:00,  1.00s/it]\n"
     ]
    }
   ],
   "source": [
    "path = 'D:\\Datasets\\Symbolic Dataset\\Datasets\\Mesh_Simple_GPT2_Sorted\\TrainDatasetFixed\\*.json'\n",
    "files = glob.glob(path)\n",
    "text = processDataFiles(files[:3 if block_size>60 else 10]) #[files[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3f35843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avgBlockSize = 0\n",
    "# upNum = 100\n",
    "# for i in tqdm(range(0,upNum)):\n",
    "#     avgBlockSize += len(text.split('\\n')[i])\n",
    "# avgBlockSize /= upNum\n",
    "# print('avg block size is {}'.format(avgBlockSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db4ee98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 2430722170 characters, 46 unique.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CharDataset(text, files, block_size, extractAtt=extractAttributes, pointsAsList=pointsAsList, padding=padding) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab046434",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:tensor([23,  9, 42, 35, 38,  4, 42, 35, 38,  4, 12, 10, 14,  6, 44, 13,  5,  5,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0])\n",
      "M:tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]])\n",
      "y:tensor([ 9, 42, 35, 38,  4, 42, 35, 38,  4, 12, 10, 14,  6, 44, 13,  5,  5, 24,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0])\n",
      "Points:tensor([[ 3.0000,  2.9000,  2.7900,  2.6900,  2.5900,  2.4800,  2.3800,  2.2800,\n",
      "          2.1700,  2.0700,  1.9700,  1.8600,  1.7600,  1.6600,  1.5500,  1.4500,\n",
      "          1.3400,  1.2400,  1.1400,  1.0300,  0.9300,  0.8300,  0.7200,  0.6200,\n",
      "          0.5200,  0.4100,  0.3100,  0.2100,  0.1000,  0.0000],\n",
      "        [-0.5300, -0.5100, -0.5000, -0.4800, -0.4700, -0.4500, -0.4300, -0.4200,\n",
      "         -0.4000, -0.3800, -0.3700, -0.3500, -0.3300, -0.3100, -0.2900, -0.2800,\n",
      "         -0.2600, -0.2400, -0.2200, -0.2000, -0.1800, -0.1600, -0.1400, -0.1200,\n",
      "         -0.1000, -0.0800, -0.0600, -0.0400, -0.0200,  0.0000]])\n",
      "torch.Size([2, 30])\n",
      "x:<-sin(sin(0.2*x1))PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "\n",
      "y:-sin(sin(0.2*x1))>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(min(train_dataset.__len__(),1000))\n",
    "sample = train_dataset.__getitem__(idx)\n",
    "batch = sample\n",
    "if extractAttributes:\n",
    "    x,y,p,m = batch\n",
    "    #print('XS:{}\\nMS:{}\\nyS:{}\\nPointsS:{}'.format(x.shape,m.shape,y.shape,len(p)))\n",
    "    print('X:{}\\nM:{}\\ny:{}\\nPoints:{}'.format(x,m,y,p))\n",
    "    print(p.shape)\n",
    "else:\n",
    "    x,y = batch\n",
    "    print('X:{}\\ny:{}\\n'.format(x,y))\n",
    "    \n",
    "xc = ''.join([train_dataset.itos[int(i)] for i in x])#.strip('\"')\n",
    "yc = ''.join([train_dataset.itos[int(i)] for i in y])#.strip('\"')\n",
    "print('x:{}\\n\\ny:{}'.format(xc,yc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39960a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 334.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 901208 characters, 46 unique.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path = 'D:\\Datasets\\Symbolic Dataset\\Datasets\\Mesh_Simple_GPT2_Sorted\\TestDataset\\*.json'\n",
    "files = glob.glob(path)\n",
    "textTest = processDataFiles([files[0]])\n",
    "test_dataset = CharDataset(textTest, block_size, extractAtt=extractAttributes,\n",
    "                           testTime=True,\n",
    "                           chars=train_dataset.chars, stoi=train_dataset.stoi, \n",
    "                           itos=train_dataset.itos,\n",
    "                           pointsAsList=pointsAsList, padding=padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78173f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 47\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.vocab_size, test_dataset.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "080ac4aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da3f4f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/18/2021 23:28:25 - INFO - mingpt.model -   number of parameters: 2.961353e+07\n"
     ]
    }
   ],
   "source": [
    "from mingpt.model import GPT, GPTConfig, PointNetConfig\n",
    "pconf = PointNetConfig(embeddingSize=embeddingSize, \n",
    "                       numberofPoints=numPoints, \n",
    "                       numberofVars=numVars, \n",
    "                       numberofYs=numYs,\n",
    "                       method=method)\n",
    "mconf = GPTConfig(train_dataset.vocab_size, train_dataset.block_size-1 if extractAttributes else train_dataset.block_size,\n",
    "                  n_layer=8, n_head=12, n_embd=embeddingSize, grad_norm_clip=1.0,\n",
    "                  padToken=paddingToken, padId=padId)\n",
    "model = GPT(mconf, pconf) if extractAttributes else GPT(mconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18fd0d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (pointNet): TNet(\n",
       "    (conv1): Conv1d(2, 504, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Conv1d(504, 1008, kernel_size=(1,), stride=(1,))\n",
       "    (conv3): Conv1d(1008, 2016, kernel_size=(1,), stride=(1,))\n",
       "    (fc1): Linear(in_features=2016, out_features=1008, bias=True)\n",
       "    (fc2): Linear(in_features=1008, out_features=504, bias=True)\n",
       "    (input_batch_norm): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn1): BatchNorm1d(504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(1008, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn3): BatchNorm1d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn4): BatchNorm1d(1008, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn5): BatchNorm1d(504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (tok_emb): Embedding(47, 504)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (ln1): LayerNorm((504,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((504,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): CausalSelfAttention(\n",
       "        (key): Linear(in_features=504, out_features=504, bias=True)\n",
       "        (query): Linear(in_features=504, out_features=504, bias=True)\n",
       "        (value): Linear(in_features=504, out_features=504, bias=True)\n",
       "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "        (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=504, out_features=504, bias=True)\n",
       "      )\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=504, out_features=2016, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Linear(in_features=2016, out_features=504, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (ln1): LayerNorm((504,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((504,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): CausalSelfAttention(\n",
       "        (key): Linear(in_features=504, out_features=504, bias=True)\n",
       "        (query): Linear(in_features=504, out_features=504, bias=True)\n",
       "        (value): Linear(in_features=504, out_features=504, bias=True)\n",
       "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "        (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=504, out_features=504, bias=True)\n",
       "      )\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=504, out_features=2016, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Linear(in_features=2016, out_features=504, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (ln1): LayerNorm((504,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((504,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): CausalSelfAttention(\n",
       "        (key): Linear(in_features=504, out_features=504, bias=True)\n",
       "        (query): Linear(in_features=504, out_features=504, bias=True)\n",
       "        (value): Linear(in_features=504, out_features=504, bias=True)\n",
       "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "        (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=504, out_features=504, bias=True)\n",
       "      )\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=504, out_features=2016, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Linear(in_features=2016, out_features=504, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (ln1): LayerNorm((504,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((504,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): CausalSelfAttention(\n",
       "        (key): Linear(in_features=504, out_features=504, bias=True)\n",
       "        (query): Linear(in_features=504, out_features=504, bias=True)\n",
       "        (value): Linear(in_features=504, out_features=504, bias=True)\n",
       "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "        (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=504, out_features=504, bias=True)\n",
       "      )\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=504, out_features=2016, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Linear(in_features=2016, out_features=504, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Block(\n",
       "      (ln1): LayerNorm((504,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((504,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): CausalSelfAttention(\n",
       "        (key): Linear(in_features=504, out_features=504, bias=True)\n",
       "        (query): Linear(in_features=504, out_features=504, bias=True)\n",
       "        (value): Linear(in_features=504, out_features=504, bias=True)\n",
       "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "        (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=504, out_features=504, bias=True)\n",
       "      )\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=504, out_features=2016, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Linear(in_features=2016, out_features=504, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): Block(\n",
       "      (ln1): LayerNorm((504,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((504,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): CausalSelfAttention(\n",
       "        (key): Linear(in_features=504, out_features=504, bias=True)\n",
       "        (query): Linear(in_features=504, out_features=504, bias=True)\n",
       "        (value): Linear(in_features=504, out_features=504, bias=True)\n",
       "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "        (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=504, out_features=504, bias=True)\n",
       "      )\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=504, out_features=2016, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Linear(in_features=2016, out_features=504, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): Block(\n",
       "      (ln1): LayerNorm((504,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((504,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): CausalSelfAttention(\n",
       "        (key): Linear(in_features=504, out_features=504, bias=True)\n",
       "        (query): Linear(in_features=504, out_features=504, bias=True)\n",
       "        (value): Linear(in_features=504, out_features=504, bias=True)\n",
       "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "        (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=504, out_features=504, bias=True)\n",
       "      )\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=504, out_features=2016, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Linear(in_features=2016, out_features=504, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): Block(\n",
       "      (ln1): LayerNorm((504,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((504,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): CausalSelfAttention(\n",
       "        (key): Linear(in_features=504, out_features=504, bias=True)\n",
       "        (query): Linear(in_features=504, out_features=504, bias=True)\n",
       "        (value): Linear(in_features=504, out_features=504, bias=True)\n",
       "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "        (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=504, out_features=504, bias=True)\n",
       "      )\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=504, out_features=2016, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Linear(in_features=2016, out_features=504, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((504,), eps=1e-05, elementwise_affine=True)\n",
       "  (ln_fp): LayerNorm((504,), eps=1e-05, elementwise_affine=True)\n",
       "  (head): Linear(in_features=504, out_features=47, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d82db6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 124: train loss 0.77729. lr 4.999879e-04:   1%|▏                    | 124/19532 [00:58<2:30:43,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-->Inputs: tensor([23, 12, 10, 17, 19,  6, 44, 13,  6,  6, 14,  7, 14, 10, 20, 14,  6, 44,\n",
      "        13,  7, 12, 10, 17, 20,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0], device='cuda:0') \n",
      "Logits: tensor([12, 10, 20, 16,  6, 44, 13,  6,  6, 14,  7, 12, 10, 12,  6,  6, 44, 13,\n",
      "        24, 12, 10, 15, 16, 24,  6, 24, 24, 24, 24, 24, 24, 24, 24, 24, 12, 12,\n",
      "        16, 24, 24, 24, 24, 24, 24, 16, 24, 24, 24, 24, 24, 24, 24, 16, 24, 16,\n",
      "        24, 24, 16, 16, 24], device='cuda:0') \n",
      "Targets: tensor([12, 10, 17, 19,  6, 44, 13,  6,  6, 14,  7, 14, 10, 20, 14,  6, 44, 13,\n",
      "         7, 12, 10, 17, 20, 24,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0], device='cuda:0')\n",
      "Inputs:<0.57*x1**2+2.82*x1+0.58PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "Logits:0.84*x1**2+0.0**x1>0.34>*>>>>>>>>>004>>>>>>4>>>>>>>4>4>>44>\n",
      "Targets:0.57*x1**2+2.82*x1+0.58>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 393: train loss 0.73747. lr 4.998791e-04:   2%|▍                    | 394/19532 [03:06<2:29:18,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-->Inputs: tensor([23, 42, 40, 41, 43,  4, 44, 13,  9, 12, 10, 12, 13,  5,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0], device='cuda:0') \n",
      "Logits: tensor([42, 35, 41, 43,  4, 44, 13,  5, 12, 10, 21, 15,  5, 24,  6,  6,  6,  6,\n",
      "        42,  6,  6,  6, 35, 12,  6, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n",
      "        24, 24, 24, 24, 16, 24, 24, 24, 24, 12, 24, 24, 24, 12, 24, 12, 24, 24,\n",
      "        24, 24, 24, 24, 24], device='cuda:0') \n",
      "Targets: tensor([42, 40, 41, 43,  4, 44, 13,  9, 12, 10, 12, 13,  5, 24,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0], device='cuda:0')\n",
      "Inputs:<sqrt(x1-0.01)PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "Logits:sirt(x1)0.93)>****s***i0*>>>>>>>>>>>>>>>4>>>>0>>>0>0>>>>>>>\n",
      "Targets:sqrt(x1-0.01)>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 537: train loss 0.76020. lr 4.997743e-04:   3%|▌                    | 538/19532 [04:13<2:29:24,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from mingpt.trainer import Trainer, TrainerConfig\n",
    "\n",
    "# initialize a trainer instance and kick off training\n",
    "tconf = TrainerConfig(max_epochs=150, batch_size=batchSize, learning_rate=5e-4,\n",
    "                      lr_decay=True, warmup_tokens=512*20, final_tokens=2*len(train_dataset)*block_size,\n",
    "                      num_workers=0, ckpt_path='./SavedModels/bestModel/checkpoint.pt')\n",
    "trainer = Trainer(model, train_dataset, test_dataset, tconf)\n",
    "\n",
    "try:\n",
    "    trainer.train()\n",
    "except KeyboardInterrupt:\n",
    "    print('KeyboardInterrupt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a2a8d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, './SavedModels/savedModel.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "233b7fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('./SavedModels/bestModel/checkpoint.pt'))\n",
    "# model = model.eval().to(trainer.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4aafe31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a safe wrapper for numpy math functions\n",
    "from numpy import *\n",
    "import numpy as np\n",
    "\n",
    "def divide(x, y):\n",
    "  x = np.nan_to_num(x)\n",
    "  y = np.nan_to_num(y)\n",
    "  return np.divide(x,y+1e-5)\n",
    "\n",
    "def sqrt(x):\n",
    "  x = np.nan_to_num(x)\n",
    "  return np.sqrt(np.abs(x)) \n",
    "\n",
    "# Mean square error\n",
    "def mse(y, y_hat):\n",
    "    y_hat = np.reshape(y_hat, [1, -1])[0]\n",
    "    y_gold = np.reshape(y, [1, -1])[0]\n",
    "    our_sum = 0\n",
    "    for i in range(len(y_gold)):\n",
    "        our_sum += (y_hat[i] - y_gold[i]) ** 2\n",
    "\n",
    "    return our_sum / len(y_gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b51b1558",
   "metadata": {},
   "outputs": [],
   "source": [
    "fName = '{}_SymbolicGPT_{}_{}_{}Epochs_{}.txt'.format(dataInfo, method, \n",
    "                                                      'Repetitive' if not padding else 'Padding',\n",
    "                                                      trainer.epoch,\n",
    "                                                      block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22b9d64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case 0.\n",
      "Target:-sin(1.1*x1+0.64)\n",
      "Predicted:sin(x1)\n",
      "MSE:1.483690849489537\n",
      "\n",
      "Test Case 1.\n",
      "Target:-1.42*x1+sqrt(x1+0.53)\n",
      "Predicted:0.96*x1\n",
      "MSE:77.1599010371758\n",
      "\n",
      "Test Case 2.\n",
      "Target:sqrt(-sin(0.2*x1))\n",
      "Predicted:0.38*x1**2-0.07*x1+sqrt(x1+0.67)\n",
      "MSE:94.64021752323555\n",
      "\n",
      "Test Case 3.\n",
      "Target:sin(sqrt(x1))\n",
      "Predicted:0.52*(-0.39*x1-1)**(1/4)\n",
      "MSE:-0.0811882735121786\n",
      "\n",
      "Test Case 4.\n",
      "Target:0.86*x1**2-0.59*x1+1.36\n",
      "Predicted:sqrt(x1)*sin(x1)\n",
      "MSE:387.15753105656864\n",
      "\n",
      "Test Case 5.\n",
      "Target:0.28*sqrt(-x1**2)\n",
      "Predicted:1.56*x1-0.16\n",
      "MSE:33.30833066666667\n",
      "\n",
      "Test Case 6.\n",
      "Target:sin(0.07*x1**2+0.28*x1)\n",
      "Predicted:1.85*x1\n",
      "MSE:71.39143990775572\n",
      "\n",
      "Test Case 7.\n",
      "Target:sin(x1)\n",
      "Predicted:1.16*x1**2-0.66\n",
      "MSE:704.8015709883308\n",
      "\n",
      "Test Case 8.\n",
      "Target:0.81*sqrt(-x1**2-0.95*x1+0.12)\n",
      "Predicted:-0.63*x1\n",
      "MSE:49.285431581346785\n",
      "\n",
      "Test Case 9.\n",
      "Target:sin(x1+0.37)\n",
      "Predicted:0.76*sqrt(x1)\n",
      "MSE:5.210347616482671\n",
      "\n",
      "Test Case 10.\n",
      "Target:-0.68*x1**2+1.77*x1\n",
      "Predicted:1.3*sqrt(x1-0.42)\n",
      "MSE:100.95271414902156\n",
      "\n",
      "Test Case 11.\n",
      "Target:sqrt(x1)+0.51*x1**2-0.17*x1\n",
      "Predicted:0.53*x1**2-0.35\n",
      "MSE:1.6251549139600343\n",
      "\n",
      "Test Case 12.\n",
      "Target:1.25*x1+0.85*sqrt(-0.68*x1-1)\n",
      "Predicted:-0.5*x1*sqrt(x1-0.72)\n",
      "MSE:148.66739037697434\n",
      "\n",
      "Test Case 13.\n",
      "Target:sin(x1**2-0.11*x1)\n",
      "Predicted:sqrt(sin(0.45*x1*+0.94))\n",
      "MSE:1.4479285959443047\n",
      "\n",
      "Test Case 14.\n",
      "Target:0.7*sqrt(x1-0.51)\n",
      "Predicted:sqrt(x1)\n",
      "MSE:0.5276747508918646\n",
      "\n",
      "Test Case 15.\n",
      "Target:sqrt(x1**2+0.31*x1)\n",
      "Predicted:x1\n",
      "MSE:0.023211979644680684\n",
      "\n",
      "Test Case 16.\n",
      "Target:4*x1-0.25\n",
      "Predicted:0.75*sqrt(x1)-0.48*x1+0.58\n",
      "MSE:336.48819380660876\n",
      "\n",
      "Test Case 17.\n",
      "Target:1.64*x1**2-0.31*x1-0.13\n",
      "Predicted:-0.74*x1**2-0.47*x1+sin(0.62*x1+0.44)\n",
      "MSE:3056.4391524602174\n",
      "\n",
      "Test Case 18.\n",
      "Target:sqrt(-sin(0.37*x1-0.65))\n",
      "Predicted:0.92*sqrt(0.66*x1-1)\n",
      "MSE:0.16192635483019727\n",
      "\n",
      "Test Case 19.\n",
      "Target:1.48*x1**2+0.55\n",
      "Predicted:0.39*x1**2\n",
      "MSE:646.995390373\n",
      "\n",
      "Test Case 20.\n",
      "Target:0.56*x1**2+0.69*x1+0.82\n",
      "Predicted:0.35-0.35*x1\n",
      "MSE:324.7007629546668\n",
      "\n",
      "Test Case 21.\n",
      "Target:0.93*sqrt(0.62*x1+1)\n",
      "Predicted:0.31*sqrt(-x1)-sqrt(0.54*x1+1)\n",
      "MSE:9.09771983816157\n",
      "\n",
      "Test Case 22.\n",
      "Target:2*x1+sin(x1)-0.89\n",
      "Predicted:sin(sqrt(x1))\n",
      "MSE:48.21941699463423\n",
      "\n",
      "Test Case 23.\n",
      "Target:0.93*x1*sin(0.85*x1+0.49)\n",
      "Predicted:-0.94*x1\n",
      "MSE:2.085819059940598\n",
      "\n",
      "Test Case 24.\n",
      "Target:-sin(sin(0.4*x1+0.16))\n",
      "Predicted:1.36*sqrt(x1)\n",
      "MSE:13.289987354283218\n",
      "\n",
      "Test Case 25.\n",
      "Target:0.1*x1**3\n",
      "Predicted:sqrt(x1+0.85)\n",
      "MSE:95.02303173968038\n",
      "\n",
      "Test Case 26.\n",
      "Target:0.8*sqrt(x1)\n",
      "Predicted:0.61*sin(0.23*x1)\n",
      "MSE:1.4052992712474839\n",
      "\n",
      "Test Case 27.\n",
      "Target:0.83*sqrt(x1)+x1\n",
      "Predicted:sqrt(x1+0.11)\n",
      "MSE:18.02546363394005\n",
      "\n",
      "Test Case 28.\n",
      "Target:1.83*x1-1.34\n",
      "Predicted:sqrt(sin(x1))\n",
      "MSE:40.77376292587799\n",
      "\n",
      "Test Case 29.\n",
      "Target:1.79*x1**2\n",
      "Predicted:0.97*sqrt(x1)\n",
      "MSE:1515.1954607823666\n",
      "\n",
      "Test Case 30.\n",
      "Target:-0.53*x1-0.76*sin(x1-0.43)\n",
      "Predicted:x1**(1/4)\n",
      "MSE:11.97320912413333\n",
      "\n",
      "Test Case 31.\n",
      "Target:sqrt(sin(x1-0.76))\n",
      "Predicted:0.86*x1**2+0.74*x1\n",
      "MSE:496.52106652485134\n",
      "\n",
      "Test Case 32.\n",
      "Target:0.34*x1**2-0.05*x1-0.08\n",
      "Predicted:0.69*(-0.07*x1-1)**(1/4)\n",
      "MSE:48.46346058123588\n",
      "\n",
      "Test Case 33.\n",
      "Target:sqrt(2)*sqrt(x1)\n",
      "Predicted:-sin(0.64*x1**2-0.56*x1)\n",
      "MSE:9.240093637427615\n",
      "\n",
      "Test Case 34.\n",
      "Target:x1**2+0.09*x1+0.69\n",
      "Predicted:-0.3*x1\n",
      "MSE:639.9005551666667\n",
      "\n",
      "Test Case 35.\n",
      "Target:0.97*sqrt(-x1)\n",
      "Predicted:1.11*sqrt(x1)\n",
      "MSE:0.08918000000000018\n",
      "\n",
      "Test Case 36.\n",
      "Target:-sin(0.14*x1**2-0.53*x1)\n",
      "Predicted:x1\n",
      "MSE:26.559443658307448\n",
      "\n",
      "Test Case 37.\n",
      "Target:0.85*sqrt(0.1*x1-1)\n",
      "Predicted:1.04*sqrt(x1)\n",
      "MSE:2.5739538293694517\n",
      "\n",
      "Test Case 38.\n",
      "Target:sin(0.56*sqrt(x1))\n",
      "Predicted:0.12*sqrt(x1)\n",
      "MSE:0.4454444814311156\n",
      "\n",
      "Test Case 39.\n",
      "Target:1.99*x1+0.57\n",
      "Predicted:0.29*sqrt(-x1)+sin(x1)\n",
      "MSE:96.642590911747\n",
      "\n",
      "Test Case 40.\n",
      "Target:sqrt(sin(0.06*x1+0.44))\n",
      "Predicted:sin(x1)\n",
      "MSE:2.242153897538275\n",
      "\n",
      "Test Case 41.\n",
      "Target:0.45*x1**2\n",
      "Predicted:0.97*sqrt(x1)\n",
      "MSE:68.95592405025965\n",
      "\n",
      "Test Case 42.\n",
      "Target:x1**2-0.65*x1-0.02\n",
      "Predicted:0.85*sqrt(-x1**2+0.93*x1)\n",
      "MSE:269.42064116428134\n",
      "\n",
      "Test Case 43.\n",
      "Target:0.97*sqrt(x1**2-0.28*x1-0.35)\n",
      "Predicted:sin(0.84*sqrt(0.17*x1+1))\n",
      "MSE:11.82105031206857\n",
      "\n",
      "Test Case 44.\n",
      "Target:(x1-0.15)**(1/4)\n",
      "Predicted:0.91*(x1+0.09)**(1/4)\n",
      "MSE:0.012583355477105311\n",
      "\n",
      "Test Case 45.\n",
      "Target:-sin(0.11*x1)\n",
      "Predicted:sin(x1)\n",
      "MSE:0.11065639798079169\n",
      "\n",
      "Test Case 46.\n",
      "Target:2*x1-1.48\n",
      "Predicted:-0.09*x1**2+0.86*x1\n",
      "MSE:34.661784972999996\n",
      "\n",
      "Test Case 47.\n",
      "Target:0.73*sqrt(x1)\n",
      "Predicted:1.36*x1+0.82\n",
      "MSE:30.846692207554778\n",
      "\n",
      "Test Case 48.\n",
      "Target:0.14*x1\n",
      "Predicted:0.43*sqrt(-x1**2)\n",
      "MSE:1.8040851666666666\n",
      "\n",
      "Test Case 49.\n",
      "Target:0.88*(-x1)**(1/4)\n",
      "Predicted:0.84*sqrt(-0.37*x1+1)\n",
      "MSE:-0.7505062075971365\n",
      "\n",
      "Test Case 50.\n",
      "Target:0.82*x1**2-0.84*x1+0.22\n",
      "Predicted:0.28*x1-0.08\n",
      "MSE:194.1289244253333\n",
      "\n",
      "Test Case 51.\n",
      "Target:sqrt(sin(0.03*x1))\n",
      "Predicted:-0.03*x1**2-0.16*x1\n",
      "MSE:3.1914379818240133\n",
      "\n",
      "Test Case 52.\n",
      "Target:(x1+0.54)**(1/4)\n",
      "Predicted:0.97*sqrt(0.78*x1**2-x1)\n",
      "MSE:3.7243051751092744\n",
      "\n",
      "Test Case 53.\n",
      "Target:1.8*x1-0.56\n",
      "Predicted:0.71*x1\n",
      "MSE:20.245685166666664\n",
      "\n",
      "Test Case 54.\n",
      "Target:sin(0.62*sqrt(0.63*x1+1))\n",
      "Predicted:0.96*sqrt(x1)\n",
      "MSE:1.2465829490373663\n",
      "\n",
      "Test Case 55.\n",
      "Target:sqrt(x1-0.89)\n",
      "Predicted:0.95*x1**2-0.09*x1\n",
      "MSE:378.443446786873\n",
      "\n",
      "Test Case 56.\n",
      "Target:sin(0.08*x1**2-0.04*x1)\n",
      "Predicted:0.52*x1**(6/2)\n",
      "MSE:3698.9627182752643\n",
      "\n",
      "Test Case 57.\n",
      "Target:-0.70\n",
      "Predicted:0.07-1.3*x1\n",
      "MSE:27.737116666666665\n",
      "\n",
      "Test Case 58.\n",
      "Target:sin(sin(x1))\n",
      "Predicted:sin(1.07*x1-0.43)\n",
      "MSE:0.01597876703792331\n",
      "\n",
      "Test Case 59.\n",
      "Target:x1**3+0.71*x1\n",
      "Predicted:1.23*sqrt(x1-0.43)\n",
      "MSE:14199.676278761875\n",
      "\n",
      "Test Case 60.\n",
      "Target:sin(sqrt(x1+0.83))\n",
      "Predicted:0.4*sqrt(-x1**2)\n",
      "MSE:1.4212691787982152\n",
      "\n",
      "Test Case 61.\n",
      "Target:0.92*x1+0.09*sin(0.37*x1-0.48)\n",
      "Predicted:sqrt(sin(x1+0.11))\n",
      "MSE:12.725391055746451\n",
      "\n",
      "Test Case 62.\n",
      "Target:sqrt(sin(x1-0.86))\n",
      "Predicted:sqrt(x1)+x1+0.62\n",
      "MSE:43.689831749453624\n",
      "\n",
      "Test Case 63.\n",
      "Target:sqrt(-sin(0.11*x1))\n",
      "Predicted:0.79*sqrt(x1)\n",
      "MSE:0.9880620679251995\n",
      "\n",
      "Test Case 64.\n",
      "Target:2*x1-0.16\n",
      "Predicted:-0.11*x1+sqrt(x1+0.81)-0.31\n",
      "MSE:58.082042306891665\n",
      "\n",
      "Test Case 65.\n",
      "Target:(x1-0.76)**(1/4)\n",
      "Predicted:sin(0.08*x1-0.07)\n",
      "MSE:1.2082627851486092\n",
      "\n",
      "Test Case 66.\n",
      "Target:2.64*x1+0.2\n",
      "Predicted:x1**2*sin(0.1*x1+0.95)+0.18*x1-0.11\n",
      "MSE:129.10141950475045\n",
      "\n",
      "Test Case 67.\n",
      "Target:-0.93*x1+sqrt(x1-0.91)\n",
      "Predicted:2*x1+0.44\n",
      "MSE:146.3950789721445\n",
      "\n",
      "Test Case 68.\n",
      "Target:0.91*sqrt(x1)+x1**2-0.86*x1\n",
      "Predicted:0.84*sqrt(0.85*x1-1)\n",
      "MSE:377.51292783770094\n",
      "\n",
      "Test Case 69.\n",
      "Target:sin(sin(x1))\n",
      "Predicted:-sin(0.85*x1)\n",
      "MSE:1.6318665974527204\n",
      "\n",
      "Test Case 70.\n",
      "Target:0.78*x1**2\n",
      "Predicted:0.74*x1-0.18\n",
      "MSE:214.0318486386667\n",
      "\n",
      "Test Case 71.\n",
      "Target:sin(0.68*sqrt(-x1))\n",
      "Predicted:0.71*sqrt(x1)\n",
      "MSE:0.2918939372909659\n",
      "\n",
      "Test Case 72.\n",
      "Target:-sin(0.8*x1)*sin(x1-0.87)\n",
      "Predicted:2*x1-0.25\n",
      "MSE:90.65349856489105\n",
      "\n",
      "Test Case 73.\n",
      "Target:x1**(1/4)\n",
      "Predicted:0.33*x1*sqrt(-x1-0.08)\n",
      "MSE:4.022126875077821\n",
      "\n",
      "Test Case 74.\n",
      "Target:0.41*sqrt(x1**2+0.94*x1)\n",
      "Predicted:0.5*x1\n",
      "MSE:0.05694696656058755\n",
      "\n",
      "Test Case 75.\n",
      "Target:0.5*x1**2-0.43*x1-0.57\n",
      "Predicted:sin(-0.53*x1**2-0.58*x1)\n",
      "MSE:81.83990842450663\n",
      "\n",
      "Test Case 76.\n",
      "Target:0.62*sqrt(0.87*x1+1)\n",
      "Predicted:0.35*sqrt(-x1)\n",
      "MSE:0.40238356323390395\n",
      "\n",
      "Test Case 77.\n",
      "Target:0.97*x1**2+0.54*x1+1.11\n",
      "Predicted:sin(x1+0.15)\n",
      "MSE:693.0221424955384\n",
      "\n",
      "Test Case 78.\n",
      "Target:-0.33*x1**2-0.29*x1+0.89*sqrt(-x1)\n",
      "Predicted:1.38*sqrt(x1)\n",
      "MSE:97.84556747356818\n",
      "\n",
      "Test Case 79.\n",
      "Target:0.18*x1**2-0.27*x1\n",
      "Predicted:x1**2-0.8*x1-0.48\n",
      "MSE:252.3570059253334\n",
      "\n",
      "Test Case 80.\n",
      "Target:0.88*x1-0.64\n",
      "Predicted:-sin(0.56*x1**2-0.72*x1)\n",
      "MSE:12.346944903246397\n",
      "\n",
      "Test Case 81.\n",
      "Target:-0.04*x1*sin(0.74*x1+0.23)+0.42\n",
      "Predicted:0.21*x1+0.75\n",
      "MSE:1.4543326391580567\n",
      "\n",
      "Test Case 82.\n",
      "Target:0.95*x1**2*sqrt(-x1)-0.12*x1\n",
      "Predicted:0.52*x1**2-0.89*x1*sin(x1)\n",
      "MSE:1161.3849536345353\n",
      "\n",
      "Test Case 83.\n",
      "Target:-sin(0.87*x1-0.58)\n",
      "Predicted:sin(x1+0.05)\n",
      "MSE:1.291166038146359\n",
      "\n",
      "Test Case 84.\n",
      "Target:-sin(0.25*x1-0.4)\n",
      "Predicted:-0.44\n",
      "MSE:0.0721396433468005\n",
      "\n",
      "Test Case 85.\n",
      "Target:sin(2*x1)\n",
      "Predicted:0.24*x1**(3/2)-0.67*x1\n",
      "MSE:1.1266000366355657\n",
      "\n",
      "Test Case 86.\n",
      "Target:0.75*x1**2*sin(0.67*x1)-0.33*x1\n",
      "Predicted:0.3*x1**2+0.91*x1\n",
      "MSE:338.22987349950745\n",
      "\n",
      "Test Case 87.\n",
      "Target:x1-0.21\n",
      "Predicted:0.81*x1-0.45\n",
      "MSE:1.2469651666666661\n",
      "\n",
      "Test Case 88.\n",
      "Target:0.33*x1-0.98\n",
      "Predicted:x1-sin(0.51*x1+0.58)-0.54\n",
      "MSE:11.67703753479436\n",
      "\n",
      "Test Case 89.\n",
      "Target:sqrt(x1-0.1)\n",
      "Predicted:sqrt(x1+0.86)+sin(x1-0.33)\n",
      "MSE:0.318581770523104\n",
      "\n",
      "Test Case 90.\n",
      "Target:1.42*x1+0.77\n",
      "Predicted:0.92*sqrt(1-0.08*x1)\n",
      "MSE:43.839844390865764\n",
      "\n",
      "Test Case 91.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:sin(0.34*x1)\n",
      "Predicted:0.25*x1+0.92\n",
      "MSE:1.2564892942995216\n",
      "\n",
      "Test Case 92.\n",
      "Target:0.83*sqrt(-x1)\n",
      "Predicted:1.34*x1**2+0.32*x1\n",
      "MSE:923.2611413123908\n",
      "\n",
      "Test Case 93.\n",
      "Target:sin(x1)+sin(x1-0.38)\n",
      "Predicted:sqrt(sin(x1))\n",
      "MSE:4.867237859962289\n",
      "\n",
      "Test Case 94.\n",
      "Target:0.94*sqrt(-0.65*x1-1)\n",
      "Predicted:sqrt(x1)\n",
      "MSE:0.07164133644008151\n",
      "\n",
      "Test Case 95.\n",
      "Target:-2*x1*sin(0.58*x1)+1.0\n",
      "Predicted:sqrt(0.37*x1)-sin(0.44*x1)\n",
      "MSE:15.502363208163969\n",
      "\n",
      "Test Case 96.\n",
      "Target:sin(sqrt(x1+0.02))\n",
      "Predicted:sin(sqrt(x1-0.71))\n",
      "MSE:0.0064911617838162\n",
      "\n",
      "Test Case 97.\n",
      "Target:x1**(1/4)\n",
      "Predicted:sin(1.63*x1)\n",
      "MSE:1.8175155885389565\n",
      "\n",
      "Test Case 98.\n",
      "Target:\n",
      "Predicted:0.98*x1-0.99\n",
      "MSE:9318.953460666666\n",
      "\n",
      "Test Case 99.\n",
      "Target:2*x1*sin(0.88*x1)+0.35\n",
      "Predicted:-0.22*x1*sqrt(x1-0.16)\n",
      "MSE:27.274900643242287\n",
      "\n",
      "Test Case 100.\n",
      "Target:sqrt(x1+0.22)\n",
      "Predicted:-0.41*x1**4+x1+0.14*sqrt(0.22*x1-1)-0.19\n",
      "MSE:66266.02782610904\n",
      "\n",
      "Test Case 101.\n",
      "Target:sin(x1)\n",
      "Predicted:sqrt(x1)\n",
      "MSE:7.910562652285602\n",
      "\n",
      "Test Case 102.\n",
      "Target:sqrt(x1)+sin(x1+0.65)\n",
      "Predicted:0.47*sqrt(-0.7*x1**2-x1)\n",
      "MSE:0.3586194860202425\n",
      "\n",
      "Test Case 103.\n",
      "Target:-sin(0.83*x1**2+0.97*x1)\n",
      "Predicted:sqrt(sin(x1-0.07))\n",
      "MSE:1.1778967690135345\n",
      "\n",
      "Test Case 104.\n",
      "Target:sqrt(x1**2+0.7*x1)\n",
      "Predicted:sqrt(sin(x1-0.39))\n",
      "MSE:17.485128912594785\n",
      "\n",
      "Test Case 105.\n",
      "Target:0.94*sqrt(-x1**2-0.16*x1)\n",
      "Predicted:sin(x1)\n",
      "MSE:26.014594684982445\n",
      "\n",
      "Test Case 106.\n",
      "Target:sin(sin(x1))\n",
      "Predicted:sqrt(sin(x1))\n",
      "MSE:2.0893488347622458\n",
      "\n",
      "Test Case 107.\n",
      "Target:sin(x1)\n",
      "Predicted:-sin(0.89*x1)\n",
      "MSE:1.988688239469692\n",
      "\n",
      "Test Case 108.\n",
      "Target:sin(sqrt(x1-0.19))\n",
      "Predicted:0.86*sqrt(-0.26*x1-1)+sqrt(x1-0.13)\n",
      "MSE:6.417528955920742\n",
      "\n",
      "Test Case 109.\n",
      "Target:sqrt(x1)+0.05*x1**2-0.17*x1+0.12\n",
      "Predicted:x1**(1/4)\n",
      "MSE:1.3271775592959156\n",
      "\n",
      "Test Case 110.\n",
      "Target:x1+0.49\n",
      "Predicted:1.37*x1-0.35\n",
      "MSE:0.8140531666666678\n",
      "\n",
      "Test Case 111.\n",
      "Target:0.03-0.78*x1**2\n",
      "Predicted:sin(0.22*x1)\n",
      "MSE:346.5317409867129\n",
      "\n",
      "Test Case 112.\n",
      "Target:-0.07*x1**2-0.46*x1*sqrt(1-0.6*x1)\n",
      "Predicted:sin(0.43*x1)\n",
      "MSE:28.513885975181207\n",
      "\n",
      "Test Case 113.\n",
      "Target:0.55*x1\n",
      "Predicted:0.99*sqrt(-x1**2+0.77*x1)\n",
      "MSE:2.7156571980750357\n",
      "\n",
      "Test Case 114.\n",
      "Target:0.42*sqrt(1-0.89*x1)\n",
      "Predicted:0.29*x1**2+0.23*x1-0.49\n",
      "MSE:42.35202513784877\n",
      "\n",
      "Test Case 115.\n",
      "Target:-1.65*x1+0.68*sqrt(-0.21*x1-1)-0.62\n",
      "Predicted:0.47*x1\n",
      "MSE:89.99670648590332\n",
      "\n",
      "Test Case 116.\n",
      "Target:0.55*sqrt(x1)-0.61*x1\n",
      "Predicted:0.59*sqrt(-0.87*x1**2+x1-0.7)\n",
      "MSE:15.447601276093023\n",
      "\n",
      "Test Case 117.\n",
      "Target:0.58*sqrt(x1**2+0.53*x1)\n",
      "Predicted:-sin(0.58*x1+0.73)\n",
      "MSE:6.71254112718352\n",
      "\n",
      "Test Case 118.\n",
      "Target:sin(sin(x1))\n",
      "Predicted:sin(sqrt(x1+0.07))\n",
      "MSE:2.047555525448901\n",
      "\n",
      "Test Case 119.\n",
      "Target:2*x1+1.23*sin(x1+0.72)\n",
      "Predicted:sin(x1**2)\n",
      "MSE:76.92072108437281\n",
      "\n",
      "Test Case 120.\n",
      "Target:0.75*sqrt(-x1**2-0.25*x1)\n",
      "Predicted:-0.03*x1**2+0.51*x1+sqrt(x1-0.06)\n",
      "MSE:0.13652489774074505\n",
      "\n",
      "Test Case 121.\n",
      "Target:0.12*x1**2+0.13\n",
      "Predicted:sqrt(x1)\n",
      "MSE:0.8939446871061337\n",
      "\n",
      "Test Case 122.\n",
      "Target:0.92*x1+0.98\n",
      "Predicted:sqrt(sin(x1))\n",
      "MSE:19.76433041548452\n",
      "\n",
      "Test Case 123.\n",
      "Target:sin(sin(0.47*x1))\n",
      "Predicted:0.42*sqrt(x1)*sin(x1)\n",
      "MSE:1.7305745249226079\n",
      "\n",
      "Test Case 124.\n",
      "Target:-0.12*x1**2+0.63*x1+0.29\n",
      "Predicted:sqrt(x1-0.02)\n",
      "MSE:2.7308304984929697\n",
      "\n",
      "Test Case 125.\n",
      "Target:0.82*sqrt(x1+0.77)\n",
      "Predicted:1.04*x1-0.82\n",
      "MSE:4.664394167411657\n",
      "\n",
      "Test Case 126.\n",
      "Target:-0.14*x1**3-0.76\n",
      "Predicted:sqrt(sin(0.52*x1-0.57))\n",
      "MSE:325.9767370276478\n",
      "\n",
      "Test Case 127.\n",
      "Target:sin(0.79*x1-0.22)\n",
      "Predicted:0.12*x1**2-0.16\n",
      "MSE:9.051255985485858\n",
      "\n",
      "Test Case 128.\n",
      "Target:sin(sin(x1-0.53))\n",
      "Predicted:-sin(0.45*x1)\n",
      "MSE:0.4725755584006201\n",
      "\n",
      "Test Case 129.\n",
      "Target:sin(0.44*x1**2+0.2*x1)\n",
      "Predicted:sin(0.29*x1)\n",
      "MSE:1.3938614976489867\n",
      "\n",
      "Test Case 130.\n",
      "Target:-sin(sin(0.04*x1+0.33))\n",
      "Predicted:sqrt(sin(x1+0.75))\n",
      "MSE:1.5716173109721565\n",
      "\n",
      "Test Case 131.\n",
      "Target:sin(2*x1-0.33)\n",
      "Predicted:0.0*x1**2+0.37*x1+0.81\n",
      "MSE:6.987866259969947\n",
      "\n",
      "Test Case 132.\n",
      "Target:0.41-0.16*x1\n",
      "Predicted:sqrt(x1)\n",
      "MSE:6.077337833488415\n",
      "\n",
      "Test Case 133.\n",
      "Target:0.86*sqrt(1-0.52*x1)\n",
      "Predicted:0.24*x1**2*sqrt(x1+0.46)\n",
      "MSE:143.92170036707975\n",
      "\n",
      "Test Case 134.\n",
      "Target:-sin(0.31*x1**2+0.11*x1)\n",
      "Predicted:-sin(0.79*x1+0.14)\n",
      "MSE:0.9892416080082097\n",
      "\n",
      "Test Case 135.\n",
      "Target:0.91*sqrt(-x1)\n",
      "Predicted:sqrt(sin(x1))\n",
      "MSE:1.3713738610893071\n",
      "\n",
      "Test Case 136.\n",
      "Target:0.33*x1+1.22\n",
      "Predicted:sin(sqrt(x1))\n",
      "MSE:3.7172511983470553\n",
      "\n",
      "Test Case 137.\n",
      "Target:0.13*x1\n",
      "Predicted:0.76*sqrt(x1)*sqrt(-x1-0.95)\n",
      "MSE:10.603947251646263\n",
      "\n",
      "Test Case 138.\n",
      "Target:-0.68*x1**(5/2)\n",
      "Predicted:-sin(0.33*x1+0.39)\n",
      "MSE:1183.7347120214476\n",
      "\n",
      "Test Case 139.\n",
      "Target:2*x1+0.84*sqrt(0.81*x1+1)-0.3\n",
      "Predicted:0.48*sqrt(x1)\n",
      "MSE:95.17571382014737\n",
      "\n",
      "Test Case 140.\n",
      "Target:1.04*x1**2+0.83*x1\n",
      "Predicted:sqrt(x1)+sin(x1+0.92)\n",
      "MSE:665.6681556831579\n",
      "\n",
      "Test Case 141.\n",
      "Target:-0.44*x1**2\n",
      "Predicted:sqrt(x1-0.55)+sin(0.29*x1)\n",
      "MSE:166.99063503116705\n",
      "\n",
      "Test Case 142.\n",
      "Target:0.95*x1**2-0.37*x1\n",
      "Predicted:-0.32*x1+sqrt(x1-0.2)+0.03\n",
      "MSE:378.36348283631173\n",
      "\n",
      "Test Case 143.\n",
      "Target:x1**2+0.65*x1\n",
      "Predicted:x1**(1/4)\n",
      "MSE:597.3613658648607\n",
      "\n",
      "Test Case 144.\n",
      "Target:0.38*x1**2-0.54*x1+0.07\n",
      "Predicted:x1**2+0.91*x1\n",
      "MSE:430.9835322186666\n",
      "\n",
      "Test Case 145.\n",
      "Target:0.41*sqrt(-x1**2)\n",
      "Predicted:sin(sqrt(x1-0.72))\n",
      "MSE:1.1050757239070768\n",
      "\n",
      "Test Case 146.\n",
      "Target:x1\n",
      "Predicted:-0.69*x1*sin(0.18*x1)-0.15\n",
      "MSE:52.040049748100884\n",
      "\n",
      "Test Case 147.\n",
      "Target:0.39*sqrt(-x1)\n",
      "Predicted:1.95*x1+0.34\n",
      "MSE:72.88464447824396\n",
      "\n",
      "Test Case 148.\n",
      "Target:0.33*x1-0.73\n",
      "Predicted:0.78*sqrt(x1+0.08)\n",
      "MSE:0.8251773411545641\n",
      "\n",
      "Test Case 149.\n",
      "Target:-0.2*x1**2+2.13*x1-0.72\n",
      "Predicted:sqrt(x1)-0.19*x1-0.75\n",
      "MSE:17.476983151261642\n",
      "\n",
      "Test Case 150.\n",
      "Target:x1**2+sin(x1)\n",
      "Predicted:x1-0.81\n",
      "MSE:339.3891854674996\n",
      "\n",
      "Test Case 151.\n",
      "Target:sqrt(x1)*sin(x1-0.13)\n",
      "Predicted:-1.24*x1-0.42\n",
      "MSE:22.41802023143195\n",
      "\n",
      "Test Case 152.\n",
      "Target:1.28*x1-0.32\n",
      "Predicted:-0.47*x1**2+0.47*x1+0.04\n",
      "MSE:199.25411926366667\n",
      "\n",
      "Test Case 153.\n",
      "Target:0.58*sqrt(x1-0.21)\n",
      "Predicted:0.33*x1+sin(0.02*x1)-0.44\n",
      "MSE:0.035364918806550925\n",
      "\n",
      "Test Case 154.\n",
      "Target:sin(0.72*x1)\n",
      "Predicted:sin(0.75*x1)\n",
      "MSE:0.011686405139678252\n",
      "\n",
      "Test Case 155.\n",
      "Target:0.83*(x1-0.81)**(1/4)\n",
      "Predicted:0.74*x1**2*sqrt(1-0.92*x1)\n",
      "MSE:995.201251446652\n",
      "\n",
      "Test Case 156.\n",
      "Target:0.59*sqrt(x1-0.39)\n",
      "Predicted:sqrt(sin(0.08*x1))\n",
      "MSE:0.36908030109986184\n",
      "\n",
      "Test Case 157.\n",
      "Target:sin(x1)\n",
      "Predicted:sin(0.88*sqrt(-0.21*x1-1))\n",
      "MSE:2.6480343245540903\n",
      "\n",
      "Test Case 158.\n",
      "Target:sqrt(sin(0.12*x1+0.81))\n",
      "Predicted:-0.29*x1**2+0.27*x1+0.46\n",
      "MSE:34.737740269886686\n",
      "\n",
      "Test Case 159.\n",
      "Target:-0.16*x1**3-0.08*x1\n",
      "Predicted:-0.05*x1**2\n",
      "MSE:329.63501603646665\n",
      "\n",
      "Test Case 160.\n",
      "Target:0.14*x1*sqrt(x1+0.75)\n",
      "Predicted:sin(1.48*x1)\n",
      "MSE:1.9333413564455428\n",
      "\n",
      "Test Case 161.\n",
      "Target:1.62-0.78*x1**2\n",
      "Predicted:sin(0.35*x1**2-0.64*x1)\n",
      "MSE:271.70148413604096\n",
      "\n",
      "Test Case 162.\n",
      "Target:sqrt(x1**2-0.9*x1)\n",
      "Predicted:0.59*sqrt(x1)\n",
      "MSE:8.523149636721772\n",
      "\n",
      "Test Case 163.\n",
      "Target:0.79*(0.16*x1-1)**(1/4)\n",
      "Predicted:1.9*x1+0.71\n",
      "MSE:83.1061300761312\n",
      "\n",
      "Test Case 164.\n",
      "Target:-sin(0.13*x1)\n",
      "Predicted:0.96*x1+sin(0.14*x1)\n",
      "MSE:31.430199254763362\n",
      "\n",
      "Test Case 165.\n",
      "Target:sin(0.16*x1-0.74)\n",
      "Predicted:x1**2\n",
      "MSE:521.0199532167885\n",
      "\n",
      "Test Case 166.\n",
      "Target:0.39*sqrt(x1**2+0.6*x1)\n",
      "Predicted:0.91*sqrt(0.91*x1**2-x1)\n",
      "MSE:2.5810413173766245\n",
      "\n",
      "Test Case 167.\n",
      "Target:-0.6*x1+0.03*sin(x1)\n",
      "Predicted:0.64*(0.43*x1-1)**(1/4)\n",
      "MSE:11.719985720980855\n",
      "\n",
      "Test Case 168.\n",
      "Target:0.77*sqrt(-x1)\n",
      "Predicted:-sin(0.53*x1**2)\n",
      "MSE:3.0504487382358776\n",
      "\n",
      "Test Case 169.\n",
      "Target:-0.65*x1*sin(0.58*x1+0.22)+0.81\n",
      "Predicted:x1**2-0.98*x1\n",
      "MSE:311.5455265587984\n",
      "\n",
      "Test Case 170.\n",
      "Target:sin(0.85*x1+0.1)\n",
      "Predicted:0.12*x1\n",
      "MSE:1.5079925616531917\n",
      "\n",
      "Test Case 171.\n",
      "Target:1.43*x1*sqrt(x1-0.07)+0.68\n",
      "Predicted:sin(0.19*x1+0.59)\n",
      "MSE:202.0351692201388\n",
      "\n",
      "Test Case 172.\n",
      "Target:sin(sqrt(x1))\n",
      "Predicted:-0.81*x1**2+0.18*x1\n",
      "MSE:340.1513208426971\n",
      "\n",
      "Test Case 173.\n",
      "Target:sin(0.6*sqrt(x1))\n",
      "Predicted:x1**2-0.5*x1+0.61\n",
      "MSE:410.1826874348233\n",
      "\n",
      "Test Case 174.\n",
      "Target:sin(0.76*x1-0.31)\n",
      "Predicted:0.81*x1**(1/4)\n",
      "MSE:1.8043203572975446\n",
      "\n",
      "Test Case 175.\n",
      "Target:x1**(1/4)\n",
      "Predicted:sqrt(x1+0.67)\n",
      "MSE:0.689039214549166\n",
      "\n",
      "Test Case 176.\n",
      "Target:1.02*x1+1.36\n",
      "Predicted:sin(0.5*sqrt(x1+0.35)+0.46\n",
      "MSE:8836.591434\n",
      "\n",
      "Test Case 177.\n",
      "Target:sin(x1)\n",
      "Predicted:0.91*sqrt(x1+0.87)\n",
      "MSE:7.824590790526269\n",
      "\n",
      "Test Case 178.\n",
      "Target:-sin(0.65*x1**2-0.13*x1)\n",
      "Predicted:0.98*x1+0.97\n",
      "MSE:31.531803165221262\n",
      "\n",
      "Test Case 179.\n",
      "Target:-sin(0.4*x1)\n",
      "Predicted:0.89*x1**2+0.55*sqrt(-0.82*x1-1)\n",
      "MSE:498.85408298094006\n",
      "\n",
      "Test Case 180.\n",
      "Target:x1**2+1.17*x1-0.12\n",
      "Predicted:sin(sin(x1))\n",
      "MSE:823.0031309499321\n",
      "\n",
      "Test Case 181.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:2.25*x1-0.82\n",
      "Predicted:1.55*x1-0.47\n",
      "MSE:8.404316666666663\n",
      "\n",
      "Test Case 182.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-4826915ddd57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m             yHat = sample(model, x, block_size, points=p, \n\u001b[0;32m     41\u001b[0m                           \u001b[0mtemperature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m                           top_k=10)[0]\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0msos_eq_loc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'E'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mas_tuple\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - University of Waterloo\\Projects\\symbolicgpt2\\mingpt\\utils.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(model, x, steps, points, temperature, sample, top_k)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mx_cond\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mblock_size\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mblock_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# crop context if needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_cond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[1;31m# pluck the logits at the final step and scale by temperature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - University of Waterloo\\Projects\\symbolicgpt2\\mingpt\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, idx, targets, points, masks, dataset)\u001b[0m\n\u001b[0;32m    398\u001b[0m                 \u001b[0minput_embedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoken_embeddings\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mposition_embeddings\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpoints_embeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'outputConcat'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m                 \u001b[0mpoints_embeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoints_embeddings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munSqDim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m                 \u001b[0mposition_embeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_emb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# each position maps to a (learnable) vector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m                 \u001b[0minput_embedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoken_embeddings\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mposition_embeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# alright, let's sample some character-level symbolic GPT\n",
    "from mingpt.utils import sample\n",
    "#from gp_model import Genetic_Model\n",
    "#from mlp_model import MLP_Model\n",
    "    \n",
    "loader = torch.utils.data.DataLoader(\n",
    "                                test_dataset, \n",
    "                                shuffle=False, \n",
    "                                pin_memory=True,\n",
    "                                batch_size=1,\n",
    "                                num_workers=0)\n",
    "\n",
    "testRange = [3.1,6.0]\n",
    "numTestPoints = 10\n",
    "#test = np.linspace(3.1,6.0,numTestPoints)\n",
    "\n",
    "# gpm = Genetic_Model(n_jobs=-1)\n",
    "# mlp = MLP_Model()\n",
    "\n",
    "resultDict = {}\n",
    "with open(fName, 'w', encoding=\"utf-8\") as o:\n",
    "    textTestList = textTest.split('\\n')\n",
    "    modelName = 'SymbolicGPT'\n",
    "    resultDict[fName] = {modelName:[]}\n",
    "    \n",
    "    for i, batch in enumerate(loader):\n",
    "        if extractAttributes:\n",
    "            x,y,p,m = batch\n",
    "        else:\n",
    "            x,y = batch\n",
    "        \n",
    "        print('Test Case {}.'.format(i))\n",
    "        o.write('Test Case {}/{}.\\n'.format(i,len(textTestList)))\n",
    "        \n",
    "        t = json.loads(textTestList[i])\n",
    "        \n",
    "        if model.pointNetConfig:\n",
    "            x = x[:,0:1].to(trainer.device)\n",
    "            p = [e.to(trainer.device) for e in p] if pointsAsList else p.to(trainer.device)\n",
    "            yHat = sample(model, x, block_size, points=p, \n",
    "                          temperature=1.0, sample=True, \n",
    "                          top_k=10)[0]\n",
    "        else:\n",
    "            sos_eq_loc = loc = (x == test_dataset.stoi['E']).nonzero(as_tuple=True) \n",
    "            # pass everything (x,y) to the model except the equations\n",
    "            x = x[:,:loc[1].item()+5].to(trainer.device)\n",
    "            #x = x[:,0:sos_eq_loc].to(trainer.device)\n",
    "            yHat = sample(model, x, block_size, points=None, \n",
    "                          temperature=1.0, sample=True, \n",
    "                          top_k=10)[0]\n",
    "            \n",
    "        # filter out predicted\n",
    "        target = ''.join([train_dataset.itos[int(i)] for i in y[0]])\n",
    "        predicted = ''.join([train_dataset.itos[int(i)] for i in yHat])\n",
    "        \n",
    "        #raise\n",
    "                \n",
    "        if extractAttributes:\n",
    "            target = target.strip(paddingToken).split('>')\n",
    "            target = target[0] if len(target[0])>1 else target[1]\n",
    "            target = target.strip('<').strip(\">\")\n",
    "            predicted = predicted.strip(paddingToken).split('>')\n",
    "            predicted = predicted[0] if len(predicted[0])>1 else predicted[1]\n",
    "            predicted = predicted.strip('<').strip(\">\")\n",
    "        else:\n",
    "            target = target[loc[1].item()+5:].split('>')[0]\n",
    "            predicted = predicted[loc[1].item()+5+1:].split('>')[0]\n",
    "            target = target.strip(paddingToken).strip('<').strip(\">\")\n",
    "            predicted = predicted.strip(paddingToken).strip('<').strip(\">\")\n",
    "            \n",
    "        \n",
    "\n",
    "        o.write('{}\\n'.format(target))\n",
    "        \n",
    "        print('Target:{}\\nPredicted:{}'.format(target, predicted))\n",
    "        \n",
    "        Ys = [] #t['YT']\n",
    "        Yhats = []\n",
    "        for xs in t['XT']:\n",
    "            try:\n",
    "                eqTmp = target + '' # copy eq\n",
    "                eqTmp = eqTmp.replace(' ','')\n",
    "                eqTmp = eqTmp.replace('\\n','')\n",
    "                for i,x in enumerate(xs):\n",
    "                    # replace xi with the value in the eq\n",
    "                    eqTmp = eqTmp.replace('x{}'.format(i+1), str(x))\n",
    "                    if ',' in eqTmp:\n",
    "                        assert 'There is a , in the equation!'\n",
    "                YEval = eval(eqTmp)\n",
    "                YEval = 0 if np.isnan(YEval) else YEval\n",
    "                YEval = 100 if np.isinf(YEval) else YEval\n",
    "            except:\n",
    "                YEval = 100 #TODO: Maybe I have to punish the model for each wrong template\n",
    "            Ys.append(YEval)\n",
    "            try:\n",
    "                eqTmp = predicted + '' # copy eq\n",
    "                eqTmp = eqTmp.replace(' ','')\n",
    "                eqTmp = eqTmp.replace('\\n','')\n",
    "                for i,x in enumerate(xs):\n",
    "                    # replace xi with the value in the eq\n",
    "                    eqTmp = eqTmp.replace('x{}'.format(i+1), str(x))\n",
    "                    if ',' in eqTmp:\n",
    "                        assert 'There is a , in the equation!'\n",
    "                Yhat = eval(eqTmp)\n",
    "                Yhat = 0 if np.isnan(Yhat) else Yhat\n",
    "                Yhat = 100 if np.isinf(Yhat) else Yhat\n",
    "            except:\n",
    "                Yhat = 100\n",
    "            Yhats.append(Yhat)\n",
    "        mseErr = mse(Ys,Yhats)\n",
    "        \n",
    "        if type(mseErr) is np.complex128:\n",
    "            mseErr = mseErr.real\n",
    "        #elif mseErr < 0.00005: # to handle negative infinity, and log 0\n",
    "        #    mseErr = 0.00005\n",
    "            \n",
    "        resultDict[fName][modelName].append(mseErr)\n",
    "        \n",
    "        o.write('{}:{}\\n{}\\n\\n'.format(modelName, \n",
    "                               mseErr,\n",
    "                               predicted))\n",
    "        \n",
    "        print('MSE:{}\\n'.format(mseErr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3e018c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Avg MSE:{}'.format(np.mean(resultDict[fName][modelName])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fd5a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86533ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f46c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccaf785",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target.strip(paddingToken).strip(\"'\").split('\"')\n",
    "target = target[0] if len(target[0])>1 else target[1]\n",
    "target = target.strip('\"')\n",
    "predicted = predicted.strip(\"'\").strip(paddingToken).split('\"')\n",
    "predicted = predicted[0] if len(predicted[0])>1 else predicted[1]\n",
    "predicted = predicted.strip('\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d01c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ad31bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672dd4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the GP and MLP if it's available\n",
    "# expPath = 'C:/Users/vpcom/OneDrive - University of Waterloo/Projects/symbolicgpt2/Experiments/OLD/'\n",
    "# expFile = 'test_1var_simple_mesh_GPT2_XYSorted_1024_88000.out'\n",
    "\n",
    "# with open(expPath+expFile, 'r') as f:\n",
    "#     resultDict[fName]['GP'] = []\n",
    "#     lines = f.readlines()\n",
    "#     for line in lines:\n",
    "#         filt = 'GP: '\n",
    "#         if filt in line:\n",
    "#             # save the error\n",
    "#             err = float(line.split(filt)[1].strip('\\n'))\n",
    "#             resultDict[fName]['GP'].append(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9796d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the error frequency for model comparison\n",
    "from matplotlib import pyplot as plt\n",
    "num_eqns = len(resultDict[fName]['SymbolicGPT'])\n",
    "num_vars = pconf.numberofVars\n",
    "\n",
    "models = list(resultDict[fName].keys())\n",
    "lists_of_error_scores = [resultDict[fName][key] for key in models]\n",
    "linestyles = [\"-\",\"dashdot\",\"dotted\",\"--\"]\n",
    "\n",
    "eps = 0.00001\n",
    "y, x, _ = plt.hist([np.log([max(min(x+eps, 100000),1e-5) for x in e]) for e in lists_of_error_scores],\n",
    "                   label=models,\n",
    "                   cumulative=True, \n",
    "                   histtype=\"step\", \n",
    "                   bins=2000, \n",
    "                   density=\"true\")\n",
    "y = np.expand_dims(y,0)\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for idx, m in enumerate(models): \n",
    "    plt.plot(x[:-1], \n",
    "           y[idx] * 100, \n",
    "           linestyle=linestyles[idx], \n",
    "           label=m)\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.title(\"{} equations of {} variables\".format(num_eqns, num_vars))\n",
    "plt.xlabel(\"Log of Mean Square Error\")\n",
    "plt.ylabel(\"Normalized Cumulative Frequency\")\n",
    "\n",
    "name = '{}.png'.format(fName)\n",
    "plt.savefig(name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
