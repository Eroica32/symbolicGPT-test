{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make deterministic\n",
    "from mingpt.utils import set_seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "embeddingSize=504\n",
    "numPoints=30 # number of points that we are going to receive to make a prediction about f given x and y\n",
    "numVars=1 # the dimenstion of input points x\n",
    "numYs=1 # the dimension of output points y = f(x)\n",
    "blockSize = 60 # spatial extent of the model for its context\n",
    "batchSize = 256\n",
    "dataInfo = 'Mesh_XYSorted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CharDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, block_size, chars):\n",
    "        data_size, vocab_size = len(data), len(chars)\n",
    "        print('data has %d examples, %d unique.' % (data_size, vocab_size))\n",
    "        \n",
    "        self.stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "        self.itos = { i:ch for i,ch in enumerate(chars) }\n",
    "        \n",
    "        # padding token\n",
    "        self.paddingToken = '_'\n",
    "        self.paddingID = self.stoi[self.paddingToken]\n",
    "        self.stoi[self.paddingToken] = self.paddingID\n",
    "        self.itos[self.paddingID] = self.paddingToken\n",
    "        self.threshold = [-1000,1000]\n",
    "        \n",
    "        self.block_size = block_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.data = data # it should be a list of examples\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # grab an example from the data\n",
    "        chunk = self.data[idx] # sequence of tokens including x, y, eq, etc.\n",
    "        chunk = json.loads(chunk) # convert the sequence tokens to a dictionary\n",
    "        \n",
    "        # encode every character in the equation to an integer\n",
    "        # < is SOS, > is EOS\n",
    "        dix = [self.stoi[s] for s in '<'+chunk['EQ']+'>']\n",
    "        inputs = dix[:-1]\n",
    "        outputs = dix[1:]\n",
    "        \n",
    "        # add the padding to the equations\n",
    "        paddingSize = max(self.block_size-len(inputs),0)\n",
    "        paddingList = [self.paddingID]*paddingSize\n",
    "        inputs += paddingList\n",
    "        outputs += paddingList        \n",
    "        \n",
    "        # extract points from the input sequence\n",
    "        points = torch.zeros(numVars+numYs, numPoints)\n",
    "        for idx, xy in enumerate(zip(chunk['X'], chunk['Y'])):\n",
    "            x = xy[0] + [0]*(max(numVars-len(xy[0]),0)) # padding\n",
    "            y = [xy[1]] if type(xy[1])== float else xy[1]\n",
    "            y = y + [0]*(max(numYs-len(y),0)) # padding\n",
    "            p = x+y # because it is only one point \n",
    "            p = torch.tensor(p)\n",
    "            #replace nan and inf\n",
    "            p = torch.nan_to_num(p, nan=0.0, \n",
    "                                 posinf=self.threshold[1], \n",
    "                                 neginf=self.threshold[0])\n",
    "            points[:,idx] = p\n",
    "        \n",
    "        \"\"\"\n",
    "        arrange data and targets so that the first i elements of x\n",
    "        will be asked to predict the i-th element of y. Notice that\n",
    "        the eventual language model will actually make block_size\n",
    "        individual predictions at the same time based on this data,\n",
    "        so we are being clever and amortizing the cost of the forward\n",
    "        pass of the network. So for example if block_size is 4, then\n",
    "        we could e.g. sample a chunk of text \"hello\", the integers in\n",
    "        x will correspond to \"hell\" and in y will be \"ello\". This will\n",
    "        then actually \"multitask\" 4 separate examples at the same time\n",
    "        in the language model:\n",
    "        - given just \"h\", please predict \"e\" as next\n",
    "        - given \"he\" please predict \"l\" next\n",
    "        - given \"hel\" predict \"l\" next\n",
    "        - given \"hell\" predict \"o\" next\n",
    "        \n",
    "        In addition, because the DataLoader will create batches of examples,\n",
    "        every forward/backward pass during traning will simultaneously train\n",
    "        a LOT of predictions, amortizing a lot of computation. In particular,\n",
    "        for a batched input of integers X (B, T) where B is batch size and\n",
    "        T is block_size and Y (B, T), the network will during training be\n",
    "        simultaneously training to make B*T predictions, all at once! Of course,\n",
    "        at test time we can paralellize across batch B, but unlike during training\n",
    "        we cannot parallelize across the time dimension T - we have to run\n",
    "        a forward pass of the network to recover the next single character of the \n",
    "        sequence along each batch dimension, and repeatedly always feed in a next\n",
    "        character to get the next one.\n",
    "        \n",
    "        So yes there is a big asymmetry between train/test time of autoregressive\n",
    "        models. During training we can go B*T at a time with every forward pass,\n",
    "        but during test time we can only go B at a time, T times, with T forward \n",
    "        passes.\n",
    "        \"\"\"\n",
    "        inputs = torch.tensor(inputs, dtype=torch.long)\n",
    "        outputs = torch.tensor(outputs, dtype=torch.long)\n",
    "        return inputs, outputs, points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "def processDataFiles(files):\n",
    "    text = ''\"\"\n",
    "    for f in tqdm(files):\n",
    "        with open(f, 'r') as h: \n",
    "            lines = h.read() # don't worry we won't run out of file handles\n",
    "            text += lines #json.loads(line)                \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:10<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 5000001 examples, 47 unique.\n"
     ]
    }
   ],
   "source": [
    "path = 'D:\\Datasets\\Symbolic Dataset\\Datasets\\Mesh_Simple_GPT2_Sorted\\TrainDatasetFixed\\*.json'\n",
    "files = glob.glob(path)\n",
    "text = processDataFiles(files)\n",
    "chars = sorted(list(set(text))+['_','T','<','>']) # extract unique characters from the text before converting the text to a list\n",
    "# T is for the test data\n",
    "text = text.split('\\n') # convert the raw text to a set of examples\n",
    "train_dataset = CharDataset(text, blockSize, chars) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:tensor([22, 42, 35, 38,  3, 42, 40, 41, 43,  3, 44, 12,  4,  4, 33, 33, 33, 33,\n",
      "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
      "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
      "        33, 33, 33, 33, 33, 33])\n",
      "id:1692743\n",
      "inputs:<sin(sqrt(x1))______________________________________________\n",
      "outputs:sin(sqrt(x1))>______________________________________________\n",
      "points:tensor([[0.0000, 0.1000, 0.2100, 0.3100, 0.4100, 0.5200, 0.6200, 0.7200, 0.8300,\n",
      "         0.9300, 1.0300, 1.1400, 1.2400, 1.3400, 1.4500, 1.5500, 1.6600, 1.7600,\n",
      "         1.8600, 1.9700, 2.0700, 2.9000, 3.0000, 2.1700, 2.2800, 2.3800, 2.4800,\n",
      "         2.5900, 2.6900, 2.7900],\n",
      "        [0.0000, 0.3100, 0.4400, 0.5300, 0.6000, 0.6600, 0.7100, 0.7500, 0.7900,\n",
      "         0.8200, 0.8500, 0.8800, 0.9000, 0.9200, 0.9300, 0.9500, 0.9600, 0.9700,\n",
      "         0.9800, 0.9900, 0.9900, 0.9900, 0.9900, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(train_dataset.__len__())\n",
    "inputs, outputs, points = train_dataset.__getitem__(idx)\n",
    "print('inputs:{}'.format(inputs))\n",
    "inputs = ''.join([train_dataset.itos[int(i)] for i in inputs])\n",
    "outputs = ''.join([train_dataset.itos[int(i)] for i in outputs])\n",
    "print('id:{}\\ninputs:{}\\noutputs:{}\\npoints:{}'.format(idx,inputs,outputs,points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 334.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 1001 examples, 47 unique.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path = 'D:\\Datasets\\Symbolic Dataset\\Datasets\\Mesh_Simple_GPT2_Sorted\\TestDataset\\*.json'\n",
    "files = glob.glob(path)\n",
    "textTest = processDataFiles([files[0]])\n",
    "textTest = textTest.split('\\n') # convert the raw text to a set of examples\n",
    "test_dataset = CharDataset(textTest, blockSize, chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id:700\n",
      "inputs:<0.73*sqrt(-x1**2)__________________________________________\n",
      "outputs:0.73*sqrt(-x1**2)>__________________________________________\n",
      "points:tensor([[0.0000, 0.1000, 0.2100, 0.3100, 0.4100, 0.5200, 0.6200, 0.7200, 0.8300,\n",
      "         0.9300, 1.0300, 1.1400, 1.2400, 1.3400, 1.4500, 1.5500, 1.6600, 1.7600,\n",
      "         1.8600, 1.9700, 2.0700, 2.1700, 2.2800, 2.3800, 2.4800, 2.5900, 2.6900,\n",
      "         2.7900, 2.9000, 3.0000],\n",
      "        [0.0000, 0.0700, 0.1500, 0.2300, 0.3000, 0.3800, 0.4600, 0.5300, 0.6100,\n",
      "         0.6800, 0.7600, 0.8400, 0.9100, 0.9800, 1.0700, 1.1400, 1.2200, 1.2900,\n",
      "         1.3700, 1.4500, 1.5200, 1.5900, 1.6700, 1.7500, 1.8200, 1.9000, 1.9800,\n",
      "         2.0500, 2.1300, 2.2000]])\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(test_dataset.__len__())\n",
    "inputs, outputs, points = train_dataset.__getitem__(idx)\n",
    "    \n",
    "inputs = ''.join([train_dataset.itos[int(i)] for i in inputs])\n",
    "outputs = ''.join([train_dataset.itos[int(i)] for i in outputs])\n",
    "print('id:{}\\ninputs:{}\\noutputs:{}\\npoints:{}'.format(idx,inputs,outputs,points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/19/2021 01:16:34 - INFO - mingpt.model -   number of parameters: 2.529894e+07\n"
     ]
    }
   ],
   "source": [
    "from mingpt.model import GPT, GPTConfig\n",
    "mconf = GPTConfig(train_dataset.vocab_size, train_dataset.block_size,\n",
    "                  n_layer=8, n_head=8, n_embd=512, padding_idx=train_dataset.paddingID)\n",
    "model = GPT(mconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 47: train loss 0.79919. lr 5.999978e-06:   0%|                       | 48/19532 [00:20<2:17:43,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from mingpt.trainer import Trainer, TrainerConfig\n",
    "\n",
    "# initialize a trainer instance and kick off training\n",
    "tconf = TrainerConfig(max_epochs=2, batch_size=batchSize, learning_rate=6e-6,\n",
    "                      lr_decay=True, warmup_tokens=512*20, final_tokens=2*len(train_dataset)*blockSize,\n",
    "                      num_workers=0, ckpt_path='./SavedModels/bestModel/checkpoint.pt')\n",
    "trainer = Trainer(model, train_dataset, test_dataset, tconf)\n",
    "\n",
    "try:\n",
    "    trainer.train()\n",
    "except KeyboardInterrupt:\n",
    "    print('KeyboardInterrupt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a safe wrapper for numpy math functions\n",
    "from numpy import *\n",
    "import numpy as np\n",
    "\n",
    "def divide(x, y):\n",
    "  x = np.nan_to_num(x)\n",
    "  y = np.nan_to_num(y)\n",
    "  return np.divide(x,y+1e-5)\n",
    "\n",
    "def sqrt(x):\n",
    "  x = np.nan_to_num(x)\n",
    "  return np.sqrt(np.abs(x)) \n",
    "\n",
    "# Mean square error\n",
    "def mse(y, y_hat):\n",
    "    y_hat = np.reshape(y_hat, [1, -1])[0]\n",
    "    y_gold = np.reshape(y, [1, -1])[0]\n",
    "    our_sum = 0\n",
    "    for i in range(len(y_gold)):\n",
    "        our_sum += (y_hat[i] - y_gold[i]) ** 2\n",
    "\n",
    "    return our_sum / len(y_gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fName = '{}_SymbolicGPT_{}_{}_{}.txt'.format(dataInfo, \n",
    "                                             'GPTRAWEQ', \n",
    "                                             'Padding',\n",
    "                                             blockSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case 0.\n",
      "Target:-sin(1.1*x1+0.64)\n",
      "Predicted:sqrt(-sin(0.3*x1))\n",
      "MSE:0.778124934902231\n",
      "\n",
      "Test Case 1.\n",
      "Target:-1.42*x1+sqrt(x1+0.53)\n",
      "Predicted:0.85*sqrt(x1**2+0.52*x1)\n",
      "MSE:71.99488528437138\n",
      "\n",
      "Test Case 2.\n",
      "Target:sqrt(-sin(0.2*x1))\n",
      "Predicted:0.28*x1**2+sin(0.73*x1)\n",
      "MSE:27.408434818121684\n",
      "\n",
      "Test Case 3.\n",
      "Target:sin(sqrt(x1))\n",
      "Predicted:sqrt(x1**2)\n",
      "MSE:14.754285680325067\n",
      "\n",
      "Test Case 4.\n",
      "Target:0.86*x1**2-0.59*x1+1.36\n",
      "Predicted:sin(sin(x1+0.74))\n",
      "MSE:345.553567173615\n",
      "\n",
      "Test Case 5.\n",
      "Target:0.28*sqrt(-x1**2)\n",
      "Predicted:0.61*sqrt(x1)\n",
      "MSE:0.014295335700979857\n",
      "\n",
      "Test Case 6.\n",
      "Target:sin(0.07*x1**2+0.28*x1)\n",
      "Predicted:0.64*x1**2+0.18*x1\n",
      "MSE:238.09210116644783\n",
      "\n",
      "Test Case 7.\n",
      "Target:sin(x1)\n",
      "Predicted:0.87*x1**(1/4)\n",
      "MSE:3.8078208783262633\n",
      "\n",
      "Test Case 8.\n",
      "Target:0.81*sqrt(-x1**2-0.95*x1+0.12)\n",
      "Predicted:-sin(0.29*x1**2-0.22*x1)\n",
      "MSE:17.87784156061148\n",
      "\n",
      "Test Case 9.\n",
      "Target:sin(x1+0.37)\n",
      "Predicted:sin(sqrt(x1))\n",
      "MSE:2.348341143969906\n",
      "\n",
      "Test Case 10.\n",
      "Target:-0.68*x1**2+1.77*x1\n",
      "Predicted:sqrt(x1)\n",
      "MSE:91.36939809002749\n",
      "\n",
      "Test Case 11.\n",
      "Target:sqrt(x1)+0.51*x1**2-0.17*x1\n",
      "Predicted:0.21*x1**3+0.13*x1+sin(0.39*x1)\n",
      "MSE:183.13484722733284\n",
      "\n",
      "Test Case 12.\n",
      "Target:1.25*x1+0.85*sqrt(-0.68*x1-1)\n",
      "Predicted:2*x1\n",
      "MSE:3.155858616654873\n",
      "\n",
      "Test Case 13.\n",
      "Target:sin(x1**2-0.11*x1)\n",
      "Predicted:-0.4*x1**2+0.07*x1+0.29\n",
      "MSE:73.46907860279022\n",
      "\n",
      "Test Case 14.\n",
      "Target:0.7*sqrt(x1-0.51)\n",
      "Predicted:sin(x1-1.05)\n",
      "MSE:3.3118431871724447\n",
      "\n",
      "Test Case 15.\n",
      "Target:sqrt(x1**2+0.31*x1)\n",
      "Predicted:-0.84*x1\n",
      "MSE:75.20258460376515\n",
      "\n",
      "Test Case 16.\n",
      "Target:4*x1-0.25\n",
      "Predicted:-sin(0.26*x1)\n",
      "MSE:367.99049838762824\n",
      "\n",
      "Test Case 17.\n",
      "Target:1.64*x1**2-0.31*x1-0.13\n",
      "Predicted:0.21*x1**2-0.14*x1+sin(x1)\n",
      "MSE:1052.4241864116275\n",
      "\n",
      "Test Case 18.\n",
      "Target:sqrt(-sin(0.37*x1-0.65))\n",
      "Predicted:sin(x1)\n",
      "MSE:2.552064025561268\n",
      "\n",
      "Test Case 19.\n",
      "Target:1.48*x1**2+0.55\n",
      "Predicted:2*x1+0.79\n",
      "MSE:601.6462593653333\n",
      "\n",
      "Test Case 20.\n",
      "Target:0.56*x1**2+0.69*x1+0.82\n",
      "Predicted:sqrt(x1)*sqrt(x1+0.36)\n",
      "MSE:143.76725365973778\n",
      "\n",
      "Test Case 21.\n",
      "Target:0.93*sqrt(0.62*x1+1)\n",
      "Predicted:-0.61*x1-0.13\n",
      "MSE:22.698399922667996\n",
      "\n",
      "Test Case 22.\n",
      "Target:2*x1+sin(x1)-0.89\n",
      "Predicted:0.08*x1**2+0.94*x1\n",
      "MSE:2.5176443002920497\n",
      "\n",
      "Test Case 23.\n",
      "Target:0.93*x1*sin(0.85*x1+0.49)\n",
      "Predicted:x1**2\n",
      "MSE:690.2898756575865\n",
      "\n",
      "Test Case 24.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-87f53acd8193>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m         outputsHat = sample(model, inputs, blockSize,\n\u001b[0;32m     36\u001b[0m                       \u001b[0mtemperature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m                       top_k=10)[0]\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;31m# filter out predicted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - University of Waterloo\\Projects\\symbolicgpt2\\mingpt\\utils.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(model, x, steps, temperature, sample, top_k)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mx_cond\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mblock_size\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mblock_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# crop context if needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_cond\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[1;31m# pluck the logits at the final step and scale by temperature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - University of Waterloo\\Projects\\symbolicgpt2\\mingpt\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, idx, targets, tokenizer)\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[0mposition_embeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_emb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# each position maps to a (learnable) vector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken_embeddings\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mposition_embeddings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mln_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - University of Waterloo\\Projects\\symbolicgpt2\\mingpt\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mln1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mln2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - University of Waterloo\\Projects\\symbolicgpt2\\mingpt\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, layer_past)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;31m# output projection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresid_drop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1751\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1752\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1753\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# alright, let's sample some character-level symbolic GPT\n",
    "from mingpt.utils import sample\n",
    "#from gp_model import Genetic_Model\n",
    "#from mlp_model import MLP_Model\n",
    "    \n",
    "loader = torch.utils.data.DataLoader(\n",
    "                                test_dataset, \n",
    "                                shuffle=False, \n",
    "                                pin_memory=True,\n",
    "                                batch_size=1,\n",
    "                                num_workers=0)\n",
    "\n",
    "testRange = [3.1,6.0]\n",
    "numTestPoints = 10\n",
    "#test = np.linspace(3.1,6.0,numTestPoints)\n",
    "\n",
    "# gpm = Genetic_Model(n_jobs=-1)\n",
    "# mlp = MLP_Model()\n",
    "\n",
    "resultDict = {}\n",
    "with open(fName, 'w', encoding=\"utf-8\") as o:\n",
    "    modelName = 'SymbolicGPT'\n",
    "    resultDict[fName] = {modelName:[]}\n",
    "    \n",
    "    for i, batch in enumerate(loader):\n",
    "        inputs,outputs,points = batch\n",
    "        \n",
    "        print('Test Case {}.'.format(i))\n",
    "        o.write('Test Case {}/{}.\\n'.format(i,len(textTest)))\n",
    "        \n",
    "        t = json.loads(textTest[i])\n",
    "        \n",
    "        inputs = inputs[:,0:1].to(trainer.device)\n",
    "        points = points.to(trainer.device)\n",
    "        outputsHat = sample(model, inputs, blockSize,\n",
    "                      temperature=1.0, sample=True, \n",
    "                      top_k=10)[0]\n",
    "            \n",
    "        # filter out predicted\n",
    "        target = ''.join([train_dataset.itos[int(i)] for i in outputs[0]])\n",
    "        predicted = ''.join([train_dataset.itos[int(i)] for i in outputsHat])\n",
    "\n",
    "        target = target.strip(train_dataset.paddingToken).split('>')\n",
    "        target = target[0] if len(target[0])>1 else target[1]\n",
    "        target = target.strip('<').strip(\">\")\n",
    "        predicted = predicted.strip(train_dataset.paddingToken).split('>')\n",
    "        predicted = predicted[0] if len(predicted[0])>1 else predicted[1]\n",
    "        predicted = predicted.strip('<').strip(\">\")\n",
    "       \n",
    "        o.write('{}\\n'.format(target))\n",
    "        \n",
    "        print('Target:{}\\nPredicted:{}'.format(target, predicted))\n",
    "        \n",
    "        Ys = [] #t['YT']\n",
    "        Yhats = []\n",
    "        for xs in t['XT']:\n",
    "            try:\n",
    "                eqTmp = target + '' # copy eq\n",
    "                eqTmp = eqTmp.replace(' ','')\n",
    "                eqTmp = eqTmp.replace('\\n','')\n",
    "                for i,x in enumerate(xs):\n",
    "                    # replace xi with the value in the eq\n",
    "                    eqTmp = eqTmp.replace('x{}'.format(i+1), str(x))\n",
    "                    if ',' in eqTmp:\n",
    "                        assert 'There is a , in the equation!'\n",
    "                YEval = eval(eqTmp)\n",
    "                YEval = 0 if np.isnan(YEval) else YEval\n",
    "                YEval = 100 if np.isinf(YEval) else YEval\n",
    "            except:\n",
    "                YEval = 100 #TODO: Maybe I have to punish the model for each wrong template\n",
    "            Ys.append(YEval)\n",
    "            try:\n",
    "                eqTmp = predicted + '' # copy eq\n",
    "                eqTmp = eqTmp.replace(' ','')\n",
    "                eqTmp = eqTmp.replace('\\n','')\n",
    "                for i,x in enumerate(xs):\n",
    "                    # replace xi with the value in the eq\n",
    "                    eqTmp = eqTmp.replace('x{}'.format(i+1), str(x))\n",
    "                    if ',' in eqTmp:\n",
    "                        assert 'There is a , in the equation!'\n",
    "                Yhat = eval(eqTmp)\n",
    "                Yhat = 0 if np.isnan(Yhat) else Yhat\n",
    "                Yhat = 100 if np.isinf(Yhat) else Yhat\n",
    "            except:\n",
    "                Yhat = 100\n",
    "            Yhats.append(Yhat)\n",
    "        mseErr = mse(Ys,Yhats)\n",
    "        \n",
    "        if type(mseErr) is np.complex128:\n",
    "            mseErr = mseErr.real\n",
    "            \n",
    "        resultDict[fName][modelName].append(mseErr)\n",
    "        \n",
    "        o.write('{}:{}\\n{}\\n\\n'.format(modelName, \n",
    "                               mseErr,\n",
    "                               predicted))\n",
    "        \n",
    "        print('MSE:{}\\n'.format(mseErr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
