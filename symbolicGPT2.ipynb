{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "symbolicGPT2_1Var_Mine.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "75b1d39decf248f0bfc3948c45a8a8ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9ae13a824a28438082e7591175b0b68a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5d8c3be29ed84b05972070649eec786f",
              "IPY_MODEL_405057cecc244d198bf82313a2198a75"
            ]
          }
        },
        "9ae13a824a28438082e7591175b0b68a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5d8c3be29ed84b05972070649eec786f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_827cf30c443a442c867fc8f3616ba9fe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_08aafcad0e434cd78d66369c3c695b6c"
          }
        },
        "405057cecc244d198bf82313a2198a75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_88da38f6587f4e25abcdf02f39f9b6be",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1000/? [12:28:54&lt;00:00, 44.93s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6b057647e72f4887841cf9933ee581e6"
          }
        },
        "827cf30c443a442c867fc8f3616ba9fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "08aafcad0e434cd78d66369c3c695b6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "88da38f6587f4e25abcdf02f39f9b6be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6b057647e72f4887841cf9933ee581e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4sQPcK9YNLC",
        "outputId": "6ea7a9e0-8f9a-445c-958a-f791ae1b89f2"
      },
      "source": [
        "# install libraries and other requirements\n",
        "!pip install -I tensorflow-gpu==2.3.1 &> tmp.log #1.15.2\n",
        "!pip install tokenizers\n",
        "!pip install wrapt_timeout_decorator \n",
        "!pip install gplearn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tokenizers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 16.3MB/s \n",
            "\u001b[?25hInstalling collected packages: tokenizers\n",
            "Successfully installed tokenizers-0.10.2\n",
            "Collecting wrapt_timeout_decorator\n",
            "  Downloading https://files.pythonhosted.org/packages/86/01/a749e2119a3b1917698de50ef9338b008dd3fe7f4dae0735fac73c155e2a/wrapt_timeout_decorator-1.3.1-py3-none-any.whl\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.7/dist-packages (from wrapt_timeout_decorator) (1.12.1)\n",
            "Requirement already satisfied: pathlib in /usr/local/lib/python3.7/dist-packages (from wrapt_timeout_decorator) (1.0.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from wrapt_timeout_decorator) (0.3.3)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from wrapt_timeout_decorator) (0.70.11.1)\n",
            "Installing collected packages: wrapt-timeout-decorator\n",
            "Successfully installed wrapt-timeout-decorator-1.3.1\n",
            "Collecting gplearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/6b/ee38cd74b32ad5056603aabbef622f9691f19d0869574dfc610034f18662/gplearn-0.4.1-py3-none-any.whl (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.13.0 in /usr/local/lib/python3.7/dist-packages (from gplearn) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from gplearn) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->gplearn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->gplearn) (1.19.5)\n",
            "Installing collected packages: gplearn\n",
            "Successfully installed gplearn-0.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlzbAbvgYUGm",
        "outputId": "8444f950-10e2-46a4-dbc7-f62f092e1dfb"
      },
      "source": [
        "# download weights and codes\n",
        "import os\n",
        "!git clone https://m5valipo:1ezHio5Rff6y-GET5drm@git.uwaterloo.ca/data-analytics-lab/symbolicgpt2.git\n",
        "%cd symbolicgpt2/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'symbolicgpt2'...\n",
            "remote: Enumerating objects: 203, done.\u001b[K\n",
            "remote: Counting objects: 100% (203/203), done.\u001b[K\n",
            "remote: Compressing objects: 100% (119/119), done.\u001b[K\n",
            "remote: Total 353 (delta 111), reused 160 (delta 83), pack-reused 150\u001b[K\n",
            "Receiving objects: 100% (353/353), 1.90 MiB | 3.24 MiB/s, done.\n",
            "Resolving deltas: 100% (188/188), done.\n",
            "/content/symbolicgpt2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zO0SvIOvY16t",
        "outputId": "6359c58d-95ce-41e9-c360-0711bc2d355a"
      },
      "source": [
        "# upload the latest weights for the model\n",
        "!wget https://www.dropbox.com/s/78ci3h59nmlud5g/expSymbolic_Mesh_Simple_GPT2_256_base_model.ckpt-128000.data-00000-of-00001\n",
        "!wget https://www.dropbox.com/s/ukope902t62qcl1/expSymbolic_Mesh_Simple_GPT2_256_base_model.ckpt-128000.index\n",
        "!wget https://www.dropbox.com/s/r026187a7w0rz0s/expSymbolic_Mesh_Simple_GPT2_256_base_model.ckpt-128000.meta"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-19 22:13:07--  https://www.dropbox.com/s/78ci3h59nmlud5g/expSymbolic_Mesh_Simple_GPT2_256_base_model.ckpt-128000.data-00000-of-00001\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.18, 2620:100:6021:18::a27d:4112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/78ci3h59nmlud5g/expSymbolic_Mesh_Simple_GPT2_256_base_model.ckpt-128000.data-00000-of-00001 [following]\n",
            "--2021-04-19 22:13:08--  https://www.dropbox.com/s/raw/78ci3h59nmlud5g/expSymbolic_Mesh_Simple_GPT2_256_base_model.ckpt-128000.data-00000-of-00001\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc9ec1017c0e22e2ee4e0e61c13a.dl.dropboxusercontent.com/cd/0/inline/BM95nL-t7c30aZeWYY2P9iQuZb5033glQmI-lVCkPkl_Bu9lGF6abjBbnfV10dlenpdOCKr1OpCAFjSuqiOAw5X7MmOYzNiDGOp918LmUmDP1DfTe-y_kps9GM4oE0Omx8_QAk-onMlIiPLBVtGQ5y3O/file# [following]\n",
            "--2021-04-19 22:13:08--  https://uc9ec1017c0e22e2ee4e0e61c13a.dl.dropboxusercontent.com/cd/0/inline/BM95nL-t7c30aZeWYY2P9iQuZb5033glQmI-lVCkPkl_Bu9lGF6abjBbnfV10dlenpdOCKr1OpCAFjSuqiOAw5X7MmOYzNiDGOp918LmUmDP1DfTe-y_kps9GM4oE0Omx8_QAk-onMlIiPLBVtGQ5y3O/file\n",
            "Resolving uc9ec1017c0e22e2ee4e0e61c13a.dl.dropboxusercontent.com (uc9ec1017c0e22e2ee4e0e61c13a.dl.dropboxusercontent.com)... 162.125.65.15, 2620:100:6021:15::a27d:410f\n",
            "Connecting to uc9ec1017c0e22e2ee4e0e61c13a.dl.dropboxusercontent.com (uc9ec1017c0e22e2ee4e0e61c13a.dl.dropboxusercontent.com)|162.125.65.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BM9hoqm0I3FgsDBZob7bYyKYpaytIl4QLEDuFOjqeYb7ZVwG-ntO9R01JzsSMzNHddGMG4hUvgeavcfXOybxBjoEMLOac3msyiWYHhUx5q5P-ilaM7QgQCodHGWgAc-dyZTxgJvwRCtQeYBwpBudcxkr5qETqwdTNKFaOPOA4zOwFzOS-fJ14omkCaWkrovPQgvlya3n7UkgscQ_vVjKwQVZ-wQihJXVWkkuoxSMo1TEQKn_ZHpNsMrC_tKSHjUgro5AJ5bYNGPqzAWVkE5l3eIDM164wR9xz5B5NhOOoxTyX1fnjwZWGZqfKtv2cMw-Et71Log1xPnWE0agBPpkIVKhLBohB8rxuZJkJhSEgdnQAeIA_D_im8sT1U_NyImfmy4/file [following]\n",
            "--2021-04-19 22:13:09--  https://uc9ec1017c0e22e2ee4e0e61c13a.dl.dropboxusercontent.com/cd/0/inline2/BM9hoqm0I3FgsDBZob7bYyKYpaytIl4QLEDuFOjqeYb7ZVwG-ntO9R01JzsSMzNHddGMG4hUvgeavcfXOybxBjoEMLOac3msyiWYHhUx5q5P-ilaM7QgQCodHGWgAc-dyZTxgJvwRCtQeYBwpBudcxkr5qETqwdTNKFaOPOA4zOwFzOS-fJ14omkCaWkrovPQgvlya3n7UkgscQ_vVjKwQVZ-wQihJXVWkkuoxSMo1TEQKn_ZHpNsMrC_tKSHjUgro5AJ5bYNGPqzAWVkE5l3eIDM164wR9xz5B5NhOOoxTyX1fnjwZWGZqfKtv2cMw-Et71Log1xPnWE0agBPpkIVKhLBohB8rxuZJkJhSEgdnQAeIA_D_im8sT1U_NyImfmy4/file\n",
            "Reusing existing connection to uc9ec1017c0e22e2ee4e0e61c13a.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 996958592 (951M) [application/octet-stream]\n",
            "Saving to: ‘expSymbolic_Mesh_Simple_GPT2_256_base_model.ckpt-128000.data-00000-of-00001’\n",
            "\n",
            "expSymbolic_Mesh_Si 100%[===================>] 950.77M  21.8MB/s    in 48s     \n",
            "\n",
            "2021-04-19 22:13:57 (19.8 MB/s) - ‘expSymbolic_Mesh_Simple_GPT2_256_base_model.ckpt-128000.data-00000-of-00001’ saved [996958592/996958592]\n",
            "\n",
            "--2021-04-19 22:13:58--  https://www.dropbox.com/s/ukope902t62qcl1/expSymbolic_Mesh_Simple_GPT2_256_base_model.ckpt-128000.index\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.64.18, 2620:100:6021:18::a27d:4112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.64.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/ukope902t62qcl1/expSymbolic_Mesh_Simple_GPT2_256_base_model.ckpt-128000.index [following]\n",
            "--2021-04-19 22:13:58--  https://www.dropbox.com/s/raw/ukope902t62qcl1/expSymbolic_Mesh_Simple_GPT2_256_base_model.ckpt-128000.index\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uce2a2e407c3766b278ac4aba091.dl.dropboxusercontent.com/cd/0/inline/BM_B7Jsdf9Y7GNa54YAmPCxSdYfoPL_8b17aZVjwtWMVoEHK3kY9jxNCkKy-Yn876gEn2CAQz7qv0QWfB9FwYB71sghD_XkAhs06gbJzEUAI3OpJmQKqjyrNikqlektm7pBh015riBfZehYLeIUG1ahu/file# [following]\n",
            "--2021-04-19 22:13:58--  https://uce2a2e407c3766b278ac4aba091.dl.dropboxusercontent.com/cd/0/inline/BM_B7Jsdf9Y7GNa54YAmPCxSdYfoPL_8b17aZVjwtWMVoEHK3kY9jxNCkKy-Yn876gEn2CAQz7qv0QWfB9FwYB71sghD_XkAhs06gbJzEUAI3OpJmQKqjyrNikqlektm7pBh015riBfZehYLeIUG1ahu/file\n",
            "Resolving uce2a2e407c3766b278ac4aba091.dl.dropboxusercontent.com (uce2a2e407c3766b278ac4aba091.dl.dropboxusercontent.com)... 162.125.65.15, 2620:100:6021:15::a27d:410f\n",
            "Connecting to uce2a2e407c3766b278ac4aba091.dl.dropboxusercontent.com (uce2a2e407c3766b278ac4aba091.dl.dropboxusercontent.com)|162.125.65.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BM_-pcqweXXV3gJwta98Hlruz9jedzu6ALKwg7oiR-YzORzIi7bfHq0OEdUEEt21_o9EInVqzCo6mkyOL8VGP-w0nTUuzZc80Qvu8IJES9d3GtDs-RHtFd0bHJSCfHg7Jd3fHjkE9GXXWZM0uu3PgJNnyXyU-LPAOxOT3SKUh8g24nDy6lgIx93uCSrN994aRQIvasZSNjM30KrULEmtzEol0dMWe1i_xNQNu9bboIJtomdw7dBpDIZtlpnhEFmIPrawKQhj-oih5lk5nyZGMhkMEknQFLtyqMafQfdO-GennD6MkX1CHUvKLbVmn7H3uow9cD3X9OlMWKGGBf1yVOdIa5wYBBOc_MWFKe49DPTNy9tPEVqYn8SyPnf08VWaNQI/file [following]\n",
            "--2021-04-19 22:13:59--  https://uce2a2e407c3766b278ac4aba091.dl.dropboxusercontent.com/cd/0/inline2/BM_-pcqweXXV3gJwta98Hlruz9jedzu6ALKwg7oiR-YzORzIi7bfHq0OEdUEEt21_o9EInVqzCo6mkyOL8VGP-w0nTUuzZc80Qvu8IJES9d3GtDs-RHtFd0bHJSCfHg7Jd3fHjkE9GXXWZM0uu3PgJNnyXyU-LPAOxOT3SKUh8g24nDy6lgIx93uCSrN994aRQIvasZSNjM30KrULEmtzEol0dMWe1i_xNQNu9bboIJtomdw7dBpDIZtlpnhEFmIPrawKQhj-oih5lk5nyZGMhkMEknQFLtyqMafQfdO-GennD6MkX1CHUvKLbVmn7H3uow9cD3X9OlMWKGGBf1yVOdIa5wYBBOc_MWFKe49DPTNy9tPEVqYn8SyPnf08VWaNQI/file\n",
            "Reusing existing connection to uce2a2e407c3766b278ac4aba091.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10073 (9.8K) [application/octet-stream]\n",
            "Saving to: ‘expSymbolic_Mesh_Simple_GPT2_256_base_model.ckpt-128000.index’\n",
            "\n",
            "expSymbolic_Mesh_Si 100%[===================>]   9.84K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-04-19 22:13:59 (290 MB/s) - ‘expSymbolic_Mesh_Simple_GPT2_256_base_model.ckpt-128000.index’ saved [10073/10073]\n",
            "\n",
            "--2021-04-19 22:13:59--  https://www.dropbox.com/s/r026187a7w0rz0s/expSymbolic_Mesh_Simple_GPT2_256_base_model.ckpt-128000.meta\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.64.18, 2620:100:6027:18::a27d:4812\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.64.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/r026187a7w0rz0s/expSymbolic_Mesh_Simple_GPT2_256_base_model.ckpt-128000.meta [following]\n",
            "--2021-04-19 22:13:59--  https://www.dropbox.com/s/raw/r026187a7w0rz0s/expSymbolic_Mesh_Simple_GPT2_256_base_model.ckpt-128000.meta\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc592a58385270832d705512935f.dl.dropboxusercontent.com/cd/0/inline/BM8fXqdVi8HZKWZ7ffPPD0GFfQ_wBb9xOnquJ7wlnLQ62VaCup7UEP8-w8WndBiySvc9SPCSdqgo0133NuoA7_2b8N6lr_u3Fy_Hc2sqdfLkQM7-312Y1j-atXJcbOblORQY8OIIbAeRvHJrvFkBf2Yk/file# [following]\n",
            "--2021-04-19 22:14:00--  https://uc592a58385270832d705512935f.dl.dropboxusercontent.com/cd/0/inline/BM8fXqdVi8HZKWZ7ffPPD0GFfQ_wBb9xOnquJ7wlnLQ62VaCup7UEP8-w8WndBiySvc9SPCSdqgo0133NuoA7_2b8N6lr_u3Fy_Hc2sqdfLkQM7-312Y1j-atXJcbOblORQY8OIIbAeRvHJrvFkBf2Yk/file\n",
            "Resolving uc592a58385270832d705512935f.dl.dropboxusercontent.com (uc592a58385270832d705512935f.dl.dropboxusercontent.com)... 162.125.65.15, 2620:100:6021:15::a27d:410f\n",
            "Connecting to uc592a58385270832d705512935f.dl.dropboxusercontent.com (uc592a58385270832d705512935f.dl.dropboxusercontent.com)|162.125.65.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5123541 (4.9M) [text/plain]\n",
            "Saving to: ‘expSymbolic_Mesh_Simple_GPT2_256_base_model.ckpt-128000.meta’\n",
            "\n",
            "expSymbolic_Mesh_Si 100%[===================>]   4.89M  13.3MB/s    in 0.4s    \n",
            "\n",
            "2021-04-19 22:14:00 (13.3 MB/s) - ‘expSymbolic_Mesh_Simple_GPT2_256_base_model.ckpt-128000.meta’ saved [5123541/5123541]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7lFZQMRtZKZ",
        "outputId": "d3894f70-a88c-493d-e6e8-6b49de7aba61"
      },
      "source": [
        "# update code, pull the recent changes\n",
        "!git pull origin master"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From https://git.uwaterloo.ca/data-analytics-lab/symbolicgpt2\n",
            " * branch            master     -> FETCH_HEAD\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PLwh7oEo4ot"
      },
      "source": [
        "#!git reset --hard 3a4aed7c39cc33c6925ffdefea8c7ab7a164284d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XY0YoITHeGo0"
      },
      "source": [
        "# # generate data given an equation\n",
        "# import numpy as np\n",
        "# decimals = 2\n",
        "# supportPoints = np.linspace(0.1,3.1,30)\n",
        "# supportPoints = [[np.round(p,decimals)] for p in supportPoints]\n",
        "# nv = 1\n",
        "# Y = []\n",
        "# for x in supportPoints:\n",
        "#   formula = np.exp(np.sin(x[0])) + x[0] * 1.3 + 0.1\n",
        "#   formula = formula\n",
        "#   Y.append(np.round(formula,2))\n",
        "# # use this input:\n",
        "# print('<SOS_X>{}<EOS_X><SOS_Y>{}<EOS_Y><SOS_EQ>'.format(str(supportPoints), str(Y)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W6QmmThgzDy"
      },
      "source": [
        "# # validate results\n",
        "# #sin(x1 + 1.49)\n",
        "# from scipy.spatial import distance\n",
        "# YPred = []\n",
        "# for x in supportPoints:\n",
        "#   formula = np.cos(x) + np.sin(x) + 1.08 #np.sin(x[0] + 1.56)\n",
        "#   formula = formula#[0]\n",
        "#   YPred.append(np.round(formula,2))\n",
        "# # use this input:\n",
        "# print('<SOS_X>{}<EOS_X><SOS_Y>{}<EOS_Y><SOS_EQ>'.format(str(supportPoints), str(YPred)))\n",
        "# print(distance.euclidean(Y,YPred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sv6_MLAo7UcE"
      },
      "source": [
        "#cd symbolicgpt2/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldMWkMV3Y3h7"
      },
      "source": [
        "# #@title #Inference\n",
        "# min_len = 0 #@param {type:\"number\", min:5, max:1024, step:1}\n",
        "# sample_num = 1 #@param {type:\"number\", min:1, max:50, step:1}\n",
        "# top_p = 0.7 #@param {type:\"number\", min:0, max:1}\n",
        "# model_type = 'large' #@param {type:\"string\"}\n",
        "# extraName = '' #'-finetune'\n",
        "# config_fn = 'configs/{}.json'.format(model_type) #'lm/configs/{}.json'.format(model_type) #@param {type:\"string\"}\n",
        "# ckpt_fn = './experimentsSymbolic_{}{}_model.ckpt-188000'.format(model_type, extraName) #@param {type:\"string\"}\n",
        "# filters = '' #@param {type:\"string\"} # text;\n",
        "# saveFlag = False #@param {type:\"boolean\"}from scripts import demodemo.wraper(top_p, config_fn, ckpt_fn, min_len, sample_num, saveFlag, filters)\n",
        "\n",
        "# #from scripts import demo\n",
        "# import demo\n",
        "# demo.wraper(top_p, config_fn, ckpt_fn, min_len, sample_num, saveFlag, filters, context='user')\n",
        "\n",
        "# # Some cool Example As Input:\n",
        "\n",
        "# # <SOS_X>[[0.1], [0.2], [0.31], [0.41], [0.51], [0.62], [0.72], [0.82], [0.93], [1.03], [1.13], [1.24], [1.34], [1.44], [1.55], [1.65], [1.76], [1.86], [1.96], [2.07], [2.17], [2.27], [2.38], [2.48], [2.58], [2.69], [2.79], [2.89], [3.0], [3.1]]<EOS_X><SOS_Y>[-2.54, -1.97, -1.6, -1.34, -1.12, -0.89, -0.67, -0.45, -0.18, 0.08, 0.38, 0.74, 1.12, 1.54, 2.06, 2.61, 3.29, 3.99, 4.78, 5.77, 6.79, 7.93, 9.37, 10.85, 12.51, 14.58, 16.71, 19.1, 22.07, 25.11]<EOS_Y><SOS_EQ>exp(x1)*log(x1)<EOS_EQ>\n",
        "# # <SOS_X>[[0.1], [0.2], [0.31], [0.41], [0.51], [0.62], [0.72], [0.82], [0.93], [1.03], [1.13], [1.24], [1.34], [1.44], [1.55], [1.65], [1.76], [1.86], [1.96], [2.07], [2.17], [2.27], [2.38], [2.48], [2.58], [2.69], [2.79], [2.89], [3.0], [3.1]]<EOS_X><SOS_Y>[-2.31, -1.61, -1.17, -0.89, -0.67, -0.48, -0.33, -0.2, -0.07, 0.03, 0.12, 0.22, 0.29, 0.36, 0.44, 0.5, 0.57, 0.62, 0.67, 0.73, 0.77, 0.82, 0.87, 0.91, 0.95, 0.99, 1.03, 1.06, 1.1, 1.13]<EOS_Y><SOS_EQ>log(x1)<EOS_EQ>\n",
        "# # <SOS_X>[[0.1], [0.2], [0.31], [0.41], [0.51], [0.62], [0.72], [0.82], [0.93], [1.03], [1.13], [1.24], [1.34], [1.44], [1.55], [1.65], [1.76], [1.86], [1.96], [2.07], [2.17], [2.27], [2.38], [2.48], [2.58], [2.69], [2.79], [2.89], [3.0], [3.1]]<EOS_X><SOS_Y>[-2.1, -1.21, -0.55, -0.07, 0.35, 0.76, 1.11, 1.44, 1.79, 2.09, 2.38, 2.7, 2.97, 3.24, 3.54, 3.8, 4.09, 4.34, 4.59, 4.87, 5.11, 5.36, 5.63, 5.87, 6.11, 6.37, 6.61, 6.84, 7.1, 7.33]<EOS_Y><SOS_EQ>2*x1 + log(x1)<EOS_EQ>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtN25bVZl44J",
        "outputId": "677e4cb0-21fb-41da-c1f3-b25923614b8d"
      },
      "source": [
        "# load the test data\n",
        "!wget https://www.dropbox.com/sh/5e5f5cfs4tfknst/AAC-bYCki_HSw0YPaNrM6_FBa\n",
        "!unzip AAC-bYCki_HSw0YPaNrM6_FBa -d ./TestData/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-19 22:14:01--  https://www.dropbox.com/sh/5e5f5cfs4tfknst/AAC-bYCki_HSw0YPaNrM6_FBa\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.64.18, 2620:100:6027:18::a27d:4812\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.64.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /sh/raw/5e5f5cfs4tfknst/AAC-bYCki_HSw0YPaNrM6_FBa [following]\n",
            "--2021-04-19 22:14:02--  https://www.dropbox.com/sh/raw/5e5f5cfs4tfknst/AAC-bYCki_HSw0YPaNrM6_FBa\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc1c53f67d9c136ad01cd1cf9f01.dl.dropboxusercontent.com/zip_download_get/AwXJG3KmX7wm7lSi3eCLoRw-8XG72p7nD8R0q-VER8sBHZlNfqYonTWgvuhRhRO4I-jLGEmfJo2aT_rCr9YTsfyex_BRNjw9FbTF4c0FZ-rBow [following]\n",
            "--2021-04-19 22:14:02--  https://uc1c53f67d9c136ad01cd1cf9f01.dl.dropboxusercontent.com/zip_download_get/AwXJG3KmX7wm7lSi3eCLoRw-8XG72p7nD8R0q-VER8sBHZlNfqYonTWgvuhRhRO4I-jLGEmfJo2aT_rCr9YTsfyex_BRNjw9FbTF4c0FZ-rBow\n",
            "Resolving uc1c53f67d9c136ad01cd1cf9f01.dl.dropboxusercontent.com (uc1c53f67d9c136ad01cd1cf9f01.dl.dropboxusercontent.com)... 162.125.65.15, 2620:100:6027:15::a27d:480f\n",
            "Connecting to uc1c53f67d9c136ad01cd1cf9f01.dl.dropboxusercontent.com (uc1c53f67d9c136ad01cd1cf9f01.dl.dropboxusercontent.com)|162.125.65.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 902418 (881K) [application/zip]\n",
            "Saving to: ‘AAC-bYCki_HSw0YPaNrM6_FBa’\n",
            "\n",
            "AAC-bYCki_HSw0YPaNr 100%[===================>] 881.27K  --.-KB/s    in 0.09s   \n",
            "\n",
            "2021-04-19 22:14:03 (9.22 MB/s) - ‘AAC-bYCki_HSw0YPaNrM6_FBa’ saved [902418/902418]\n",
            "\n",
            "Archive:  AAC-bYCki_HSw0YPaNrM6_FBa\n",
            "warning:  stripped absolute path spec from /\n",
            "mapname:  conversion of  failed\n",
            " extracting: ./TestData/Test.json    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puaOnAlx9aPf"
      },
      "source": [
        "# import demo\n",
        "# result = demo.wraper(top_p, config_fn, ckpt_fn, min_len, sample_num, saveFlag, filters, context=['<SOS_EQ>','<SOS_X>'])\n",
        "# print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHa5bq3__2Rg"
      },
      "source": [
        "def cleanEquation(eq):\n",
        "  import re\n",
        "  eq = eq.replace('\\n','')\n",
        "  eq = re.sub(r'(?=)\\[.+?\\](?=)', '', eq) # remove anything between lists\n",
        "  eq = eq.replace(',','')\n",
        "  eq = eq.replace('<SOS_X>','')\n",
        "  eq = eq.replace('<EOS_X>','')\n",
        "  eq = eq.replace('<SOS_Y>','')\n",
        "  eq = eq.replace('<EOS_Y>','')\n",
        "  eq = eq.replace('<SOS_EQ>','')\n",
        "  eq = eq.replace('<EOS_EQ>','')\n",
        "  eq = eq.replace('<SOS_Skeleton>','')\n",
        "  eq = eq.replace('<EOS_Skeleton>','')\n",
        "  eq = eq.replace('[','')\n",
        "  eq = eq.replace(']','')\n",
        "  eq = eq.strip()\n",
        "  return eq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48YtMr2fIj_I"
      },
      "source": [
        "# Mean square error\n",
        "def mse(y, y_hat):\n",
        "    y_hat = np.reshape(y_hat, [1, -1])[0]\n",
        "    y_gold = np.reshape(y, [1, -1])[0]\n",
        "    our_sum = 0\n",
        "    for i in range(len(y_gold)):\n",
        "        our_sum += (y_hat[i] - y_gold[i]) ** 2\n",
        "\n",
        "    return our_sum / len(y_gold)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZIQ6Z0U_bpv"
      },
      "source": [
        "# add a safe wrapper for numpy math functions\n",
        "from numpy import *\n",
        "import numpy as np\n",
        "\n",
        "def divide(x, y):\n",
        "  x = np.nan_to_num(x)\n",
        "  y = np.nan_to_num(y)\n",
        "  return np.divide(x,y+1e-5)\n",
        "\n",
        "def sqrt(x):\n",
        "  x = np.nan_to_num(x)\n",
        "  return np.sqrt(np.abs(x)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "75b1d39decf248f0bfc3948c45a8a8ab",
            "9ae13a824a28438082e7591175b0b68a",
            "5d8c3be29ed84b05972070649eec786f",
            "405057cecc244d198bf82313a2198a75",
            "827cf30c443a442c867fc8f3616ba9fe",
            "08aafcad0e434cd78d66369c3c695b6c",
            "88da38f6587f4e25abcdf02f39f9b6be",
            "6b057647e72f4887841cf9933ee581e6"
          ]
        },
        "id": "pDqCmya4pto8",
        "outputId": "b880e554-c761-4fe8-b63a-f2a8987727ea"
      },
      "source": [
        "# calculate test error, show the real performance using a metric\n",
        "import re\n",
        "import json\n",
        "import math\n",
        "import demo\n",
        "from glob import glob\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# config\n",
        "show_found_eqns = True\n",
        "min_len = 0 #@param {type:\"number\", min:5, max:1024, step:1}\n",
        "sample_num = 1 #@param {type:\"number\", min:1, max:50, step:1}\n",
        "top_p = 0.95 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "model_size = 'base' # @param [\"large\", \"base\", \"mega\"]\n",
        "model_type = 'GPT2' # @param [\"GPT2\", \"PT\"]\n",
        "extraName = '' #'-finetune' \n",
        "#'lm/configs/{}.json'.format(model_type) \n",
        "config_fn = 'configs/{}.json'.format(model_size) #@param {type:\"string\"}\n",
        "#ckpt_fn = './expSymbolic_{}_{}{}_model.ckpt-524000'.format(model_type, model_size, extraName) #@param {type:\"string\"}\n",
        "#ckpt_fn = './experimentsSymbolic_{}_model.ckpt-524000'.format(model_size) #@param {type:\"string\"}\n",
        "ckpt_fn = 'expSymbolic_Mesh_Simple_GPT2_256_base_model.ckpt-128000'\n",
        "filters = 'EQ' #@param {type:\"string\"} # text;\n",
        "saveFlag = False #@param {type:\"boolean\"}\n",
        "\n",
        "resultDict = {}\n",
        "threshold = 1e5 # to handle inf or very big points\n",
        "\n",
        "for fName in glob('./TestData/*.json'):\n",
        "  print('Processing {}'.format(fName))\n",
        "  \n",
        "  if 'little' in fName:# or '0_1_0_02022021_164747.json' in fName:# or '0_5_4_02022021_164747.json' in fName: # This one was only for the development testing\n",
        "    continue\n",
        "\n",
        "  # outputName = './{}-var_{}.out'.format(re.findall(\n",
        "  #                                   r'_\\d_', fName.split(\n",
        "  #                                   '.json')[0].split(\n",
        "  #                                   '/')[-1])[0].strip('_'),\n",
        "  #                                   model_type)\n",
        "  outputName = './{}-var_{}.out'.format(\n",
        "                            fName.split('.json')[0],\n",
        "                            #re.findall(r'\\d', fName)[0],\n",
        "                            model_type\n",
        "                          )\n",
        "\n",
        "  with open(fName, 'r', encoding=\"utf-8\") as f, open(outputName, 'w', encoding=\"utf-8\") as o:\n",
        "    resultDict[fName] = {'GPT2':[],\n",
        "                         'MLP':[],\n",
        "                         'GP':[]}\n",
        "\n",
        "    lines = f.readlines()#[:10]\n",
        "    \n",
        "    # <SOS_X>{}<EOS_X>\n",
        "    context = ['<SOS_Y>{}<EOS_Y><SOS_EQ>'.format(\n",
        "        *(np.round(val,2).tolist() for key, val in json.loads(line).items(\n",
        "              ) if key == 'Y')) for line in lines]\n",
        "    print(context)\n",
        "    equations = demo.wraper(top_p, config_fn, ckpt_fn, min_len, sample_num, \n",
        "                            saveFlag, filters, context=context, \n",
        "                            modelType=model_type, max_num_points=30, \n",
        "                            max_num_vars=5)\n",
        "    \n",
        "    wrongEQCounter = 0\n",
        "    yPred = []\n",
        "    # compare results with other models\n",
        "    from gp_model import Genetic_Model\n",
        "    from mlp_model import MLP_Model\n",
        "\n",
        "    show_found_eqns = True\n",
        "    num_vars = 1\n",
        "    gpm = Genetic_Model(n_jobs=-1)\n",
        "    mlp = MLP_Model()\n",
        "\n",
        "    for idx, line in tqdm(enumerate(lines)):\n",
        "      print(\"Test case {}/{}.\".format(idx, len(lines)))\n",
        "      \n",
        "      # TODO: don't skip infinities\n",
        "      if \"Infinity\" in line or \"NaN\" in line: #or i < 134:\n",
        "        print('infinity or nan in input!')\n",
        "        continue\n",
        "\n",
        "      data = json.loads(line) # 50000 samples in each file\n",
        "\n",
        "      # run the model\n",
        "      #TODO: calculate the model output\n",
        "      #context = ['<SOS_X>{}<EOS_X><SOS_Y>{}<EOS_Y><SOS_EQ>'.format(data['X'],data['Y'])]\n",
        "      #YPred = demo.wraper(top_p, config_fn, ckpt_fn, min_len, sample_num, saveFlag, filters, context=context)\n",
        "\n",
        "      # use Y as target labels\n",
        "      Y = data['YT']\n",
        "\n",
        "      # Evaluate YPred & Extract predicted equation\n",
        "      eq = equations[idx]\n",
        "      eq = cleanEquation(eq)\n",
        "      yPred = []      \n",
        "      YN = []\n",
        "      YPredN = []\n",
        "      try:\n",
        "        # replace vars with values\n",
        "        for xs in data['XT']:\n",
        "          eqTmp = eq + '' # copy eq\n",
        "          eqTmp = eqTmp.replace(' ','')\n",
        "          eqTmp = eqTmp.replace('\\n','')\n",
        "          for i,x in enumerate(xs):\n",
        "            #print('x{}'.format(i+1),x)\n",
        "            # replace xi with the value in the eq\n",
        "            eqTmp = eqTmp.replace('x{}'.format(i+1), str(x))\n",
        "            if ',' in eqTmp:\n",
        "              assert 'There is a , in the equation!'\n",
        "          eqEvaluated = eval(eqTmp)\n",
        "          eqEvaluated = 0 if np.isnan(eqEvaluated) else eqEvaluated\n",
        "          eqEvaluated = 10000 if np.isinf(eqEvaluated) else eqEvaluated\n",
        "          yPred.append(eqEvaluated)\n",
        "        \n",
        "        # ignore inf, or NAN\n",
        "        for i, v in enumerate(Y):\n",
        "          if np.isinf(Y[i]) or np.isinf(yPred[i]):\n",
        "            continue\n",
        "          if np.isnan(Y[i]) or np.isnan(yPred[i]):\n",
        "            continue\n",
        "          YN.append(Y[i])\n",
        "          YPredN.append(yPred[i])\n",
        "          \n",
        "          # if not np.isnan(v): #float('nan'): # v < threshold and \n",
        "          #   if np.isinf(Y[i]):\n",
        "          #     YN.append(10000)\n",
        "          #   else:\n",
        "          #     YN.append(Y[i])\n",
        "\n",
        "          #   if np.isinf(yPred[i]):# yPred[i] == np.inf:\n",
        "          #     YPredN.append(10000)\n",
        "          #   else:\n",
        "          #     YPredN.append(yPred[i])\n",
        "      except Exception as e: #SyntaxError or AssertionError or NameError or TypeError:\n",
        "        print('{} \\n\\n Error: {}, EQ:{}'.format(TypeError, eqTmp, eq))\n",
        "        #TODO: Find a fair strategy, Resample/Ignore?!\n",
        "        #continue # ignore this sample\n",
        "        #yPred = np.zeros_like(Y) # no prediction\n",
        "        wrongEQCounter += 1\n",
        "\n",
        "      # ignore noisy samples with zero data on X & Y\n",
        "      if len(YN) == 0:\n",
        "        o.write('Test case {}/{}.\\n{}\\n{}: {}\\n{}\\n\\n'.format(\n",
        "          idx, len(lines),\n",
        "          data['EQ'],\n",
        "          model_type, \"Not calculated!\",\n",
        "          eq\n",
        "        ))\n",
        "        print('Not calculated')\n",
        "        continue\n",
        "\n",
        "      dict_line = eval(line)\n",
        "      print(\"True equation: {}\".format(dict_line[\"EQ\"]))\n",
        "\n",
        "      # calculate rmse between YPred and Y\n",
        "      #mseValue = np.log(mean_squared_error(YN,YPredN, squared=True))\n",
        "      model_err = mse(YN,YPredN)\n",
        "      test_err = max(np.exp(-10), model_err) \n",
        "\n",
        "      if show_found_eqns:\n",
        "          print(\"{} function:  {}\".format('GPT2', eq)[:550])\n",
        "\n",
        "      print(\" ---> {} Test Error: {:.5f}\".format('GPT2', test_err))\n",
        "\n",
        "      resultDict[fName]['GPT2'].append(test_err)\n",
        "      o.write('Test case {}/{}.\\n{}\\n{}: {}\\n{}'.format(\n",
        "          idx, len(lines),\n",
        "          data['EQ'],\n",
        "          model_type, test_err,\n",
        "          eq\n",
        "      ))\n",
        "\n",
        "      # tokenize to get input x, input y, and true eqn\n",
        "      train_data_x = dict_line[\"X\"]\n",
        "      train_data_y = dict_line[\"Y\"]\n",
        "      test_data_x = dict_line[\"XT\"]\n",
        "      test_data_y = dict_line[\"YT\"]\n",
        "      #print(\"{} training points, {} test points.\".format(len(train_data_x), len(test_data_x)))\n",
        "\n",
        "      # train MLP model\n",
        "      mlp.reset()\n",
        "      model_eqn, _, best_err = mlp.repeat_train(train_data_x, train_data_y,\n",
        "                                                test_x=test_data_x, test_y=test_data_y,                                     verbose=False)\n",
        "      if show_found_eqns:\n",
        "          print(\"{} function:  {}\".format(mlp.name, model_eqn)[:550])\n",
        "\n",
        "      # Test model on that equation\n",
        "      test_err = max(np.exp(-10), best_err)  # data_utils.test_from_formula(model_eqn, test_data_x, test_data_y)\n",
        "      print(\" ---> {} Test Error: {:.5f}\".format(mlp.short_name, test_err))\n",
        "\n",
        "      resultDict[fName]['MLP'].append(test_err)\n",
        "      o.write('\\n{}: {}\\n{}'.format('MLP', \n",
        "                                   test_err,\n",
        "                                   model_eqn))\n",
        "\n",
        "      # train GPL model\n",
        "      gpm.reset()\n",
        "      model_eqn, _, best_err = gpm.repeat_train(train_data_x, train_data_y,\n",
        "                                                test_x=test_data_x, test_y=test_data_y,\n",
        "                                                verbose=False)\n",
        "      if show_found_eqns:\n",
        "          print(\"{} function:  {}\".format(gpm.name, model_eqn)[:550])\n",
        "\n",
        "      # Test model on that equation\n",
        "      # test_err = model.test(test_data_x, test_data_y)\n",
        "      test_err = max(np.exp(-10), best_err)  # data_utils.test_from_formula(model_eqn, test_data_x, test_data_y)\n",
        "      print(\" ---> {} Test Error: {:.5f}\".format(gpm.short_name, test_err))\n",
        "\n",
        "      resultDict[fName]['GP'].append(test_err)\n",
        "      o.write('\\n{}: {}\\n{}'.format('GP', \n",
        "                                   test_err,\n",
        "                                   model_eqn))\n",
        "\n",
        "      # o.write('Test case {}/{}.\\n{}\\n{}: {}\\n{}\\n\\n'.format(\n",
        "      #     idx, len(lines),\n",
        "      #     data['Skeleton'],\n",
        "      #     model_type, mseValue,\n",
        "      #     eq\n",
        "      # ))\n",
        "\n",
        "      o.write('\\n\\n')\n",
        "\n",
        "    print('{} of {} equations have wrong structures!'.format(wrongEQCounter, len(lines)))\n",
        "    #break # for now just use one test file\n",
        "  from google.colab import files\n",
        "  files.download(outputName) "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing ./TestData/Test.json\n",
            "['<SOS_Y>[-0.6, -0.68, -0.77, -0.83, -0.89, -0.94, -0.97, -0.99, -1.0, -1.0, -0.98, -0.95, -0.91, -0.86, -0.79, -0.72, -0.63, -0.54, -0.44, -0.33, -0.23, -0.12, 0.0, 0.11, 0.22, 0.33, 0.44, 0.53, 0.63, 0.71]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.73, 0.65, 0.56, 0.48, 0.39, 0.29, 0.19, 0.1, -0.01, -0.11, -0.22, -0.33, -0.43, -0.54, -0.65, -0.76, -0.88, -0.99, -1.1, -1.22, -1.33, -1.44, -1.57, -1.68, -1.79, -1.92, -2.03, -2.15, -2.27, -2.39]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.14, 0.2, 0.25, 0.28, 0.32, 0.35, 0.38, 0.4, 0.43, 0.45, 0.47, 0.49, 0.51, 0.53, 0.55, 0.57, 0.58, 0.6, 0.61, 0.63, 0.64, 0.66, 0.67, 0.68, 0.7, 0.71, 0.72, 0.73, 0.75]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.31, 0.44, 0.53, 0.6, 0.66, 0.71, 0.75, 0.79, 0.82, 0.85, 0.88, 0.9, 0.92, 0.93, 0.95, 0.96, 0.97, 0.98, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 0.99]<EOS_Y><SOS_EQ>', '<SOS_Y>[1.36, 1.31, 1.28, 1.27, 1.27, 1.29, 1.33, 1.39, 1.47, 1.56, 1.67, 1.81, 1.95, 2.12, 2.31, 2.51, 2.75, 2.98, 3.23, 3.53, 3.82, 4.12, 4.48, 4.82, 5.17, 5.59, 5.98, 6.39, 6.86, 7.31]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.03, 0.06, 0.09, 0.11, 0.14, 0.17, 0.2, 0.23, 0.26, 0.28, 0.31, 0.34, 0.37, 0.4, 0.43, 0.46, 0.49, 0.51, 0.54, 0.57, 0.6, 0.63, 0.66, 0.68, 0.71, 0.74, 0.77, 0.8, 0.83]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.03, 0.06, 0.09, 0.13, 0.17, 0.2, 0.24, 0.28, 0.32, 0.36, 0.41, 0.45, 0.49, 0.54, 0.58, 0.63, 0.67, 0.71, 0.75, 0.79, 0.82, 0.86, 0.89, 0.92, 0.94, 0.96, 0.98, 0.99, 1.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.31, 0.4, 0.5, 0.58, 0.66, 0.74, 0.8, 0.86, 0.91, 0.95, 0.97, 0.99, 1.0, 1.0, 0.98, 0.96, 0.92, 0.88, 0.83, 0.76, 0.69, 0.61, 0.52, 0.44, 0.34, 0.24, 0.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.28, 0.09, 0.29, 0.42, 0.54, 0.65, 0.75, 0.84, 0.94, 1.03, 1.12, 1.21, 1.3, 1.39, 1.48, 1.56, 1.66, 1.74, 1.82, 1.91, 2.0, 2.08, 2.17, 2.25, 2.34, 2.43, 2.51, 2.59, 2.68, 2.76]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.36, 0.45, 0.55, 0.63, 0.7, 0.78, 0.84, 0.89, 0.93, 0.96, 0.99, 1.0, 1.0, 0.99, 0.97, 0.94, 0.9, 0.85, 0.79, 0.72, 0.65, 0.57, 0.47, 0.38, 0.29, 0.18, 0.08, -0.02, -0.13, -0.22]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.01, -0.02, -0.02, 0.0, 0.06, 0.16, 0.31, 0.55, 0.84, 1.22, 1.74, 2.33, 3.03, 3.94, 4.92, 6.16, 7.46, 8.92, 10.73, 12.58, 14.63, 17.13, 19.63, 22.36, 25.65, 28.9, 32.41, 36.59, 40.68]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.3, 0.44, 0.55, 0.66, 0.77, 0.88, 0.99, 1.12, 1.25, 1.38, 1.53, 1.68, 1.84, 2.03, 2.2, 2.41, 2.61, 2.81, 3.05, 3.27, 3.51, 3.77, 4.03, 4.29, 4.59, 4.87, 5.17, 5.5, 5.82]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.85, 1.0, 1.17, 1.32, 1.47, 1.64, 1.79, 1.93, 2.1, 2.25, 2.39, 2.55, 2.7, 2.85, 3.01, 3.15, 3.31, 3.46, 3.6, 3.76, 3.9, 4.05, 4.2, 4.35, 4.49, 4.65, 4.79, 4.93, 5.09, 5.23]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.0, 0.02, 0.06, 0.12, 0.21, 0.31, 0.42, 0.56, 0.69, 0.81, 0.92, 0.98, 1.0, 0.93, 0.79, 0.54, 0.24, -0.11, -0.49, -0.79, -0.97, -0.97, -0.78, -0.4, 0.13, 0.6, 0.93, 0.97, 0.69]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.5, 0.45, 0.38, 0.31, 0.22, 0.07, 0.23, 0.32, 0.39, 0.45, 0.5, 0.55, 0.6, 0.63, 0.68, 0.71, 0.75, 0.78, 0.81, 0.84, 0.87, 0.9, 0.93, 0.95, 0.98, 1.0, 1.03, 1.05, 1.08, 1.1]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.2, 0.33, 0.44, 0.54, 0.66, 0.76, 0.86, 0.97, 1.07, 1.18, 1.29, 1.39, 1.49, 1.6, 1.7, 1.81, 1.91, 2.01, 2.12, 2.22, 2.32, 2.43, 2.53, 2.63, 2.74, 2.84, 2.94, 3.05, 3.15]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.25, 0.15, 0.59, 0.99, 1.39, 1.83, 2.23, 2.63, 3.07, 3.47, 3.87, 4.31, 4.71, 5.11, 5.55, 5.95, 6.39, 6.79, 7.19, 7.63, 8.03, 8.43, 8.87, 9.27, 9.67, 10.11, 10.51, 10.91, 11.35, 11.75]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.13, -0.15, -0.13, -0.07, 0.02, 0.15, 0.31, 0.49, 0.74, 1.0, 1.29, 1.65, 2.01, 2.4, 2.87, 3.33, 3.87, 4.4, 4.97, 5.62, 6.26, 6.92, 7.69, 8.42, 9.19, 10.07, 10.91, 11.77, 12.77, 13.7]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.78, 0.76, 0.74, 0.72, 0.69, 0.67, 0.64, 0.61, 0.58, 0.55, 0.52, 0.48, 0.44, 0.39, 0.34, 0.28, 0.19, 0.03, 0.2, 0.28, 0.34, 0.39, 0.44, 0.48, 0.52, 0.55, 0.58, 0.61, 0.64, 0.67]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.04, 0.11, 0.21, 0.35, 0.56, 0.8, 1.1, 1.5, 1.94, 2.46, 3.12, 3.82, 4.61, 5.6, 6.61, 7.86, 9.11, 10.5, 12.17, 13.84, 15.65, 17.82, 19.96, 22.26, 24.98, 27.64, 30.49, 33.83, 37.08]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.82, 0.89, 0.99, 1.08, 1.19, 1.33, 1.46, 1.6, 1.78, 1.94, 2.12, 2.33, 2.53, 2.75, 2.99, 3.23, 3.5, 3.76, 4.03, 4.34, 4.64, 4.94, 5.29, 5.62, 5.96, 6.35, 6.71, 7.08, 7.51, 7.91]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.93, 0.95, 0.98, 1.01, 1.04, 1.06, 1.09, 1.11, 1.14, 1.16, 1.19, 1.21, 1.23, 1.25, 1.28, 1.3, 1.32, 1.34, 1.36, 1.38, 1.4, 1.42, 1.44, 1.46, 1.48, 1.5, 1.51, 1.53, 1.55, 1.57]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.89, -0.59, -0.26, 0.04, 0.33, 0.65, 0.94, 1.21, 1.51, 1.78, 2.03, 2.3, 2.54, 2.77, 3.01, 3.21, 3.43, 3.62, 3.79, 3.98, 4.13, 4.28, 4.43, 4.56, 4.69, 4.82, 4.93, 5.04, 5.15, 5.26]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.05, 0.12, 0.2, 0.28, 0.39, 0.49, 0.6, 0.72, 0.83, 0.94, 1.05, 1.15, 1.24, 1.33, 1.4, 1.46, 1.5, 1.52, 1.52, 1.51, 1.47, 1.4, 1.32, 1.21, 1.07, 0.91, 0.74, 0.53, 0.31]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.16, -0.2, -0.24, -0.28, -0.31, -0.35, -0.39, -0.42, -0.45, -0.49, -0.52, -0.55, -0.57, -0.6, -0.62, -0.65, -0.67, -0.69, -0.71, -0.73, -0.74, -0.76, -0.77, -0.78, -0.79, -0.8, -0.81, -0.82, -0.82, -0.83]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.02, 0.04, 0.05, 0.08, 0.1, 0.14, 0.18, 0.23, 0.29, 0.35, 0.43, 0.51, 0.61, 0.72, 0.84, 0.96, 1.12, 1.27, 1.44, 1.64, 1.84, 2.05, 2.3, 2.55]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.25, 0.37, 0.45, 0.52, 0.58, 0.63, 0.68, 0.73, 0.78, 0.82, 0.86, 0.9, 0.93, 0.97, 1.0, 1.04, 1.07, 1.1, 1.13, 1.16, 1.18, 1.21, 1.24, 1.27, 1.29, 1.32, 1.34, 1.37, 1.39]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.36, 0.59, 0.77, 0.94, 1.11, 1.27, 1.42, 1.58, 1.73, 1.87, 2.02, 2.16, 2.3, 2.44, 2.58, 2.72, 2.85, 2.99, 3.13, 3.26, 3.39, 3.53, 3.65, 3.78, 3.92, 4.04, 4.17, 4.31, 4.43]<EOS_Y><SOS_EQ>', '<SOS_Y>[-1.34, -1.15, -0.95, -0.77, -0.59, -0.38, -0.2, -0.02, 0.18, 0.36, 0.55, 0.75, 0.93, 1.11, 1.32, 1.5, 1.7, 1.88, 2.07, 2.27, 2.45, 2.63, 2.83, 3.02, 3.2, 3.4, 3.58, 3.77, 3.97, 4.15]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.01, 0.04, 0.11, 0.2, 0.35, 0.54, 0.78, 1.11, 1.48, 1.93, 2.5, 3.11, 3.82, 4.7, 5.61, 6.74, 7.88, 9.15, 10.69, 12.23, 13.92, 15.93, 17.93, 20.08, 22.64, 25.15, 27.83, 30.99, 34.07]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.32, 0.26, 0.19, 0.11, 0.02, -0.09, -0.21, -0.33, -0.47, -0.6, -0.74, -0.89, -1.03, -1.17, -1.31, -1.43, -1.55, -1.65, -1.74, -1.81, -1.86, -1.89, -1.9, -1.89, -1.85, -1.78, -1.69, -1.58, -1.43, -1.28]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.83, 0.78, 0.72, 0.66, 0.58, 0.48, 0.37, 0.19, 0.27, 0.42, 0.52, 0.61, 0.68, 0.74, 0.8, 0.84, 0.89, 0.92, 0.94, 0.97, 0.98, 0.99, 1.0, 1.0, 0.99, 0.98, 0.97, 0.95, 0.92, 0.88]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.08, -0.08, -0.07, -0.06, -0.04, -0.01, 0.02, 0.06, 0.12, 0.17, 0.23, 0.31, 0.38, 0.47, 0.57, 0.66, 0.78, 0.89, 1.01, 1.14, 1.27, 1.41, 1.57, 1.73, 1.89, 2.07, 2.24, 2.43, 2.63, 2.83]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.45, 0.65, 0.79, 0.91, 1.02, 1.11, 1.2, 1.29, 1.36, 1.44, 1.51, 1.57, 1.64, 1.7, 1.76, 1.82, 1.88, 1.93, 1.98, 2.03, 2.08, 2.14, 2.18, 2.23, 2.28, 2.32, 2.36, 2.41, 2.45]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.69, 0.71, 0.75, 0.81, 0.9, 1.01, 1.13, 1.27, 1.46, 1.64, 1.85, 2.09, 2.34, 2.61, 2.93, 3.24, 3.6, 3.95, 4.32, 4.75, 5.17, 5.6, 6.1, 6.57, 7.07, 7.64, 8.18, 8.73, 9.37, 9.97]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.31, 0.45, 0.54, 0.62, 0.7, 0.77, 0.82, 0.89, 0.94, 0.99, 1.04, 1.08, 1.13, 1.17, 1.21, 1.25, 1.29, 1.33, 1.36, 1.4, 1.43, 1.47, 1.5, 1.53, 1.56, 1.59, 1.62, 1.66, 1.68]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.05, 0.1, 0.15, 0.19, 0.23, 0.27, 0.3, 0.33, 0.36, 0.38, 0.4, 0.42, 0.43, 0.45, 0.45, 0.46, 0.46, 0.46, 0.46, 0.46, 0.45, 0.44, 0.43, 0.41, 0.39, 0.37, 0.35, 0.32, 0.28]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.85, 0.85, 0.85, 0.84, 0.84, 0.83, 0.83, 0.83, 0.82, 0.82, 0.81, 0.81, 0.81, 0.8, 0.8, 0.79, 0.79, 0.78, 0.78, 0.78, 0.77, 0.77, 0.76, 0.76, 0.75, 0.75, 0.74, 0.74, 0.73, 0.73]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.18, 0.25, 0.31, 0.35, 0.39, 0.43, 0.46, 0.49, 0.51, 0.54, 0.56, 0.58, 0.6, 0.62, 0.64, 0.66, 0.67, 0.69, 0.71, 0.72, 0.73, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.57, 0.77, 0.99, 1.19, 1.39, 1.6, 1.8, 2.0, 2.22, 2.42, 2.62, 2.84, 3.04, 3.23, 3.45, 3.65, 3.87, 4.07, 4.27, 4.49, 4.69, 4.89, 5.1, 5.3, 5.5, 5.72, 5.92, 6.12, 6.34, 6.54]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.65, 0.66, 0.66, 0.66, 0.67, 0.67, 0.68, 0.68, 0.69, 0.69, 0.69, 0.7, 0.7, 0.71, 0.71, 0.72, 0.72, 0.72, 0.73, 0.73, 0.73, 0.74, 0.74, 0.75, 0.75, 0.75, 0.76, 0.76, 0.76, 0.77]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.0, 0.02, 0.04, 0.08, 0.12, 0.17, 0.24, 0.31, 0.39, 0.48, 0.59, 0.7, 0.81, 0.95, 1.09, 1.25, 1.41, 1.57, 1.76, 1.94, 2.14, 2.36, 2.57, 2.79, 3.04, 3.28, 3.53, 3.82, 4.08]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.02, -0.06, -0.09, -0.09, -0.06, 0.01, 0.13, 0.35, 0.64, 1.01, 1.55, 2.16, 2.91, 3.89, 4.94, 6.3, 7.72, 9.33, 11.35, 13.4, 15.69, 18.49, 21.3, 24.37, 28.08, 31.76, 35.74, 40.49, 45.15]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.58, 0.59, 0.59, 0.57, 0.53, 0.46, 0.37, 0.19, 0.31, 0.48, 0.63, 0.77, 0.88, 1.0, 1.12, 1.23, 1.35, 1.45, 1.56, 1.67, 1.77, 1.87, 1.98, 2.09, 2.19, 2.3, 2.4, 2.5, 2.6, 2.7]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.62, 0.46, 0.5, 0.64, 0.72, 0.78, 0.83, 0.87, 0.91, 0.94, 0.97, 1.0, 1.02, 1.05, 1.07, 1.09, 1.11, 1.13, 1.14, 1.16, 1.18, 1.19, 1.21, 1.22, 1.24, 1.25, 1.26, 1.28, 1.29, 1.3]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.01, -0.02, -0.04, -0.05, -0.06, -0.07, -0.08, -0.09, -0.11, -0.12, -0.13, -0.14, -0.15, -0.17, -0.18, -0.19, -0.2, -0.21, -0.22, -0.23, -0.25, -0.26, -0.27, -0.28, -0.29, -0.3, -0.31, -0.33, -0.34]<EOS_Y><SOS_EQ>', '<SOS_Y>[-1.48, -1.28, -1.06, -0.86, -0.66, -0.44, -0.24, -0.04, 0.18, 0.38, 0.58, 0.8, 1.0, 1.2, 1.42, 1.62, 1.84, 2.04, 2.24, 2.46, 2.66, 2.86, 3.08, 3.28, 3.48, 3.7, 3.9, 4.1, 4.32, 4.52]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.23, 0.33, 0.4, 0.46, 0.52, 0.57, 0.62, 0.66, 0.7, 0.74, 0.77, 0.81, 0.84, 0.87, 0.9, 0.94, 0.96, 0.99, 1.02, 1.04, 1.07, 1.1, 1.12, 1.14, 1.17, 1.19, 1.21, 1.24, 1.26]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.02, 0.05, 0.07, 0.08, 0.1, 0.11, 0.12, 0.13, 0.14, 0.14, 0.14, 0.14, 0.14, 0.13, 0.12, 0.11, 0.1, 0.08, 0.06, 0.04, 0.02, -0.0, -0.03, -0.06, -0.09, -0.13, -0.16, -0.2, -0.24]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.49, 0.59, 0.65, 0.7, 0.74, 0.78, 0.81, 0.83, 0.86, 0.88, 0.9, 0.92, 0.94, 0.96, 0.98, 0.99, 1.01, 1.02, 1.04, 1.05, 1.06, 1.07, 1.09, 1.1, 1.11, 1.12, 1.13, 1.14, 1.15]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.22, 0.15, 0.08, 0.04, 0.02, 0.01, 0.02, 0.04, 0.09, 0.15, 0.23, 0.33, 0.44, 0.57, 0.73, 0.89, 1.09, 1.28, 1.5, 1.75, 2.0, 2.26, 2.57, 2.87, 3.18, 3.55, 3.9, 4.26, 4.68, 5.08]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.06, 0.08, 0.1, 0.12, 0.13, 0.14, 0.15, 0.17, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.23, 0.24, 0.25, 0.25, 0.26, 0.27, 0.27, 0.28, 0.29, 0.29, 0.3, 0.3, 0.31, 0.31]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.86, 0.89, 0.93, 0.96, 0.99, 1.01, 1.04, 1.06, 1.08, 1.1, 1.12, 1.14, 1.15, 1.17, 1.19, 1.2, 1.22, 1.23, 1.24, 1.26, 1.27, 1.28, 1.3, 1.31, 1.32, 1.33, 1.34, 1.35, 1.36, 1.37]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.56, -0.38, -0.19, -0.01, 0.17, 0.37, 0.55, 0.73, 0.93, 1.11, 1.29, 1.48, 1.66, 1.84, 2.04, 2.22, 2.42, 2.6, 2.78, 2.97, 3.15, 3.33, 3.53, 3.71, 3.89, 4.09, 4.27, 4.45, 4.64, 4.82]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.58, 0.6, 0.61, 0.63, 0.64, 0.66, 0.67, 0.68, 0.69, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.79, 0.8, 0.81, 0.82, 0.83, 0.83, 0.84, 0.85, 0.85, 0.86, 0.87, 0.87]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.94, 0.89, 0.82, 0.76, 0.69, 0.6, 0.52, 0.41, 0.24, 0.21, 0.38, 0.5, 0.6, 0.67, 0.75, 0.82, 0.88, 0.94, 0.99, 1.04, 1.09, 1.13, 1.18, 1.22, 1.26, 1.31, 1.34, 1.38, 1.42, 1.45]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.0, -0.0, -0.0, -0.0, 0.0, 0.01, 0.01, 0.02, 0.03, 0.04, 0.06, 0.07, 0.09, 0.11, 0.13, 0.15, 0.17, 0.19, 0.22, 0.25, 0.28, 0.31, 0.34, 0.37, 0.41, 0.44, 0.48, 0.51, 0.55]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.0, -0.0, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.0, -0.0, 0.0, 0.0, 0.01, 0.01, 0.02, 0.02, 0.03]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.3, 0.39, 0.48, 0.55, 0.61, 0.67, 0.72, 0.76, 0.79, 0.81, 0.83, 0.84, 0.84, 0.84, 0.83, 0.82, 0.8, 0.77, 0.74, 0.69, 0.64, 0.58, 0.5, 0.42, 0.34, 0.24, 0.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.01, 0.04, 0.1, 0.19, 0.33, 0.51, 0.74, 1.06, 1.42, 1.85, 2.41, 3.0, 3.69, 4.55, 5.44, 6.54, 7.66, 8.91, 10.42, 11.93, 13.58, 15.56, 17.53, 19.65, 22.16, 24.63, 27.28, 30.4, 33.43]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.79, 0.82, 0.85, 0.88, 0.9, 0.92, 0.93, 0.95, 0.96, 0.97, 0.98, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 0.99, 0.99, 0.98, 0.98, 0.97, 0.96, 0.95, 0.95, 0.94, 0.93]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.04, -0.08, -0.11, -0.13, -0.15, -0.16, -0.16, -0.16, -0.15, -0.13, -0.11, -0.07, -0.03, 0.01, 0.07, 0.13, 0.21, 0.28, 0.36, 0.45, 0.54, 0.64, 0.76, 0.87, 0.98, 1.11, 1.23, 1.36, 1.51, 1.64]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.87, 0.83, 0.78, 0.72, 0.66, 0.58, 0.49, 0.37, 0.17, 0.27, 0.41, 0.53, 0.61, 0.68, 0.75, 0.8, 0.85, 0.89, 0.92, 0.95, 0.97, 0.98, 0.99, 1.0, 1.0, 0.99, 0.98, 0.97, 0.94, 0.92]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.15, 0.18, 0.21, 0.24, 0.26, 0.28, 0.3, 0.32, 0.33, 0.35, 0.36, 0.38, 0.39, 0.41, 0.42, 0.43, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.16, 0.04, 0.26, 0.46, 0.66, 0.88, 1.08, 1.28, 1.5, 1.7, 1.9, 2.12, 2.32, 2.52, 2.74, 2.94, 3.16, 3.36, 3.56, 3.78, 3.98, 4.18, 4.4, 4.6, 4.8, 5.02, 5.22, 5.42, 5.64, 5.84]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.93, 0.9, 0.86, 0.82, 0.77, 0.7, 0.61, 0.45, 0.51, 0.64, 0.72, 0.78, 0.83, 0.87, 0.91, 0.94, 0.97, 1.0, 1.02, 1.05, 1.07, 1.09, 1.11, 1.13, 1.15, 1.16, 1.18, 1.19, 1.21, 1.22]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.2, 0.46, 0.75, 1.02, 1.28, 1.57, 1.84, 2.1, 2.39, 2.66, 2.92, 3.21, 3.48, 3.74, 4.03, 4.29, 4.59, 4.85, 5.11, 5.4, 5.67, 5.93, 6.22, 6.49, 6.75, 7.04, 7.31, 7.57, 7.86, 8.13]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.95, 0.81, 0.64, 0.49, 0.33, 0.14, -0.04, -0.23, -0.49, -0.71, -0.6, -0.57, -0.57, -0.58, -0.61, -0.63, -0.67, -0.71, -0.75, -0.79, -0.84, -0.89, -0.94, -0.99, -1.04, -1.1, -1.16, -1.21, -1.27, -1.33]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.21, 0.28, 0.34, 0.4, 0.48, 0.57, 0.67, 0.8, 0.94, 1.1, 1.29, 1.48, 1.69, 1.95, 2.2, 2.5, 2.79, 3.1, 3.46, 3.81, 4.18, 4.61, 5.02, 5.45, 5.94, 6.41, 6.9, 7.46, 7.99]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.3, 0.39, 0.48, 0.55, 0.61, 0.67, 0.72, 0.76, 0.79, 0.81, 0.83, 0.84, 0.84, 0.84, 0.83, 0.82, 0.8, 0.77, 0.74, 0.69, 0.64, 0.58, 0.5, 0.42, 0.34, 0.24, 0.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.01, 0.03, 0.07, 0.13, 0.21, 0.3, 0.4, 0.54, 0.67, 0.83, 1.01, 1.2, 1.4, 1.64, 1.87, 2.15, 2.41, 2.69, 3.02, 3.34, 3.67, 4.05, 4.41, 4.79, 5.22, 5.63, 6.06, 6.55, 7.01]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.21, 0.31, 0.37, 0.42, 0.47, 0.51, 0.55, 0.58, 0.61, 0.64, 0.66, 0.69, 0.71, 0.73, 0.75, 0.77, 0.78, 0.8, 0.82, 0.83, 0.84, 0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.92]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.06, 0.1, 0.13, 0.14, 0.14, 0.12, 0.08, 0.02, -0.04, -0.12, -0.21, -0.31, -0.4, -0.51, -0.6, -0.69, -0.77, -0.84, -0.89, -0.93, -0.95, -0.96, -0.94, -0.91, -0.87, -0.81, -0.74, -0.65, -0.57]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.56, 0.68, 0.75, 0.8, 0.85, 0.89, 0.92, 0.95, 0.98, 1.01, 1.03, 1.06, 1.08, 1.1, 1.12, 1.14, 1.15, 1.17, 1.18, 1.2, 1.21, 1.23, 1.24, 1.25, 1.27, 1.28, 1.29, 1.3, 1.32]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.13, 0.2, 0.26, 0.31, 0.36, 0.4, 0.45, 0.5, 0.54, 0.59, 0.63, 0.68, 0.72, 0.76, 0.81, 0.85, 0.89, 0.94, 0.98, 1.02, 1.07, 1.11, 1.15, 1.2, 1.24, 1.28, 1.32, 1.37, 1.41]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.11, -0.06, -0.03, -0.01, -0.0, -0.0, -0.0, -0.0, 0.0, 0.01, 0.04, 0.08, 0.14, 0.21, 0.33, 0.47, 0.65, 0.86, 1.1, 1.42, 1.76, 2.15, 2.64, 3.14, 3.7, 4.4, 5.1, 5.87, 6.8, 7.73]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.63, 0.65, 0.68, 0.71, 0.73, 0.76, 0.78, 0.8, 0.82, 0.84, 0.86, 0.89, 0.91, 0.92, 0.94, 0.96, 0.98, 1.0, 1.02, 1.03, 1.05, 1.07, 1.09, 1.1, 1.12, 1.13, 1.15, 1.16, 1.18, 1.19]<EOS_Y><SOS_EQ>', '<SOS_Y>[1.11, 1.18, 1.27, 1.37, 1.5, 1.66, 1.82, 2.01, 2.23, 2.46, 2.7, 2.99, 3.28, 3.58, 3.94, 4.28, 4.69, 5.07, 5.48, 5.95, 6.39, 6.86, 7.39, 7.9, 8.43, 9.03, 9.6, 10.18, 10.85, 11.48]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.25, 0.33, 0.38, 0.4, 0.41, 0.4, 0.38, 0.35, 0.31, 0.26, 0.2, 0.14, 0.06, -0.03, -0.12, -0.22, -0.33, -0.44, -0.58, -0.71, -0.84, -1.0, -1.15, -1.31, -1.49, -1.66, -1.84, -2.05, -2.25]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.03, -0.05, -0.07, -0.08, -0.09, -0.1, -0.1, -0.1, -0.09, -0.08, -0.07, -0.05, -0.03, -0.0, 0.03, 0.06, 0.1, 0.14, 0.19, 0.23, 0.29, 0.35, 0.41, 0.47, 0.54, 0.61, 0.69, 0.77, 0.86]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.33, -0.3, -0.25, -0.2, -0.15, -0.08, -0.01, 0.07, 0.16, 0.25, 0.35, 0.47, 0.58, 0.7, 0.84, 0.98, 1.14, 1.29, 1.45, 1.63, 1.8, 1.98, 2.19, 2.38, 2.58, 2.81, 3.03, 3.26, 3.51, 3.75]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.09, 0.12, 0.15, 0.18, 0.2, 0.23, 0.25, 0.27, 0.29, 0.3, 0.32, 0.33, 0.33, 0.34, 0.35, 0.35, 0.35, 0.34, 0.34, 0.33, 0.32, 0.31, 0.3, 0.29, 0.27, 0.26, 0.24, 0.22, 0.2, 0.18]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.0, 0.01, 0.03, 0.07, 0.14, 0.23, 0.35, 0.51, 0.7, 0.91, 1.19, 1.48, 1.81, 2.22, 2.64, 3.15, 3.66, 4.22, 4.89, 5.55, 6.26, 7.1, 7.92, 8.8, 9.83, 10.83, 11.88, 13.11, 14.29]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.55, 0.47, 0.38, 0.3, 0.22, 0.13, 0.04, -0.05, -0.14, -0.23, -0.31, -0.4, -0.48, -0.55, -0.63, -0.69, -0.76, -0.81, -0.86, -0.9, -0.94, -0.96, -0.98, -1.0, -1.0, -1.0, -0.98, -0.96, -0.94, -0.9]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.39, 0.37, 0.34, 0.32, 0.29, 0.27, 0.24, 0.22, 0.19, 0.16, 0.14, 0.11, 0.09, 0.06, 0.03, 0.01, -0.02, -0.05, -0.07, -0.1, -0.12, -0.15, -0.18, -0.2, -0.23, -0.25, -0.28, -0.3, -0.33, -0.35]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.2, 0.41, 0.58, 0.73, 0.86, 0.95, 0.99, 1.0, 0.96, 0.88, 0.76, 0.61, 0.45, 0.24, 0.04, -0.18, -0.37, -0.55, -0.72, -0.84, -0.93, -0.99, -1.0, -0.97, -0.89, -0.79, -0.65, -0.46, -0.28]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.0, -0.01, -0.01, -0.0, 0.01, 0.03, 0.07, 0.13, 0.2, 0.29, 0.41, 0.54, 0.7, 0.9, 1.1, 1.35, 1.6, 1.86, 2.17, 2.47, 2.78, 3.12, 3.44, 3.75, 4.09, 4.39, 4.67, 4.95, 5.18]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.21, -0.11, -0.0, 0.1, 0.2, 0.31, 0.41, 0.51, 0.62, 0.72, 0.82, 0.93, 1.03, 1.13, 1.24, 1.34, 1.45, 1.55, 1.65, 1.76, 1.86, 1.96, 2.07, 2.17, 2.27, 2.38, 2.48, 2.58, 2.69, 2.79]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.5, 0.38, 0.27, 0.18, 0.11, 0.05, 0.01, -0.02, -0.03, -0.03, -0.01, 0.02, 0.07, 0.14, 0.22, 0.31, 0.43, 0.56, 0.7, 0.86, 1.03, 1.22, 1.43, 1.65, 1.88, 2.14, 2.4, 2.67, 2.99, 3.29]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.31, 0.05, 0.34, 0.46, 0.56, 0.65, 0.72, 0.79, 0.86, 0.91, 0.97, 1.02, 1.07, 1.11, 1.16, 1.21, 1.25, 1.29, 1.33, 1.37, 1.4, 1.44, 1.48, 1.51, 1.54, 1.58, 1.61, 1.64, 1.67, 1.7]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.29, -0.17, -0.03, 0.13, 0.3, 0.5, 0.71, 0.94, 1.21, 1.47, 1.76, 2.09, 2.41, 2.75, 3.14, 3.52, 3.95, 4.36, 4.8, 5.29, 5.76, 6.25, 6.81, 7.34, 7.88, 8.5, 9.09, 9.69, 10.37, 11.01]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.03, 0.07, 0.1, 0.14, 0.18, 0.21, 0.24, 0.28, 0.31, 0.34, 0.38, 0.41, 0.44, 0.47, 0.5, 0.53, 0.56, 0.59, 0.62, 0.65, 0.67, 0.7, 0.72, 0.75, 0.77, 0.79, 0.81, 0.83, 0.85]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.26, 0.38, 0.46, 0.53, 0.6, 0.65, 0.7, 0.75, 0.8, 0.84, 0.88, 0.92, 0.96, 0.99, 1.03, 1.06, 1.1, 1.13, 1.16, 1.19, 1.22, 1.25, 1.27, 1.3, 1.33, 1.35, 1.38, 1.41, 1.43]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.37, -0.17, 0.04, 0.24, 0.43, 0.64, 0.82, 1.0, 1.18, 1.33, 1.47, 1.6, 1.71, 1.79, 1.87, 1.92, 1.96, 1.96, 1.95, 1.92, 1.87, 1.8, 1.7, 1.6, 1.48, 1.32, 1.17, 1.01, 0.82, 0.64]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.94, 0.97, 1.0, 1.03, 1.05, 1.08, 1.11, 1.14, 1.16, 1.19, 1.21, 1.24, 1.26, 1.28, 1.31, 1.33, 1.35, 1.37, 1.39, 1.42, 1.44, 1.46, 1.48, 1.5, 1.52, 1.54, 1.55, 1.57, 1.59, 1.61]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.07, -0.17, -0.29, -0.43, -0.61, -0.79, -1.0, -1.24, -1.48, -1.73, -2.03, -2.31, -2.6, -2.92, -3.23, -3.56, -3.87, -4.18, -4.51, -4.81, -5.1, -5.4, -5.67, -5.92, -6.17, -6.38, -6.57, -6.75, -6.88]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.15, 0.34, 0.46, 0.55, 0.61, 0.67, 0.72, 0.76, 0.8, 0.83, 0.86, 0.88, 0.9, 0.92, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 0.99, 0.99]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.56, 0.68, 0.75, 0.8, 0.85, 0.89, 0.92, 0.95, 0.98, 1.01, 1.03, 1.06, 1.08, 1.1, 1.12, 1.14, 1.15, 1.17, 1.18, 1.2, 1.21, 1.23, 1.24, 1.25, 1.27, 1.28, 1.29, 1.3, 1.32]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.03, 0.03]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.05, 0.14, 0.26, 0.41, 0.61, 0.82, 1.06, 1.34, 1.61, 1.9, 2.22, 2.51, 2.8, 3.11, 3.38, 3.65, 3.87, 4.07, 4.24, 4.36, 4.44, 4.47, 4.45, 4.37, 4.23, 4.04, 3.8, 3.47, 3.11]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.47, 0.57, 0.66, 0.73, 0.79, 0.86, 0.92, 0.97, 1.02, 1.07, 1.12, 1.17, 1.21, 1.25, 1.29, 1.33, 1.37, 1.41, 1.44, 1.48, 1.51, 1.55, 1.58, 1.61, 1.64, 1.68, 1.71, 1.73, 1.77, 1.79]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.0, 0.1, 0.21, 0.3, 0.4, 0.5, 0.58, 0.66, 0.74, 0.8, 0.86, 0.91, 0.95, 0.97, 0.99, 1.0, 1.0, 0.98, 0.96, 0.92, 0.88, 0.83, 0.76, 0.69, 0.62, 0.52, 0.44, 0.35, 0.24, 0.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.61, 1.0, 1.22, 1.38, 1.51, 1.64, 1.74, 1.83, 1.91, 1.96, 2.01, 2.04, 2.06, 2.07, 2.07, 2.05, 2.03, 1.99, 1.95, 1.9, 1.85, 1.79, 1.72, 1.65, 1.58, 1.51, 1.44, 1.37, 1.3, 1.24]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.11, -0.24, -0.37, -0.51, -0.67, -0.8, -0.9, -0.98, -1.0, -0.95, -0.82, -0.62, -0.35, 0.01, 0.34, 0.68, 0.9, 1.0, 0.92, 0.66, 0.28, -0.23, -0.66, -0.94, -0.98, -0.73, -0.27, 0.34, 0.81]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.28, 0.44, 0.56, 0.67, 0.8, 0.91, 1.01, 1.13, 1.23, 1.34, 1.45, 1.55, 1.65, 1.77, 1.87, 1.98, 2.08, 2.18, 2.29, 2.4, 2.5, 2.61, 2.71, 2.81, 2.92, 3.02, 3.12, 3.23, 3.33]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.15, 0.26, 0.36, 0.45, 0.56, 0.65, 0.75, 0.85, 0.95, 1.04, 1.15, 1.24, 1.33, 1.44, 1.53, 1.64, 1.73, 1.82, 1.93, 2.02, 2.12, 2.22, 2.31, 2.41, 2.51, 2.61, 2.7, 2.8, 2.9]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.3, 0.39, 0.48, 0.55, 0.61, 0.67, 0.72, 0.76, 0.79, 0.81, 0.83, 0.84, 0.84, 0.84, 0.83, 0.82, 0.8, 0.77, 0.74, 0.69, 0.64, 0.58, 0.5, 0.42, 0.34, 0.24, 0.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.31, 0.4, 0.5, 0.58, 0.66, 0.74, 0.8, 0.86, 0.91, 0.95, 0.97, 0.99, 1.0, 1.0, 0.98, 0.96, 0.92, 0.88, 0.83, 0.76, 0.69, 0.61, 0.52, 0.44, 0.34, 0.24, 0.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.42, 0.3, 0.14, 0.34, 0.45, 0.54, 0.61, 0.67, 0.72, 0.76, 0.79, 0.83, 0.85, 0.88, 0.9, 0.92, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.12, 0.42, 0.55, 0.63, 0.7, 0.77, 0.82, 0.87, 0.92, 0.97, 1.01, 1.05, 1.09, 1.13, 1.17, 1.21, 1.25, 1.29, 1.32, 1.36, 1.4, 1.44, 1.48, 1.51, 1.55, 1.59, 1.63, 1.67, 1.71, 1.75]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.49, 0.59, 0.7, 0.8, 0.9, 1.01, 1.11, 1.21, 1.32, 1.42, 1.52, 1.63, 1.73, 1.83, 1.94, 2.04, 2.15, 2.25, 2.35, 2.46, 2.56, 2.66, 2.77, 2.87, 2.97, 3.08, 3.18, 3.28, 3.39, 3.49]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.09, -0.02, 0.03, 0.06, 0.08, 0.08, 0.06, 0.03, -0.02, -0.09, -0.17, -0.27, -0.39, -0.52, -0.68, -0.84, -1.04, -1.23, -1.44, -1.69, -1.94, -2.2, -2.5, -2.79, -3.1, -3.46, -3.8, -4.16, -4.57, -4.96]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.04, -0.09, -0.13, -0.17, -0.21, -0.24, -0.27, -0.29, -0.31, -0.32, -0.33, -0.32, -0.31, -0.27, -0.22, -0.06, -0.22, -0.34, -0.46, -0.56, -0.66, -0.78, -0.88, -0.99, -1.11, -1.23, -1.34, -1.47, -1.6]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.05, 0.11, 0.17, 0.22, 0.28, 0.34, 0.39, 0.45, 0.51, 0.56, 0.62, 0.68, 0.73, 0.79, 0.85, 0.91, 0.96, 1.02, 1.08, 1.13, 1.19, 1.25, 1.3, 1.36, 1.42, 1.47, 1.53, 1.59, 1.64]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.42, 0.4, 0.38, 0.35, 0.33, 0.3, 0.27, 0.24, 0.2, 0.16, 0.09, 0.1, 0.16, 0.2, 0.24, 0.27, 0.31, 0.33, 0.35, 0.38, 0.4, 0.42, 0.44, 0.46, 0.48, 0.49, 0.51, 0.53, 0.54, 0.56]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.07, -0.09, -0.26, -0.42, -0.58, -0.75, -0.91, -1.07, -1.24, -1.4, -1.56, -1.73, -1.89, -2.05, -2.22, -2.38, -2.56, -2.71, -2.87, -3.05, -3.21, -3.37, -3.54, -3.7, -3.86, -4.03, -4.19, -4.35, -4.52, -4.68]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.15, 0.19, 0.2, 0.19, 0.17, 0.14, 0.09, 0.04, -0.02, -0.08, -0.15, -0.23, -0.31, -0.4, -0.49, -0.59, -0.69, -0.79, -0.91, -1.02, -1.13, -1.26, -1.38, -1.51, -1.65, -1.78, -1.91, -2.06, -2.2]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.15, 0.23, 0.3, 0.36, 0.43, 0.49, 0.55, 0.62, 0.68, 0.74, 0.8, 0.86, 0.92, 0.99, 1.05, 1.11, 1.17, 1.23, 1.29, 1.35, 1.41, 1.47, 1.53, 1.59, 1.66, 1.72, 1.77, 1.84, 1.9]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.3, 0.39, 0.48, 0.55, 0.61, 0.67, 0.72, 0.76, 0.79, 0.81, 0.83, 0.84, 0.84, 0.84, 0.83, 0.82, 0.8, 0.77, 0.74, 0.69, 0.64, 0.58, 0.5, 0.42, 0.34, 0.24, 0.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.82, 1.05, 1.33, 1.59, 1.86, 2.15, 2.41, 2.65, 2.89, 3.08, 3.24, 3.36, 3.43, 3.45, 3.4, 3.3, 3.13, 2.9, 2.62, 2.24, 1.83, 1.36, 0.79, 0.22, -0.39, -1.1, -1.78, -2.48, -3.27, -3.98]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.14, 0.23, 0.31, 0.39, 0.48, 0.55, 0.63, 0.71, 0.79, 0.86, 0.95, 1.02, 1.1, 1.18, 1.25, 1.34, 1.41, 1.49, 1.57, 1.65, 1.72, 1.8, 1.88, 1.95, 2.04, 2.11, 2.19, 2.27, 2.34]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.0, 0.01, 0.02, 0.04, 0.05, 0.07, 0.09, 0.11, 0.13, 0.15, 0.16, 0.18, 0.2, 0.21, 0.22, 0.23, 0.23, 0.24, 0.23, 0.22, 0.21, 0.19, 0.16, 0.13, 0.09, 0.04, -0.01, -0.08, -0.15]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.98, 1.07, 1.17, 1.27, 1.36, 1.46, 1.55, 1.65, 1.75, 1.84, 1.93, 2.03, 2.13, 2.22, 2.32, 2.41, 2.51, 2.61, 2.7, 2.8, 2.89, 2.98, 3.09, 3.18, 3.27, 3.37, 3.46, 3.56, 3.66, 3.75]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.05, 0.1, 0.15, 0.19, 0.24, 0.28, 0.33, 0.37, 0.41, 0.45, 0.49, 0.52, 0.56, 0.59, 0.62, 0.65, 0.67, 0.7, 0.72, 0.74, 0.75, 0.77, 0.78, 0.8, 0.81, 0.82, 0.82, 0.83, 0.83]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.29, 0.35, 0.42, 0.48, 0.53, 0.59, 0.64, 0.68, 0.73, 0.78, 0.81, 0.86, 0.89, 0.92, 0.95, 0.98, 1.01, 1.03, 1.05, 1.07, 1.08, 1.09, 1.1, 1.11, 1.11, 1.11, 1.11, 1.11, 1.1, 1.09]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.72, 0.77, 0.81, 0.86, 0.89, 0.93, 0.97, 1.0, 1.04, 1.07, 1.1, 1.14, 1.17, 1.2, 1.23, 1.25, 1.28, 1.31, 1.33, 1.36, 1.39, 1.41, 1.44, 1.46, 1.48, 1.51, 1.53, 1.55, 1.58, 1.6]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.0, -0.01, -0.02, -0.04, -0.07, -0.1, -0.14, -0.2, -0.26, -0.34, -0.43, -0.53, -0.65, -0.78, -0.92, -1.09, -1.27, -1.46, -1.7, -1.93, -2.19, -2.49, -2.79]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.21, -0.14, -0.05, 0.03, 0.11, 0.19, 0.27, 0.34, 0.42, 0.49, 0.56, 0.63, 0.69, 0.74, 0.8, 0.84, 0.89, 0.92, 0.95, 0.97, 0.99, 1.0, 1.0, 1.0, 0.99, 0.97, 0.95, 0.92, 0.88, 0.84]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.49, -0.41, -0.31, -0.22, -0.12, -0.01, 0.09, 0.18, 0.29, 0.38, 0.46, 0.54, 0.6, 0.66, 0.71, 0.75, 0.78, 0.81, 0.82, 0.84, 0.84, 0.84, 0.83, 0.82, 0.8, 0.77, 0.74, 0.7, 0.64, 0.59]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.01, 0.02, 0.05, 0.1, 0.15, 0.21, 0.28, 0.36, 0.44, 0.53, 0.62, 0.71, 0.79, 0.87, 0.93, 0.98, 1.0, 0.99, 0.95, 0.87, 0.75, 0.6, 0.4, 0.18, -0.05, -0.31, -0.54, -0.74, -0.9, -0.99]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.32, -0.33, -0.33, -0.33, -0.34, -0.34, -0.35, -0.35, -0.35, -0.36, -0.36, -0.37, -0.37, -0.37, -0.38, -0.38, -0.39, -0.39, -0.39, -0.4, -0.4, -0.41, -0.41, -0.41, -0.42, -0.42, -0.42, -0.43, -0.43, -0.44]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.33, -0.13, 0.08, 0.28, 0.47, 0.65, 0.79, 0.89, 0.97, 1.0, 0.99, 0.93, 0.84, 0.71, 0.55, 0.37, 0.16, -0.04, -0.24, -0.45, -0.62, -0.76, -0.88, -0.96, -1.0, -0.99, -0.95, -0.86, -0.73, -0.58]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.41, 0.4, 0.38, 0.36, 0.35, 0.33, 0.32, 0.3, 0.28, 0.27, 0.25, 0.23, 0.22, 0.2, 0.19, 0.17, 0.15, 0.14, 0.12, 0.11, 0.09, 0.07, 0.06, 0.04, 0.03, 0.01, -0.01, -0.02, -0.04, -0.05]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.86, 0.83, 0.81, 0.78, 0.76, 0.73, 0.7, 0.68, 0.65, 0.61, 0.58, 0.55, 0.51, 0.47, 0.42, 0.37, 0.31, 0.24, 0.15, 0.15, 0.24, 0.31, 0.37, 0.42, 0.47, 0.51, 0.55, 0.58, 0.61, 0.65]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.01, -0.04, -0.06, -0.1, -0.14, -0.18, -0.23, -0.3, -0.36, -0.42, -0.5, -0.57, -0.64, -0.72, -0.79, -0.85, -0.91, -0.95, -0.99, -1.0, -0.99, -0.96, -0.91, -0.84, -0.72, -0.59, -0.44, -0.25, -0.06]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.29, 0.42, 0.5, 0.58, 0.65, 0.71, 0.77, 0.83, 0.87, 0.92, 0.97, 1.01, 1.05, 1.09, 1.13, 1.17, 1.2, 1.24, 1.27, 1.3, 1.33, 1.37, 1.4, 1.43, 1.46, 1.49, 1.51, 1.54, 1.57]<EOS_Y><SOS_EQ>', '<SOS_Y>[1.22, 1.26, 1.29, 1.33, 1.36, 1.4, 1.43, 1.46, 1.5, 1.53, 1.57, 1.6, 1.64, 1.67, 1.71, 1.74, 1.78, 1.81, 1.84, 1.88, 1.91, 1.95, 1.99, 2.02, 2.05, 2.09, 2.12, 2.16, 2.19, 2.23]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.01, 0.03, 0.04, 0.05, 0.07, 0.08, 0.09, 0.11, 0.12, 0.13, 0.14, 0.16, 0.17, 0.18, 0.2, 0.21, 0.22, 0.24, 0.25, 0.26, 0.27, 0.29, 0.3, 0.31, 0.33, 0.34, 0.35, 0.37, 0.38]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.0, -0.01, -0.04, -0.07, -0.13, -0.2, -0.3, -0.42, -0.56, -0.73, -0.94, -1.16, -1.41, -1.71, -2.02, -2.4, -2.78, -3.19, -3.69, -4.17, -4.69, -5.31, -5.91, -6.55, -7.3, -8.03, -8.8, -9.69, -10.55]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.54, 0.78, 1.03, 1.26, 1.49, 1.75, 1.97, 2.2, 2.45, 2.68, 2.9, 3.15, 3.38, 3.6, 3.84, 4.07, 4.31, 4.53, 4.76, 5.0, 5.22, 5.44, 5.68, 5.9, 6.12, 6.37, 6.58, 6.8, 7.04, 7.26]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.0, 0.09, 0.22, 0.35, 0.51, 0.71, 0.91, 1.13, 1.4, 1.66, 1.95, 2.29, 2.62, 2.97, 3.38, 3.77, 4.23, 4.67, 5.12, 5.65, 6.15, 6.68, 7.27, 7.84, 8.43, 9.1, 9.73, 10.38, 11.12, 11.81]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.01, -0.04, -0.07, -0.12, -0.18, -0.25, -0.31, -0.38, -0.43, -0.49, -0.53, -0.56, -0.58, -0.57, -0.55, -0.49, -0.42, -0.32, -0.17, 0.01, 0.22, 0.49, 0.78, 1.12, 1.55, 1.99, 2.49, 3.1, 3.71]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.03, -0.04, -0.02, 0.01, 0.06, 0.14, 0.23, 0.35, 0.48, 0.63, 0.81, 1.0, 1.21, 1.46, 1.71, 2.01, 2.29, 2.6, 2.96, 3.31, 3.67, 4.1, 4.5, 4.93, 5.42, 5.88, 6.37, 6.92, 7.44]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.07, 0.18, 0.3, 0.43, 0.61, 0.79, 0.98, 1.23, 1.47, 1.73, 2.04, 2.34, 2.66, 3.04, 3.41, 3.83, 4.24, 4.66, 5.16, 5.62, 6.11, 6.67, 7.2, 7.76, 8.38, 8.98, 9.59, 10.29, 10.94]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.07, 0.02, -0.02, -0.06, -0.08, -0.1, -0.11, -0.12, -0.11, -0.1, -0.08, -0.04, -0.01, 0.04, 0.1, 0.16, 0.23, 0.31, 0.4, 0.5, 0.6, 0.71, 0.84, 0.96, 1.1, 1.25, 1.4, 1.56, 1.74, 1.91]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.04, 0.09, 0.13, 0.17, 0.22, 0.26, 0.3, 0.34, 0.39, 0.43, 0.47, 0.52, 0.56, 0.6, 0.64, 0.69, 0.73, 0.77, 0.82, 0.86, 0.9, 0.95, 0.99, 1.03, 1.08, 1.12, 1.16, 1.2, 1.25]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.31, 0.41, 0.52, 0.62, 0.72, 0.83, 0.93, 1.03, 1.14, 1.24, 1.34, 1.45, 1.55, 1.66, 1.76, 1.86, 1.97, 2.07, 2.17, 2.28, 2.38, 2.48, 2.59, 2.69, 2.79, 2.9, 3.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.12, 0.18, 0.22, 0.25, 0.28, 0.31, 0.33, 0.35, 0.37, 0.39, 0.41, 0.43, 0.45, 0.47, 0.48, 0.5, 0.51, 0.53, 0.54, 0.56, 0.57, 0.59, 0.6, 0.61, 0.62, 0.64, 0.65, 0.66, 0.67]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.73, -0.7, -0.66, -0.63, -0.59, -0.56, -0.52, -0.49, -0.45, -0.42, -0.39, -0.35, -0.32, -0.29, -0.25, -0.22, -0.18, -0.15, -0.11, -0.08, -0.04, -0.01, 0.03, 0.06, 0.09, 0.13, 0.16, 0.2, 0.23, 0.27]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.72, -0.51, -0.29, -0.08, 0.12, 0.33, 0.52, 0.71, 0.91, 1.09, 1.26, 1.45, 1.61, 1.78, 1.95, 2.1, 2.27, 2.41, 2.55, 2.71, 2.84, 2.97, 3.11, 3.23, 3.35, 3.47, 3.58, 3.68, 3.79, 3.89]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.11, 0.25, 0.4, 0.57, 0.77, 0.97, 1.18, 1.43, 1.67, 1.92, 2.21, 2.48, 2.77, 3.1, 3.4, 3.75, 4.08, 4.42, 4.8, 5.16, 5.53, 5.96, 6.35, 6.76, 7.23, 7.67, 8.13, 8.65, 9.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.01, 0.04, 0.1, 0.18, 0.28, 0.37, 0.47, 0.59, 0.69, 0.8, 0.91, 1.0, 1.08, 1.17, 1.23, 1.29, 1.32, 1.35, 1.35, 1.34, 1.31, 1.26, 1.2, 1.12, 1.01, 0.9, 0.77, 0.61, 0.46]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.32, -0.19, -0.05, 0.08, 0.2, 0.35, 0.47, 0.6, 0.74, 0.87, 1.0, 1.14, 1.27, 1.4, 1.54, 1.66, 1.81, 1.93, 2.06, 2.2, 2.33, 2.46, 2.6, 2.73, 2.86, 3.0, 3.12, 3.25, 3.39, 3.52]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.27, 0.19, 0.01, 0.18, 0.26, 0.32, 0.37, 0.41, 0.46, 0.49, 0.53, 0.56, 0.59, 0.62, 0.65, 0.67, 0.7, 0.72, 0.75, 0.77, 0.79, 0.81, 0.84, 0.86, 0.87, 0.9, 0.91, 0.93, 0.95, 0.97]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.07, 0.15, 0.22, 0.29, 0.37, 0.43, 0.5, 0.56, 0.62, 0.68, 0.73, 0.78, 0.82, 0.87, 0.9, 0.93, 0.96, 0.97, 0.99, 1.0, 1.0, 1.0, 0.99, 0.98, 0.95, 0.93, 0.9, 0.87, 0.83]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.79, 0.76, 0.73, 0.7, 0.66, 0.61, 0.55, 0.45, 0.31, 0.49, 0.57, 0.63, 0.67, 0.71, 0.74, 0.77, 0.8, 0.82, 0.84, 0.86, 0.88, 0.89, 0.91, 0.93, 0.94, 0.96, 0.97, 0.98, 1.0, 1.01]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.37, 0.32, 0.25, 0.17, 0.09, 0.22, 0.29, 0.34, 0.4, 0.44, 0.48, 0.52, 0.55, 0.58, 0.61, 0.64, 0.67, 0.7, 0.72, 0.75, 0.77, 0.79, 0.82, 0.84, 0.86, 0.88, 0.9, 0.92, 0.94, 0.96]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.31, 0.4, 0.5, 0.58, 0.66, 0.74, 0.8, 0.86, 0.91, 0.95, 0.97, 0.99, 1.0, 1.0, 0.98, 0.96, 0.92, 0.88, 0.83, 0.76, 0.69, 0.61, 0.52, 0.44, 0.34, 0.24, 0.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.85, 0.85, 0.86, 0.86, 0.87, 0.87, 0.88, 0.88, 0.89, 0.89, 0.89, 0.9, 0.9, 0.91, 0.91, 0.91, 0.92, 0.92, 0.92, 0.93, 0.93, 0.93, 0.94, 0.94, 0.94, 0.95, 0.95, 0.95, 0.95, 0.96]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.0, -0.01, -0.01, -0.03, -0.05, -0.07, -0.1, -0.15, -0.2, -0.26, -0.34, -0.43, -0.53, -0.66, -0.79, -0.95, -1.12, -1.3, -1.53, -1.75, -2.0, -2.3, -2.59, -2.91, -3.3, -3.67, -4.07, -4.54, -5.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.01, 0.03, 0.04, 0.06, 0.08, 0.1, 0.12, 0.14, 0.16, 0.19, 0.21, 0.24, 0.26, 0.29, 0.32, 0.35, 0.38, 0.41, 0.44, 0.47, 0.5, 0.54, 0.57, 0.61, 0.64, 0.68, 0.71, 0.75, 0.79]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.07, -0.18, -0.29, -0.43, -0.6, -0.78, -0.99, -1.25, -1.51, -1.8, -2.15, -2.5, -2.89, -3.35, -3.81, -4.35, -4.88, -5.45, -6.12, -6.78, -7.47, -8.29, -9.08, -9.91, -10.88, -11.82, -12.8, -13.94, -15.03]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.28, 0.38, 0.43, 0.45, 0.45, 0.42, 0.36, 0.25, 0.16, 0.36, 0.52, 0.65, 0.76, 0.89, 1.0, 1.12, 1.23, 1.33, 1.45, 1.55, 1.66, 1.77, 1.87, 1.98, 2.09, 2.19, 2.29, 2.41, 2.51]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.79, 0.79, 0.78, 0.78, 0.78, 0.77, 0.77, 0.77, 0.76, 0.76, 0.76, 0.75, 0.75, 0.75, 0.74, 0.74, 0.73, 0.73, 0.73, 0.72, 0.72, 0.71, 0.71, 0.7, 0.7, 0.69, 0.69, 0.68, 0.68, 0.67]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.01, -0.03, -0.04, -0.05, -0.07, -0.08, -0.09, -0.11, -0.12, -0.13, -0.14, -0.16, -0.17, -0.18, -0.2, -0.21, -0.22, -0.23, -0.25, -0.26, -0.27, -0.29, -0.3, -0.31, -0.32, -0.34, -0.35, -0.36, -0.37]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.68, -0.66, -0.65, -0.64, -0.62, -0.61, -0.6, -0.58, -0.57, -0.56, -0.54, -0.53, -0.51, -0.5, -0.48, -0.47, -0.45, -0.44, -0.42, -0.41, -0.39, -0.38, -0.36, -0.34, -0.33, -0.31, -0.3, -0.28, -0.26, -0.25]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.16, 0.21, 0.25, 0.3, 0.34, 0.38, 0.42, 0.47, 0.51, 0.55, 0.59, 0.63, 0.67, 0.71, 0.76, 0.8, 0.84, 0.88, 0.92, 0.96, 1.0, 1.04, 1.08, 1.12, 1.16, 1.2, 1.25, 1.29]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.0, -0.02, -0.05, -0.09, -0.14, -0.2, -0.27, -0.35, -0.43, -0.51, -0.6, -0.68, -0.76, -0.84, -0.9, -0.97, -1.01, -1.04, -1.06, -1.07, -1.05, -1.02, -0.97, -0.9, -0.8, -0.69, -0.57, -0.41, -0.25]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.24, 0.35, 0.43, 0.49, 0.55, 0.61, 0.65, 0.7, 0.74, 0.78, 0.82, 0.86, 0.89, 0.93, 0.96, 0.99, 1.02, 1.05, 1.08, 1.11, 1.13, 1.16, 1.19, 1.21, 1.24, 1.26, 1.29, 1.31, 1.33]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.18, 0.21, 0.23, 0.24, 0.24, 0.24, 0.22, 0.2, 0.17, 0.14, 0.1, 0.05, 0.0, -0.05, -0.12, -0.18, -0.25, -0.32, -0.38, -0.46, -0.53, -0.6, -0.67, -0.73, -0.79, -0.86, -0.91, -0.96, -1.01, -1.05]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.1, 0.19, 0.28, 0.36, 0.44, 0.52, 0.59, 0.66, 0.72, 0.78, 0.83, 0.88, 0.92, 0.95, 0.97, 0.99, 1.0, 1.0, 0.99, 0.98, 0.96, 0.93, 0.89, 0.85, 0.8, 0.74, 0.68, 0.62, 0.54, 0.47]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.18, 0.13, 0.36, 0.55, 0.73, 0.95, 1.16, 1.37, 1.62, 1.86, 2.11, 2.39, 2.65, 2.93, 3.23, 3.52, 3.85, 4.16, 4.47, 4.82, 5.15, 5.49, 5.86, 6.21, 6.57, 6.97, 7.34, 7.71, 8.13, 8.52]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.31, 0.44, 0.53, 0.6, 0.66, 0.71, 0.75, 0.79, 0.82, 0.85, 0.88, 0.9, 0.92, 0.93, 0.95, 0.96, 0.97, 0.98, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 0.99]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.19, 0.27, 0.33, 0.38, 0.42, 0.46, 0.49, 0.52, 0.55, 0.58, 0.6, 0.62, 0.64, 0.66, 0.68, 0.7, 0.72, 0.73, 0.75, 0.76, 0.78, 0.79, 0.8, 0.81, 0.83, 0.84, 0.85, 0.86, 0.87]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.3, -0.23, -0.15, -0.07, 0.0, 0.09, 0.16, 0.24, 0.32, 0.39, 0.46, 0.53, 0.59, 0.65, 0.71, 0.76, 0.81, 0.86, 0.89, 0.93, 0.95, 0.97, 0.99, 1.0, 1.0, 1.0, 0.99, 0.97, 0.95, 0.92]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.56, 0.68, 0.75, 0.8, 0.85, 0.89, 0.92, 0.95, 0.98, 1.01, 1.03, 1.06, 1.08, 1.1, 1.12, 1.14, 1.15, 1.17, 1.18, 1.2, 1.21, 1.23, 1.24, 1.25, 1.27, 1.28, 1.29, 1.3, 1.32]<EOS_Y><SOS_EQ>', '<SOS_Y>[1.37, 1.47, 1.58, 1.68, 1.78, 1.9, 2.0, 2.1, 2.21, 2.31, 2.42, 2.53, 2.63, 2.73, 2.84, 2.94, 3.06, 3.16, 3.26, 3.37, 3.47, 3.57, 3.69, 3.79, 3.89, 4.0, 4.1, 4.21, 4.32, 4.42]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.31, 0.4, 0.5, 0.58, 0.66, 0.74, 0.8, 0.86, 0.91, 0.95, 0.97, 0.99, 1.0, 1.0, 0.98, 0.96, 0.92, 0.88, 0.83, 0.76, 0.69, 0.61, 0.52, 0.44, 0.34, 0.24, 0.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.01, -0.0, -0.02, -0.06, -0.11, -0.17, -0.24, -0.34, -0.43, -0.53, -0.65, -0.75, -0.84, -0.93, -0.98, -1.0, -0.97, -0.9, -0.75, -0.57, -0.33, -0.03, 0.26, 0.54, 0.79, 0.95, 1.0, 0.91, 0.7]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.04, -0.08, -0.12, -0.16, -0.21, -0.24, -0.28, -0.32, -0.36, -0.4, -0.44, -0.47, -0.51, -0.55, -0.58, -0.61, -0.64, -0.67, -0.71, -0.73, -0.76, -0.79, -0.81, -0.83, -0.86, -0.88, -0.9, -0.91, -0.93]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.12, 0.01, 0.17, 0.34, 0.53, 0.76, 0.99, 1.24, 1.54, 1.84, 2.15, 2.52, 2.87, 3.25, 3.68, 4.1, 4.58, 5.04, 5.52, 6.07, 6.59, 7.13, 7.75, 8.33, 8.94, 9.62, 10.27, 10.93, 11.69, 12.4]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.82, -0.59, -0.35, -0.12, 0.1, 0.35, 0.57, 0.8, 1.05, 1.27, 1.5, 1.74, 1.97, 2.19, 2.44, 2.66, 2.91, 3.14, 3.36, 3.61, 3.83, 4.06, 4.3, 4.53, 4.75, 5.0, 5.22, 5.45, 5.7, 5.92]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.01, 0.07, 0.16, 0.26, 0.35, 0.47, 0.57, 0.68, 0.81, 0.92, 1.03, 1.15, 1.26, 1.36, 1.47, 1.56, 1.65, 1.73, 1.8, 1.87, 1.93, 1.97, 2.01, 2.03, 2.04, 2.05, 2.04, 2.02, 1.99, 1.95]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.02, -0.04, -0.05, -0.05, -0.05, -0.04, -0.02, 0.0, 0.03, 0.06, 0.1, 0.15, 0.2, 0.26, 0.32, 0.4, 0.47, 0.55, 0.65, 0.74, 0.84, 0.95, 1.06, 1.18, 1.31, 1.44, 1.58, 1.73, 1.88]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.62, 0.65, 0.68, 0.71, 0.74, 0.77, 0.79, 0.82, 0.84, 0.86, 0.88, 0.9, 0.92, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 0.99, 0.99, 0.98, 0.97, 0.96, 0.95]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.0, -0.01, -0.01, -0.0, -0.0, 0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.07, 0.08, 0.1, 0.12, 0.15, 0.17, 0.19, 0.22, 0.25, 0.28, 0.31, 0.35, 0.38, 0.42, 0.46, 0.5, 0.54, 0.58]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.44, -0.24, -0.02, 0.18, 0.38, 0.6, 0.8, 1.0, 1.22, 1.42, 1.62, 1.84, 2.04, 2.24, 2.46, 2.66, 2.88, 3.08, 3.28, 3.5, 3.7, 3.9, 4.12, 4.32, 4.52, 4.74, 4.94, 5.14, 5.36, 5.56]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.07, -0.13, -0.17, -0.19, -0.19, -0.18, -0.15, -0.1, -0.04, 0.04, 0.15, 0.27, 0.4, 0.57, 0.75, 0.96, 1.18, 1.41, 1.69, 1.96, 2.26, 2.6, 2.93, 3.29, 3.7, 4.09, 4.5, 4.98, 5.43]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.08, -0.17, -0.25, -0.33, -0.42, -0.5, -0.58, -0.67, -0.75, -0.83, -0.92, -1.0, -1.08, -1.17, -1.25, -1.34, -1.42, -1.5, -1.59, -1.67, -1.75, -1.84, -1.92, -2.0, -2.09, -2.17, -2.26, -2.34, -2.42]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.03, 0.07, 0.1, 0.13, 0.17, 0.2, 0.23, 0.27, 0.3, 0.34, 0.37, 0.4, 0.44, 0.47, 0.51, 0.54, 0.57, 0.61, 0.64, 0.68, 0.71, 0.74, 0.78, 0.81, 0.85, 0.88, 0.91, 0.95, 0.98]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.0, -0.0, -0.01, -0.02, -0.03, -0.06, -0.1, -0.16, -0.23, -0.32, -0.44, -0.57, -0.73, -0.93, -1.15, -1.42, -1.7, -2.02, -2.41, -2.8, -3.24, -3.77, -4.3, -4.88, -5.58, -6.26, -7.0, -7.88, -8.74]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.32, 0.46, 0.55, 0.63, 0.7, 0.76, 0.81, 0.86, 0.9, 0.93, 0.95, 0.97, 0.99, 1.0, 1.0, 1.0, 0.99, 0.98, 0.96, 0.94, 0.91, 0.87, 0.83, 0.78, 0.72, 0.66, 0.59, 0.49, 0.38]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.3, 0.42, 0.51, 0.57, 0.63, 0.68, 0.72, 0.76, 0.79, 0.82, 0.85, 0.87, 0.89, 0.91, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.07, 0.1, 0.12, 0.14, 0.16, 0.17, 0.19, 0.2, 0.21, 0.22, 0.24, 0.25, 0.25, 0.27, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.32, 0.33, 0.34, 0.35, 0.35, 0.36, 0.37, 0.38, 0.38]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.31, 0.41, 0.52, 0.62, 0.72, 0.83, 0.93, 1.03, 1.14, 1.24, 1.34, 1.45, 1.55, 1.66, 1.76, 1.86, 1.97, 2.07, 2.17, 2.28, 2.38, 2.48, 2.59, 2.69, 2.79, 2.9, 3.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.32, 0.46, 0.56, 0.64, 0.72, 0.79, 0.85, 0.91, 0.96, 1.01, 1.07, 1.11, 1.16, 1.2, 1.24, 1.29, 1.33, 1.36, 1.4, 1.44, 1.47, 1.51, 1.54, 1.57, 1.61, 1.64, 1.67, 1.7, 1.73]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.11, -0.18, -0.24, -0.29, -0.35, -0.41, -0.46, -0.53, -0.59, -0.65, -0.72, -0.78, -0.85, -0.92, -0.99, -1.07, -1.14, -1.21, -1.3, -1.37, -1.45, -1.54, -1.62, -1.7, -1.79, -1.87, -1.96, -2.05, -2.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.02, 0.05, 0.09, 0.14, 0.21, 0.29, 0.38, 0.49, 0.6, 0.72, 0.87, 1.02, 1.18, 1.37, 1.56, 1.77, 1.98, 2.2, 2.46, 2.7, 2.96, 3.25, 3.54, 3.83, 4.16, 4.48, 4.81, 5.18, 5.54]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.84, 0.89, 0.93, 0.97, 1.01, 1.05, 1.09, 1.13, 1.17, 1.21, 1.24, 1.28, 1.32, 1.35, 1.39, 1.43, 1.46, 1.5, 1.53, 1.57, 1.6, 1.63, 1.67, 1.7, 1.73, 1.77, 1.8, 1.83, 1.86, 1.9]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.0, -0.01, -0.03, -0.04, -0.06, -0.07, -0.09, -0.11, -0.13, -0.15, -0.18, -0.2, -0.23, -0.26, -0.29, -0.32, -0.35, -0.37, -0.41, -0.44, -0.47, -0.51, -0.54, -0.58, -0.62, -0.65, -0.69, -0.73, -0.77]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.01, 0.09, 0.21, 0.37, 0.55, 0.79, 1.04, 1.31, 1.62, 1.92, 2.22, 2.54, 2.83, 3.1, 3.37, 3.58, 3.78, 3.91, 3.99, 4.02, 3.99, 3.9, 3.73, 3.51, 3.22, 2.83, 2.41, 1.92, 1.33, 0.73]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.44, 0.93, 1.27, 1.55, 1.81, 2.08, 2.33, 2.56, 2.82, 3.05, 3.28, 3.53, 3.75, 3.97, 4.21, 4.43, 4.67, 4.88, 5.1, 5.33, 5.55, 5.76, 5.99, 6.2, 6.41, 6.64, 6.85, 7.05, 7.28, 7.49]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.09, 0.18, 0.27, 0.35, 0.45, 0.54, 0.62, 0.72, 0.81, 0.89, 0.99, 1.07, 1.16, 1.26, 1.34, 1.44, 1.52, 1.61, 1.71, 1.79, 1.88, 1.97, 2.06, 2.15, 2.24, 2.33, 2.42, 2.51, 2.6]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.2, 0.42, 0.61, 0.8, 0.99, 1.16, 1.32, 1.48, 1.6, 1.71, 1.82, 1.89, 1.95, 1.99, 2.0, 1.99, 1.96, 1.92, 1.84, 1.76, 1.65, 1.52, 1.38, 1.23, 1.05, 0.87, 0.69, 0.48, 0.28]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.0, -0.0, -0.01, -0.01, -0.02, -0.02, -0.03, -0.03, -0.04, -0.04, -0.05, -0.06, -0.06, -0.07, -0.08, -0.09, -0.09, -0.1, -0.11, -0.12, -0.13, -0.14, -0.15, -0.15, -0.17, -0.17, -0.18, -0.2, -0.21]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.42, 0.5, 0.58, 0.64, 0.69, 0.74, 0.77, 0.8, 0.82, 0.83, 0.84, 0.84, 0.84, 0.83, 0.81, 0.79, 0.76, 0.72, 0.67, 0.61, 0.55, 0.48, 0.39, 0.3, 0.21, 0.1, 0.0, -0.1, -0.21, -0.3]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.01, -0.01, -0.01, -0.01, 0.0, 0.01, 0.03, 0.05, 0.07, 0.1, 0.13, 0.17, 0.2, 0.25, 0.29, 0.35, 0.4, 0.45, 0.52, 0.58, 0.65, 0.73, 0.8, 0.88, 0.97, 1.06, 1.14, 1.25, 1.34]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.13, 0.28, 0.4, 0.52, 0.64, 0.73, 0.82, 0.89, 0.94, 0.98, 1.0, 1.0, 0.98, 0.94, 0.88, 0.8, 0.72, 0.62, 0.5, 0.38, 0.25, 0.11, -0.03, -0.16, -0.3, -0.42, -0.54, -0.66, -0.75]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.32, 0.47, 0.57, 0.66, 0.74, 0.81, 0.87, 0.93, 0.99, 1.04, 1.09, 1.14, 1.19, 1.23, 1.28, 1.32, 1.36, 1.4, 1.44, 1.47, 1.51, 1.55, 1.58, 1.61, 1.65, 1.68, 1.71, 1.74, 1.77]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.48, 0.47, 0.63, 0.71, 0.77, 0.83, 0.87, 0.9, 0.94, 0.97, 0.99, 1.02, 1.04, 1.07, 1.09, 1.11, 1.13, 1.14, 1.16, 1.18, 1.19, 1.21, 1.22, 1.24, 1.25, 1.26, 1.27, 1.29, 1.3, 1.31]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.01, 0.02, 0.04, 0.05, 0.06, 0.06, 0.07, 0.06, 0.06, 0.05, 0.03, 0.01, -0.02, -0.06, -0.11, -0.17, -0.23, -0.31, -0.4, -0.5, -0.61, -0.75, -0.89, -1.05, -1.23, -1.42, -1.62, -1.86, -2.1]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.31, 0.44, 0.53, 0.6, 0.66, 0.71, 0.75, 0.79, 0.82, 0.85, 0.88, 0.9, 0.92, 0.93, 0.95, 0.96, 0.97, 0.98, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 0.99]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.65, 0.7, 0.74, 0.78, 0.8, 0.82, 0.83, 0.84, 0.84, 0.84, 0.83, 0.81, 0.78, 0.75, 0.71, 0.66, 0.6, 0.54, 0.46, 0.37, 0.28, 0.19, 0.08, -0.02, -0.12, -0.23, -0.32, -0.4, -0.49, -0.56]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.89, 0.81, 0.72, 0.63, 0.55, 0.46, 0.38, 0.3, 0.2, 0.12, 0.04, -0.05, -0.13, -0.22, -0.31, -0.39, -0.48, -0.56, -0.65, -0.74, -0.82, -0.9, -0.99, -1.08, -1.16, -1.25, -1.33, -1.42, -1.51, -1.59]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.89, 1.15, 1.3, 1.41, 1.51, 1.61, 1.7, 1.78, 1.86, 1.94, 2.01, 2.08, 2.15, 2.21, 2.28, 2.34, 2.4, 2.46, 2.51, 2.57, 2.62, 2.68, 2.73, 2.78, 2.83, 2.88, 2.93, 2.97, 3.02, 3.07]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.2, 0.42, 0.62, 0.82, 1.04, 1.24, 1.44, 1.66, 1.86, 2.06, 2.28, 2.48, 2.68, 2.9, 3.1, 3.32, 3.52, 3.72, 3.94, 4.14, 4.34, 4.56, 4.76, 4.96, 5.18, 5.38, 5.58, 5.8, 6.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.4, -0.21, 0.01, 0.2, 0.39, 0.59, 0.74, 0.86, 0.95, 0.99, 1.0, 0.96, 0.88, 0.77, 0.61, 0.44, 0.23, 0.04, -0.16, -0.37, -0.55, -0.71, -0.84, -0.93, -0.99, -1.0, -0.97, -0.9, -0.78, -0.64]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.02, 0.02, 0.03, 0.03, 0.04, 0.04, 0.05, 0.05, 0.06, 0.07, 0.07, 0.08, 0.08, 0.09, 0.1, 0.11, 0.11, 0.12, 0.13, 0.14, 0.14, 0.15, 0.16]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.51, 0.42, 0.27, 0.2, 0.41, 0.57, 0.69, 0.8, 0.92, 1.02, 1.12, 1.23, 1.32, 1.41, 1.52, 1.61, 1.71, 1.79, 1.88, 1.98, 2.07, 2.16, 2.25, 2.34, 2.43, 2.52, 2.61, 2.69, 2.79, 2.87]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.56, -0.38, -0.17, 0.03, 0.23, 0.43, 0.6, 0.75, 0.88, 0.96, 0.99, 0.99, 0.95, 0.87, 0.74, 0.59, 0.4, 0.21, 0.01, -0.21, -0.4, -0.57, -0.74, -0.86, -0.94, -0.99, -1.0, -0.96, -0.88, -0.77]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.05, 0.09, 0.12, 0.14, 0.16, 0.17, 0.17, 0.16, 0.15, 0.13, 0.1, 0.06, 0.02, -0.04, -0.1, -0.17, -0.25, -0.33, -0.43, -0.52, -0.63, -0.75, -0.87, -0.99, -1.14, -1.28, -1.43, -1.6, -1.77]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.06, 0.15, 0.25, 0.36, 0.5, 0.64, 0.8, 0.99, 1.18, 1.39, 1.63, 1.87, 2.12, 2.41, 2.7, 3.03, 3.34, 3.68, 4.06, 4.42, 4.8, 5.23, 5.64, 6.06, 6.55, 7.01, 7.48, 8.01, 8.52]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.82, 1.02, 1.24, 1.44, 1.64, 1.86, 2.06, 2.26, 2.48, 2.68, 2.88, 3.1, 3.3, 3.5, 3.72, 3.92, 4.14, 4.34, 4.54, 4.76, 4.96, 5.16, 5.38, 5.58, 5.78, 6.0, 6.2, 6.4, 6.62, 6.82]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.3, 0.39, 0.48, 0.55, 0.61, 0.67, 0.72, 0.76, 0.79, 0.81, 0.83, 0.84, 0.84, 0.84, 0.83, 0.82, 0.8, 0.77, 0.74, 0.69, 0.64, 0.58, 0.5, 0.42, 0.34, 0.24, 0.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.03, -0.06, -0.09, -0.12, -0.15, -0.18, -0.21, -0.25, -0.28, -0.31, -0.34, -0.37, -0.4, -0.43, -0.46, -0.49, -0.52, -0.55, -0.59, -0.62, -0.65, -0.68, -0.71, -0.74, -0.77, -0.8, -0.83, -0.86, -0.89]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.65, 0.69, 0.73, 0.75, 0.77, 0.78, 0.78, 0.78, 0.78, 0.76, 0.74, 0.71, 0.67, 0.63, 0.56, 0.49, 0.37, 0.2, 0.26, 0.44, 0.57, 0.68, 0.79, 0.88, 0.97, 1.07, 1.15, 1.23, 1.32, 1.4]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.3, 0.38, 0.48, 0.56, 0.65, 0.74, 0.83, 0.91, 1.01, 1.09, 1.18, 1.27, 1.36, 1.44, 1.54, 1.62, 1.72, 1.8, 1.89, 1.98, 2.07, 2.15, 2.25, 2.33, 2.42, 2.51, 2.6, 2.68, 2.78, 2.86]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.01, 0.04, 0.1, 0.17, 0.27, 0.38, 0.5, 0.64, 0.76, 0.87, 0.96, 1.0, 0.97, 0.86, 0.67, 0.38, 0.04, -0.31, -0.67, -0.91, -1.0, -0.88, -0.58, -0.13, 0.41, 0.82, 1.0, 0.85, 0.41]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.31, 0.45, 0.54, 0.62, 0.7, 0.75, 0.8, 0.85, 0.89, 0.92, 0.95, 0.97, 0.98, 0.99, 1.0, 1.0, 1.0, 0.99, 0.97, 0.95, 0.93, 0.89, 0.86, 0.82, 0.76, 0.71, 0.65, 0.56, 0.47]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.09, 0.06, 0.18, 0.28, 0.38, 0.48, 0.57, 0.67, 0.77, 0.86, 0.96, 1.06, 1.15, 1.25, 1.34, 1.45, 1.54, 1.63, 1.73, 1.83, 1.92, 2.02, 2.11, 2.21, 2.31, 2.4, 2.49, 2.6, 2.69]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.04, 0.01, -0.03, -0.07, -0.1, -0.14, -0.16, -0.19, -0.2, -0.21, -0.21, -0.2, -0.17, -0.14, -0.08, -0.01, 0.08, 0.19, 0.32, 0.48, 0.65, 0.84, 1.08, 1.33, 1.61, 1.94, 2.28, 2.65, 3.09, 3.53]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.07, 0.14, 0.2, 0.27, 0.34, 0.41, 0.47, 0.54, 0.61, 0.67, 0.75, 0.81, 0.88, 0.95, 1.01, 1.09, 1.15, 1.22, 1.29, 1.35, 1.42, 1.49, 1.56, 1.62, 1.69, 1.76, 1.82, 1.9, 1.96]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.01, 0.04, 0.06, 0.1, 0.14, 0.18, 0.22, 0.28, 0.33, 0.38, 0.44, 0.5, 0.57, 0.64, 0.7, 0.78, 0.85, 0.92, 1.01, 1.08, 1.16, 1.25, 1.34, 1.42, 1.52, 1.61, 1.7, 1.8, 1.89]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.2, 0.29, 0.36, 0.41, 0.46, 0.51, 0.54, 0.58, 0.62, 0.65, 0.69, 0.71, 0.74, 0.77, 0.8, 0.83, 0.85, 0.88, 0.9, 0.92, 0.95, 0.97, 0.99, 1.01, 1.03, 1.05, 1.07, 1.09, 1.11]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.05, -0.11, -0.16, -0.21, -0.26, -0.31, -0.36, -0.41, -0.45, -0.49, -0.53, -0.57, -0.6, -0.63, -0.66, -0.69, -0.71, -0.73, -0.75, -0.77, -0.79, -0.8, -0.81, -0.82, -0.83, -0.83, -0.84, -0.84, -0.84]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.08, 0.16, 0.23, 0.3, 0.38, 0.44, 0.5, 0.56, 0.6, 0.65, 0.69, 0.72, 0.75, 0.78, 0.8, 0.81, 0.83, 0.83, 0.84, 0.84, 0.84, 0.83, 0.83, 0.81, 0.8, 0.78, 0.75, 0.72, 0.69]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.41, 0.26, 0.2, 0.38, 0.49, 0.59, 0.67, 0.74, 0.81, 0.87, 0.93, 0.99, 1.04, 1.08, 1.13, 1.18, 1.22, 1.26, 1.3, 1.34, 1.38, 1.41, 1.45, 1.49, 1.52, 1.56, 1.59, 1.62, 1.65, 1.68]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.09, -0.18, -0.24, -0.3, -0.34, -0.37, -0.39, -0.4, -0.4, -0.38, -0.35, -0.31, -0.26, -0.19, -0.11, -0.02, 0.08, 0.19, 0.32, 0.46, 0.6, 0.78, 0.95, 1.13, 1.34, 1.54, 1.76, 2.01, 2.25]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.51, 0.62, 0.68, 0.73, 0.77, 0.81, 0.84, 0.87, 0.89, 0.92, 0.94, 0.96, 0.98, 1.0, 1.02, 1.03, 1.05, 1.06, 1.08, 1.09, 1.11, 1.12, 1.13, 1.14, 1.16, 1.17, 1.18, 1.19, 1.2]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.07, 0.16, 0.23, 0.31, 0.39, 0.46, 0.54, 0.62, 0.69, 0.77, 0.85, 0.93, 1.0, 1.08, 1.16, 1.24, 1.31, 1.39, 1.47, 1.55, 1.62, 1.7, 1.78, 1.85, 1.93, 2.01, 2.08, 2.17, 2.24]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.28, 0.37, 0.47, 0.56, 0.64, 0.72, 0.78, 0.84, 0.9, 0.94, 0.97, 0.99, 1.0, 1.0, 0.99, 0.97, 0.93, 0.89, 0.84, 0.78, 0.71, 0.64, 0.55, 0.46, 0.37, 0.27, 0.17, 0.07, -0.04, -0.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.81, 0.79, 0.76, 0.74, 0.71, 0.68, 0.64, 0.61, 0.56, 0.51, 0.46, 0.39, 0.31, 0.18, 0.19, 0.31, 0.4, 0.46, 0.52, 0.57, 0.61, 0.64, 0.68, 0.71, 0.74, 0.76, 0.79, 0.81, 0.83, 0.84]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.45, 0.58, 0.72, 0.86, 1.01, 1.18, 1.34, 1.51, 1.71, 1.89, 2.08, 2.3, 2.5, 2.7, 2.94, 3.16, 3.4, 3.63, 3.86, 4.12, 4.37, 4.62, 4.89, 5.15, 5.41, 5.7, 5.98, 6.25, 6.56, 6.84]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.02, 0.07, 0.13, 0.21, 0.32, 0.44, 0.56, 0.7, 0.82, 0.92, 0.99, 0.99, 0.93, 0.77, 0.54, 0.2, -0.15, -0.5, -0.82, -0.98, -0.97, -0.74, -0.35, 0.14, 0.65, 0.95, 0.97, 0.64, 0.09]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.0, 0.01, 0.03, 0.04, 0.07, 0.1, 0.14, 0.18, 0.23, 0.28, 0.34, 0.4, 0.46, 0.53, 0.6, 0.67, 0.74, 0.8, 0.86, 0.91, 0.95, 0.98, 1.0, 1.0, 0.98, 0.94, 0.88, 0.78, 0.68]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.0, -0.0, -0.0, -0.01, -0.01, -0.01, -0.02, -0.02, -0.03, -0.03, -0.04, -0.05, -0.05, -0.06, -0.07, -0.07, -0.08, -0.08, -0.09, -0.09, -0.09, -0.1, -0.1, -0.1, -0.1, -0.1, -0.09, -0.09, -0.08]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.01, 0.02, 0.01, -0.02, -0.08, -0.16, -0.26, -0.41, -0.58, -0.78, -1.04, -1.32, -1.63, -2.02, -2.42, -2.91, -3.41, -3.94, -4.59, -5.23, -5.92, -6.74, -7.54, -8.39, -9.39, -10.36, -11.39, -12.59, -13.74]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.0, -0.01, -0.02, -0.03, -0.05, -0.07, -0.08, -0.1, -0.11, -0.12, -0.12, -0.12, -0.11, -0.1, -0.08, -0.04, -0.0, 0.05, 0.12, 0.2, 0.28, 0.4, 0.52, 0.66, 0.83, 1.0, 1.19, 1.42, 1.66]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.04, -0.02, -0.01, 0.01, 0.02, 0.04, 0.05, 0.07, 0.08, 0.1, 0.11, 0.13, 0.14, 0.15, 0.17, 0.18, 0.2, 0.21, 0.23, 0.24, 0.26, 0.27, 0.29, 0.3, 0.32, 0.33, 0.35, 0.36, 0.38, 0.39]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.73, 0.9, 1.09, 1.26, 1.43, 1.61, 1.78, 1.95, 2.14, 2.31, 2.48, 2.67, 2.83, 3.0, 3.19, 3.36, 3.55, 3.72, 3.89, 4.07, 4.24, 4.41, 4.6, 4.77, 4.94, 5.12, 5.29, 5.46, 5.65, 5.82]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.64, -0.6, -0.53, -0.45, -0.34, -0.2, -0.04, 0.14, 0.36, 0.58, 0.83, 1.13, 1.43, 1.75, 2.13, 2.5, 2.93, 3.35, 3.79, 4.3, 4.79, 5.3, 5.88, 6.44, 7.02, 7.69, 8.32, 8.97, 9.72, 10.42]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.59, -0.58, -0.56, -0.55, -0.54, -0.52, -0.51, -0.5, -0.49, -0.47, -0.46, -0.45, -0.43, -0.42, -0.41, -0.4, -0.38, -0.37, -0.36, -0.34, -0.33, -0.32, -0.3, -0.29, -0.28, -0.27, -0.25, -0.24, -0.23, -0.21]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.09, -0.18, -0.26, -0.34, -0.43, -0.5, -0.57, -0.65, -0.71, -0.76, -0.81, -0.85, -0.89, -0.91, -0.93, -0.94, -0.95, -0.94, -0.92, -0.9, -0.87, -0.83, -0.78, -0.73, -0.67, -0.6, -0.53, -0.45, -0.37]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.2, 0.19, 0.17, 0.16, 0.15, 0.14, 0.13, 0.12, 0.11, 0.1, 0.1, 0.1, 0.09, 0.09, 0.09, 0.1, 0.1, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.19, 0.21, 0.22, 0.24, 0.26]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.02, 0.04, 0.06, 0.08, 0.1, 0.1, 0.08, 0.05, -0.01, -0.09, -0.21, -0.36, -0.54, -0.78, -1.05, -1.4, -1.77, -2.19, -2.72, -3.27, -3.88, -4.64, -5.4, -6.24, -7.25, -8.25, -9.35, -10.65, -11.94]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.06, 0.15, 0.25, 0.37, 0.51, 0.64, 0.77, 0.9, 0.97, 1.0, 0.95, 0.83, 0.62, 0.3, -0.05, -0.44, -0.75, -0.95, -0.99, -0.81, -0.45, 0.08, 0.56, 0.9, 0.99, 0.73, 0.22, -0.45, -0.89]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.0, 0.01, 0.02, 0.03, 0.06, 0.09, 0.13, 0.18, 0.23, 0.29, 0.37, 0.45, 0.55, 0.66, 0.78, 0.92, 1.06, 1.21, 1.4, 1.58, 1.77, 2.01, 2.23, 2.48, 2.76, 3.04, 3.34, 3.68, 4.01]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.0, 0.0, 0.01, 0.01, 0.02, 0.04, 0.06, 0.08, 0.11, 0.14, 0.19, 0.23, 0.28, 0.35, 0.41, 0.49, 0.57, 0.65, 0.75, 0.85, 0.96, 1.09, 1.22, 1.35, 1.51, 1.66, 1.82, 2.01, 2.19]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.22, 0.32, 0.39, 0.44, 0.49, 0.53, 0.57, 0.6, 0.63, 0.66, 0.69, 0.71, 0.73, 0.76, 0.78, 0.79, 0.81, 0.83, 0.84, 0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94, 0.94]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.14, 0.18, 0.19, 0.18, 0.16, 0.13, 0.09, 0.04, -0.01, -0.07, -0.14, -0.21, -0.29, -0.37, -0.45, -0.55, -0.64, -0.74, -0.85, -0.95, -1.06, -1.18, -1.29, -1.4, -1.54, -1.66, -1.78, -1.92, -2.05]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.03, 0.07, 0.1, 0.13, 0.17, 0.2, 0.24, 0.27, 0.31, 0.34, 0.37, 0.41, 0.44, 0.48, 0.51, 0.55, 0.58, 0.61, 0.65, 0.68, 0.71, 0.75, 0.78, 0.81, 0.85, 0.88, 0.92, 0.95, 0.99]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.13, -0.09, 0.0, 0.13, 0.31, 0.49, 0.7, 0.95, 1.2, 1.47, 1.78, 2.08, 2.39, 2.75, 3.09, 3.49, 3.85, 4.24, 4.67, 5.07, 5.49, 5.96, 6.4, 6.84, 7.35, 7.82, 8.29, 8.83, 9.33]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.31, 0.4, 0.5, 0.58, 0.66, 0.74, 0.8, 0.86, 0.91, 0.95, 0.97, 0.99, 1.0, 1.0, 0.98, 0.96, 0.92, 0.88, 0.83, 0.76, 0.69, 0.61, 0.52, 0.44, 0.34, 0.24, 0.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.03, -0.06, -0.08, -0.09, -0.09, -0.09, -0.08, -0.06, -0.04, -0.01, 0.03, 0.08, 0.13, 0.19, 0.25, 0.33, 0.4, 0.48, 0.56, 0.64, 0.72, 0.8, 0.87, 0.92, 0.97, 0.99, 1.0, 0.98, 0.93]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.19, 0.32, 0.42, 0.53, 0.64, 0.74, 0.84, 0.95, 1.06, 1.16, 1.27, 1.37, 1.47, 1.58, 1.68, 1.79, 1.89, 1.99, 2.1, 2.2, 2.3, 2.41, 2.51, 2.61, 2.72, 2.82, 2.92, 3.03, 3.13]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.08, -0.17, -0.23, -0.3, -0.36, -0.41, -0.45, -0.48, -0.51, -0.53, -0.55, -0.56, -0.56, -0.55, -0.54, -0.52, -0.49, -0.45, -0.41, -0.36, -0.31, -0.24, -0.17, -0.1, -0.01, 0.08, 0.17, 0.29, 0.4]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.52, 0.65, 0.8, 0.94, 1.08, 1.23, 1.37, 1.49, 1.61, 1.71, 1.78, 1.84, 1.87, 1.87, 1.84, 1.78, 1.68, 1.55, 1.39, 1.19, 0.97, 0.72, 0.42, 0.11, -0.21, -0.58, -0.94, -1.31, -1.71, -2.09]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.05, -0.1, -0.15, -0.2, -0.25, -0.29, -0.34, -0.38, -0.42, -0.46, -0.5, -0.54, -0.57, -0.6, -0.63, -0.66, -0.69, -0.71, -0.73, -0.75, -0.76, -0.78, -0.79, -0.8, -0.81, -0.82, -0.83, -0.83, -0.84]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.3, 0.44, 0.56, 0.68, 0.83, 0.98, 1.15, 1.35, 1.55, 1.76, 2.02, 2.27, 2.54, 2.86, 3.17, 3.54, 3.89, 4.26, 4.68, 5.09, 5.52, 6.01, 6.48, 6.97, 7.53, 8.06, 8.6, 9.23, 9.82]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.0, 0.01, 0.01, 0.02, 0.03, 0.05, 0.06, 0.08, 0.1, 0.13, 0.15, 0.18, 0.21, 0.25, 0.28, 0.32, 0.36, 0.4, 0.44, 0.49, 0.53, 0.58, 0.62, 0.67, 0.71, 0.76, 0.8, 0.84, 0.88]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.32, 0.46, 0.56, 0.64, 0.72, 0.79, 0.85, 0.91, 0.96, 1.01, 1.07, 1.11, 1.16, 1.2, 1.24, 1.29, 1.33, 1.36, 1.4, 1.44, 1.47, 1.51, 1.54, 1.57, 1.61, 1.64, 1.67, 1.7, 1.73]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.34, 0.38, 0.43, 0.48, 0.52, 0.57, 0.61, 0.65, 0.69, 0.73, 0.76, 0.8, 0.83, 0.86, 0.88, 0.91, 0.93, 0.95, 0.96, 0.98, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 0.99, 0.98, 0.97, 0.95]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.07, 0.14, 0.2, 0.27, 0.34, 0.41, 0.47, 0.54, 0.61, 0.67, 0.74, 0.81, 0.87, 0.94, 1.01, 1.08, 1.15, 1.21, 1.28, 1.35, 1.41, 1.48, 1.55, 1.61, 1.68, 1.75, 1.81, 1.89, 1.95]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.16, -0.17, -0.2, -0.22, -0.24, -0.26, -0.28, -0.31, -0.33, -0.36, -0.38, -0.41, -0.44, -0.47, -0.5, -0.53, -0.56, -0.59, -0.63, -0.66, -0.7, -0.73, -0.77, -0.81, -0.85, -0.89, -0.93, -0.97, -1.01, -1.05]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.07, -0.09, -0.1, -0.09, -0.09, -0.07, -0.06, -0.03, -0.01, 0.02, 0.05, 0.08, 0.11, 0.15, 0.19, 0.23, 0.28, 0.32, 0.37, 0.42, 0.47, 0.52, 0.57, 0.63, 0.69, 0.74, 0.8, 0.87, 0.93]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.02, 0.04, 0.07, 0.09, 0.12, 0.15, 0.18, 0.22, 0.26, 0.3, 0.35, 0.41, 0.46, 0.54, 0.61, 0.69, 0.77, 0.86, 0.97, 1.07, 1.18, 1.31, 1.43, 1.56, 1.71, 1.85, 1.99, 2.16, 2.31]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.01, -0.02, -0.01, -0.01, -0.0, 0.01, 0.02, 0.04, 0.06, 0.08, 0.1, 0.13, 0.16, 0.2, 0.23, 0.28, 0.32, 0.37, 0.42, 0.48, 0.54, 0.6, 0.67, 0.74, 0.82, 0.9, 0.98, 1.08, 1.17]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.31, 0.4, 0.5, 0.58, 0.66, 0.74, 0.8, 0.86, 0.91, 0.95, 0.97, 0.99, 1.0, 1.0, 0.98, 0.96, 0.92, 0.88, 0.83, 0.76, 0.69, 0.61, 0.52, 0.44, 0.34, 0.24, 0.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.27, -0.32, -0.37, -0.41, -0.46, -0.51, -0.55, -0.6, -0.64, -0.69, -0.73, -0.78, -0.83, -0.87, -0.92, -0.97, -1.02, -1.06, -1.11, -1.16, -1.2, -1.25, -1.3, -1.34, -1.39, -1.44, -1.48, -1.53, -1.57, -1.62]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.31, 0.4, 0.5, 0.58, 0.66, 0.74, 0.8, 0.86, 0.91, 0.95, 0.97, 0.99, 1.0, 1.0, 0.98, 0.96, 0.92, 0.88, 0.83, 0.76, 0.69, 0.61, 0.52, 0.44, 0.34, 0.24, 0.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.49, 0.59, 0.65, 0.7, 0.74, 0.77, 0.8, 0.83, 0.86, 0.88, 0.9, 0.92, 0.94, 0.96, 0.97, 0.99, 1.0, 1.02, 1.03, 1.05, 1.06, 1.07, 1.08, 1.09, 1.11, 1.12, 1.13, 1.14, 1.15]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.71, 0.75, 0.79, 0.81, 0.83, 0.84, 0.84, 0.84, 0.83, 0.82, 0.8, 0.77, 0.74, 0.7, 0.64, 0.58, 0.51, 0.43, 0.35, 0.25, 0.15, 0.05, -0.06, -0.16, -0.25, -0.35, -0.44, -0.51, -0.59, -0.65]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.51, 0.61, 0.68, 0.73, 0.77, 0.81, 0.84, 0.87, 0.89, 0.91, 0.94, 0.96, 0.98, 1.0, 1.01, 1.03, 1.05, 1.06, 1.08, 1.09, 1.1, 1.12, 1.13, 1.14, 1.15, 1.16, 1.17, 1.18, 1.19]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.23, 0.34, 0.41, 0.47, 0.53, 0.58, 0.62, 0.67, 0.71, 0.74, 0.78, 0.81, 0.85, 0.88, 0.91, 0.94, 0.97, 1.0, 1.03, 1.05, 1.08, 1.11, 1.13, 1.15, 1.18, 1.2, 1.22, 1.25, 1.27]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.75, 0.75, 0.75, 0.76, 0.76, 0.76, 0.77, 0.77, 0.77, 0.78, 0.78, 0.78, 0.78, 0.79, 0.79, 0.79, 0.8, 0.8, 0.8, 0.81, 0.81, 0.81, 0.82, 0.82, 0.82, 0.83, 0.83, 0.83, 0.83, 0.84]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.01, -0.01, -0.02, -0.03, -0.04, -0.05, -0.06, -0.08, -0.09, -0.11, -0.14, -0.16, -0.18, -0.21, -0.24, -0.27, -0.3, -0.34, -0.38, -0.42, -0.46, -0.51, -0.56, -0.61]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.48, 0.52, 0.55, 0.58, 0.61, 0.64, 0.66, 0.68, 0.7, 0.71, 0.72, 0.73, 0.73, 0.74, 0.74, 0.73, 0.73, 0.72, 0.71, 0.69, 0.68, 0.66, 0.63, 0.61, 0.58, 0.55, 0.52, 0.48, 0.44, 0.4]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.01, 0.02, 0.04, 0.06, 0.08, 0.11, 0.14, 0.17, 0.21, 0.24, 0.29, 0.33, 0.38, 0.43, 0.48, 0.53, 0.58, 0.64, 0.69, 0.74, 0.79, 0.84, 0.88, 0.92, 0.95, 0.98, 0.99, 1.0, 1.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.56, 0.68, 0.75, 0.8, 0.85, 0.89, 0.92, 0.95, 0.98, 1.01, 1.03, 1.06, 1.08, 1.1, 1.12, 1.14, 1.15, 1.17, 1.18, 1.2, 1.21, 1.23, 1.24, 1.25, 1.27, 1.28, 1.29, 1.3, 1.32]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.17, 0.27, 0.37, 0.47, 0.6, 0.74, 0.88, 1.06, 1.25, 1.44, 1.68, 1.91, 2.16, 2.45, 2.73, 3.07, 3.39, 3.72, 4.11, 4.48, 4.87, 5.32, 5.75, 6.19, 6.7, 7.18, 7.67, 8.24, 8.77]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.0, -0.01, -0.01, -0.01, -0.01, -0.02, -0.02, -0.02, -0.02, -0.02, -0.03, -0.03, -0.03, -0.04, -0.04, -0.04, -0.04, -0.05, -0.05, -0.05, -0.05, -0.06, -0.06, -0.06, -0.06, -0.07, -0.07, -0.07, -0.07]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.61, -0.46, -0.28, -0.1, 0.08, 0.27, 0.44, 0.59, 0.74, 0.84, 0.93, 0.98, 1.0, 0.99, 0.93, 0.86, 0.74, 0.61, 0.46, 0.27, 0.1, -0.08, -0.27, -0.44, -0.59, -0.74, -0.85, -0.93, -0.98, -1.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.69, 0.66, 0.62, 0.59, 0.56, 0.53, 0.49, 0.46, 0.43, 0.4, 0.37, 0.34, 0.31, 0.28, 0.25, 0.22, 0.19, 0.16, 0.14, 0.11, 0.08, 0.05, 0.03, 0.0, -0.02, -0.05, -0.07, -0.1, -0.12, -0.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.04, 0.14, 0.25, 0.34, 0.43, 0.53, 0.61, 0.69, 0.76, 0.82, 0.88, 0.92, 0.96, 0.98, 1.0, 1.0, 0.99, 0.97, 0.95, 0.91, 0.86, 0.8, 0.73, 0.66, 0.58, 0.49, 0.4, 0.31, 0.2, 0.1]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.34, 0.43, 0.51, 0.58, 0.64, 0.69, 0.74, 0.77, 0.8, 0.82, 0.83, 0.84, 0.84, 0.84, 0.83, 0.81, 0.79, 0.75, 0.72, 0.67, 0.61, 0.55, 0.47, 0.38, 0.3, 0.19, 0.1, -0.0, -0.11, -0.21]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.42, 0.67, 0.86, 1.04, 1.22, 1.37, 1.51, 1.65, 1.77, 1.87, 1.98, 2.06, 2.13, 2.2, 2.24, 2.28, 2.31, 2.32, 2.32, 2.32, 2.3, 2.27, 2.23, 2.19, 2.13, 2.08, 2.01, 1.94, 1.87]<EOS_Y><SOS_EQ>', '<SOS_Y>[-1.15, -1.31, -1.51, -1.71, -1.93, -2.19, -2.44, -2.71, -3.03, -3.33, -3.66, -4.04, -4.4, -4.78, -5.21, -5.63, -6.1, -6.56, -7.03, -7.56, -8.07, -8.59, -9.19, -9.74, -10.32, -10.98, -11.59, -12.22, -12.93, -13.6]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.1, 0.05, 0.21, 0.36, 0.51, 0.67, 0.82, 0.97, 1.13, 1.28, 1.43, 1.59, 1.74, 1.89, 2.05, 2.2, 2.36, 2.51, 2.66, 2.82, 2.97, 3.12, 3.28, 3.43, 3.58, 3.74, 3.89, 4.04, 4.2, 4.35]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.26, 0.35, 0.4, 0.42, 0.42, 0.41, 0.37, 0.29, 0.13, 0.25, 0.41, 0.53, 0.64, 0.76, 0.86, 0.97, 1.06, 1.16, 1.26, 1.36, 1.45, 1.55, 1.65, 1.74, 1.84, 1.93, 2.02, 2.12, 2.21]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.72, 0.75, 0.78, 0.81, 0.84, 0.88, 0.9, 0.93, 0.96, 0.98, 1.01, 1.03, 1.06, 1.08, 1.1, 1.13, 1.15, 1.17, 1.19, 1.21, 1.23, 1.25, 1.27, 1.29, 1.31, 1.33, 1.35, 1.37, 1.39, 1.41]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.28, 0.41, 0.49, 0.57, 0.64, 0.7, 0.75, 0.81, 0.85, 0.9, 0.95, 0.99, 1.02, 1.07, 1.1, 1.14, 1.17, 1.21, 1.24, 1.27, 1.3, 1.34, 1.37, 1.39, 1.42, 1.45, 1.48, 1.51, 1.53]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.3, 0.39, 0.48, 0.55, 0.61, 0.67, 0.72, 0.76, 0.79, 0.81, 0.83, 0.84, 0.84, 0.84, 0.83, 0.82, 0.8, 0.77, 0.74, 0.69, 0.64, 0.58, 0.5, 0.42, 0.34, 0.24, 0.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.37, -0.28, -0.17, -0.08, 0.02, 0.13, 0.23, 0.32, 0.42, 0.5, 0.57, 0.63, 0.68, 0.73, 0.77, 0.79, 0.82, 0.83, 0.84, 0.84, 0.84, 0.83, 0.81, 0.79, 0.76, 0.72, 0.68, 0.62, 0.55, 0.48]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.3, 0.39, 0.48, 0.55, 0.61, 0.67, 0.72, 0.76, 0.79, 0.81, 0.83, 0.84, 0.84, 0.84, 0.83, 0.82, 0.8, 0.77, 0.74, 0.69, 0.64, 0.58, 0.5, 0.42, 0.34, 0.24, 0.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.01, 0.01, 0.02, 0.02, 0.03, 0.03, 0.04, 0.05, 0.05, 0.06, 0.06, 0.07, 0.07, 0.08, 0.09, 0.09, 0.1, 0.1, 0.11, 0.11, 0.12, 0.13, 0.13, 0.14, 0.14, 0.15, 0.15, 0.16, 0.17]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.18, 0.37, 0.55, 0.72, 0.92, 1.09, 1.27, 1.47, 1.64, 1.82, 2.01, 2.19, 2.37, 2.56, 2.74, 2.93, 3.11, 3.28, 3.48, 3.66, 3.83, 4.03, 4.2, 4.38, 4.57, 4.75, 4.93, 5.12, 5.3]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.03, 0.07, 0.13, 0.21, 0.33, 0.46, 0.62, 0.84, 1.07, 1.33, 1.67, 2.01, 2.4, 2.89, 3.38, 3.98, 4.58, 5.24, 6.04, 6.82, 7.67, 8.69, 9.68, 10.75, 12.01, 13.23, 14.54, 16.07, 17.55]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.0, 0.02, 0.04, 0.08, 0.13, 0.18, 0.23, 0.28, 0.32, 0.35, 0.35, 0.3, 0.09, 0.4, 0.65, 0.93, 1.2, 1.5, 1.86, 2.22, 2.61, 3.07, 3.53, 4.02, 4.6, 5.16, 5.76, 6.47, 7.15]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.02, -0.07, -0.12, -0.18, -0.26, -0.34, -0.42, -0.52, -0.62, -0.72, -0.84, -0.95, -1.07, -1.2, -1.33, -1.47, -1.6, -1.74, -1.9, -2.05, -2.2, -2.36, -2.52, -2.68, -2.86, -3.03, -3.2, -3.39, -3.57]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.06, 0.13, 0.19, 0.25, 0.33, 0.4, 0.47, 0.54, 0.62, 0.69, 0.78, 0.86, 0.94, 1.03, 1.11, 1.2, 1.29, 1.38, 1.48, 1.57, 1.66, 1.76, 1.86, 1.95, 2.06, 2.16, 2.26, 2.37, 2.47]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.31, 0.41, 0.52, 0.62, 0.72, 0.83, 0.93, 1.03, 1.14, 1.24, 1.34, 1.45, 1.55, 1.66, 1.76, 1.86, 1.97, 2.07, 2.17, 2.28, 2.38, 2.48, 2.59, 2.69, 2.79, 2.9, 3.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.04, -0.07, -0.07, -0.06, -0.01, 0.05, 0.13, 0.24, 0.36, 0.5, 0.68, 0.86, 1.06, 1.31, 1.56, 1.85, 2.14, 2.44, 2.8, 3.15, 3.52, 3.95, 4.36, 4.8, 5.29, 5.77, 6.26, 6.83, 7.36]<EOS_Y><SOS_EQ>', '<SOS_Y>[1.15, 1.23, 1.27, 1.44, 1.8, 2.13, 2.41, 2.68, 2.96, 3.22, 3.47, 3.74, 3.98, 4.22, 4.48, 4.71, 4.97, 5.2, 5.43, 5.68, 5.91, 6.14, 6.38, 6.61, 6.83, 7.08, 7.3, 7.52, 7.76, 7.98]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.06, 0.13, 0.2, 0.26, 0.33, 0.39, 0.45, 0.51, 0.56, 0.61, 0.67, 0.71, 0.76, 0.8, 0.84, 0.87, 0.9, 0.93, 0.95, 0.97, 0.98, 0.99, 1.0, 1.0, 1.0, 0.99, 0.98, 0.96, 0.94]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.69, 0.57, 0.43, 0.28, 0.09, -0.01, 0.12, 0.19, 0.24, 0.28, 0.31, 0.33, 0.35, 0.36, 0.38, 0.38, 0.39, 0.39, 0.39, 0.39, 0.39, 0.39, 0.38, 0.38, 0.37, 0.36, 0.35, 0.35, 0.33, 0.32]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.71, 0.78, 0.85, 0.91, 0.96, 1.01, 1.06, 1.11, 1.16, 1.2, 1.24, 1.28, 1.32, 1.36, 1.4, 1.44, 1.47, 1.51, 1.54, 1.57, 1.61, 1.64, 1.67, 1.7, 1.73, 1.76, 1.79, 1.82, 1.85, 1.87]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.95, 0.98, 1.01, 1.03, 1.05, 1.08, 1.1, 1.11, 1.13, 1.15, 1.17, 1.18, 1.2, 1.21, 1.23, 1.24, 1.25, 1.27, 1.28, 1.29, 1.3, 1.31, 1.33, 1.34, 1.35, 1.36, 1.37, 1.38, 1.39, 1.4]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.0, 0.0, 0.01, 0.04, 0.09, 0.17, 0.28, 0.44, 0.64, 0.9, 1.24, 1.62, 2.07, 2.66, 3.28, 4.06, 4.88, 5.79, 6.92, 8.07, 9.34, 10.89, 12.43, 14.11, 16.13, 18.12, 20.27, 22.83, 25.33]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.75, 0.76, 0.77, 0.78, 0.79, 0.81, 0.82, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.87, 0.88, 0.89, 0.9, 0.9, 0.91, 0.91, 0.92, 0.92, 0.93, 0.93, 0.94, 0.94, 0.95, 0.95, 0.95, 0.96]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.49, -0.39, -0.28, -0.18, -0.08, 0.03, 0.13, 0.23, 0.34, 0.44, 0.54, 0.65, 0.75, 0.85, 0.96, 1.06, 1.17, 1.27, 1.37, 1.48, 1.58, 1.68, 1.79, 1.89, 1.99, 2.1, 2.2, 2.3, 2.41, 2.51]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.02, 0.04, 0.06, 0.08, 0.11, 0.13, 0.15, 0.17, 0.19, 0.21, 0.23, 0.25, 0.27, 0.3, 0.32, 0.34, 0.36, 0.38, 0.4, 0.42, 0.44, 0.47, 0.49, 0.51, 0.53, 0.55, 0.57, 0.59, 0.61]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.09, 0.19, 0.28, 0.37, 0.46, 0.54, 0.61, 0.69, 0.75, 0.81, 0.86, 0.91, 0.94, 0.97, 0.99, 1.0, 1.0, 0.99, 0.97, 0.95, 0.92, 0.87, 0.82, 0.77, 0.7, 0.63, 0.56, 0.47, 0.39]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.53, 0.64, 0.7, 0.75, 0.8, 0.83, 0.87, 0.9, 0.92, 0.95, 0.97, 0.99, 1.01, 1.03, 1.05, 1.07, 1.08, 1.1, 1.11, 1.13, 1.14, 1.16, 1.17, 1.18, 1.19, 1.2, 1.22, 1.23, 1.24]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.08, 0.19, 0.29, 0.4, 0.52, 0.65, 0.78, 0.93, 1.07, 1.21, 1.38, 1.54, 1.7, 1.89, 2.06, 2.26, 2.44, 2.63, 2.84, 3.04, 3.24, 3.46, 3.67, 3.89, 4.12, 4.35, 4.57, 4.82, 5.05]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.03, -0.07, -0.1, -0.13, -0.16, -0.19, -0.22, -0.26, -0.29, -0.32, -0.35, -0.38, -0.41, -0.44, -0.47, -0.5, -0.52, -0.55, -0.58, -0.6, -0.63, -0.66, -0.68, -0.7, -0.73, -0.75, -0.77, -0.79, -0.81]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.28, 0.38, 0.42, 0.43, 0.4, 0.35, 0.27, 0.16, 0.03, -0.12, -0.3, -0.5, -0.72, -0.98, -1.24, -1.55, -1.86, -2.18, -2.57, -2.94, -3.33, -3.78, -4.22, -4.67, -5.2, -5.7, -6.21, -6.81, -7.37]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.31, 0.45, 0.55, 0.63, 0.71, 0.77, 0.83, 0.9, 0.95, 1.0, 1.05, 1.09, 1.14, 1.18, 1.22, 1.27, 1.3, 1.34, 1.38, 1.41, 1.45, 1.48, 1.52, 1.55, 1.58, 1.61, 1.64, 1.67, 1.7]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.27, 0.27, 0.28, 0.29, 0.3, 0.31, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.36, 0.37, 0.38, 0.39, 0.39, 0.4, 0.41, 0.42, 0.43, 0.43, 0.44, 0.45, 0.46, 0.46, 0.47, 0.48, 0.49, 0.49]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.75, -0.7, -0.64, -0.59, -0.52, -0.45, -0.39, -0.32, -0.24, -0.17, -0.1, -0.01, 0.06, 0.13, 0.21, 0.28, 0.36, 0.43, 0.49, 0.56, 0.62, 0.68, 0.73, 0.78, 0.83, 0.87, 0.9, 0.93, 0.96, 0.98]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.61, -0.41, -0.19, 0.01, 0.21, 0.43, 0.63, 0.83, 1.05, 1.25, 1.45, 1.67, 1.87, 2.07, 2.29, 2.49, 2.71, 2.91, 3.11, 3.33, 3.53, 3.73, 3.95, 4.15, 4.35, 4.57, 4.77, 4.97, 5.19, 5.39]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.07, -0.15, -0.22, -0.29, -0.36, -0.43, -0.49, -0.56, -0.61, -0.67, -0.72, -0.77, -0.81, -0.86, -0.89, -0.92, -0.95, -0.97, -0.99, -0.99, -1.0, -1.0, -0.99, -0.98, -0.96, -0.94, -0.92, -0.88, -0.85]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.07, -0.1, -0.08, -0.02, 0.08, 0.21, 0.37, 0.58, 0.79, 1.01, 1.27, 1.51, 1.75, 2.0, 2.22, 2.43, 2.59, 2.72, 2.82, 2.86, 2.86, 2.79, 2.68, 2.51, 2.25, 1.96, 1.62, 1.18, 0.72]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.13, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.31, 0.41, 0.52, 0.62, 0.72, 0.83, 0.93, 1.03, 1.14, 1.24, 1.34, 1.45, 1.55, 1.66, 1.76, 1.86, 1.97, 2.07, 2.17, 2.28, 2.38, 2.48, 2.59, 2.69, 2.79, 2.9, 3.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.2, 0.42, 0.61, 0.8, 0.99, 1.16, 1.32, 1.48, 1.6, 1.71, 1.82, 1.89, 1.95, 1.99, 2.0, 1.99, 1.96, 1.92, 1.84, 1.76, 1.65, 1.52, 1.38, 1.23, 1.05, 0.87, 0.69, 0.48, 0.28]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.08, 0.02, 0.13, 0.23, 0.32, 0.42, 0.51, 0.6, 0.68, 0.75, 0.81, 0.87, 0.92, 0.95, 0.98, 0.99, 1.0, 0.99, 0.98, 0.95, 0.91, 0.87, 0.81, 0.75, 0.68, 0.59, 0.51, 0.42, 0.32, 0.22]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.32, 0.46, 0.56, 0.64, 0.72, 0.79, 0.85, 0.91, 0.96, 1.01, 1.07, 1.11, 1.16, 1.2, 1.24, 1.29, 1.33, 1.36, 1.4, 1.44, 1.47, 1.51, 1.54, 1.57, 1.61, 1.64, 1.67, 1.7, 1.73]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.28, 0.36, 0.47, 0.59, 0.72, 0.88, 1.05, 1.23, 1.44, 1.66, 1.88, 2.15, 2.41, 2.69, 3.01, 3.32, 3.68, 4.02, 4.38, 4.79, 5.18, 5.58, 6.05, 6.49, 6.94, 7.46, 7.94, 8.44, 9.01, 9.55]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.0, 0.05, 0.12, 0.2, 0.31, 0.42, 0.53, 0.67, 0.81, 0.95, 1.12, 1.28, 1.44, 1.64, 1.82, 2.02, 2.21, 2.41, 2.64, 2.85, 3.06, 3.3, 3.53, 3.76, 4.02, 4.26, 4.51, 4.78, 5.04]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.25, 0.35, 0.43, 0.49, 0.54, 0.58, 0.62, 0.66, 0.69, 0.72, 0.75, 0.77, 0.79, 0.81, 0.83, 0.85, 0.87, 0.88, 0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.96, 0.97, 0.98, 0.98]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.27, 0.46, 0.61, 0.75, 0.89, 1.01, 1.12, 1.23, 1.32, 1.41, 1.49, 1.55, 1.6, 1.65, 1.67, 1.69, 1.7, 1.7, 1.68, 1.66, 1.62, 1.58, 1.53, 1.47, 1.4, 1.33, 1.25, 1.16, 1.08]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.08, -0.17, -0.24, -0.32, -0.4, -0.47, -0.54, -0.61, -0.67, -0.73, -0.79, -0.83, -0.87, -0.91, -0.94, -0.97, -0.98, -1.0, -1.0, -1.0, -0.99, -0.97, -0.95, -0.92, -0.89, -0.85, -0.8, -0.75, -0.69]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.0, -0.01, -0.03, -0.05, -0.08, -0.11, -0.15, -0.2, -0.25, -0.31, -0.37, -0.44, -0.51, -0.58, -0.65, -0.73, -0.79, -0.85, -0.91, -0.95, -0.98, -1.0, -0.99, -0.97, -0.92, -0.84, -0.74, -0.61, -0.46]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.15, 0.22, 0.27, 0.31, 0.34, 0.37, 0.4, 0.43, 0.45, 0.47, 0.5, 0.52, 0.53, 0.55, 0.57, 0.59, 0.6, 0.62, 0.63, 0.65, 0.66, 0.67, 0.68, 0.69, 0.71, 0.72, 0.73, 0.74, 0.75]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.88, 0.88, 0.88, 0.88, 0.89, 0.89, 0.89, 0.89, 0.9, 0.9, 0.9, 0.9, 0.91, 0.91, 0.91, 0.91, 0.92, 0.92, 0.92, 0.92, 0.93, 0.93, 0.93, 0.93, 0.94, 0.94, 0.94, 0.94, 0.95, 0.95]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.47, 0.55, 0.62, 0.67, 0.72, 0.76, 0.79, 0.81, 0.83, 0.84, 0.84, 0.84, 0.83, 0.82, 0.8, 0.77, 0.73, 0.69, 0.64, 0.57, 0.5, 0.43, 0.33, 0.24, 0.15, 0.04, -0.06, -0.16, -0.27, -0.36]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.31, 0.41, 0.52, 0.62, 0.72, 0.83, 0.93, 1.03, 1.14, 1.24, 1.34, 1.45, 1.55, 1.66, 1.76, 1.86, 1.97, 2.07, 2.17, 2.28, 2.38, 2.48, 2.59, 2.69, 2.79, 2.9, 3.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.06, 0.11, 0.14, 0.15, 0.15, 0.13, 0.1, 0.04, -0.03, -0.11, -0.21, -0.33, -0.46, -0.62, -0.78, -0.98, -1.17, -1.38, -1.63, -1.87, -2.13, -2.43, -2.72, -3.02, -3.37, -3.71, -4.06, -4.47, -4.85]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.84, 1.06, 1.3, 1.52, 1.73, 1.96, 2.17, 2.38, 2.6, 2.8, 3.01, 3.23, 3.43, 3.63, 3.85, 4.04, 4.26, 4.46, 4.65, 4.87, 5.06, 5.26, 5.47, 5.66, 5.85, 6.06, 6.26, 6.45, 6.66, 6.85]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.02, 0.04, 0.06, 0.08, 0.1, 0.12, 0.14, 0.16, 0.18, 0.2, 0.22, 0.24, 0.26, 0.28, 0.3, 0.32, 0.34, 0.36, 0.38, 0.4, 0.42, 0.44, 0.46, 0.48, 0.5, 0.52, 0.54, 0.56, 0.58]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.01, -0.04, -0.08, -0.14, -0.22, -0.32, -0.45, -0.62, -0.81, -1.04, -1.33, -1.63, -1.98, -2.41, -2.86, -3.41, -3.97, -4.58, -5.33, -6.07, -6.88, -7.85, -8.8, -9.84, -11.06, -12.25, -13.53, -15.04, -16.5]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.29, 0.24, 0.19, 0.15, 0.11, 0.08, 0.05, 0.02, 0.0, -0.01, -0.02, -0.03, -0.03, -0.03, -0.02, -0.01, 0.01, 0.03, 0.05, 0.09, 0.12, 0.16, 0.2, 0.25, 0.3, 0.36, 0.42, 0.48, 0.56, 0.63]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.08, -0.15, -0.19, -0.22, -0.22, -0.21, -0.17, -0.11, -0.04, 0.04, 0.14, 0.24, 0.34, 0.45, 0.54, 0.62, 0.69, 0.74, 0.77, 0.78, 0.77, 0.73, 0.68, 0.61, 0.52, 0.43, 0.33, 0.23, 0.13]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.01, 0.03, 0.07, 0.13, 0.21, 0.3, 0.4, 0.54, 0.67, 0.83, 1.01, 1.2, 1.4, 1.64, 1.87, 2.15, 2.42, 2.7, 3.03, 3.34, 3.67, 4.05, 4.42, 4.8, 5.23, 5.64, 6.07, 6.56, 7.02]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.49, 0.33, 0.44, 0.54, 0.6, 0.65, 0.69, 0.72, 0.75, 0.78, 0.8, 0.82, 0.84, 0.86, 0.88, 0.9, 0.91, 0.93, 0.94, 0.96, 0.97, 0.98, 0.99, 1.01, 1.02, 1.03, 1.04, 1.05, 1.06, 1.07]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.21, 0.3, 0.36, 0.41, 0.45, 0.48, 0.51, 0.54, 0.56, 0.57, 0.59, 0.6, 0.61, 0.61, 0.62, 0.62, 0.62, 0.61, 0.6, 0.6, 0.58, 0.57, 0.55, 0.53, 0.5, 0.47, 0.44, 0.39, 0.34]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.43, 0.42, 0.41, 0.41, 0.4, 0.39, 0.39, 0.38, 0.38, 0.37, 0.36, 0.36, 0.35, 0.34, 0.34, 0.33, 0.33, 0.32, 0.31, 0.31, 0.3, 0.29, 0.29, 0.28, 0.28, 0.27, 0.26, 0.26, 0.25, 0.24]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.25, -0.19, -0.12, -0.06, 0.01, 0.09, 0.17, 0.25, 0.34, 0.43, 0.52, 0.63, 0.73, 0.83, 0.94, 1.05, 1.17, 1.29, 1.41, 1.54, 1.67, 1.8, 1.94, 2.08, 2.22, 2.38, 2.52, 2.67, 2.84, 3.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.54, 0.61, 0.68, 0.75, 0.8, 0.85, 0.89, 0.93, 0.96, 0.98, 0.99, 1.0, 1.0, 0.99, 0.97, 0.94, 0.91, 0.87, 0.82, 0.77, 0.71, 0.64, 0.57, 0.5, 0.42, 0.33, 0.25, 0.16, 0.07, -0.02]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.16, 0.34, 0.53, 0.73, 0.95, 1.17, 1.4, 1.66, 1.91, 2.16, 2.45, 2.71, 2.99, 3.29, 3.58, 3.89, 4.19, 4.49, 4.82, 5.13, 5.45, 5.81, 6.14, 6.49, 6.87, 7.23, 7.61, 8.03, 8.43]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.56, 0.68, 0.75, 0.8, 0.85, 0.89, 0.92, 0.95, 0.98, 1.01, 1.03, 1.06, 1.08, 1.1, 1.12, 1.14, 1.15, 1.17, 1.18, 1.2, 1.21, 1.23, 1.24, 1.25, 1.27, 1.28, 1.29, 1.3, 1.32]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.38, 0.61, 0.79, 0.96, 1.13, 1.27, 1.4, 1.53, 1.64, 1.74, 1.84, 1.92, 1.98, 2.04, 2.09, 2.12, 2.14, 2.15, 2.15, 2.13, 2.11, 2.08, 2.04, 1.99, 1.93, 1.87, 1.8, 1.73, 1.65]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.01, 0.04, 0.1, 0.17, 0.27, 0.38, 0.5, 0.64, 0.76, 0.87, 0.96, 1.0, 0.97, 0.86, 0.67, 0.38, 0.04, -0.31, -0.67, -0.91, -1.0, -0.88, -0.58, -0.13, 0.41, 0.82, 1.0, 0.85, 0.41]<EOS_Y><SOS_EQ>', '<SOS_Y>[1.06, 0.98, 0.9, 0.83, 0.75, 0.67, 0.59, 0.52, 0.44, 0.36, 0.28, 0.2, 0.13, 0.05, -0.03, -0.11, -0.19, -0.26, -0.34, -0.42, -0.5, -0.57, -0.66, -0.73, -0.81, -0.89, -0.96, -1.04, -1.12, -1.2]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.66, 0.66, 0.65, 0.64, 0.63, 0.62, 0.62, 0.61, 0.6, 0.59, 0.58, 0.58, 0.57, 0.56, 0.55, 0.54, 0.53, 0.52, 0.52, 0.51, 0.5, 0.49, 0.48, 0.47, 0.46, 0.45, 0.44, 0.44, 0.43, 0.42]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.32, 0.46, 0.55, 0.63, 0.7, 0.76, 0.81, 0.86, 0.9, 0.93, 0.95, 0.97, 0.99, 1.0, 1.0, 1.0, 0.99, 0.98, 0.96, 0.94, 0.91, 0.87, 0.83, 0.78, 0.72, 0.66, 0.59, 0.49, 0.38]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.23, 0.29, 0.3, 0.31, 0.3, 0.3, 0.29, 0.28, 0.27, 0.26, 0.26, 0.26, 0.26, 0.27, 0.29, 0.31, 0.33, 0.36, 0.41, 0.45, 0.5, 0.56, 0.62, 0.69, 0.77, 0.85, 0.93, 1.03, 1.12]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.08, 0.02, 0.13, 0.23, 0.33, 0.44, 0.54, 0.64, 0.75, 0.85, 0.95, 1.06, 1.16, 1.26, 1.37, 1.47, 1.58, 1.68, 1.78, 1.89, 1.99, 2.09, 2.2, 2.3, 2.4, 2.51, 2.61, 2.71, 2.82, 2.92]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.87, -0.67, -0.45, -0.25, -0.05, 0.17, 0.37, 0.57, 0.79, 0.99, 1.19, 1.41, 1.61, 1.81, 2.03, 2.23, 2.45, 2.65, 2.85, 3.07, 3.27, 3.47, 3.69, 3.89, 4.09, 4.31, 4.51, 4.71, 4.93, 5.13]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.0, 0.0, -0.0, -0.01, -0.02, -0.03, -0.04, -0.05, -0.07, -0.09, -0.11, -0.13, -0.16, -0.19, -0.21, -0.25, -0.28, -0.32, -0.36, -0.4, -0.44, -0.49, -0.54, -0.59, -0.64, -0.69, -0.75, -0.81, -0.87]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.17, -0.36, -0.52, -0.69, -0.87, -1.03, -1.19, -1.37, -1.52, -1.67, -1.83, -1.97, -2.11, -2.25, -2.38, -2.51, -2.62, -2.73, -2.85, -2.95, -3.04, -3.13, -3.21, -3.29, -3.36, -3.42, -3.48, -3.54, -3.59]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.56, 0.68, 0.75, 0.8, 0.85, 0.89, 0.92, 0.95, 0.98, 1.01, 1.03, 1.06, 1.08, 1.1, 1.12, 1.14, 1.15, 1.17, 1.18, 1.2, 1.21, 1.23, 1.24, 1.25, 1.27, 1.28, 1.29, 1.3, 1.32]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.74, -0.74, -0.75, -0.75, -0.75, -0.76, -0.76, -0.77, -0.77, -0.77, -0.78, -0.78, -0.78, -0.79, -0.79, -0.79, -0.79, -0.8, -0.8, -0.8, -0.8, -0.81, -0.81, -0.81, -0.81, -0.82, -0.82, -0.82, -0.82, -0.82]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.0, -0.01, -0.02, -0.03, -0.05, -0.08, -0.1, -0.14, -0.17, -0.21, -0.25, -0.29, -0.34, -0.39, -0.44, -0.5, -0.55, -0.61, -0.67, -0.73, -0.78, -0.85, -0.9, -0.96, -1.02, -1.07, -1.12, -1.18, -1.23]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.01, -0.02, -0.02, -0.01, -0.0, 0.01, 0.03, 0.06, 0.09, 0.13, 0.17, 0.22, 0.26, 0.32, 0.38, 0.45, 0.52, 0.59, 0.68, 0.76, 0.84, 0.94, 1.03, 1.12, 1.23, 1.33, 1.44, 1.56, 1.67]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.14, -0.15, -0.12, -0.08, -0.01, 0.07, 0.16, 0.27, 0.38, 0.5, 0.64, 0.78, 0.93, 1.1, 1.26, 1.44, 1.62, 1.8, 2.01, 2.2, 2.4, 2.63, 2.84, 3.05, 3.29, 3.52, 3.75, 4.01, 4.25]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.73, -0.86, -1.02, -1.18, -1.36, -1.57, -1.77, -2.0, -2.26, -2.51, -2.78, -3.1, -3.4, -3.72, -4.09, -4.44, -4.84, -5.22, -5.62, -6.08, -6.51, -6.95, -7.46, -7.94, -8.43, -8.99, -9.51, -10.06, -10.67, -11.24]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.76, 0.97, 1.19, 1.38, 1.56, 1.75, 1.92, 2.07, 2.23, 2.37, 2.49, 2.62, 2.73, 2.83, 2.93, 3.01, 3.08, 3.15, 3.2, 3.25, 3.28, 3.3, 3.32, 3.33, 3.33, 3.31, 3.29, 3.26, 3.22, 3.17]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.12, -0.07, 0.01, 0.11, 0.22, 0.37, 0.51, 0.65, 0.8, 0.91, 0.98, 0.99, 0.93, 0.77, 0.51, 0.19, -0.21, -0.56, -0.84, -1.0, -0.94, -0.68, -0.21, 0.29, 0.73, 0.99, 0.91, 0.52, -0.12, -0.69]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.52, 0.46, 0.4, 0.33, 0.26, 0.18, 0.11, 0.03, -0.06, -0.15, -0.23, -0.33, -0.41, -0.5, -0.59, -0.66, -0.74, -0.81, -0.87, -0.92, -0.96, -0.99, -1.0, -1.0, -0.98, -0.94, -0.9, -0.83, -0.74, -0.64]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.53, -0.57, -0.61, -0.65, -0.68, -0.71, -0.73, -0.76, -0.78, -0.79, -0.81, -0.82, -0.83, -0.83, -0.84, -0.84, -0.84, -0.84, -0.83, -0.83, -0.82, -0.81, -0.79, -0.78, -0.76, -0.73, -0.71, -0.68, -0.65, -0.61]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.12, 0.25, 0.37, 0.48, 0.6, 0.71, 0.8, 0.9, 0.99, 1.06, 1.14, 1.19, 1.24, 1.28, 1.31, 1.32, 1.33, 1.33, 1.31, 1.28, 1.25, 1.2, 1.15, 1.09, 1.02, 0.95, 0.88, 0.79, 0.71]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.16, 0.23, 0.28, 0.32, 0.36, 0.39, 0.42, 0.45, 0.48, 0.51, 0.53, 0.56, 0.58, 0.6, 0.62, 0.64, 0.66, 0.68, 0.7, 0.72, 0.73, 0.75, 0.77, 0.79, 0.8, 0.82, 0.83, 0.85, 0.86]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.06, -0.12, -0.17, -0.23, -0.29, -0.34, -0.39, -0.44, -0.48, -0.52, -0.57, -0.6, -0.64, -0.67, -0.7, -0.72, -0.75, -0.76, -0.78, -0.8, -0.81, -0.82, -0.83, -0.83, -0.84, -0.84, -0.84, -0.84, -0.84]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.08, 0.18, 0.29, 0.38, 0.47, 0.57, 0.65, 0.72, 0.79, 0.85, 0.9, 0.94, 0.97, 0.99, 1.0, 1.0, 0.99, 0.96, 0.93, 0.89, 0.84, 0.78, 0.7, 0.63, 0.55, 0.45, 0.36, 0.27, 0.16, 0.06]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.29, 0.42, 0.5, 0.58, 0.65, 0.7, 0.75, 0.8, 0.83, 0.87, 0.9, 0.92, 0.95, 0.96, 0.98, 0.99, 1.0, 1.0, 1.0, 1.0, 0.99, 0.98, 0.96, 0.94, 0.92, 0.89, 0.86, 0.82, 0.79]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.31, 0.41, 0.52, 0.62, 0.72, 0.83, 0.93, 1.03, 1.14, 1.24, 1.34, 1.45, 1.55, 1.66, 1.76, 1.86, 1.97, 2.07, 2.17, 2.28, 2.38, 2.48, 2.59, 2.69, 2.79, 2.9, 3.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.29, 0.41, 0.5, 0.58, 0.65, 0.71, 0.77, 0.82, 0.87, 0.92, 0.97, 1.01, 1.05, 1.09, 1.13, 1.17, 1.2, 1.23, 1.27, 1.3, 1.33, 1.37, 1.4, 1.43, 1.46, 1.48, 1.51, 1.54, 1.57]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.05, 0.15, 0.26, 0.36, 0.46, 0.57, 0.67, 0.77, 0.88, 0.98, 1.08, 1.19, 1.29, 1.39, 1.5, 1.6, 1.71, 1.81, 1.91, 2.02, 2.12, 2.22, 2.33, 2.43, 2.53, 2.64, 2.74, 2.84, 2.95, 3.05]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.42, 0.67, 0.86, 1.04, 1.22, 1.37, 1.51, 1.65, 1.77, 1.87, 1.98, 2.06, 2.13, 2.2, 2.24, 2.28, 2.31, 2.32, 2.32, 2.32, 2.3, 2.27, 2.23, 2.19, 2.13, 2.08, 2.01, 1.94, 1.87]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.69, 0.63, 0.59, 0.55, 0.52, 0.45, 0.62, 0.89, 1.17, 1.43, 1.7, 2.0, 2.3, 2.61, 2.97, 3.32, 3.72, 4.11, 4.51, 4.98, 5.42, 5.88, 6.41, 6.91, 7.43, 8.02, 8.58, 9.16, 9.82, 10.44]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.13, 0.26, 0.39, 0.5, 0.62, 0.71, 0.79, 0.87, 0.93, 0.97, 0.99, 1.0, 0.99, 0.96, 0.92, 0.85, 0.78, 0.7, 0.59, 0.48, 0.37, 0.23, 0.11, -0.02, -0.16, -0.28, -0.4, -0.53, -0.63]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.05, -0.11, -0.15, -0.2, -0.26, -0.3, -0.35, -0.39, -0.44, -0.48, -0.52, -0.55, -0.58, -0.62, -0.65, -0.68, -0.7, -0.72, -0.74, -0.76, -0.78, -0.79, -0.8, -0.81, -0.82, -0.83, -0.83, -0.84, -0.84]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.01, 0.05, 0.12, 0.2, 0.32, 0.44, 0.59, 0.77, 0.94, 1.13, 1.34, 1.53, 1.73, 1.94, 2.13, 2.33, 2.49, 2.64, 2.77, 2.88, 2.95, 3.0, 3.02, 3.0, 2.94, 2.85, 2.72, 2.53, 2.32]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.25, 0.18, 0.44, 0.65, 0.84, 1.04, 1.22, 1.39, 1.57, 1.74, 1.9, 2.07, 2.22, 2.38, 2.54, 2.69, 2.86, 3.01, 3.15, 3.31, 3.46, 3.6, 3.76, 3.9, 4.04, 4.2, 4.34, 4.48, 4.63, 4.77]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.32, 0.46, 0.56, 0.64, 0.72, 0.79, 0.85, 0.91, 0.96, 1.01, 1.07, 1.11, 1.16, 1.2, 1.24, 1.29, 1.33, 1.36, 1.4, 1.44, 1.47, 1.51, 1.54, 1.57, 1.61, 1.64, 1.67, 1.7, 1.73]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.85, 0.79, 0.72, 0.64, 0.56, 0.45, 0.33, 0.08, 0.32, 0.45, 0.55, 0.64, 0.72, 0.78, 0.85, 0.91, 0.97, 1.02, 1.06, 1.12, 1.16, 1.2, 1.25, 1.29, 1.32, 1.37, 1.4, 1.44, 1.47, 1.51]<EOS_Y><SOS_EQ>', '<SOS_Y>[1.15, 1.17, 1.19, 1.21, 1.22, 1.22, 1.22, 1.21, 1.2, 1.19, 1.17, 1.14, 1.11, 1.08, 1.03, 0.99, 0.94, 0.88, 0.82, 0.75, 0.69, 0.61, 0.53, 0.45, 0.36, 0.26, 0.16, 0.06, -0.05, -0.17]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.51, 0.51, 0.49, 0.44, 0.38, 0.3, 0.2, 0.08, -0.07, -0.23, -0.4, -0.61, -0.83, -1.06, -1.34, -1.61, -1.93, -2.24, -2.57, -2.95, -3.32, -3.7, -4.15, -4.57, -5.02, -5.53, -6.01, -6.51, -7.08, -7.62]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.01, 0.04, 0.07, 0.12, 0.17, 0.24, 0.31, 0.41, 0.5, 0.61, 0.73, 0.86, 1.0, 1.16, 1.31, 1.5, 1.67, 1.86, 2.08, 2.29, 2.51, 2.76, 3.0, 3.25, 3.53, 3.8, 4.08, 4.4, 4.7]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.76, -0.81, -0.86, -0.91, -0.95, -1.01, -1.05, -1.1, -1.15, -1.2, -1.25, -1.3, -1.35, -1.4, -1.45, -1.5, -1.55, -1.6, -1.65, -1.7, -1.75, -1.8, -1.85, -1.9, -1.94, -2.0, -2.04, -2.09, -2.15, -2.19]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.75, -0.68, -0.6, -0.52, -0.43, -0.33, -0.23, -0.13, -0.02, 0.08, 0.18, 0.28, 0.38, 0.47, 0.56, 0.64, 0.72, 0.79, 0.85, 0.9, 0.94, 0.97, 0.99, 1.0, 1.0, 0.99, 0.96, 0.93, 0.89, 0.84]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.01, 0.01, 0.02, 0.02, 0.03, 0.03, 0.04, 0.04, 0.05, 0.05, 0.06, 0.07, 0.07, 0.08, 0.08, 0.09, 0.09, 0.1, 0.1, 0.11, 0.11, 0.12, 0.13, 0.13, 0.14, 0.14, 0.15, 0.15, 0.16]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.77, -0.73, -0.69, -0.65, -0.61, -0.57, -0.53, -0.49, -0.44, -0.41, -0.37, -0.32, -0.28, -0.24, -0.2, -0.16, -0.12, -0.08, -0.04, 0.01, 0.05, 0.09, 0.13, 0.17, 0.21, 0.25, 0.29, 0.33, 0.38, 0.42]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.15, 0.26, 0.42, 0.59, 0.78, 1.02, 1.24, 1.48, 1.74, 1.98, 2.21, 2.45, 2.65, 2.83, 2.99, 3.1, 3.18, 3.21, 3.19, 3.12, 3.0, 2.83, 2.58, 2.3, 1.97, 1.55, 1.12, 0.65, 0.09, -0.46]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.02, 0.04, 0.07, 0.09, 0.11, 0.13, 0.15, 0.18, 0.2, 0.22, 0.24, 0.26, 0.28, 0.3, 0.32, 0.35, 0.37, 0.39, 0.41, 0.43, 0.44, 0.47, 0.48, 0.5, 0.52, 0.54, 0.56, 0.58, 0.6]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.02, -0.05, -0.05, -0.03, 0.0, 0.07, 0.15, 0.25, 0.38, 0.52, 0.69, 0.89, 1.09, 1.32, 1.59, 1.85, 2.17, 2.48, 2.8, 3.19, 3.56, 3.95, 4.4, 4.83, 5.28, 5.8, 6.3, 6.81, 7.4, 7.96]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.09, 0.18, 0.27, 0.35, 0.45, 0.53, 0.62, 0.71, 0.8, 0.89, 0.98, 1.07, 1.15, 1.25, 1.33, 1.43, 1.51, 1.6, 1.69, 1.78, 1.87, 1.96, 2.05, 2.13, 2.23, 2.31, 2.4, 2.49, 2.58]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.39, 0.4, 0.42, 0.43, 0.43, 0.42, 0.4, 0.38, 0.34, 0.3, 0.25, 0.18, 0.1, 0.02, -0.08, -0.19, -0.31, -0.44, -0.57, -0.72, -0.87, -1.02, -1.19, -1.36, -1.53, -1.71, -1.88, -2.06, -2.24, -2.41]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.05, 0.13, 0.22, 0.32, 0.46, 0.6, 0.76, 0.96, 1.15, 1.37, 1.62, 1.87, 2.14, 2.45, 2.75, 3.11, 3.45, 3.8, 4.22, 4.61, 5.02, 5.49, 5.94, 6.4, 6.94, 7.44, 7.95, 8.54, 9.1]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.28, 0.4, 0.49, 0.56, 0.63, 0.69, 0.74, 0.8, 0.84, 0.89, 0.93, 0.97, 1.01, 1.05, 1.09, 1.13, 1.16, 1.19, 1.23, 1.26, 1.29, 1.32, 1.35, 1.38, 1.41, 1.43, 1.46, 1.49, 1.51]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.0, -0.02, -0.03, -0.06, -0.09, -0.13, -0.17, -0.22, -0.27, -0.33, -0.39, -0.45, -0.52, -0.59, -0.66, -0.74, -0.81, -0.89, -0.97, -1.04, -1.11, -1.19, -1.26, -1.33, -1.4, -1.47, -1.53, -1.59, -1.65]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.03, 0.09, 0.17, 0.27, 0.39, 0.53, 0.69, 0.89, 1.09, 1.31, 1.57, 1.83, 2.12, 2.45, 2.77, 3.15, 3.52, 3.9, 4.35, 4.78, 5.23, 5.74, 6.23, 6.74, 7.33, 7.88, 8.45, 9.1, 9.72]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.02, 0.1, 0.21, 0.34, 0.48, 0.66, 0.84, 1.04, 1.29, 1.53, 1.79, 2.1, 2.41, 2.73, 3.11, 3.47, 3.9, 4.3, 4.72, 5.21, 5.68, 6.16, 6.72, 7.24, 7.79, 8.41, 8.99, 9.6, 10.28, 10.93]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.27, 0.4, 0.48, 0.55, 0.62, 0.68, 0.73, 0.79, 0.83, 0.88, 0.92, 0.96, 1.0, 1.04, 1.08, 1.11, 1.15, 1.18, 1.21, 1.24, 1.27, 1.31, 1.33, 1.36, 1.39, 1.42, 1.44, 1.47, 1.5]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.31, 0.4, 0.5, 0.58, 0.66, 0.74, 0.8, 0.86, 0.91, 0.95, 0.97, 0.99, 1.0, 1.0, 0.98, 0.96, 0.92, 0.88, 0.83, 0.76, 0.69, 0.61, 0.52, 0.44, 0.34, 0.24, 0.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.35, 0.15, 0.3, 0.43, 0.53, 0.62, 0.69, 0.75, 0.81, 0.85, 0.89, 0.92, 0.95, 0.97, 0.99, 0.99, 1.0, 1.0, 0.99, 0.98, 0.96, 0.94, 0.91, 0.88, 0.84, 0.79, 0.74, 0.68, 0.6, 0.51]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.86, -0.89, -0.91, -0.93, -0.95, -0.96, -0.98, -0.98, -0.99, -1.0, -1.0, -1.0, -1.0, -0.99, -0.98, -0.97, -0.96, -0.94, -0.93, -0.9, -0.88, -0.86, -0.83, -0.8, -0.77, -0.73, -0.7, -0.66, -0.62, -0.58]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.2, 0.3, 0.39, 0.5, 0.59, 0.69, 0.79, 0.89, 0.98, 1.09, 1.18, 1.28, 1.38, 1.48, 1.58, 1.68, 1.77, 1.88, 1.98, 2.07, 2.18, 2.27, 2.37, 2.47, 2.57, 2.66, 2.77, 2.86]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.65, 0.62, 0.57, 0.52, 0.45, 0.22, 0.42, 0.51, 0.57, 0.61, 0.64, 0.67, 0.7, 0.72, 0.75, 0.77, 0.79, 0.8, 0.82, 0.84, 0.85, 0.86, 0.88, 0.89, 0.9, 0.91, 0.92, 0.94, 0.95, 0.96]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.1, 0.19, 0.3, 0.4, 0.49, 0.6, 0.7, 0.81, 0.92, 1.03, 1.14, 1.27, 1.39, 1.51, 1.65, 1.78, 1.93, 2.07, 2.22, 2.38, 2.54, 2.7, 2.89, 3.06, 3.23, 3.43, 3.62, 3.81, 4.03, 4.23]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.41, -0.39, -0.37, -0.35, -0.33, -0.3, -0.28, -0.26, -0.24, -0.21, -0.19, -0.17, -0.15, -0.13, -0.1, -0.08, -0.05, -0.03, -0.01, 0.01, 0.04, 0.06, 0.08, 0.1, 0.13, 0.15, 0.17, 0.19, 0.22, 0.24]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.82, 0.85, 0.88, 0.9, 0.92, 0.93, 0.95, 0.96, 0.97, 0.98, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 0.99, 0.99, 0.98, 0.98, 0.97, 0.96, 0.95, 0.94, 0.94, 0.93, 0.92]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.16, 0.18, 0.12, 0.15, 0.29, 0.4, 0.51, 0.63, 0.73, 0.83, 0.94, 1.05, 1.15, 1.26, 1.36, 1.47, 1.57, 1.67, 1.78, 1.88, 1.98, 2.09, 2.19, 2.29, 2.4, 2.5, 2.61, 2.72, 2.82]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.41, 0.35, 0.27, 0.16, 0.14, 0.27, 0.34, 0.4, 0.45, 0.5, 0.53, 0.57, 0.6, 0.63, 0.66, 0.68, 0.71, 0.73, 0.75, 0.77, 0.79, 0.8, 0.82, 0.83, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.09, 0.19, 0.29, 0.38, 0.46, 0.54, 0.61, 0.66, 0.72, 0.75, 0.78, 0.81, 0.83, 0.84, 0.84, 0.84, 0.83, 0.82, 0.8, 0.77, 0.74, 0.7, 0.64, 0.58, 0.51, 0.43, 0.34, 0.25, 0.15, 0.05]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.3, 0.39, 0.48, 0.55, 0.61, 0.67, 0.72, 0.76, 0.79, 0.81, 0.83, 0.84, 0.84, 0.84, 0.83, 0.82, 0.8, 0.77, 0.74, 0.69, 0.64, 0.58, 0.5, 0.42, 0.34, 0.24, 0.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.26, 0.38, 0.46, 0.53, 0.6, 0.66, 0.71, 0.76, 0.8, 0.84, 0.89, 0.93, 0.96, 1.0, 1.04, 1.07, 1.1, 1.13, 1.17, 1.2, 1.23, 1.26, 1.28, 1.31, 1.34, 1.36, 1.39, 1.42, 1.44]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.49, -0.42, -0.35, -0.29, -0.23, -0.16, -0.09, -0.03, 0.04, 0.1, 0.16, 0.23, 0.3, 0.36, 0.43, 0.49, 0.56, 0.62, 0.69, 0.76, 0.82, 0.88, 0.95, 1.01, 1.08, 1.15, 1.21, 1.27, 1.34, 1.4]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.03, -0.06, -0.1, -0.13, -0.17, -0.22, -0.26, -0.31, -0.36, -0.41, -0.47, -0.52, -0.58, -0.64, -0.7, -0.77, -0.83, -0.89, -0.97, -1.03, -1.1, -1.18, -1.25, -1.31, -1.39, -1.46, -1.53, -1.61, -1.68]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.22, -0.1, 0.04, 0.16, 0.28, 0.39, 0.49, 0.58, 0.67, 0.74, 0.8, 0.86, 0.9, 0.93, 0.95, 0.96, 0.96, 0.95, 0.94, 0.91, 0.87, 0.83, 0.78, 0.73, 0.67, 0.61, 0.55, 0.49, 0.42, 0.36]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.01, 0.02, 0.03, 0.03, 0.01, -0.01, -0.05, -0.11, -0.18, -0.28, -0.4, -0.53, -0.69, -0.89, -1.1, -1.35, -1.61, -1.9, -2.25, -2.6, -2.97, -3.42, -3.86, -4.34, -4.9, -5.44, -6.02, -6.7, -7.35]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.31, 0.41, 0.52, 0.62, 0.72, 0.83, 0.93, 1.03, 1.14, 1.24, 1.34, 1.45, 1.55, 1.66, 1.76, 1.86, 1.97, 2.07, 2.17, 2.28, 2.38, 2.48, 2.59, 2.69, 2.79, 2.9, 3.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.02, 0.04, 0.08, 0.12, 0.17, 0.23, 0.3, 0.38, 0.45, 0.53, 0.63, 0.71, 0.79, 0.87, 0.93, 0.98, 1.0, 1.0, 0.96, 0.89, 0.79, 0.64, 0.46, 0.26, 0.02, -0.21, -0.44, -0.67, -0.84]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.31, 0.4, 0.5, 0.58, 0.66, 0.74, 0.8, 0.86, 0.91, 0.95, 0.97, 0.99, 1.0, 1.0, 0.98, 0.96, 0.92, 0.88, 0.83, 0.76, 0.69, 0.61, 0.52, 0.44, 0.34, 0.24, 0.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[-1.34, -1.14, -0.92, -0.72, -0.52, -0.3, -0.1, 0.1, 0.32, 0.52, 0.72, 0.94, 1.14, 1.34, 1.56, 1.76, 1.98, 2.18, 2.38, 2.6, 2.8, 3.0, 3.22, 3.42, 3.62, 3.84, 4.04, 4.24, 4.46, 4.66]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.03, -0.03, -0.02, 0.02, 0.08, 0.15, 0.24, 0.35, 0.46, 0.57, 0.71, 0.83, 0.95, 1.08, 1.19, 1.29, 1.37, 1.44, 1.48, 1.5, 1.49, 1.46, 1.39, 1.3, 1.17, 1.02, 0.84, 0.61, 0.37]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.09, 0.14, 0.22, 0.3, 0.38, 0.49, 0.59, 0.69, 0.8, 0.88, 0.95, 0.99, 1.0, 0.96, 0.86, 0.72, 0.5, 0.26, -0.01, -0.32, -0.59, -0.81, -0.96, -1.0, -0.91, -0.68, -0.36, 0.02, 0.45, 0.78]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.83, 0.73, 0.6, 0.48, 0.35, 0.19, -0.0, -0.16, 0.0, 0.08, 0.13, 0.18, 0.21, 0.24, 0.26, 0.28, 0.3, 0.32, 0.34, 0.35, 0.37, 0.38, 0.4, 0.42, 0.44, 0.46, 0.48, 0.5, 0.52, 0.54]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.65, 0.57, 0.5, 0.46, 0.43, 0.43, 0.44, 0.48, 0.54, 0.61, 0.7, 0.83, 0.96, 1.11, 1.29, 1.48, 1.71, 1.94, 2.18, 2.48, 2.76, 3.06, 3.42, 3.76, 4.12, 4.54, 4.94, 5.35, 5.83, 6.29]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.04, 0.11, 0.19, 0.29, 0.43, 0.57, 0.73, 0.94, 1.14, 1.37, 1.64, 1.91, 2.19, 2.53, 2.86, 3.25, 3.62, 4.01, 4.47, 4.9, 5.35, 5.88, 6.37, 6.89, 7.48, 8.04, 8.61, 9.27, 9.89]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.17, 0.27, 0.37, 0.46, 0.55, 0.64, 0.72, 0.8, 0.87, 0.93, 0.98, 1.03, 1.06, 1.08, 1.1, 1.1, 1.09, 1.07, 1.05, 1.0, 0.96, 0.9, 0.83, 0.76, 0.68, 0.58, 0.49, 0.39, 0.28, 0.18]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.45, 0.5, 0.54, 0.58, 0.62, 0.65, 0.68, 0.71, 0.73, 0.76, 0.77, 0.79, 0.8, 0.82, 0.83, 0.83, 0.84, 0.84, 0.84, 0.84, 0.84, 0.83, 0.83, 0.82, 0.81, 0.79, 0.78, 0.76, 0.74, 0.71]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.74, 0.79, 0.84, 0.88, 0.93, 0.97, 1.02, 1.06, 1.11, 1.16, 1.2, 1.25, 1.29, 1.34, 1.39, 1.43, 1.48, 1.53, 1.57, 1.62, 1.66, 1.71, 1.76, 1.8, 1.84, 1.89, 1.94, 1.98, 2.03, 2.08]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.79, 0.84, 0.88, 0.91, 0.94, 0.98, 1.0, 1.03, 1.05, 1.07, 1.09, 1.11, 1.13, 1.15, 1.16, 1.18, 1.2, 1.21, 1.22, 1.24, 1.25, 1.26, 1.28, 1.29, 1.3, 1.31, 1.32, 1.34, 1.35, 1.36]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.59, 0.55, 0.5, 0.45, 0.38, 0.27, 0.09, 0.25, 0.37, 0.47, 0.55, 0.63, 0.69, 0.76, 0.82, 0.88, 0.95, 1.0, 1.06, 1.11, 1.17, 1.22, 1.28, 1.33, 1.38, 1.43, 1.48, 1.53, 1.58, 1.63]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.22, 0.33, 0.46, 0.6, 0.74, 0.88, 1.05, 1.2, 1.36, 1.55, 1.72, 1.9, 2.1, 2.29, 2.5, 2.7, 2.9, 3.13, 3.34, 3.56, 3.8, 4.02, 4.25, 4.51, 4.74, 4.98, 5.25, 5.5]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.1, -0.22, -0.3, -0.36, -0.38, -0.35, -0.25, -0.05, 0.22, 0.6, 1.14, 1.77, 2.53, 3.54, 4.64, 6.04, 7.52, 9.2, 11.29, 13.42, 15.8, 18.7, 21.62, 24.81, 28.65, 32.45, 36.57, 41.48, 46.29]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.2, 0.42, 0.62, 0.82, 1.04, 1.24, 1.44, 1.66, 1.86, 2.06, 2.28, 2.48, 2.68, 2.9, 3.1, 3.32, 3.52, 3.72, 3.94, 4.14, 4.34, 4.56, 4.76, 4.96, 5.18, 5.38, 5.58, 5.8, 6.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.3, 0.39, 0.48, 0.55, 0.61, 0.67, 0.72, 0.76, 0.79, 0.81, 0.83, 0.84, 0.84, 0.84, 0.83, 0.82, 0.8, 0.77, 0.74, 0.69, 0.64, 0.58, 0.5, 0.42, 0.34, 0.24, 0.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.18, 0.26, 0.42, 0.53, 0.62, 0.7, 0.77, 0.83, 0.89, 0.95, 1.0, 1.05, 1.1, 1.14, 1.19, 1.23, 1.28, 1.31, 1.35, 1.39, 1.43, 1.46, 1.5, 1.53, 1.56, 1.6, 1.63, 1.66, 1.69, 1.72]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.91, -0.84, -0.76, -0.69, -0.62, -0.54, -0.47, -0.4, -0.32, -0.24, -0.17, -0.09, -0.02, 0.06, 0.14, 0.21, 0.29, 0.37, 0.44, 0.52, 0.6, 0.68, 0.76, 0.84, 0.92, 1.0, 1.08, 1.16, 1.25, 1.33]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.54, -0.59, -0.65, -0.69, -0.73, -0.76, -0.78, -0.8, -0.82, -0.83, -0.84, -0.84, -0.84, -0.84, -0.83, -0.81, -0.79, -0.77, -0.74, -0.7, -0.66, -0.62, -0.56, -0.5, -0.44, -0.36, -0.29, -0.21, -0.12, -0.04]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.2, 0.41, 0.58, 0.73, 0.86, 0.95, 0.99, 1.0, 0.96, 0.88, 0.76, 0.61, 0.45, 0.24, 0.04, -0.18, -0.37, -0.55, -0.72, -0.84, -0.93, -0.99, -1.0, -0.97, -0.89, -0.79, -0.65, -0.46, -0.28]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.61, 0.82, 1.07, 1.32, 1.58, 1.89, 2.18, 2.49, 2.84, 3.18, 3.52, 3.92, 4.29, 4.67, 5.11, 5.51, 5.97, 6.39, 6.83, 7.32, 7.77, 8.24, 8.76, 9.24, 9.73, 10.28, 10.79, 11.3, 11.88, 12.42]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.75, 0.69, 0.63, 0.56, 0.49, 0.4, 0.28, 0.05, 0.29, 0.4, 0.49, 0.57, 0.63, 0.69, 0.75, 0.8, 0.85, 0.89, 0.94, 0.98, 1.02, 1.06, 1.09, 1.13, 1.16, 1.2, 1.23, 1.26, 1.29, 1.32]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.74, 0.72, 0.7, 0.69, 0.67, 0.65, 0.63, 0.61, 0.58, 0.56, 0.54, 0.51, 0.48, 0.46, 0.42, 0.39, 0.36, 0.32, 0.28, 0.22, 0.15, 0.05, 0.17, 0.24, 0.28, 0.33, 0.37, 0.4, 0.43, 0.46]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.96, 1.06, 1.17, 1.27, 1.37, 1.48, 1.58, 1.68, 1.79, 1.89, 1.99, 2.1, 2.2, 2.3, 2.41, 2.51, 2.62, 2.72, 2.82, 2.93, 3.03, 3.13, 3.24, 3.34, 3.44, 3.55, 3.65, 3.75, 3.86, 3.96]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.51, -0.59, -0.66, -0.73, -0.79, -0.85, -0.89, -0.93, -0.96, -0.98, -1.0, -1.0, -0.99, -0.98, -0.96, -0.93, -0.88, -0.84, -0.78, -0.72, -0.65, -0.58, -0.49, -0.41, -0.32, -0.23, -0.14, -0.05, 0.06, 0.15]<EOS_Y><SOS_EQ>', '<SOS_Y>[1.0, 1.0, 1.01, 1.02, 1.03, 1.04, 1.04, 1.05, 1.06, 1.07, 1.07, 1.08, 1.09, 1.09, 1.1, 1.11, 1.12, 1.12, 1.13, 1.14, 1.14, 1.15, 1.16, 1.17, 1.17, 1.18, 1.19, 1.19, 1.2, 1.21]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.32, 0.46, 0.55, 0.63, 0.7, 0.76, 0.81, 0.86, 0.9, 0.93, 0.95, 0.97, 0.99, 1.0, 1.0, 1.0, 0.99, 0.98, 0.96, 0.94, 0.91, 0.87, 0.83, 0.78, 0.72, 0.66, 0.59, 0.49, 0.38]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.03, 0.06, 0.09, 0.12, 0.15, 0.18, 0.2, 0.23, 0.26, 0.29, 0.32, 0.34, 0.37, 0.39, 0.42, 0.44, 0.47, 0.49, 0.51, 0.53, 0.55, 0.57, 0.59, 0.61, 0.63, 0.64, 0.66, 0.67, 0.69]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.68, 0.66, 0.64, 0.62, 0.6, 0.57, 0.55, 0.53, 0.5, 0.47, 0.45, 0.41, 0.39, 0.36, 0.32, 0.29, 0.26, 0.22, 0.19, 0.15, 0.12, 0.08, 0.05, 0.01, -0.02, -0.06, -0.09, -0.13, -0.17, -0.2]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.22, -0.02, 0.19, 0.38, 0.57, 0.77, 0.95, 1.13, 1.31, 1.47, 1.62, 1.77, 1.91, 2.03, 2.15, 2.25, 2.35, 2.44, 2.51, 2.57, 2.63, 2.67, 2.71, 2.73, 2.75, 2.77, 2.77, 2.78, 2.77, 2.77]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.24, -0.19, -0.12, -0.06, -0.0, 0.07, 0.14, 0.2, 0.28, 0.35, 0.42, 0.5, 0.58, 0.66, 0.74, 0.83, 0.92, 1.0, 1.08, 1.18, 1.27, 1.36, 1.46, 1.55, 1.64, 1.75, 1.84, 1.94, 2.04, 2.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.11, 0.19, 0.29, 0.39, 0.5, 0.61, 0.73, 0.84, 0.96, 1.07, 1.17, 1.27, 1.35, 1.43, 1.49, 1.53, 1.55, 1.56, 1.54, 1.5, 1.44, 1.36, 1.25, 1.13, 0.98, 0.8, 0.62, 0.41, 0.17, -0.06]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.01, -0.03, -0.05, -0.08, -0.12, -0.16, -0.2, -0.25, -0.3, -0.35, -0.4, -0.46, -0.51, -0.57, -0.63, -0.69, -0.75, -0.81, -0.88, -0.94, -1.0, -1.06, -1.12, -1.18, -1.25, -1.31, -1.36, -1.43, -1.48]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.28, 0.26, 0.25, 0.23, 0.22, 0.2, 0.19, 0.17, 0.15, 0.14, 0.12, 0.11, 0.09, 0.07, 0.06, 0.04, 0.02, 0.0, -0.01, -0.03, -0.05, -0.06, -0.08, -0.1, -0.12, -0.14, -0.16, -0.18, -0.2, -0.22]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.04, 0.08, 0.1, 0.12, 0.12, 0.12, 0.1, 0.07, 0.04, -0.0, -0.06, -0.13, -0.2, -0.29, -0.38, -0.5, -0.61, -0.73, -0.88, -1.02, -1.17, -1.34, -1.51, -1.69, -1.9, -2.1, -2.31, -2.55, -2.78]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.51, 0.57, 0.66, 0.75, 0.86, 0.99, 1.12, 1.26, 1.43, 1.6, 1.77, 1.97, 2.17, 2.37, 2.61, 2.84, 3.1, 3.35, 3.61, 3.92, 4.21, 4.52, 4.88, 5.22, 5.57, 5.99, 6.39, 6.81, 7.3, 7.76]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.85, 0.82, 0.78, 0.75, 0.7, 0.64, 0.57, 0.49, 0.36, 0.14, 0.31, 0.49, 0.61, 0.72, 0.83, 0.93, 1.03, 1.12, 1.21, 1.3, 1.39, 1.47, 1.56, 1.65, 1.73, 1.82, 1.9, 1.99, 2.08, 2.16]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.03, -0.0, -0.06, -0.13, -0.21, -0.33, -0.44, -0.58, -0.75, -0.92, -1.1, -1.32, -1.54, -1.78, -2.06, -2.33, -2.64, -2.94, -3.26, -3.64, -3.99, -4.36, -4.79, -5.19, -5.61, -6.09, -6.55, -7.02, -7.55, -8.06]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.32, 0.46, 0.56, 0.64, 0.72, 0.79, 0.85, 0.91, 0.96, 1.01, 1.07, 1.11, 1.16, 1.2, 1.24, 1.29, 1.33, 1.36, 1.4, 1.44, 1.47, 1.51, 1.54, 1.57, 1.61, 1.64, 1.67, 1.7, 1.73]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.01, -0.02, -0.03, -0.04, -0.06, -0.07, -0.08, -0.09, -0.1, -0.11, -0.12, -0.13, -0.14, -0.15, -0.16, -0.18, -0.19, -0.2, -0.21, -0.22, -0.23, -0.24, -0.25, -0.26, -0.27, -0.28, -0.29, -0.3, -0.31]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.21, 0.3, 0.37, 0.42, 0.48, 0.52, 0.56, 0.6, 0.63, 0.66, 0.69, 0.72, 0.75, 0.77, 0.79, 0.82, 0.84, 0.85, 0.87, 0.89, 0.9, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.98]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.01, 0.01, 0.02, 0.03, 0.03, 0.04, 0.05, 0.05, 0.06, 0.06, 0.07, 0.08, 0.08, 0.09, 0.1, 0.1, 0.11, 0.12, 0.12, 0.13, 0.14, 0.14, 0.15, 0.16, 0.16, 0.17, 0.17, 0.18, 0.19]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.01, 0.04, 0.1, 0.18, 0.3, 0.45, 0.62, 0.86, 1.11, 1.41, 1.77, 2.16, 2.58, 3.1, 3.62, 4.26, 4.88, 5.56, 6.37, 7.16, 8.01, 9.01, 9.98, 11.01, 12.21, 13.37, 14.59, 16.01, 17.37]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.1, -0.06, -0.02, 0.02, 0.06, 0.11, 0.15, 0.18, 0.23, 0.27, 0.3, 0.34, 0.38, 0.42, 0.46, 0.49, 0.53, 0.56, 0.6, 0.63, 0.66, 0.69, 0.72, 0.75, 0.77, 0.8, 0.82, 0.84, 0.87, 0.89]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.41, 0.27, 0.18, 0.36, 0.47, 0.57, 0.65, 0.72, 0.79, 0.85, 0.9, 0.96, 1.01, 1.05, 1.1, 1.15, 1.19, 1.23, 1.27, 1.31, 1.35, 1.38, 1.42, 1.45, 1.48, 1.52, 1.55, 1.58, 1.61, 1.64]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.69, 0.71, 0.73, 0.74, 0.76, 0.78, 0.79, 0.81, 0.82, 0.84, 0.85, 0.87, 0.88, 0.89, 0.91, 0.92, 0.93, 0.95, 0.96, 0.97, 0.99, 1.0, 1.01, 1.02, 1.03, 1.05, 1.06, 1.07, 1.08, 1.09]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.97, 0.97, 0.98, 0.98, 0.99, 0.99, 1.0, 1.0, 1.0, 1.01, 1.01, 1.02, 1.02, 1.02, 1.03, 1.03, 1.04, 1.04, 1.04, 1.05, 1.05, 1.05, 1.06, 1.06, 1.06, 1.07, 1.07, 1.07, 1.08, 1.08]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.96, 1.0, 1.05, 1.09, 1.13, 1.18, 1.22, 1.25, 1.29, 1.33, 1.36, 1.4, 1.43, 1.46, 1.49, 1.52, 1.56, 1.59, 1.61, 1.64, 1.67, 1.7, 1.73, 1.75, 1.78, 1.81, 1.83, 1.86, 1.88, 1.91]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.09, 0.18, 0.27, 0.36, 0.45, 0.54, 0.63, 0.73, 0.81, 0.9, 1.0, 1.08, 1.17, 1.27, 1.35, 1.45, 1.54, 1.63, 1.72, 1.81, 1.9, 1.99, 2.08, 2.17, 2.26, 2.35, 2.44, 2.53, 2.62]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.84, 0.8, 0.74, 0.69, 0.63, 0.56, 0.49, 0.4, 0.28, 0.03, 0.28, 0.4, 0.49, 0.56, 0.63, 0.69, 0.75, 0.8, 0.84, 0.89, 0.93, 0.97, 1.02, 1.05, 1.09, 1.13, 1.16, 1.19, 1.23, 1.26]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.54, -0.44, -0.33, -0.23, -0.13, -0.02, 0.08, 0.18, 0.29, 0.39, 0.49, 0.6, 0.7, 0.8, 0.91, 1.01, 1.12, 1.22, 1.32, 1.43, 1.53, 1.63, 1.74, 1.84, 1.94, 2.05, 2.15, 2.25, 2.36, 2.46]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.07, 0.15, 0.22, 0.28, 0.35, 0.41, 0.47, 0.53, 0.58, 0.62, 0.66, 0.7, 0.73, 0.76, 0.78, 0.8, 0.81, 0.82, 0.83, 0.84, 0.84, 0.84, 0.84, 0.83, 0.82, 0.81, 0.79, 0.77, 0.75]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.9, 0.94, 0.97, 1.01, 1.04, 1.07, 1.1, 1.13, 1.16, 1.19, 1.21, 1.24, 1.27, 1.29, 1.32, 1.35, 1.37, 1.39, 1.42, 1.44, 1.46, 1.49, 1.51, 1.53, 1.55, 1.57, 1.59, 1.61, 1.64, 1.66]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.0, 0.0, 0.01, 0.02, 0.05, 0.08, 0.12, 0.18, 0.25, 0.33, 0.43, 0.53, 0.63, 0.76, 0.87, 0.99, 1.1, 1.2, 1.29, 1.36, 1.41, 1.43, 1.42, 1.37, 1.27, 1.14, 0.97, 0.73, 0.46]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.91, 0.89, 0.87, 0.85, 0.83, 0.81, 0.79, 0.76, 0.74, 0.71, 0.69, 0.66, 0.63, 0.6, 0.56, 0.53, 0.49, 0.46, 0.42, 0.38, 0.34, 0.3, 0.26, 0.22, 0.18, 0.13, 0.08, 0.04, -0.01, -0.06]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.03, 0.3, 0.63, 0.91, 1.18, 1.48, 1.74, 2.0, 2.27, 2.53, 2.77, 3.04, 3.29, 3.53, 3.79, 4.03, 4.3, 4.53, 4.77, 5.03, 5.26, 5.5, 5.75, 5.98, 6.22, 6.47, 6.7, 6.93, 7.18, 7.41]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.08, -0.0, -0.09, -0.18, -0.26, -0.34, -0.42, -0.5, -0.57, -0.64, -0.7, -0.76, -0.81, -0.86, -0.9, -0.94, -0.96, -0.98, -0.99, -1.0, -1.0, -0.99, -0.97, -0.94, -0.91, -0.87, -0.83, -0.78, -0.72, -0.66]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.31, 0.4, 0.5, 0.58, 0.66, 0.74, 0.8, 0.86, 0.91, 0.95, 0.97, 0.99, 1.0, 1.0, 0.98, 0.96, 0.92, 0.88, 0.83, 0.76, 0.69, 0.61, 0.52, 0.44, 0.34, 0.24, 0.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.65, 0.85, 1.07, 1.27, 1.47, 1.69, 1.89, 2.09, 2.31, 2.51, 2.71, 2.93, 3.13, 3.33, 3.55, 3.75, 3.97, 4.17, 4.37, 4.59, 4.79, 4.99, 5.21, 5.41, 5.61, 5.83, 6.03, 6.23, 6.45, 6.65]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.13, -0.08, -0.01, 0.05, 0.1, 0.17, 0.22, 0.28, 0.35, 0.4, 0.46, 0.52, 0.58, 0.64, 0.7, 0.76, 0.82, 0.88, 0.94, 1.0, 1.06, 1.12, 1.18, 1.24, 1.3, 1.36, 1.42, 1.48, 1.54, 1.6]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.08, 0.12, 0.14, 0.16, 0.18, 0.2, 0.21, 0.23, 0.24, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.41, 0.42, 0.43, 0.44]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.57, 0.64, 0.69, 0.72, 0.73, 0.71, 0.67, 0.6, 0.49, 0.37, 0.22, 0.02, -0.19, -0.43, -0.72, -1.02, -1.39, -1.75, -2.14, -2.6, -3.05, -3.53, -4.08, -4.62, -5.18, -5.83, -6.44, -7.08, -7.8, -8.49]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.0, -0.01, -0.03, -0.05, -0.08, -0.12, -0.15, -0.2, -0.24, -0.29, -0.33, -0.38, -0.42, -0.46, -0.49, -0.52, -0.54, -0.55, -0.56, -0.55, -0.54, -0.52, -0.49, -0.45, -0.39, -0.34, -0.27, -0.2, -0.12]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.39, 0.49, 0.59, 0.67, 0.75, 0.82, 0.88, 0.93, 0.97, 0.99, 1.01, 1.01, 1.0, 0.98, 0.94, 0.9, 0.84, 0.77, 0.7, 0.61, 0.51, 0.41, 0.29, 0.18, 0.06, -0.07, -0.2, -0.33, -0.47, -0.6]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.32, 0.46, 0.56, 0.64, 0.72, 0.79, 0.85, 0.91, 0.96, 1.01, 1.07, 1.11, 1.16, 1.2, 1.24, 1.29, 1.33, 1.36, 1.4, 1.44, 1.47, 1.51, 1.54, 1.57, 1.61, 1.64, 1.67, 1.7, 1.73]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.3, 0.39, 0.48, 0.55, 0.61, 0.67, 0.72, 0.76, 0.79, 0.81, 0.83, 0.84, 0.84, 0.84, 0.83, 0.82, 0.8, 0.77, 0.73, 0.69, 0.63, 0.57, 0.5, 0.42, 0.33, 0.23, 0.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.26, 0.38, 0.45, 0.51, 0.57, 0.62, 0.66, 0.7, 0.73, 0.76, 0.78, 0.81, 0.83, 0.85, 0.87, 0.89, 0.9, 0.91, 0.93, 0.94, 0.95, 0.96, 0.96, 0.97, 0.98, 0.98, 0.99, 0.99, 0.99]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.91, 0.9, 0.88, 0.87, 0.86, 0.84, 0.82, 0.81, 0.79, 0.77, 0.75, 0.73, 0.7, 0.68, 0.65, 0.63, 0.6, 0.57, 0.54, 0.5, 0.46, 0.42, 0.37, 0.32, 0.25, 0.15, 0.12, 0.23, 0.3, 0.36]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.92, 1.29, 1.59, 1.85, 2.09, 2.35, 2.59, 2.82, 3.07, 3.3, 3.53, 3.78, 4.0, 4.22, 4.47, 4.69, 4.93, 5.15, 5.37, 5.61, 5.83, 6.05, 6.28, 6.5, 6.72, 6.95, 7.17, 7.39, 7.62, 7.84]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.69, -0.61, -0.52, -0.44, -0.34, -0.24, -0.14, -0.04, 0.07, 0.17, 0.27, 0.37, 0.46, 0.55, 0.64, 0.71, 0.78, 0.84, 0.89, 0.94, 0.97, 0.99, 1.0, 1.0, 0.99, 0.97, 0.94, 0.9, 0.84, 0.78]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.12, 0.13, 0.14, 0.15, 0.16, 0.16, 0.17, 0.18, 0.19, 0.19, 0.2, 0.21, 0.22, 0.22, 0.23, 0.24, 0.24, 0.25, 0.26]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.2, -0.27, -0.31, -0.31, -0.26, -0.18, -0.05, 0.11, 0.33, 0.56, 0.82, 1.15, 1.47, 1.81, 2.19, 2.56, 2.96, 3.32, 3.67, 4.04, 4.35, 4.63, 4.89, 5.1, 5.25, 5.36, 5.4, 5.39, 5.3, 5.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.15, 0.33, 0.52, 0.67, 0.8, 0.9, 0.97, 1.0, 0.99, 0.95, 0.87, 0.75, 0.62, 0.46, 0.27, 0.08, -0.12, -0.31, -0.48, -0.65, -0.78, -0.88, -0.96, -1.0, -1.0, -0.96, -0.88, -0.78, -0.64, -0.48]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.02, 0.05, 0.1, 0.15, 0.21, 0.28, 0.35, 0.43, 0.5, 0.56, 0.63, 0.69, 0.73, 0.77, 0.8, 0.81, 0.81, 0.79, 0.76, 0.72, 0.66, 0.59, 0.51, 0.42, 0.32, 0.22, 0.13, 0.02, -0.08]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.01, -0.02, -0.05, -0.1, -0.16, -0.22, -0.3, -0.4, -0.5, -0.61, -0.75, -0.89, -1.04, -1.22, -1.39, -1.6, -1.8, -2.01, -2.25, -2.49, -2.73, -3.02, -3.29, -3.57, -3.89, -4.2, -4.52, -4.88, -5.23]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.05, 0.45, 0.68, 0.85, 1.0, 1.15, 1.28, 1.4, 1.52, 1.62, 1.72, 1.82, 1.9, 1.97, 2.05, 2.12, 2.18, 2.24, 2.28, 2.33, 2.37, 2.41, 2.44, 2.46, 2.48, 2.5, 2.5, 2.51, 2.51, 2.5]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.31, 0.41, 0.52, 0.62, 0.72, 0.83, 0.93, 1.03, 1.14, 1.24, 1.34, 1.45, 1.55, 1.66, 1.76, 1.86, 1.97, 2.07, 2.17, 2.28, 2.38, 2.48, 2.59, 2.69, 2.79, 2.9, 3.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.77, 0.76, 0.74, 0.73, 0.71, 0.69, 0.67, 0.65, 0.63, 0.61, 0.58, 0.56, 0.53, 0.5, 0.46, 0.42, 0.37, 0.32, 0.26, 0.17, 0.1, 0.22, 0.3, 0.35, 0.4, 0.44, 0.48, 0.51, 0.54, 0.57]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.89, 0.89, 0.89, 0.89, 0.89, 0.89, 0.89, 0.89, 0.89, 0.89, 0.89, 0.89, 0.89, 0.89, 0.89, 0.89, 0.89, 0.89, 0.89, 0.89, 0.89, 0.89, 0.89, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.05, 0.08, 0.12, 0.16, 0.21, 0.26, 0.31, 0.36, 0.42, 0.48, 0.54, 0.6, 0.67, 0.74, 0.81, 0.89, 0.96, 1.03, 1.12, 1.19, 1.27, 1.36, 1.45, 1.53, 1.63, 1.71, 1.8, 1.9, 2.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.19, 0.28, 0.34, 0.39, 0.43, 0.47, 0.51, 0.55, 0.58, 0.61, 0.64, 0.67, 0.7, 0.73, 0.75, 0.78, 0.8, 0.82, 0.85, 0.87, 0.89, 0.91, 0.93, 0.95, 0.97, 0.99, 1.01, 1.03, 1.04]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.52, 0.61, 0.68, 0.74, 0.8, 0.85, 0.88, 0.92, 0.95, 0.97, 0.98, 0.99, 1.0, 1.0, 0.99, 0.98, 0.97, 0.95, 0.92, 0.88, 0.85, 0.8, 0.74, 0.68, 0.61, 0.52, 0.42, 0.28, 0.18, 0.37]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.29, 0.42, 0.51, 0.58, 0.64, 0.69, 0.72, 0.75, 0.77, 0.78, 0.78, 0.77, 0.76, 0.74, 0.71, 0.67, 0.64, 0.59, 0.53, 0.47, 0.41, 0.33, 0.26, 0.17, 0.08, -0.02, -0.12, -0.23, -0.34]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.2, 0.3, 0.36, 0.41, 0.47, 0.51, 0.55, 0.59, 0.62, 0.66, 0.69, 0.72, 0.75, 0.78, 0.81, 0.83, 0.86, 0.88, 0.91, 0.93, 0.95, 0.98, 1.0, 1.02, 1.04, 1.06, 1.08, 1.1, 1.12]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.57, 0.75, 0.91, 1.04, 1.17, 1.29, 1.39, 1.48, 1.57, 1.64, 1.71, 1.77, 1.82, 1.86, 1.89, 1.91, 1.93, 1.93, 1.93, 1.92, 1.9, 1.87, 1.84, 1.8, 1.76, 1.7, 1.65, 1.59, 1.53, 1.47]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.16, 0.35, 0.48, 0.57, 0.65, 0.73, 0.79, 0.85, 0.91, 0.96, 1.01, 1.06, 1.11, 1.15, 1.19, 1.23, 1.28, 1.31, 1.35, 1.39, 1.42, 1.46, 1.49, 1.53, 1.56, 1.59, 1.62, 1.65, 1.68, 1.71]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.2, -0.12, -0.03, 0.05, 0.13, 0.21, 0.29, 0.37, 0.45, 0.52, 0.58, 0.65, 0.71, 0.77, 0.82, 0.86, 0.9, 0.94, 0.96, 0.98, 0.99, 1.0, 1.0, 0.99, 0.98, 0.95, 0.93, 0.89, 0.85, 0.81]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.07, 0.14, 0.21, 0.28, 0.35, 0.41, 0.47, 0.54, 0.59, 0.65, 0.7, 0.75, 0.79, 0.84, 0.87, 0.91, 0.93, 0.96, 0.98, 0.99, 1.0, 1.0, 1.0, 0.99, 0.98, 0.96, 0.94, 0.91, 0.88]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.47, 0.56, 0.66, 0.73, 0.79, 0.86, 0.92, 0.97, 1.02, 1.07, 1.12, 1.17, 1.21, 1.25, 1.29, 1.33, 1.37, 1.41, 1.44, 1.48, 1.51, 1.55, 1.58, 1.61, 1.64, 1.68, 1.71, 1.73, 1.77, 1.79]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.0, -0.0, -0.01, -0.02, -0.03, -0.05, -0.07, -0.09, -0.11, -0.14, -0.18, -0.21, -0.25, -0.29, -0.33, -0.38, -0.43, -0.49, -0.55, -0.61, -0.67, -0.74, -0.81, -0.88, -0.96, -1.04, -1.12, -1.21, -1.3]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.0, -0.0, -0.0, -0.0, -0.01, -0.01, -0.01, -0.02, -0.03, -0.04, -0.06, -0.08, -0.1, -0.13, -0.16, -0.2, -0.24, -0.29, -0.36, -0.43, -0.5, -0.6, -0.69, -0.8, -0.94, -1.07, -1.22, -1.4, -1.59]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.06, -0.13, -0.19, -0.25, -0.31, -0.37, -0.43, -0.49, -0.54, -0.6, -0.66, -0.71, -0.76, -0.82, -0.87, -0.93, -0.98, -1.03, -1.08, -1.13, -1.18, -1.23, -1.27, -1.32, -1.37, -1.41, -1.45, -1.5, -1.54]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.32, 0.46, 0.56, 0.64, 0.72, 0.79, 0.85, 0.91, 0.96, 1.01, 1.07, 1.11, 1.16, 1.2, 1.24, 1.29, 1.33, 1.36, 1.4, 1.44, 1.47, 1.51, 1.54, 1.57, 1.61, 1.64, 1.67, 1.7, 1.73]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.3, 0.29, 0.27, 0.26, 0.25, 0.24, 0.22, 0.21, 0.2, 0.19, 0.17, 0.16, 0.15, 0.14, 0.12, 0.11, 0.1, 0.08, 0.07, 0.06, 0.05, 0.03, 0.02, 0.01, -0.01, -0.02, -0.03, -0.04, -0.06, -0.07]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.17, 0.25, 0.34, 0.44, 0.54, 0.67, 0.79, 0.91, 1.06, 1.2, 1.34, 1.5, 1.65, 1.8, 1.98, 2.14, 2.32, 2.48, 2.65, 2.85, 3.03, 3.21, 3.43, 3.63, 3.83, 4.07, 4.3, 4.54, 4.81, 5.07]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.19, 0.27, 0.33, 0.38, 0.43, 0.47, 0.51, 0.54, 0.58, 0.61, 0.64, 0.67, 0.69, 0.72, 0.74, 0.77, 0.79, 0.81, 0.84, 0.86, 0.88, 0.9, 0.92, 0.94, 0.96, 0.98, 1.0, 1.02, 1.03]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.75, 0.73, 0.7, 0.68, 0.65, 0.62, 0.59, 0.55, 0.51, 0.47, 0.43, 0.37, 0.32, 0.25, 0.13, 0.16, 0.26, 0.33, 0.39, 0.44, 0.48, 0.52, 0.56, 0.59, 0.62, 0.66, 0.68, 0.71, 0.73, 0.76]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.07, 0.15, 0.24, 0.34, 0.46, 0.58, 0.71, 0.87, 1.02, 1.19, 1.39, 1.57, 1.77, 2.01, 2.23, 2.48, 2.73, 2.98, 3.28, 3.56, 3.85, 4.18, 4.49, 4.81, 5.18, 5.52, 5.88, 6.29, 6.66]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.2, 0.26, 0.29, 0.31, 0.32, 0.33, 0.33, 0.33, 0.33, 0.32, 0.31, 0.3, 0.29, 0.28, 0.26, 0.25, 0.23, 0.22, 0.2, 0.18, 0.16, 0.14, 0.12, 0.1, 0.08, 0.06, 0.04, 0.01, -0.01]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.28, 0.11, 0.34, 0.45, 0.55, 0.63, 0.7, 0.77, 0.83, 0.88, 0.93, 0.99, 1.03, 1.08, 1.12, 1.16, 1.21, 1.24, 1.28, 1.32, 1.35, 1.39, 1.42, 1.46, 1.49, 1.52, 1.55, 1.58, 1.61, 1.64]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.01, 0.16, 0.34, 0.49, 0.63, 0.77, 0.86, 0.94, 0.99, 1.0, 0.99, 0.94, 0.86, 0.77, 0.63, 0.49, 0.32, 0.16, -0.01, -0.2, -0.36, -0.52, -0.67, -0.78, -0.88, -0.95, -0.99, -1.0, -0.98, -0.93]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.48, 0.42, 0.35, 0.28, 0.22, 0.15, 0.09, 0.02, -0.05, -0.11, -0.17, -0.24, -0.31, -0.37, -0.44, -0.5, -0.57, -0.64, -0.7, -0.77, -0.83, -0.9, -0.97, -1.03, -1.09, -1.16, -1.23, -1.29, -1.36, -1.42]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.07, 0.15, 0.21, 0.28, 0.35, 0.41, 0.46, 0.52, 0.57, 0.61, 0.65, 0.69, 0.72, 0.75, 0.77, 0.79, 0.81, 0.82, 0.83, 0.84, 0.84, 0.84, 0.84, 0.83, 0.83, 0.82, 0.8, 0.78, 0.76]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.22, 0.21, 0.2, 0.18, 0.17, 0.16, 0.14, 0.13, 0.11, 0.09, 0.06, 0.04, 0.01, -0.01, -0.04, -0.08, -0.11, -0.15, -0.18, -0.23, -0.27, -0.31, -0.36, -0.41, -0.46, -0.51, -0.57, -0.62, -0.69, -0.75]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.05, 0.22, 0.39, 0.52, 0.64, 0.75, 0.83, 0.9, 0.95, 0.98, 0.99, 0.98, 0.96, 0.91, 0.85, 0.77, 0.67, 0.55, 0.42, 0.26, 0.09, -0.09, -0.32, -0.54, -0.78, -1.06, -1.33, -1.62, -1.96, -2.29]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.19, 0.41, 0.6, 0.81, 1.03, 1.25, 1.46, 1.7, 1.92, 2.15, 2.41, 2.64, 2.88, 3.15, 3.4, 3.67, 3.93, 4.19, 4.48, 4.75, 5.02, 5.32, 5.6, 5.88, 6.2, 6.49, 6.79, 7.12, 7.42]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.09, 0.19, 0.28, 0.37, 0.46, 0.54, 0.61, 0.69, 0.75, 0.81, 0.87, 0.91, 0.94, 0.97, 0.99, 1.0, 1.0, 0.99, 0.97, 0.95, 0.91, 0.87, 0.82, 0.76, 0.69, 0.63, 0.55, 0.46, 0.38]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.15, 0.2, 0.25, 0.3, 0.34, 0.39, 0.44, 0.48, 0.52, 0.57, 0.62, 0.66, 0.71, 0.75, 0.8, 0.85, 0.89, 0.94, 0.98, 1.02, 1.07, 1.12, 1.16, 1.21, 1.25, 1.3, 1.34, 1.39]<EOS_Y><SOS_EQ>', '<SOS_Y>[1.05, 1.07, 1.08, 1.08, 1.06, 1.0, 1.07, 1.26, 1.43, 1.57, 1.69, 1.83, 1.94, 2.06, 2.18, 2.29, 2.4, 2.51, 2.61, 2.72, 2.82, 2.92, 3.02, 3.12, 3.22, 3.32, 3.42, 3.51, 3.61, 3.71]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.23, -0.18, -0.12, -0.07, -0.02, 0.01, 0.02, 0.01, -0.04, -0.13, -0.26, -0.46, -0.69, -0.99, -1.39, -1.84, -2.41, -3.03, -3.73, -4.62, -5.53, -6.55, -7.81, -9.07, -10.46, -12.15, -13.82, -15.64, -17.81, -19.95]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.27, 0.43, 0.55, 0.66, 0.78, 0.89, 0.99, 1.11, 1.21, 1.32, 1.43, 1.53, 1.63, 1.75, 1.85, 1.96, 2.06, 2.16, 2.27, 2.37, 2.48, 2.59, 2.69, 2.79, 2.9, 3.0, 3.1, 3.21, 3.31]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.19, 0.4, 0.59, 0.77, 0.97, 1.15, 1.32, 1.5, 1.65, 1.8, 1.95, 2.08, 2.2, 2.32, 2.42, 2.51, 2.59, 2.66, 2.72, 2.77, 2.81, 2.84, 2.87, 2.88, 2.89, 2.9, 2.9, 2.89, 2.89]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.89, 0.87, 0.85, 0.82, 0.8, 0.76, 0.73, 0.69, 0.64, 0.58, 0.48, 0.29, 0.5, 0.59, 0.65, 0.7, 0.74, 0.77, 0.8, 0.83, 0.85, 0.87, 0.9, 0.92, 0.93, 0.95, 0.97, 0.98, 1.0, 1.01]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.81, 0.81, 0.81, 0.81, 0.81, 0.81, 0.81]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.32, 0.46, 0.56, 0.64, 0.72, 0.79, 0.85, 0.91, 0.96, 1.01, 1.07, 1.11, 1.16, 1.2, 1.24, 1.29, 1.33, 1.36, 1.4, 1.44, 1.47, 1.51, 1.54, 1.57, 1.61, 1.64, 1.67, 1.7, 1.73]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.42, 0.67, 0.87, 1.05, 1.24, 1.41, 1.57, 1.74, 1.89, 2.04, 2.21, 2.35, 2.5, 2.65, 2.79, 2.95, 3.09, 3.22, 3.37, 3.51, 3.64, 3.79, 3.92, 4.05, 4.2, 4.33, 4.46, 4.6, 4.73]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.74, 0.79, 0.83, 0.86, 0.89, 0.93, 0.95, 0.98, 1.0, 1.02, 1.04, 1.06, 1.08, 1.09, 1.11, 1.12, 1.14, 1.15, 1.16, 1.17, 1.18, 1.19, 1.2, 1.21, 1.22, 1.23, 1.23, 1.24, 1.25, 1.25]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.01, 0.03, 0.06, 0.12, 0.21, 0.32, 0.45, 0.63, 0.82, 1.03, 1.28, 1.53, 1.79, 2.08, 2.35, 2.62, 2.86, 3.07, 3.26, 3.39, 3.46, 3.47, 3.4, 3.26, 3.0, 2.68, 2.25, 1.68, 1.05]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.63, 0.92, 1.11, 1.28, 1.44, 1.57, 1.7, 1.82, 1.93, 2.03, 2.14, 2.23, 2.32, 2.41, 2.49, 2.58, 2.65, 2.73, 2.81, 2.88, 2.95, 3.02, 3.09, 3.15, 3.22, 3.28, 3.34, 3.41, 3.46]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.06, -0.14, -0.2, -0.26, -0.33, -0.39, -0.45, -0.51, -0.57, -0.62, -0.67, -0.72, -0.76, -0.81, -0.85, -0.88, -0.91, -0.94, -0.96, -0.97, -0.99, -1.0, -1.0, -1.0, -0.99, -0.98, -0.97, -0.95, -0.93]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.16, 0.09, 0.03, -0.0, -0.01, 0.0, 0.03, 0.08, 0.16, 0.26, 0.37, 0.52, 0.68, 0.85, 1.07, 1.29, 1.55, 1.81, 2.09, 2.42, 2.74, 3.08, 3.48, 3.87, 4.27, 4.74, 5.18, 5.65, 6.18, 6.69]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.2, -0.1, 0.01, 0.11, 0.21, 0.31, 0.4, 0.48, 0.56, 0.62, 0.67, 0.72, 0.76, 0.79, 0.81, 0.83, 0.84, 0.84, 0.84, 0.83, 0.82, 0.8, 0.77, 0.73, 0.69, 0.63, 0.57, 0.5, 0.41, 0.33]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.32, 0.46, 0.56, 0.64, 0.72, 0.79, 0.85, 0.91, 0.96, 1.01, 1.07, 1.11, 1.16, 1.2, 1.24, 1.29, 1.33, 1.36, 1.4, 1.44, 1.47, 1.51, 1.54, 1.57, 1.61, 1.64, 1.67, 1.7, 1.73]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.45, 0.6, 0.77, 0.93, 1.1, 1.28, 1.45, 1.62, 1.81, 1.99, 2.18, 2.38, 2.57, 2.76, 2.98, 3.18, 3.4, 3.61, 3.82, 4.05, 4.27, 4.49, 4.74, 4.96, 5.19, 5.45, 5.69, 5.93, 6.19, 6.44]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.75, 0.95, 1.17, 1.37, 1.57, 1.79, 1.99, 2.19, 2.41, 2.61, 2.81, 3.03, 3.23, 3.43, 3.65, 3.85, 4.07, 4.27, 4.47, 4.69, 4.89, 5.09, 5.31, 5.51, 5.71, 5.93, 6.13, 6.33, 6.55, 6.75]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.23, 0.33, 0.4, 0.46, 0.52, 0.57, 0.61, 0.66, 0.69, 0.73, 0.77, 0.8, 0.83, 0.87, 0.9, 0.93, 0.96, 0.98, 1.01, 1.04, 1.06, 1.09, 1.11, 1.13, 1.16, 1.18, 1.2, 1.23, 1.25]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.57, 0.49, 0.38, 0.23, 0.21, 0.39, 0.49, 0.56, 0.63, 0.68, 0.73, 0.77, 0.81, 0.84, 0.86, 0.89, 0.91, 0.93, 0.94, 0.95, 0.97, 0.97, 0.98, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.08, -0.13, -0.12, -0.08, 0.01, 0.12, 0.27, 0.47, 0.67, 0.89, 1.14, 1.37, 1.61, 1.86, 2.07, 2.28, 2.45, 2.58, 2.68, 2.73, 2.74, 2.68, 2.58, 2.42, 2.18, 1.9, 1.57, 1.14, 0.7]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.71, 0.75, 0.79, 0.83, 0.86, 0.89, 0.91, 0.94, 0.96, 0.98, 1.0, 1.02, 1.03, 1.05, 1.06, 1.07, 1.08, 1.09, 1.1, 1.1, 1.11, 1.11, 1.11, 1.11, 1.11, 1.11, 1.11, 1.1, 1.1, 1.09]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.51, 0.42, 0.28, 0.14, 0.34, 0.46, 0.54, 0.61, 0.67, 0.72, 0.76, 0.8, 0.83, 0.85, 0.88, 0.9, 0.92, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.01, 0.03, 0.08, 0.13, 0.21, 0.3, 0.4, 0.52, 0.63, 0.74, 0.85, 0.94, 0.99, 1.0, 0.95, 0.82, 0.64, 0.4, 0.08, -0.24, -0.54, -0.82, -0.97, -0.99, -0.84, -0.54, -0.14, 0.34, 0.73]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.84, 0.9, 0.95, 0.98, 1.0, 1.0, 0.99, 0.97, 0.92, 0.87, 0.81, 0.73, 0.64, 0.55, 0.44, 0.33, 0.21, 0.09, -0.02, -0.15, -0.26, -0.38, -0.49, -0.59, -0.68, -0.77, -0.84, -0.89, -0.94, -0.98]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.16, 0.21, 0.26, 0.31, 0.39, 0.47, 0.57, 0.7, 0.83, 0.98, 1.17, 1.36, 1.57, 1.83, 2.08, 2.37, 2.66, 2.97, 3.34, 3.68, 4.05, 4.48, 4.89, 5.32, 5.82, 6.29, 6.78, 7.34, 7.87]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.04, 0.06, 0.07, 0.06, 0.03, -0.03, -0.13, -0.26, -0.46, -0.69, -0.98, -1.36, -1.79, -2.28, -2.91, -3.58, -4.41, -5.26, -6.22, -7.39, -8.58, -9.88, -11.45, -13.01, -14.71, -16.74, -18.73, -20.88, -23.42, -25.9]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.79, 0.81, 0.83, 0.84, 0.86, 0.87, 0.89, 0.9, 0.91, 0.93, 0.94, 0.95, 0.96, 0.96, 0.97, 0.98, 0.98, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 0.99, 0.98]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.82, 0.85, 0.87, 0.9, 0.92, 0.94, 0.96, 0.98, 1.0, 1.01, 1.03, 1.05, 1.06, 1.07, 1.09, 1.1, 1.11, 1.13, 1.14, 1.15, 1.16, 1.17, 1.18, 1.19, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25]<EOS_Y><SOS_EQ>', '<SOS_Y>[1.12, 1.03, 0.88, 0.95, 1.13, 1.28, 1.39, 1.49, 1.59, 1.68, 1.76, 1.84, 1.91, 1.98, 2.06, 2.12, 2.19, 2.25, 2.31, 2.37, 2.43, 2.48, 2.54, 2.59, 2.64, 2.69, 2.74, 2.79, 2.84, 2.89]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.31, 0.4, 0.5, 0.58, 0.66, 0.74, 0.8, 0.86, 0.91, 0.95, 0.97, 0.99, 1.0, 1.0, 0.98, 0.96, 0.92, 0.88, 0.83, 0.76, 0.69, 0.61, 0.52, 0.44, 0.34, 0.24, 0.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.94, 0.83, 0.68, 0.51, 0.26, 0.39, 0.6, 0.74, 0.88, 0.99, 1.08, 1.18, 1.26, 1.34, 1.42, 1.49, 1.56, 1.62, 1.68, 1.75, 1.8, 1.86, 1.92, 1.97, 2.02, 2.07, 2.12, 2.17, 2.22, 2.26]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.9, 0.86, 0.82, 0.77, 0.71, 0.64, 0.56, 0.47, 0.33, 0.1, 0.3, 0.45, 0.54, 0.62, 0.7, 0.76, 0.81, 0.85, 0.89, 0.93, 0.95, 0.97, 0.99, 1.0, 1.0, 1.0, 0.99, 0.98, 0.96, 0.94]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.85, 0.91, 0.96, 1.01, 1.06, 1.11, 1.16, 1.2, 1.24, 1.28, 1.32, 1.36, 1.4, 1.44, 1.47, 1.51, 1.54, 1.57, 1.61, 1.64, 1.67, 1.7, 1.73, 1.76, 1.79, 1.82, 1.85, 1.87, 1.9, 1.93]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.12, 0.16, 0.18, 0.19, 0.19, 0.18, 0.16, 0.13, 0.05, 0.12, 0.19, 0.25, 0.3, 0.35, 0.4, 0.45, 0.49, 0.54, 0.59, 0.63, 0.67, 0.72, 0.76, 0.8, 0.85, 0.89, 0.93, 0.98, 1.02]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.25, 0.35, 0.41, 0.44, 0.46, 0.45, 0.43, 0.4, 0.35, 0.28, 0.2, 0.11, 0.01, -0.12, -0.25, -0.41, -0.57, -0.73, -0.93, -1.13, -1.33, -1.57, -1.8, -2.05, -2.33, -2.59, -2.87, -3.19, -3.5]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.15, 0.27, 0.36, 0.46, 0.57, 0.67, 0.78, 0.89, 1.01, 1.12, 1.25, 1.38, 1.51, 1.65, 1.79, 1.95, 2.09, 2.24, 2.41, 2.57, 2.74, 2.92, 3.1, 3.27, 3.47, 3.66, 3.85, 4.07, 4.27]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.45, 0.65, 0.79, 0.91, 1.02, 1.11, 1.2, 1.29, 1.36, 1.44, 1.51, 1.57, 1.64, 1.7, 1.76, 1.82, 1.88, 1.93, 1.98, 2.03, 2.08, 2.14, 2.18, 2.23, 2.28, 2.32, 2.36, 2.41, 2.45]<EOS_Y><SOS_EQ>', '<SOS_Y>[-1.59, -1.22, -0.81, -0.44, -0.07, 0.34, 0.71, 1.08, 1.49, 1.86, 2.23, 2.64, 3.01, 3.38, 3.79, 4.16, 4.57, 4.94, 5.31, 5.72, 6.09, 6.46, 6.87, 7.24, 7.61, 8.02, 8.39, 8.76, 9.17, 9.54]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.48, -0.53, -0.59, -0.65, -0.71, -0.79, -0.87, -0.95, -1.05, -1.15, -1.25, -1.37, -1.48, -1.6, -1.74, -1.87, -2.02, -2.17, -2.32, -2.49, -2.66, -2.82, -3.02, -3.2, -3.39, -3.6, -3.8, -4.0, -4.24, -4.45]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.07, 0.15, 0.22, 0.3, 0.38, 0.45, 0.52, 0.6, 0.67, 0.74, 0.82, 0.9, 0.97, 1.05, 1.12, 1.2, 1.27, 1.34, 1.42, 1.5, 1.57, 1.65, 1.72, 1.79, 1.87, 1.94, 2.02, 2.1, 2.17]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.15, -0.24, -0.31, -0.38, -0.46, -0.54, -0.61, -0.7, -0.78, -0.86, -0.95, -1.04, -1.12, -1.22, -1.31, -1.42, -1.51, -1.61, -1.72, -1.82, -1.92, -2.04, -2.14, -2.25, -2.37, -2.48, -2.59, -2.72, -2.84]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.62, 0.7, 0.77, 0.84, 0.89, 0.95, 1.0, 1.05, 1.1, 1.15, 1.19, 1.24, 1.28, 1.31, 1.36, 1.39, 1.43, 1.47, 1.5, 1.54, 1.57, 1.6, 1.63, 1.66, 1.69, 1.73, 1.75, 1.78, 1.81, 1.84]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.19, -0.13, -0.06, 0.0, 0.07, 0.14, 0.2, 0.27, 0.33, 0.4, 0.45, 0.52, 0.57, 0.62, 0.68, 0.72, 0.77, 0.81, 0.85, 0.88, 0.91, 0.94, 0.96, 0.97, 0.99, 1.0, 1.0, 1.0, 0.99, 0.98]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.04, 0.02, 0.0, -0.01, -0.03, -0.03, -0.04, -0.04, -0.03, -0.02, -0.01, 0.01, 0.03, 0.05, 0.08, 0.12, 0.15, 0.19, 0.24, 0.29, 0.34, 0.4, 0.46, 0.53, 0.6, 0.67, 0.75, 0.83, 0.92, 1.01]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.65, -0.49, -0.29, -0.09, 0.11, 0.32, 0.5, 0.66, 0.81, 0.91, 0.97, 1.0, 0.98, 0.92, 0.82, 0.69, 0.51, 0.33, 0.13, -0.08, -0.28, -0.47, -0.65, -0.79, -0.89, -0.97, -1.0, -0.99, -0.93, -0.84]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.85, 0.84, 0.84, 0.83, 0.83, 0.82, 0.82, 0.82, 0.81, 0.81, 0.8, 0.8, 0.79, 0.79, 0.78, 0.78, 0.77, 0.77, 0.76, 0.76, 0.75, 0.75, 0.74, 0.74, 0.73, 0.73, 0.72, 0.72, 0.71, 0.7]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.22, 0.39, 0.61, 0.75, 0.87, 0.99, 1.09, 1.17, 1.26, 1.34, 1.41, 1.49, 1.55, 1.61, 1.68, 1.74, 1.8, 1.85, 1.91, 1.96, 2.01, 2.06, 2.11, 2.16, 2.2, 2.25, 2.3, 2.34, 2.38, 2.43]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.82, -0.77, -0.71, -0.67, -0.63, -0.6, -0.58, -0.57, -0.57, -0.58, -0.6, -0.64, -0.7, -0.76, -0.86, -0.96, -1.1, -1.24, -1.4, -1.61, -1.81, -2.04, -2.32, -2.59, -2.89, -3.24, -3.58, -3.95, -4.38, -4.79]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.24, 0.27, 0.3, 0.31, 0.3, 0.27, 0.22, 0.14, 0.04, -0.07, -0.2, -0.36, -0.51, -0.66, -0.82, -0.96, -1.1, -1.2, -1.27, -1.31, -1.3, -1.25, -1.12, -0.95, -0.71, -0.37, 0.0, 0.44, 1.01, 1.58]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.5, 0.58, 0.58, 0.56, 0.53, 0.47, 0.37, 0.54, 0.65, 0.73, 0.8, 0.88, 0.94, 0.99, 1.05, 1.1, 1.15, 1.19, 1.24, 1.28, 1.32, 1.36, 1.41, 1.44, 1.48, 1.52, 1.55, 1.58, 1.62, 1.65]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.05, -0.11, -0.17, -0.22, -0.28, -0.33, -0.37, -0.42, -0.47, -0.51, -0.55, -0.59, -0.62, -0.65, -0.68, -0.71, -0.73, -0.75, -0.77, -0.79, -0.8, -0.81, -0.82, -0.83, -0.83, -0.84, -0.84, -0.84, -0.84]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.29, 0.41, 0.49, 0.56, 0.62, 0.67, 0.71, 0.75, 0.78, 0.81, 0.83, 0.86, 0.88, 0.9, 0.91, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.98, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.62, 0.58, 0.52, 0.45, 0.34, 0.09, 0.32, 0.48, 0.61, 0.73, 0.83, 0.94, 1.04, 1.13, 1.23, 1.32, 1.42, 1.51, 1.59, 1.69, 1.77, 1.86, 1.95, 2.04, 2.12, 2.21, 2.29, 2.38, 2.47, 2.55]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.56, 0.62, 0.68, 0.73, 0.77, 0.8, 0.83, 0.86, 0.89, 0.91, 0.92, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 0.99, 0.98, 0.98, 0.97, 0.97]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.14, -0.29, -0.43, -0.56, -0.71, -0.84, -0.96, -1.09, -1.2, -1.3, -1.41, -1.49, -1.57, -1.65, -1.71, -1.77, -1.81, -1.84, -1.86, -1.87, -1.88, -1.87, -1.85, -1.82, -1.78, -1.73, -1.67, -1.6, -1.53]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.67, -0.61, -0.54, -0.48, -0.41, -0.32, -0.25, -0.17, -0.09, -0.01, 0.07, 0.16, 0.23, 0.31, 0.39, 0.46, 0.54, 0.6, 0.66, 0.73, 0.78, 0.82, 0.87, 0.91, 0.94, 0.96, 0.98, 0.99, 1.0, 1.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.93, 0.9, 0.86, 0.82, 0.77, 0.7, 0.62, 0.47, 0.49, 0.63, 0.71, 0.77, 0.82, 0.86, 0.9, 0.93, 0.96, 0.99, 1.01, 1.04, 1.06, 1.08, 1.1, 1.12, 1.13, 1.15, 1.17, 1.18, 1.2, 1.21]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.06, 0.06, 0.06, 0.04, 0.01, -0.03, -0.08, -0.15, -0.23, -0.31, -0.41, -0.53, -0.65, -0.79, -0.95, -1.1, -1.29, -1.47, -1.66, -1.88, -2.1, -2.32, -2.58, -2.83, -3.09, -3.39, -3.68, -3.97, -4.31, -4.63]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.79, -0.72, -0.64, -0.56, -0.48, -0.38, -0.28, -0.19, -0.08, 0.02, 0.12, 0.23, 0.33, 0.42, 0.52, 0.6, 0.68, 0.75, 0.81, 0.87, 0.92, 0.95, 0.98, 1.0, 1.0, 0.99, 0.98, 0.95, 0.91, 0.87]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.41, 0.58, 0.75, 0.86, 0.95, 0.99, 1.0, 0.96, 0.87, 0.76, 0.61, 0.42, 0.24, 0.04, -0.18, -0.37, -0.57, -0.72, -0.84, -0.94, -0.99, -1.0, -0.96, -0.89, -0.78, -0.63, -0.46, -0.28, -0.06, 0.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.01, -0.0, -0.01, -0.02, -0.04, -0.05, -0.07, -0.09, -0.12, -0.14, -0.16, -0.19, -0.22, -0.25, -0.28, -0.31, -0.34, -0.37, -0.41, -0.44, -0.48, -0.52, -0.55, -0.59, -0.63, -0.67, -0.71, -0.76, -0.8]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.42, -0.36, -0.3, -0.25, -0.2, -0.16, -0.13, -0.1, -0.09, -0.09, -0.09, -0.11, -0.13, -0.17, -0.22, -0.28, -0.35, -0.43, -0.51, -0.62, -0.72, -0.83, -0.95, -1.07, -1.2, -1.34, -1.47, -1.6, -1.75, -1.88]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.31, 0.4, 0.5, 0.58, 0.66, 0.74, 0.8, 0.86, 0.91, 0.95, 0.97, 0.99, 1.0, 1.0, 0.98, 0.96, 0.92, 0.88, 0.83, 0.76, 0.69, 0.61, 0.52, 0.44, 0.34, 0.24, 0.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.04, 0.06, 0.03, 0.13, 0.23, 0.33, 0.43, 0.54, 0.64, 0.73, 0.83, 0.92, 0.99, 1.07, 1.12, 1.16, 1.19, 1.2, 1.19, 1.17, 1.13, 1.07, 1.0, 0.91, 0.79, 0.68, 0.54, 0.39, 0.23]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.01, -0.03, -0.03, -0.03, -0.03, -0.01, 0.02, 0.06, 0.11, 0.18, 0.27, 0.35, 0.45, 0.57, 0.68, 0.8, 0.9, 1.0, 1.1, 1.18, 1.23, 1.26, 1.26, 1.23, 1.16, 1.04, 0.89, 0.67, 0.43]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.36, 0.32, 0.27, 0.2, 0.1, 0.15, 0.23, 0.29, 0.34, 0.38, 0.42, 0.45, 0.49, 0.51, 0.54, 0.57, 0.6, 0.62, 0.64, 0.66, 0.68, 0.7, 0.72, 0.74, 0.76, 0.77, 0.79, 0.8, 0.82, 0.83]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.61, 0.51, 0.41, 0.33, 0.25, 0.18, 0.12, 0.08, 0.03, 0.0, -0.02, -0.03, -0.04, -0.03, -0.02, 0.0, 0.04, 0.07, 0.12, 0.19, 0.25, 0.33, 0.42, 0.51, 0.61, 0.73, 0.85, 0.98, 1.13, 1.27]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.08, 0.14, 0.38, 0.6, 0.82, 1.06, 1.28, 1.5, 1.74, 1.96, 2.18, 2.42, 2.64, 2.86, 3.1, 3.32, 3.56, 3.78, 4.0, 4.24, 4.46, 4.68, 4.92, 5.14, 5.36, 5.6, 5.82, 6.04, 6.28, 6.5]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.57, 0.53, 0.46, 0.31, 0.53, 0.75, 0.92, 1.08, 1.24, 1.38, 1.52, 1.67, 1.8, 1.94, 2.08, 2.22, 2.37, 2.5, 2.64, 2.79, 2.93, 3.07, 3.22, 3.36, 3.51, 3.67, 3.81, 3.96, 4.13, 4.28]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.91, 0.94, 0.96, 0.98, 0.99, 1.0, 1.0, 1.0, 0.99, 0.97, 0.95, 0.92, 0.89, 0.86, 0.81, 0.76, 0.69, 0.62, 0.54, 0.44, 0.3, 0.09, 0.34, 0.47, 0.56, 0.64, 0.71, 0.77, 0.82, 0.86]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.06, 0.35, 0.67, 0.96, 1.25, 1.57, 1.86, 2.15, 2.47, 2.76, 3.05, 3.37, 3.66, 3.95, 4.27, 4.56, 4.87, 5.16, 5.45, 5.77, 6.06, 6.35, 6.67, 6.96, 7.25, 7.57, 7.86, 8.15, 8.47, 8.76]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.08, 0.18, 0.27, 0.35, 0.45, 0.54, 0.64, 0.74, 0.84, 0.94, 1.04, 1.14, 1.25, 1.36, 1.47, 1.58, 1.69, 1.8, 1.92, 2.03, 2.15, 2.28, 2.39, 2.51, 2.64, 2.76, 2.89, 3.02, 3.15]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.34, -0.18, -0.01, 0.14, 0.3, 0.47, 0.62, 0.78, 0.95, 1.1, 1.26, 1.43, 1.59, 1.74, 1.91, 2.07, 2.24, 2.39, 2.55, 2.72, 2.87, 3.03, 3.2, 3.36, 3.51, 3.68, 3.84, 3.99, 4.16, 4.32]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.85, 0.74, 0.58, 0.42, 0.23, -0.01, -0.27, -0.6, -0.73, -0.77, -0.87, -1.03, -1.19, -1.38, -1.61, -1.85, -2.13, -2.4, -2.7, -3.04, -3.37, -3.72, -4.12, -4.51, -4.91, -5.38, -5.81, -6.27, -6.79, -7.28]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.18, 0.38, 0.57, 0.75, 0.95, 1.14, 1.32, 1.52, 1.7, 1.89, 2.09, 2.27, 2.46, 2.66, 2.84, 3.04, 3.23, 3.41, 3.61, 3.79, 3.98, 4.18, 4.36, 4.55, 4.75, 4.93, 5.11, 5.32, 5.5]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.09, -0.19, -0.28, -0.36, -0.45, -0.53, -0.6, -0.68, -0.74, -0.8, -0.85, -0.9, -0.93, -0.96, -0.98, -1.0, -1.0, -0.99, -0.98, -0.96, -0.93, -0.89, -0.84, -0.79, -0.73, -0.66, -0.59, -0.51, -0.43]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.05, 0.1, 0.15, 0.2, 0.26, 0.31, 0.36, 0.41, 0.46, 0.51, 0.56, 0.61, 0.66, 0.72, 0.77, 0.82, 0.87, 0.92, 0.97, 1.02, 1.07, 1.13, 1.18, 1.23, 1.28, 1.33, 1.38, 1.43, 1.48]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.03, -0.05, -0.06, -0.06, -0.04, -0.02, 0.02, 0.07, 0.12, 0.19, 0.27, 0.36, 0.46, 0.58, 0.7, 0.84, 0.98, 1.13, 1.31, 1.49, 1.67, 1.88, 2.09, 2.3, 2.55, 2.79, 3.03, 3.32, 3.59]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.85, 0.79, 0.71, 0.64, 0.56, 0.45, 0.32, 0.02, 0.33, 0.46, 0.56, 0.65, 0.72, 0.79, 0.85, 0.91, 0.97, 1.02, 1.07, 1.12, 1.16, 1.2, 1.25, 1.29, 1.33, 1.37, 1.4, 1.44, 1.48, 1.51]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.82, 0.75, 0.68, 0.6, 0.51, 0.38, 0.21, 0.23, 0.41, 0.51, 0.6, 0.69, 0.76, 0.82, 0.89, 0.94, 1.0, 1.05, 1.09, 1.14, 1.19, 1.23, 1.27, 1.31, 1.35, 1.39, 1.42, 1.46, 1.49, 1.53]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.69, -0.47, -0.22, 0.02, 0.28, 0.58, 0.86, 1.16, 1.5, 1.82, 2.16, 2.54, 2.9, 3.28, 3.71, 4.11, 4.57, 5.0, 5.44, 5.94, 6.41, 6.89, 7.43, 7.94, 8.46, 9.05, 9.59, 10.15, 10.78, 11.37]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.01, 0.03, 0.07, 0.13, 0.22, 0.33, 0.46, 0.64, 0.83, 1.06, 1.35, 1.65, 2.0, 2.42, 2.86, 3.39, 3.92, 4.5, 5.21, 5.9, 6.66, 7.56, 8.45, 9.39, 10.51, 11.61, 12.77, 14.13, 15.45]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.03, -0.06, -0.09, -0.12, -0.15, -0.18, -0.21, -0.24, -0.27, -0.3, -0.34, -0.37, -0.4, -0.43, -0.46, -0.49, -0.52, -0.55, -0.58, -0.61, -0.64, -0.67, -0.7, -0.73, -0.76, -0.79, -0.82, -0.86, -0.88]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.09, 0.19, 0.29, 0.39, 0.51, 0.62, 0.73, 0.87, 0.99, 1.12, 1.27, 1.41, 1.56, 1.72, 1.88, 2.05, 2.21, 2.38, 2.57, 2.75, 2.93, 3.14, 3.33, 3.53, 3.75, 3.96, 4.17, 4.41, 4.63]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.0, -0.01, -0.02, -0.04, -0.08, -0.14, -0.21, -0.32, -0.46, -0.62, -0.84, -1.08, -1.37, -1.73, -2.12, -2.6, -3.1, -3.66, -4.34, -5.04, -5.81, -6.73, -7.66, -8.67, -9.87, -11.06, -12.34, -13.86, -15.34]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.66, -0.64, -0.61, -0.59, -0.55, -0.51, -0.47, -0.42, -0.36, -0.28, -0.16, -0.19, -0.31, -0.4, -0.48, -0.55, -0.62, -0.67, -0.73, -0.79, -0.84, -0.9, -0.95, -1.0, -1.05, -1.1, -1.15, -1.2, -1.25, -1.3]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.49, -0.16, 0.01, 0.15, 0.28, 0.44, 0.58, 0.73, 0.91, 1.08, 1.26, 1.46, 1.66, 1.87, 2.12, 2.35, 2.62, 2.88, 3.14, 3.45, 3.74, 4.04, 4.39, 4.71, 5.05, 5.44, 5.8, 6.18, 6.6, 7.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.26, 0.4, 0.55, 0.68, 0.8, 0.93, 1.03, 1.12, 1.22, 1.29, 1.35, 1.41, 1.46, 1.49, 1.51, 1.53, 1.53, 1.53, 1.52, 1.5, 1.47, 1.44, 1.4, 1.37, 1.33, 1.28, 1.24, 1.2, 1.16, 1.12]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.19, 0.32, 0.43, 0.53, 0.64, 0.74, 0.85, 0.96, 1.06, 1.16, 1.27, 1.37, 1.47, 1.58, 1.68, 1.79, 1.89, 1.99, 2.1, 2.2, 2.3, 2.41, 2.51, 2.61, 2.72, 2.82, 2.92, 3.03, 3.13]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.4, 0.02, 0.28, 0.49, 0.69, 0.89, 1.08, 1.25, 1.44, 1.61, 1.77, 1.95, 2.12, 2.27, 2.45, 2.61, 2.78, 2.93, 3.08, 3.25, 3.4, 3.55, 3.72, 3.87, 4.02, 4.18, 4.33, 4.47, 4.63, 4.78]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.86, 0.9, 0.94, 0.97, 1.01, 1.05, 1.08, 1.11, 1.14, 1.17, 1.2, 1.23, 1.26, 1.28, 1.31, 1.34, 1.37, 1.39, 1.42, 1.44, 1.47, 1.49, 1.51, 1.54, 1.56, 1.58, 1.6, 1.62, 1.65, 1.67]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.67, -0.65, -0.61, -0.55, -0.48, -0.37, -0.25, -0.1, 0.08, 0.27, 0.47, 0.67, 0.84, 0.95, 1.0, 0.95, 0.76, 0.49, 0.13, -0.3, -0.66, -0.92, -1.0, -0.84, -0.47, 0.08, 0.58, 0.93, 0.97, 0.65]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.27, 0.36, 0.4, 0.41, 0.4, 0.36, 0.27, 0.07, 0.31, 0.46, 0.6, 0.72, 0.83, 0.95, 1.06, 1.18, 1.28, 1.39, 1.5, 1.61, 1.71, 1.82, 1.92, 2.03, 2.14, 2.24, 2.34, 2.45, 2.55]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.09, 0.18, 0.27, 0.36, 0.45, 0.54, 0.63, 0.72, 0.81, 0.9, 0.99, 1.08, 1.17, 1.26, 1.35, 1.45, 1.53, 1.62, 1.72, 1.8, 1.89, 1.99, 2.07, 2.16, 2.26, 2.34, 2.43, 2.53, 2.61]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.3, 0.39, 0.48, 0.55, 0.61, 0.67, 0.72, 0.76, 0.79, 0.81, 0.83, 0.84, 0.84, 0.84, 0.83, 0.82, 0.8, 0.77, 0.74, 0.69, 0.64, 0.58, 0.5, 0.42, 0.34, 0.24, 0.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.47, -0.41, -0.34, -0.27, -0.2, -0.12, -0.04, 0.04, 0.12, 0.19, 0.26, 0.34, 0.4, 0.46, 0.53, 0.58, 0.63, 0.67, 0.7, 0.74, 0.76, 0.79, 0.81, 0.82, 0.83, 0.84, 0.84, 0.84, 0.84, 0.83]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.01, 0.02, 0.04, 0.05, 0.07, 0.09, 0.11, 0.13, 0.16, 0.18, 0.21, 0.24, 0.27, 0.3, 0.33, 0.37, 0.4, 0.44, 0.48, 0.52, 0.56, 0.61, 0.65, 0.69, 0.74, 0.79, 0.84, 0.89, 0.94]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.08, 0.11, 0.14, 0.16, 0.18, 0.19, 0.21, 0.22, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.32, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.39, 0.4, 0.41, 0.42, 0.42]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.31, 0.41, 0.52, 0.62, 0.72, 0.83, 0.93, 1.03, 1.14, 1.24, 1.34, 1.45, 1.55, 1.66, 1.76, 1.86, 1.97, 2.07, 2.17, 2.28, 2.38, 2.48, 2.59, 2.69, 2.79, 2.9, 3.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.42, 0.45, 0.48, 0.5, 0.52, 0.55, 0.57, 0.59, 0.61, 0.63, 0.65, 0.66, 0.68, 0.7, 0.72, 0.73, 0.75, 0.76, 0.78, 0.8, 0.81, 0.82, 0.84, 0.85, 0.87, 0.88, 0.89, 0.91, 0.92, 0.93]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.78, 0.92, 1.07, 1.21, 1.34, 1.48, 1.62, 1.75, 1.89, 2.02, 2.14, 2.28, 2.41, 2.54, 2.67, 2.8, 2.93, 3.06, 3.18, 3.32, 3.44, 3.56, 3.69, 3.82, 3.94, 4.07, 4.19, 4.31, 4.44, 4.56]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.12, 0.05, 0.24, 0.41, 0.56, 0.71, 0.82, 0.91, 0.97, 1.0, 0.99, 0.95, 0.89, 0.79, 0.66, 0.52, 0.35, 0.18, 0.0, -0.19, -0.36, -0.51, -0.67, -0.79, -0.88, -0.96, -0.99, -1.0, -0.97, -0.91]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.76, -0.82, -0.88, -0.92, -0.96, -0.98, -1.0, -1.0, -0.99, -0.98, -0.95, -0.91, -0.86, -0.81, -0.74, -0.66, -0.58, -0.49, -0.41, -0.3, -0.21, -0.11, 0.0, 0.1, 0.2, 0.31, 0.4, 0.49, 0.58, 0.66]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.21, 0.31, 0.38, 0.43, 0.49, 0.53, 0.57, 0.62, 0.65, 0.69, 0.72, 0.75, 0.78, 0.81, 0.84, 0.87, 0.9, 0.92, 0.95, 0.97, 0.99, 1.02, 1.04, 1.06, 1.09, 1.11, 1.13, 1.15, 1.17]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.54, 0.48, 0.36, 0.38, 0.54, 0.67, 0.76, 0.85, 0.94, 1.02, 1.09, 1.17, 1.23, 1.29, 1.36, 1.42, 1.48, 1.54, 1.59, 1.65, 1.7, 1.75, 1.81, 1.85, 1.9, 1.95, 1.99, 2.04, 2.09, 2.13]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.78, 0.72, 0.64, 0.5, 0.44, 0.62, 0.7, 0.77, 0.82, 0.86, 0.9, 0.94, 0.96, 0.99, 1.02, 1.04, 1.06, 1.09, 1.1, 1.12, 1.14, 1.16, 1.18, 1.19, 1.2, 1.22, 1.23, 1.25, 1.26, 1.27]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.09, 0.2, 0.31, 0.42, 0.52, 0.64, 0.75, 0.85, 0.97, 1.07, 1.18, 1.3, 1.4, 1.51, 1.62, 1.73, 1.85, 1.95, 2.06, 2.17, 2.28, 2.39, 2.5, 2.61, 2.71, 2.83, 2.94, 3.04, 3.16, 3.26]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.54, 0.65, 0.71, 0.76, 0.81, 0.85, 0.88, 0.91, 0.94, 0.96, 0.99, 1.01, 1.03, 1.05, 1.06, 1.08, 1.1, 1.11, 1.13, 1.14, 1.16, 1.17, 1.19, 1.2, 1.21, 1.22, 1.23, 1.25, 1.26]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.05, 0.08, 0.1, 0.1, 0.01, 0.14, 0.22, 0.32, 0.42, 0.51, 0.63, 0.74, 0.85, 0.98, 1.1, 1.24, 1.37, 1.51, 1.66, 1.8, 1.95, 2.12, 2.27, 2.43, 2.61, 2.77, 2.94, 3.13, 3.3]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.22, -0.17, -0.11, -0.05, 0.02, 0.1, 0.17, 0.25, 0.34, 0.42, 0.51, 0.6, 0.68, 0.76, 0.85, 0.92, 0.99, 1.06, 1.11, 1.16, 1.2, 1.24, 1.26, 1.27, 1.27, 1.26, 1.23, 1.2, 1.15, 1.09]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.52, 0.88, 1.18, 1.46, 1.76, 2.03, 2.29, 2.57, 2.82, 3.07, 3.35, 3.59, 3.84, 4.1, 4.34, 4.61, 4.85, 5.08, 5.34, 5.58, 5.81, 6.07, 6.3, 6.53, 6.79, 7.02, 7.25, 7.5, 7.73]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.88, 0.91, 0.94, 0.96, 0.99, 1.01, 1.03, 1.05, 1.07, 1.09, 1.1, 1.12, 1.13, 1.15, 1.16, 1.18, 1.19, 1.2, 1.21, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.29, 1.3, 1.31, 1.32, 1.33]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.0, 0.01, 0.02, 0.04, 0.07, 0.1, 0.14, 0.19, 0.25, 0.32, 0.41, 0.49, 0.6, 0.72, 0.84, 1.0, 1.15, 1.31, 1.5, 1.7, 1.9, 2.14, 2.38, 2.63, 2.93, 3.21, 3.51, 3.86, 4.19]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.2, 0.42, 0.62, 0.81, 1.02, 1.2, 1.38, 1.57, 1.73, 1.89, 2.05, 2.19, 2.31, 2.44, 2.55, 2.66, 2.74, 2.82, 2.89, 2.95, 3.0, 3.04, 3.07, 3.09, 3.11, 3.13, 3.13, 3.14, 3.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.49, 0.63, 0.78, 0.91, 1.05, 1.2, 1.34, 1.47, 1.62, 1.76, 1.9, 2.05, 2.18, 2.32, 2.47, 2.61, 2.76, 2.89, 3.03, 3.18, 3.32, 3.45, 3.61, 3.74, 3.88, 4.03, 4.17, 4.3, 4.45, 4.59]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.71, 0.56, 0.32, 0.29, 0.52, 0.69, 0.82, 0.93, 1.03, 1.12, 1.2, 1.28, 1.35, 1.42, 1.49, 1.55, 1.62, 1.68, 1.73, 1.79, 1.84, 1.89, 1.95, 1.99, 2.04, 2.09, 2.14, 2.18, 2.23, 2.27]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.02, 0.04, 0.06, 0.08, 0.1, 0.11, 0.13, 0.15, 0.17, 0.19, 0.21, 0.23, 0.24, 0.26, 0.28, 0.3, 0.32, 0.34, 0.35, 0.37, 0.39, 0.41, 0.42, 0.44, 0.46, 0.47, 0.49, 0.51, 0.52]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.32, 0.46, 0.55, 0.63, 0.7, 0.76, 0.81, 0.86, 0.9, 0.93, 0.95, 0.97, 0.99, 1.0, 1.0, 1.0, 0.99, 0.98, 0.96, 0.94, 0.91, 0.87, 0.83, 0.78, 0.72, 0.66, 0.59, 0.49, 0.38]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.25, -0.12, 0.06, 0.23, 0.43, 0.67, 0.91, 1.16, 1.46, 1.74, 2.04, 2.38, 2.71, 3.04, 3.43, 3.78, 4.19, 4.57, 4.96, 5.4, 5.82, 6.24, 6.72, 7.16, 7.62, 8.13, 8.61, 9.11, 9.67, 10.2]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.42, 0.6, 0.7, 0.76, 0.81, 0.86, 0.9, 0.93, 0.96, 0.99, 1.01, 1.04, 1.06, 1.08, 1.1, 1.12, 1.14, 1.16, 1.17, 1.19, 1.2, 1.22, 1.23, 1.25, 1.26, 1.27, 1.28, 1.3, 1.31, 1.32]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.31, 0.44, 0.53, 0.6, 0.66, 0.71, 0.75, 0.79, 0.82, 0.85, 0.88, 0.9, 0.92, 0.93, 0.95, 0.96, 0.97, 0.98, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 0.99]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.04, 0.07, 0.08, 0.09, 0.08, 0.06, 0.03, -0.01, -0.06, -0.12, -0.2, -0.28, -0.38, -0.49, -0.61, -0.75, -0.89, -1.03, -1.21, -1.38, -1.56, -1.77, -1.98, -2.19, -2.44, -2.68, -2.92, -3.21, -3.48]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.13, -0.28, -0.41, -0.55, -0.69, -0.83, -0.96, -1.1, -1.24, -1.37, -1.52, -1.65, -1.78, -1.93, -2.06, -2.21, -2.34, -2.48, -2.62, -2.76, -2.89, -3.03, -3.17, -3.3, -3.45, -3.58, -3.71, -3.86, -3.99]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.23, 0.33, 0.4, 0.46, 0.51, 0.55, 0.59, 0.63, 0.66, 0.69, 0.71, 0.74, 0.76, 0.78, 0.8, 0.82, 0.83, 0.85, 0.86, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.95, 0.96]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.07, -0.16, -0.26, -0.35, -0.45, -0.54, -0.64, -0.74, -0.83, -0.93, -1.03, -1.13, -1.22, -1.33, -1.43, -1.53, -1.63, -1.72, -1.83, -1.93, -2.02, -2.13, -2.22, -2.32, -2.43, -2.52, -2.62, -2.73, -2.82]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.31, 0.44, 0.53, 0.6, 0.66, 0.71, 0.75, 0.79, 0.82, 0.85, 0.88, 0.9, 0.92, 0.93, 0.95, 0.96, 0.97, 0.98, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 0.99]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.8, 0.85, 0.89, 0.92, 0.95, 0.97, 0.98, 0.99, 1.0, 1.0, 0.99, 0.98, 0.97, 0.95, 0.92, 0.88, 0.84, 0.8, 0.74, 0.68, 0.6, 0.52, 0.4, 0.25, 0.19, 0.38, 0.49, 0.58, 0.66, 0.73]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.72, 0.85, 0.97, 1.07, 1.16, 1.25, 1.33, 1.4, 1.48, 1.54, 1.61, 1.67, 1.73, 1.79, 1.85, 1.9, 1.96, 2.01, 2.06, 2.11, 2.16, 2.21, 2.25, 2.3, 2.34, 2.39, 2.43, 2.47, 2.51, 2.55]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.75, 0.8, 0.86, 0.91, 0.96, 1.01, 1.06, 1.1, 1.15, 1.2, 1.25, 1.3, 1.34, 1.38, 1.43, 1.48, 1.53, 1.57, 1.61, 1.66, 1.7, 1.75, 1.79, 1.83, 1.88, 1.92, 1.96, 2.0, 2.05, 2.09]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.83, -0.73, -0.59, -0.44, -0.28, -0.07, 0.14, 0.37, 0.64, 0.91, 1.2, 1.54, 1.88, 2.23, 2.64, 3.04, 3.49, 3.93, 4.39, 4.91, 5.41, 5.93, 6.52, 7.08, 7.66, 8.33, 8.95, 9.59, 10.32, 11.01]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.02, 0.01, 0.07, 0.18, 0.34, 0.53, 0.75, 1.05, 1.36, 1.72, 2.15, 2.59, 3.07, 3.64, 4.2, 4.86, 5.5, 6.19, 6.99, 7.76, 8.57, 9.5, 10.39, 11.33, 12.4, 13.42, 14.47, 15.68, 16.82]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.0, -0.01, -0.02, -0.03, -0.05, -0.08, -0.1, -0.14, -0.19, -0.23, -0.29, -0.36, -0.43, -0.51, -0.59, -0.7, -0.8, -0.91, -1.04, -1.17, -1.3, -1.46, -1.62, -1.78, -1.98, -2.16, -2.36, -2.58, -2.8]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.67, 0.74, 0.81, 0.87, 0.93, 0.99, 1.04, 1.08, 1.13, 1.18, 1.22, 1.26, 1.3, 1.34, 1.38, 1.42, 1.45, 1.49, 1.52, 1.56, 1.59, 1.62, 1.65, 1.68, 1.71, 1.74, 1.77, 1.8, 1.83, 1.86]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.01, 0.01, 0.02, 0.02, 0.03, 0.04, 0.04, 0.05, 0.05, 0.06, 0.07, 0.07, 0.08, 0.08, 0.09, 0.1, 0.1, 0.11, 0.11, 0.12, 0.13, 0.13, 0.14, 0.14, 0.15, 0.16, 0.16, 0.17, 0.17]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.87, 0.83, 0.78, 0.73, 0.67, 0.59, 0.5, 0.39, 0.2, 0.24, 0.4, 0.52, 0.6, 0.67, 0.74, 0.79, 0.84, 0.88, 0.91, 0.94, 0.97, 0.98, 0.99, 1.0, 1.0, 0.99, 0.98, 0.97, 0.95, 0.92]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.43, 0.48, 0.51, 0.51, 0.5, 0.46, 0.39, 0.31, 0.18, 0.05, -0.12, -0.33, -0.56, -0.81, -1.11, -1.42, -1.8, -2.16, -2.56, -3.03, -3.48, -3.96, -4.52, -5.06, -5.62, -6.27, -6.88, -7.51, -8.24, -8.92]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.23, 0.18, 0.12, 0.08, 0.05, 0.02, 0.01, -0.01, -0.02, -0.02, -0.02, -0.01, -0.01, 0.0, 0.02, 0.03, 0.04, 0.05, 0.07, 0.08, 0.09, 0.1, 0.1, 0.1, 0.1, 0.09, 0.07, 0.06, 0.03, -0.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.02, 0.09, 0.19, 0.33, 0.52, 0.72, 0.95, 1.22, 1.49, 1.77, 2.07, 2.35, 2.61, 2.88, 3.1, 3.31, 3.46, 3.57, 3.63, 3.63, 3.58, 3.46, 3.28, 3.05, 2.71, 2.35, 1.92, 1.39, 0.85]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.01, -0.02, -0.03, -0.02, -0.02, -0.01, 0.01, 0.03, 0.06, 0.09, 0.13, 0.17, 0.22, 0.28, 0.33, 0.4, 0.47, 0.54, 0.62, 0.71, 0.79, 0.89, 0.99, 1.09, 1.21, 1.32, 1.44, 1.57, 1.7]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.84, -0.78, -0.71, -0.64, -0.56, -0.47, -0.38, -0.28, -0.17, -0.06, 0.06, 0.2, 0.33, 0.46, 0.62, 0.77, 0.94, 1.09, 1.26, 1.44, 1.61, 1.78, 1.98, 2.15, 2.33, 2.53, 2.71, 2.89, 3.09, 3.27]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0, 0.0, 0.0, -0.0, -0.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.72, 0.69, 0.64, 0.6, 0.55, 0.48, 0.41, 0.31, 0.13, 0.24, 0.36, 0.45, 0.52, 0.57, 0.63, 0.67, 0.71, 0.74, 0.77, 0.8, 0.82, 0.84, 0.86, 0.88, 0.9, 0.91, 0.93, 0.94, 0.95, 0.96]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.23, 0.32, 0.42, 0.5, 0.57, 0.63, 0.69, 0.73, 0.77, 0.8, 0.82, 0.83, 0.84, 0.84, 0.84, 0.83, 0.81, 0.79, 0.76, 0.72, 0.68, 0.62, 0.55, 0.48, 0.4, 0.31, 0.21, 0.11, 0.01, -0.09]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.03, -0.01, 0.01, 0.06, 0.11, 0.19, 0.27, 0.36, 0.47, 0.58, 0.69, 0.82, 0.93, 1.04, 1.16, 1.26, 1.36, 1.44, 1.5, 1.55, 1.57, 1.57, 1.55, 1.51, 1.44, 1.34, 1.22, 1.08, 0.9, 0.71]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.55, 0.63, 0.72, 0.82, 0.93, 1.07, 1.21, 1.36, 1.54, 1.72, 1.91, 2.14, 2.36, 2.59, 2.86, 3.12, 3.42, 3.7, 4.0, 4.34, 4.67, 5.01, 5.4, 5.76, 6.14, 6.57, 6.97, 7.39, 7.87, 8.31]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.01, 0.01, -0.01, -0.04, -0.11, -0.19, -0.3, -0.46, -0.63, -0.84, -1.12, -1.42, -1.76, -2.19, -2.63, -3.19, -3.75, -4.37, -5.12, -5.87, -6.69, -7.68, -8.65, -9.71, -10.95, -12.18, -13.48, -15.03, -16.52]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.19, -0.29, -0.4, -0.53, -0.66, -0.83, -1.0, -1.18, -1.4, -1.62, -1.85, -2.12, -2.38, -2.65, -2.97, -3.28, -3.63, -3.97, -4.32, -4.72, -5.1, -5.5, -5.95, -6.38, -6.82, -7.33, -7.8, -8.29, -8.84, -9.36]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.05, 0.09, 0.14, 0.18, 0.23, 0.28, 0.32, 0.37, 0.42, 0.46, 0.51, 0.56, 0.6, 0.65, 0.7, 0.75, 0.79, 0.84, 0.89, 0.93, 0.98, 1.03, 1.07, 1.12, 1.17, 1.21, 1.26, 1.31, 1.35]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.08, 0.24, 0.41, 0.55, 0.68, 0.8, 0.88, 0.95, 0.99, 1.0, 0.98, 0.94, 0.87, 0.78, 0.65, 0.52, 0.36, 0.21, 0.04, -0.13, -0.29, -0.44, -0.59, -0.72, -0.82, -0.91, -0.96, -0.99, -1.0, -0.97]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.63, 0.92, 1.11, 1.28, 1.44, 1.57, 1.7, 1.82, 1.93, 2.03, 2.14, 2.23, 2.32, 2.41, 2.49, 2.58, 2.65, 2.73, 2.81, 2.88, 2.95, 3.02, 3.09, 3.15, 3.22, 3.28, 3.34, 3.41, 3.46]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.18, 0.25, 0.31, 0.36, 0.4, 0.44, 0.47, 0.51, 0.54, 0.56, 0.59, 0.62, 0.64, 0.67, 0.69, 0.72, 0.74, 0.76, 0.78, 0.8, 0.82, 0.84, 0.86, 0.88, 0.9, 0.91, 0.93, 0.95, 0.96]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.1, -0.11, -0.09, -0.07, -0.03, 0.03, 0.1, 0.18, 0.28, 0.39, 0.51, 0.65, 0.8, 0.96, 1.15, 1.34, 1.57, 1.78, 2.01, 2.28, 2.53, 2.8, 3.11, 3.41, 3.72, 4.08, 4.41, 4.76, 5.16, 5.54]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.35, 0.42, 0.49, 0.54, 0.59, 0.64, 0.68, 0.72, 0.76, 0.79, 0.82, 0.86, 0.89, 0.92, 0.95, 0.98, 1.01, 1.03, 1.06, 1.09, 1.11, 1.14, 1.16, 1.18, 1.21, 1.23, 1.25, 1.27, 1.3, 1.32]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.37, -0.26, -0.12, 0.04, 0.21, 0.42, 0.63, 0.87, 1.15, 1.42, 1.72, 2.07, 2.41, 2.77, 3.18, 3.58, 4.05, 4.49, 4.95, 5.48, 5.98, 6.51, 7.11, 7.67, 8.26, 8.93, 9.56, 10.2, 10.94, 11.63]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.53, -0.45, -0.36, -0.27, -0.18, -0.07, 0.03, 0.13, 0.24, 0.33, 0.41, 0.5, 0.57, 0.63, 0.69, 0.73, 0.77, 0.8, 0.82, 0.83, 0.84, 0.84, 0.84, 0.83, 0.81, 0.79, 0.76, 0.72, 0.67, 0.62]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.01, -0.03, -0.08, -0.17, -0.33, -0.54, -0.85, -1.31, -1.87, -2.58, -3.58, -4.71, -6.08, -7.91, -9.9, -12.49, -15.26, -18.46, -22.52, -26.77, -31.58, -37.59, -43.76, -50.65, -59.14, -67.73, -77.23, -88.79, -100.37]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.02, 0.36, 0.55, 0.69, 0.82, 0.97, 1.11, 1.24, 1.4, 1.54, 1.69, 1.86, 2.02, 2.19, 2.38, 2.56, 2.76, 2.96, 3.16, 3.38, 3.59, 3.81, 4.06, 4.3, 4.54, 4.81, 5.06, 5.33, 5.62, 5.9]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.03, -0.03, -0.02, 0.01, 0.06, 0.12, 0.21, 0.32, 0.44, 0.58, 0.75, 0.92, 1.12, 1.35, 1.58, 1.85, 2.12, 2.4, 2.73, 3.05, 3.39, 3.78, 4.16, 4.55, 5.0, 5.43, 5.88, 6.39, 6.88]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.36, 0.58, 0.79, 0.97, 1.14, 1.31, 1.45, 1.58, 1.72, 1.83, 1.94, 2.04, 2.12, 2.19, 2.25, 2.3, 2.34, 2.36, 2.37, 2.37, 2.36, 2.34, 2.31, 2.28, 2.23, 2.17, 2.12, 2.05, 1.98, 1.91]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.14, 0.1, 0.04, -0.01, -0.07, -0.13, -0.19, -0.23, -0.27, -0.28, -0.24, -0.06, -0.35, -0.57, -0.82, -1.06, -1.36, -1.66, -1.98, -2.37, -2.76, -3.17, -3.66, -4.14, -4.65, -5.25, -5.83, -6.44, -7.16, -7.85]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.88, 0.91, 0.95, 0.97, 1.0, 1.03, 1.05, 1.07, 1.09, 1.11, 1.13, 1.15, 1.16, 1.18, 1.2, 1.21, 1.23, 1.24, 1.25, 1.27, 1.28, 1.29, 1.3, 1.31, 1.32, 1.34, 1.35, 1.36, 1.37, 1.38]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.67, 0.72, 0.76, 0.8, 0.83, 0.86, 0.88, 0.9, 0.92, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 0.99, 0.99, 0.98, 0.97, 0.97, 0.96, 0.95]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.8, 0.86, 0.92, 0.98, 1.03, 1.08, 1.12, 1.17, 1.21, 1.25, 1.29, 1.33, 1.37, 1.41, 1.45, 1.48, 1.52, 1.55, 1.58, 1.62, 1.65, 1.68, 1.71, 1.74, 1.77, 1.8, 1.83, 1.85, 1.88, 1.91]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.22, 0.34, 0.46, 0.61, 0.74, 0.88, 1.05, 1.2, 1.37, 1.55, 1.73, 1.91, 2.11, 2.31, 2.53, 2.74, 2.95, 3.2, 3.42, 3.66, 3.92, 4.17, 4.42, 4.71, 4.98, 5.25, 5.56, 5.84]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.59, 0.65, 0.72, 0.77, 0.82, 0.87, 0.9, 0.93, 0.96, 0.98, 0.99, 1.0, 1.0, 0.99, 0.98, 0.96, 0.93, 0.89, 0.85, 0.8, 0.75, 0.7, 0.63, 0.57, 0.5, 0.42, 0.35, 0.27, 0.19, 0.11]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.0, -0.0, 0.01, 0.03, 0.06, 0.1, 0.14, 0.2, 0.26, 0.32, 0.4, 0.48, 0.56, 0.65, 0.73, 0.81, 0.88, 0.93, 0.98, 1.0, 1.0, 0.96, 0.9, 0.8, 0.66, 0.5, 0.31, 0.08, -0.15]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.53, 0.62, 0.7, 0.77, 0.83, 0.9, 0.95, 1.0, 1.06, 1.1, 1.15, 1.19, 1.23, 1.27, 1.32, 1.35, 1.39, 1.43, 1.46, 1.5, 1.53, 1.57, 1.6, 1.63, 1.66, 1.7, 1.72, 1.75, 1.78, 1.81]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.16, -0.03, -0.24, -0.42, -0.59, -0.75, -0.86, -0.94, -0.99, -1.0, -0.97, -0.89, -0.79, -0.66, -0.48, -0.3, -0.1, 0.1, 0.29, 0.48, 0.64, 0.78, 0.89, 0.96, 1.0, 0.99, 0.95, 0.87, 0.75, 0.6]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.93, 0.9, 0.86, 0.82, 0.77, 0.7, 0.61, 0.44, 0.52, 0.64, 0.72, 0.79, 0.83, 0.87, 0.91, 0.94, 0.97, 1.0, 1.02, 1.05, 1.07, 1.09, 1.11, 1.13, 1.15, 1.16, 1.18, 1.19, 1.21, 1.22]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.04, 0.18, 0.26, 0.32, 0.37, 0.41, 0.45, 0.48, 0.51, 0.54, 0.56, 0.59, 0.61, 0.63, 0.65, 0.67, 0.69, 0.71, 0.72, 0.74, 0.75, 0.76, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.85]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.22, 0.32, 0.43, 0.54, 0.64, 0.75, 0.86, 0.97, 1.07, 1.18, 1.29, 1.39, 1.51, 1.61, 1.72, 1.83, 1.93, 2.05, 2.15, 2.25, 2.37, 2.47, 2.58, 2.69, 2.79, 2.9, 3.01, 3.12]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.0, -0.01, -0.02, -0.03, -0.04, -0.04, -0.05, -0.05, -0.05, -0.04, -0.02, 0.0, 0.04, 0.08, 0.14, 0.21, 0.29, 0.38, 0.49, 0.61, 0.74, 0.91, 1.07, 1.24, 1.46, 1.66, 1.88, 2.14, 2.4]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.71, -0.63, -0.54, -0.46, -0.37, -0.26, -0.16, -0.06, 0.05, 0.15, 0.24, 0.35, 0.44, 0.53, 0.62, 0.69, 0.77, 0.83, 0.88, 0.93, 0.96, 0.98, 1.0, 1.0, 0.99, 0.97, 0.94, 0.91, 0.86, 0.8]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.6, 0.48, 0.33, 0.14, 0.11, 0.26, 0.34, 0.41, 0.46, 0.5, 0.54, 0.58, 0.61, 0.63, 0.66, 0.68, 0.7, 0.72, 0.74, 0.76, 0.77, 0.79, 0.8, 0.82, 0.83, 0.85, 0.86, 0.87, 0.88, 0.9]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.01, 0.03, 0.05, 0.08, 0.11, 0.13, 0.12, 0.08, 0.23, 0.38, 0.57, 0.77, 1.0, 1.28, 1.58, 1.94, 2.3, 2.7, 3.19, 3.67, 4.18, 4.8, 5.41, 6.05, 6.82, 7.55, 8.34, 9.26, 10.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.09, -0.19, -0.28, -0.36, -0.44, -0.51, -0.58, -0.64, -0.68, -0.72, -0.76, -0.79, -0.81, -0.83, -0.84, -0.84, -0.84, -0.84, -0.83, -0.81, -0.79, -0.76, -0.73, -0.69, -0.64, -0.59, -0.52, -0.45, -0.37]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.01, 0.04, 0.09, 0.16, 0.25, 0.34, 0.43, 0.54, 0.64, 0.73, 0.83, 0.89, 0.95, 0.99, 1.0, 0.99, 0.96, 0.92, 0.85, 0.77, 0.68, 0.58, 0.48, 0.38, 0.27, 0.19, 0.12, 0.06, 0.02]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.32, 0.46, 0.55, 0.63, 0.7, 0.76, 0.81, 0.86, 0.9, 0.93, 0.95, 0.97, 0.99, 1.0, 1.0, 1.0, 0.99, 0.98, 0.96, 0.94, 0.91, 0.87, 0.83, 0.78, 0.72, 0.66, 0.59, 0.49, 0.38]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.02, 0.04, 0.06, 0.08, 0.1, 0.14, 0.17, 0.21, 0.26, 0.31, 0.36, 0.42, 0.47, 0.53, 0.59, 0.64, 0.7, 0.74, 0.79, 0.83, 0.86, 0.88, 0.89, 0.88]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.29, -0.2, -0.09, 0.01, 0.11, 0.22, 0.32, 0.41, 0.51, 0.59, 0.67, 0.75, 0.81, 0.86, 0.91, 0.95, 0.98, 0.99, 1.0, 0.99, 0.98, 0.95, 0.92, 0.87, 0.82, 0.75, 0.68, 0.6, 0.51, 0.43]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.53, 0.72, 0.92, 1.1, 1.29, 1.49, 1.67, 1.86, 2.06, 2.24, 2.43, 2.63, 2.81, 3.0, 3.2, 3.38, 3.59, 3.77, 3.95, 4.16, 4.34, 4.52, 4.73, 4.91, 5.09, 5.3, 5.48, 5.66, 5.87, 6.05]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.0, -0.02, -0.05, -0.1, -0.19, -0.3, -0.45, -0.67, -0.93, -1.3, -1.71, -2.21, -2.89, -3.62, -4.48, -5.59, -6.77, -8.12, -9.83, -11.61, -13.61, -16.1, -18.65]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.0, -0.01, -0.03, -0.06, -0.1, -0.15, -0.21, -0.29, -0.39, -0.5, -0.64, -0.78, -0.94, -1.14, -1.34, -1.59, -1.83, -2.08, -2.38, -2.68, -2.98, -3.34, -3.67, -4.02, -4.41, -4.77, -5.14, -5.55, -5.93]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.47, -0.62, -0.79, -0.97, -1.15, -1.38, -1.59, -1.82, -2.09, -2.35, -2.62, -2.93, -3.23, -3.55, -3.91, -4.25, -4.64, -5.01, -5.39, -5.83, -6.24, -6.67, -7.15, -7.6, -8.07, -8.6, -9.1, -9.6, -10.18, -10.72]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.0, 0.02, 0.04, 0.09, 0.16, 0.24, 0.36, 0.51, 0.67, 0.87, 1.12, 1.38, 1.68, 2.05, 2.42, 2.87, 3.32, 3.81, 4.4, 4.98, 5.61, 6.35, 7.06, 7.83, 8.73, 9.59, 10.51, 11.58, 12.6]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.51, 0.5, 0.49, 0.49, 0.48, 0.47, 0.46, 0.45, 0.44, 0.43, 0.42, 0.41, 0.4, 0.39, 0.38, 0.37, 0.36, 0.35, 0.34, 0.33, 0.31, 0.3, 0.29, 0.27, 0.26, 0.24, 0.22, 0.2, 0.18, 0.16]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.03, -0.06, -0.09, -0.12, -0.15, -0.18, -0.2, -0.24, -0.26, -0.29, -0.32, -0.35, -0.37, -0.4, -0.43, -0.46, -0.48, -0.51, -0.53, -0.56, -0.58, -0.61, -0.63, -0.65, -0.68, -0.7, -0.72, -0.74, -0.76]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.31, 0.42, 0.53, 0.63, 0.73, 0.84, 0.94, 1.05, 1.16, 1.26, 1.36, 1.47, 1.57, 1.69, 1.79, 1.89, 2.0, 2.1, 2.2, 2.32, 2.42, 2.52, 2.63, 2.73, 2.83, 2.95, 3.05]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.6, 0.54, 0.47, 0.39, 0.28, 0.04, 0.26, 0.37, 0.46, 0.53, 0.6, 0.66, 0.71, 0.76, 0.81, 0.85, 0.89, 0.93, 0.97, 1.01, 1.04, 1.07, 1.11, 1.14, 1.17, 1.2, 1.23, 1.26, 1.29, 1.32]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.47, 0.56, 0.65, 0.71, 0.77, 0.82, 0.86, 0.9, 0.93, 0.96, 0.97, 0.99, 1.0, 1.0, 1.0, 0.99, 0.98, 0.96, 0.93, 0.9, 0.87, 0.83, 0.77, 0.72, 0.65, 0.57, 0.48, 0.36, 0.14, 0.28]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.31, 0.41, 0.52, 0.62, 0.72, 0.83, 0.93, 1.03, 1.14, 1.24, 1.34, 1.45, 1.55, 1.66, 1.76, 1.86, 1.97, 2.07, 2.17, 2.28, 2.38, 2.48, 2.59, 2.69, 2.79, 2.9, 3.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.25, 0.27, 0.3, 0.33, 0.35, 0.38, 0.4, 0.43, 0.45, 0.48, 0.5, 0.53, 0.56, 0.58, 0.61, 0.63, 0.66, 0.68, 0.71, 0.74, 0.76, 0.79, 0.81, 0.84, 0.86, 0.89, 0.92, 0.94, 0.97, 0.99]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.36, 0.41, 0.47, 0.52, 0.57, 0.62, 0.67, 0.72, 0.78, 0.83, 0.88, 0.93, 0.98, 1.03, 1.08, 1.13, 1.19, 1.24, 1.29, 1.34, 1.39, 1.44, 1.5, 1.55, 1.59, 1.65, 1.7, 1.75, 1.8, 1.85]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.52, 0.49, 0.45, 0.42, 0.38, 0.33, 0.27, 0.21, 0.09, 0.15, 0.23, 0.3, 0.35, 0.39, 0.43, 0.47, 0.5, 0.53, 0.56, 0.59, 0.62, 0.64, 0.67, 0.69, 0.71, 0.74, 0.76, 0.78, 0.8, 0.82]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.26, 0.45, 0.62, 0.8, 1.02, 1.22, 1.43, 1.68, 1.92, 2.16, 2.44, 2.7, 2.97, 3.27, 3.56, 3.89, 4.19, 4.5, 4.85, 5.17, 5.5, 5.87, 6.22, 6.57, 6.96, 7.33, 7.7, 8.11, 8.49]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.09, 0.2, 0.29, 0.38, 0.49, 0.58, 0.67, 0.78, 0.87, 0.96, 1.07, 1.16, 1.25, 1.36, 1.45, 1.55, 1.65, 1.74, 1.84, 1.94, 2.03, 2.13, 2.23, 2.32, 2.42, 2.52, 2.61, 2.71, 2.81]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.01, 0.07, 0.14, 0.2, 0.26, 0.32, 0.36, 0.41, 0.46, 0.5, 0.54, 0.58, 0.62, 0.65, 0.69, 0.73, 0.76, 0.79, 0.82, 0.86, 0.89, 0.91, 0.95, 0.97, 1.0, 1.03, 1.05, 1.08, 1.11, 1.13]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.0, 0.01, 0.03, 0.07, 0.15, 0.25, 0.4, 0.63, 0.91, 1.28, 1.8, 2.4, 3.14, 4.12, 5.21, 6.63, 8.16, 9.93, 12.2, 14.58, 17.29, 20.69, 24.19, 28.11, 32.96, 37.89, 43.35, 50.01, 56.7]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.01, -0.01, -0.02, -0.02, -0.03, -0.04, -0.04, -0.05, -0.05, -0.06, -0.06, -0.07, -0.08, -0.08, -0.09, -0.09, -0.1, -0.11, -0.11, -0.12, -0.12, -0.13, -0.14, -0.14, -0.15, -0.15, -0.16, -0.16, -0.17]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.08, 0.18, 0.26, 0.34, 0.42, 0.5, 0.57, 0.64, 0.71, 0.76, 0.82, 0.86, 0.9, 0.94, 0.97, 0.99, 1.0, 1.0, 1.0, 0.99, 0.97, 0.94, 0.91, 0.87, 0.82, 0.77, 0.71, 0.64, 0.58]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.0, -0.01, -0.03, -0.05, -0.07, -0.1, -0.14, -0.19, -0.23, -0.29, -0.35, -0.41, -0.48, -0.57, -0.65, -0.74, -0.83, -0.93, -1.04, -1.15, -1.27, -1.4, -1.52, -1.65, -1.8, -1.94, -2.09, -2.26, -2.42]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.6, 0.65, 0.71, 0.76, 0.81, 0.85, 0.89, 0.92, 0.95, 0.97, 0.99, 1.0, 1.0, 1.0, 0.99, 0.98, 0.96, 0.93, 0.9, 0.86, 0.82, 0.78, 0.73, 0.67, 0.62, 0.55, 0.49, 0.42, 0.35, 0.28]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.8, -0.7, -0.59, -0.49, -0.39, -0.28, -0.18, -0.08, 0.03, 0.13, 0.23, 0.34, 0.44, 0.54, 0.65, 0.75, 0.86, 0.96, 1.06, 1.17, 1.27, 1.37, 1.48, 1.58, 1.68, 1.79, 1.89, 1.99, 2.1, 2.2]<EOS_Y><SOS_EQ>', '<SOS_Y>[-1.01, -0.97, -0.9, -0.82, -0.72, -0.59, -0.46, -0.3, -0.1, 0.09, 0.31, 0.57, 0.82, 1.1, 1.42, 1.73, 2.1, 2.45, 2.82, 3.25, 3.67, 4.1, 4.59, 5.06, 5.55, 6.11, 6.64, 7.18, 7.81, 8.39]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.01, 0.04, 0.1, 0.17, 0.27, 0.38, 0.52, 0.69, 0.86, 1.06, 1.3, 1.54, 1.8, 2.1, 2.4, 2.76, 3.1, 3.46, 3.88, 4.28, 4.71, 5.2, 5.66, 6.15, 6.71, 7.24, 7.78, 8.41, 9.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.25, 0.25, 0.25, 0.24, 0.24, 0.23, 0.23, 0.22, 0.22, 0.21, 0.21, 0.2, 0.19, 0.19, 0.18, 0.18, 0.17, 0.16, 0.16, 0.15, 0.14, 0.13, 0.12, 0.11, 0.1, 0.09, 0.07, 0.06, 0.03, 0.04]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.75, -0.4, -0.21, -0.07, 0.06, 0.19, 0.31, 0.42, 0.54, 0.65, 0.75, 0.87, 0.97, 1.07, 1.18, 1.28, 1.38, 1.48, 1.57, 1.67, 1.76, 1.85, 1.94, 2.03, 2.11, 2.2, 2.27, 2.34, 2.42, 2.49]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.0, 0.02, 0.05, 0.08, 0.13, 0.18, 0.25, 0.32, 0.4, 0.49, 0.58, 0.67, 0.76, 0.85, 0.91, 0.97, 1.0, 1.0, 0.96, 0.89, 0.77, 0.61, 0.41, 0.19, -0.07, -0.32, -0.55, -0.78, -0.92]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.0, -0.01, -0.01, -0.01, -0.02, -0.02, -0.02, -0.03, -0.03, -0.03, -0.04, -0.04, -0.04, -0.05, -0.05, -0.05, -0.06, -0.06, -0.06, -0.07, -0.07, -0.07, -0.08, -0.08, -0.08, -0.09, -0.09, -0.09, -0.1]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.03, 0.06, 0.09, 0.12, 0.15, 0.18, 0.21, 0.24, 0.26, 0.29, 0.32, 0.34, 0.37, 0.4, 0.42, 0.45, 0.47, 0.49, 0.51, 0.53, 0.55, 0.58, 0.59, 0.61, 0.63, 0.65, 0.66, 0.68, 0.69]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.18, 0.37, 0.57, 0.72, 0.84, 0.94, 0.99, 1.0, 0.96, 0.89, 0.78, 0.63, 0.46, 0.28, 0.06, -0.14, -0.35, -0.53, -0.69, -0.83, -0.92, -0.98, -1.0, -0.97, -0.91, -0.8, -0.66, -0.5, -0.3, -0.1]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.97, 0.95, 0.93, 0.91, 0.89, 0.87, 0.85, 0.83, 0.8, 0.78, 0.76, 0.73, 0.71, 0.68, 0.66, 0.63, 0.6, 0.57, 0.54, 0.5, 0.46, 0.42, 0.37, 0.33, 0.27, 0.18, 0.05, 0.19, 0.28, 0.33]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.29, 0.32, 0.36, 0.39, 0.41, 0.44, 0.46, 0.48, 0.5, 0.52, 0.54, 0.56, 0.57, 0.59, 0.6, 0.62, 0.63, 0.64, 0.66, 0.67, 0.68, 0.69, 0.7, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.01, -0.01, -0.01, -0.0, 0.01, 0.02, 0.03, 0.05, 0.05, 0.06, 0.06, 0.06, 0.04, 0.02, -0.01, -0.05, -0.11, -0.17, -0.26, -0.36, -0.48, -0.62, -0.78, -0.95, -1.16, -1.38, -1.63, -1.92, -2.22]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.66, 0.58, 0.48, 0.36, 0.16, 0.29, 0.43, 0.53, 0.63, 0.7, 0.77, 0.84, 0.9, 0.95, 1.01, 1.06, 1.11, 1.15, 1.19, 1.24, 1.28, 1.32, 1.36, 1.39, 1.43, 1.47, 1.5, 1.53, 1.57, 1.6]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.89, 0.77, 0.61, 0.41, 0.17, 0.5, 0.67, 0.8, 0.93, 1.03, 1.13, 1.22, 1.3, 1.37, 1.45, 1.52, 1.59, 1.65, 1.71, 1.77, 1.83, 1.88, 1.94, 1.99, 2.04, 2.09, 2.14, 2.19, 2.24, 2.28]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.0, 0.01, 0.01, 0.02, 0.03, 0.05, 0.06, 0.08, 0.11, 0.13, 0.16, 0.19, 0.22, 0.25, 0.29, 0.33, 0.37, 0.41, 0.46, 0.5, 0.54, 0.59, 0.64, 0.68, 0.73, 0.77, 0.81, 0.86, 0.89]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.79, 0.84, 0.89, 0.94, 0.98, 1.02, 1.06, 1.1, 1.14, 1.17, 1.21, 1.24, 1.27, 1.3, 1.34, 1.37, 1.4, 1.43, 1.46, 1.48, 1.51, 1.54, 1.57, 1.59, 1.62, 1.64, 1.67, 1.69, 1.72, 1.74]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.25, 0.39, 0.51, 0.62, 0.74, 0.85, 0.95, 1.06, 1.17, 1.27, 1.38, 1.48, 1.58, 1.7, 1.8, 1.91, 2.01, 2.11, 2.22, 2.32, 2.42, 2.53, 2.63, 2.73, 2.84, 2.94, 3.04, 3.15, 3.26]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.72, 0.69, 0.64, 0.6, 0.55, 0.48, 0.41, 0.31, 0.14, 0.24, 0.36, 0.45, 0.52, 0.57, 0.62, 0.66, 0.71, 0.74, 0.77, 0.8, 0.82, 0.84, 0.86, 0.88, 0.9, 0.91, 0.93, 0.94, 0.95, 0.96]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.14, 0.34, 0.46, 0.54, 0.61, 0.67, 0.72, 0.76, 0.8, 0.83, 0.85, 0.88, 0.9, 0.92, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 0.99, 0.99]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.0, 0.0, 0.0, 0.0, -0.01, -0.04, -0.1, -0.19, -0.32, -0.5, -0.78, -1.11, -1.54, -2.15, -2.84, -3.77, -4.79, -6.01, -7.61, -9.32, -11.29, -13.81, -16.43, -19.42, -23.15, -26.99, -31.28, -36.57, -41.93]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.64, 0.65, 0.65, 0.62, 0.44, 0.83, 1.04, 1.22, 1.39, 1.52, 1.65, 1.76, 1.86, 1.94, 2.01, 2.07, 2.11, 2.14, 2.16, 2.17, 2.17, 2.15, 2.13, 2.09, 2.05, 2.0, 1.95, 1.89, 1.82, 1.75]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.06, -0.1, -0.13, -0.13, -0.11, -0.07, -0.01, 0.08, 0.18, 0.3, 0.45, 0.6, 0.77, 0.96, 1.13, 1.33, 1.51, 1.68, 1.86, 2.01, 2.15, 2.28, 2.37, 2.44, 2.48, 2.49, 2.46, 2.4, 2.3]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.2, -0.1, 0.02, 0.13, 0.25, 0.38, 0.51, 0.64, 0.8, 0.94, 1.09, 1.26, 1.42, 1.58, 1.77, 1.95, 2.15, 2.34, 2.53, 2.75, 2.95, 3.16, 3.4, 3.62, 3.84, 4.09, 4.33, 4.57, 4.84, 5.09]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.0, 0.0, 0.01, 0.02, 0.05, 0.09, 0.15, 0.26, 0.39, 0.57, 0.82, 1.13, 1.5, 2.02, 2.59, 3.34, 4.17, 5.13, 6.37, 7.69, 9.19, 11.09, 13.06, 15.27, 18.02, 20.83, 23.95, 27.78, 31.64]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.92, 0.96, 1.0, 1.04, 1.07, 1.1, 1.13, 1.16, 1.18, 1.21, 1.23, 1.25, 1.27, 1.28, 1.3, 1.31, 1.33, 1.34, 1.35, 1.36, 1.37, 1.37, 1.38, 1.38, 1.39, 1.39, 1.39, 1.39, 1.39, 1.39]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.21, -0.25, -0.25, -0.23, -0.17, -0.11, -0.04, 0.06, 0.16, 0.27, 0.4, 0.53, 0.67, 0.83, 0.98, 1.16, 1.32, 1.5, 1.7, 1.88, 2.07, 2.29, 2.5, 2.71, 2.94, 3.16, 3.39, 3.64, 3.88]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.23, 0.33, 0.41, 0.47, 0.53, 0.57, 0.62, 0.66, 0.7, 0.74, 0.78, 0.81, 0.84, 0.88, 0.91, 0.94, 0.97, 0.99, 1.02, 1.05, 1.07, 1.1, 1.12, 1.15, 1.17, 1.2, 1.22, 1.24, 1.26]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.56, 0.68, 0.75, 0.8, 0.85, 0.89, 0.92, 0.95, 0.98, 1.01, 1.03, 1.06, 1.08, 1.1, 1.12, 1.14, 1.15, 1.17, 1.18, 1.2, 1.21, 1.23, 1.24, 1.25, 1.27, 1.28, 1.29, 1.3, 1.32]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.05, 0.06, 0.06, 0.03, 0.06, 0.1, 0.13, 0.17, 0.2, 0.23, 0.26, 0.29, 0.32, 0.35, 0.38, 0.41, 0.44, 0.47, 0.5, 0.53, 0.56, 0.59, 0.62, 0.65, 0.68, 0.71, 0.74, 0.77, 0.8]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.98, -0.75, -0.5, -0.27, -0.04, 0.21, 0.44, 0.67, 0.92, 1.15, 1.37, 1.63, 1.85, 2.08, 2.33, 2.56, 2.81, 3.04, 3.27, 3.52, 3.75, 3.98, 4.23, 4.46, 4.68, 4.94, 5.16, 5.39, 5.64, 5.87]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.2, 0.42, 0.62, 0.82, 1.04, 1.24, 1.44, 1.66, 1.86, 2.06, 2.28, 2.48, 2.68, 2.9, 3.1, 3.32, 3.52, 3.72, 3.94, 4.14, 4.34, 4.56, 4.76, 4.96, 5.18, 5.38, 5.58, 5.8, 6.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.2, 0.42, 0.62, 0.82, 1.04, 1.24, 1.44, 1.66, 1.86, 2.06, 2.28, 2.48, 2.68, 2.9, 3.1, 3.32, 3.52, 3.72, 3.94, 4.14, 4.34, 4.56, 4.76, 4.96, 5.18, 5.38, 5.58, 5.8, 6.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.0, 0.01, 0.02, 0.05, 0.1, 0.18, 0.28, 0.42, 0.6, 0.81, 1.1, 1.41, 1.78, 2.26, 2.76, 3.39, 4.04, 4.77, 5.67, 6.58, 7.58, 8.79, 10.0, 11.31, 12.89, 14.44, 16.11, 18.09, 20.02]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.3, 0.39, 0.48, 0.55, 0.61, 0.67, 0.72, 0.76, 0.79, 0.81, 0.83, 0.84, 0.84, 0.84, 0.83, 0.82, 0.8, 0.77, 0.74, 0.69, 0.64, 0.58, 0.5, 0.42, 0.34, 0.24, 0.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.94, 1.03, 1.1, 1.13, 1.12, 1.06, 0.92, 0.66, 0.46, 1.0, 1.41, 1.83, 2.21, 2.58, 2.99, 3.37, 3.8, 4.19, 4.59, 5.04, 5.46, 5.88, 6.36, 6.8, 7.25, 7.75, 8.22, 8.69, 9.22, 9.71]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.04, 0.22, 0.42, 0.59, 0.76, 0.94, 1.1, 1.25, 1.42, 1.56, 1.7, 1.84, 1.97, 2.09, 2.22, 2.33, 2.45, 2.55, 2.65, 2.74, 2.83, 2.91, 2.99, 3.06, 3.12, 3.19, 3.24, 3.29, 3.34, 3.37]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.32, 0.46, 0.56, 0.64, 0.72, 0.79, 0.85, 0.91, 0.96, 1.01, 1.07, 1.11, 1.16, 1.2, 1.24, 1.29, 1.33, 1.36, 1.4, 1.44, 1.47, 1.51, 1.54, 1.57, 1.61, 1.64, 1.67, 1.7, 1.73]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.02, -0.04, -0.06, -0.08, -0.11, -0.13, -0.16, -0.18, -0.21, -0.23, -0.25, -0.28, -0.3, -0.32, -0.34, -0.35, -0.37, -0.38, -0.38, -0.39, -0.39, -0.39, -0.38, -0.37, -0.36, -0.34, -0.32, -0.3, -0.27]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.76, 0.87, 1.01, 1.17, 1.34, 1.55, 1.76, 2.0, 2.28, 2.55, 2.85, 3.2, 3.54, 3.89, 4.31, 4.71, 5.17, 5.62, 6.08, 6.61, 7.11, 7.64, 8.24, 8.8, 9.39, 10.06, 10.69, 11.33, 12.07, 12.76]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.58, -0.49, -0.39, -0.3, -0.21, -0.12, -0.03, 0.05, 0.14, 0.22, 0.3, 0.38, 0.45, 0.53, 0.61, 0.67, 0.75, 0.82, 0.88, 0.95, 1.01, 1.07, 1.13, 1.19, 1.24, 1.3, 1.35, 1.4, 1.46, 1.5]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.63, -0.62, -0.58, -0.52, -0.45, -0.36, -0.27, -0.17, -0.06, 0.04, 0.13, 0.21, 0.28, 0.33, 0.36, 0.37, 0.35, 0.32, 0.27, 0.19, 0.11, 0.02, -0.09, -0.19, -0.28, -0.38, -0.47, -0.53, -0.59, -0.62]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.02, -0.06, -0.12, -0.19, -0.28, -0.39, -0.51, -0.66, -0.82, -0.99, -1.2, -1.4, -1.63, -1.89, -2.15, -2.45, -2.74, -3.05, -3.4, -3.74, -4.1, -4.51, -4.9, -5.31, -5.78, -6.22, -6.68, -7.2, -7.7]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.41, 0.41, 0.41, 0.42, 0.42, 0.42, 0.43, 0.43, 0.44, 0.44, 0.44, 0.45, 0.45, 0.46, 0.46, 0.46, 0.47, 0.47, 0.47, 0.48, 0.48, 0.49, 0.49, 0.49, 0.5, 0.5, 0.51, 0.51, 0.51, 0.52]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.1, -0.06, -0.01, 0.03, 0.08, 0.12, 0.17, 0.21, 0.26, 0.3, 0.34, 0.38, 0.42, 0.46, 0.5, 0.54, 0.58, 0.61, 0.65, 0.68, 0.71, 0.74, 0.77, 0.8, 0.82, 0.85, 0.87, 0.89, 0.91, 0.93]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.67, 0.69, 0.72, 0.74, 0.76, 0.78, 0.8, 0.82, 0.84, 0.86, 0.87, 0.89, 0.91, 0.93, 0.94, 0.96, 0.98, 0.99, 1.01, 1.02, 1.04, 1.05, 1.07, 1.08, 1.1, 1.11, 1.13, 1.14, 1.15, 1.17]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.07, 0.11, 0.16, 0.21, 0.26, 0.32, 0.37, 0.44, 0.5, 0.56, 0.63, 0.7, 0.77, 0.85, 0.93, 1.01, 1.09, 1.17, 1.26, 1.34, 1.43, 1.53, 1.62, 1.71, 1.81, 1.91, 2.0, 2.11, 2.21]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.31, 0.4, 0.5, 0.58, 0.66, 0.74, 0.8, 0.86, 0.91, 0.95, 0.97, 0.99, 1.0, 1.0, 0.98, 0.96, 0.92, 0.88, 0.83, 0.76, 0.69, 0.61, 0.52, 0.44, 0.34, 0.24, 0.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.05, -0.14, -0.24, -0.36, -0.51, -0.66, -0.81, -0.99, -1.14, -1.3, -1.46, -1.6, -1.72, -1.84, -1.92, -1.98, -2.01, -2.01, -1.96, -1.88, -1.76, -1.57, -1.35, -1.08, -0.71, -0.31, 0.14, 0.72, 1.33]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.17, 0.39, 0.61, 0.86, 1.16, 1.46, 1.78, 2.16, 2.53, 2.92, 3.39, 3.83, 4.3, 4.84, 5.36, 5.96, 6.53, 7.12, 7.8, 8.45, 9.11, 9.88, 10.59, 11.33, 12.18, 12.97, 13.78, 14.71, 15.57]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.06, -0.13, -0.19, -0.25, -0.32, -0.38, -0.44, -0.51, -0.57, -0.63, -0.7, -0.76, -0.82, -0.89, -0.95, -1.02, -1.08, -1.14, -1.21, -1.27, -1.33, -1.4, -1.46, -1.52, -1.59, -1.65, -1.72, -1.78, -1.84]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.31, 0.44, 0.53, 0.61, 0.68, 0.74, 0.8, 0.85, 0.9, 0.94, 0.99, 1.02, 1.06, 1.1, 1.13, 1.17, 1.2, 1.23, 1.26, 1.29, 1.32, 1.34, 1.37, 1.4, 1.42, 1.45, 1.47, 1.49, 1.51]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.92, -0.72, -0.5, -0.3, -0.1, 0.12, 0.32, 0.52, 0.74, 0.94, 1.14, 1.36, 1.56, 1.76, 1.98, 2.18, 2.4, 2.6, 2.8, 3.02, 3.22, 3.42, 3.64, 3.84, 4.04, 4.26, 4.46, 4.66, 4.88, 5.08]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.22, 0.51, 0.82, 1.11, 1.4, 1.71, 2.0, 2.28, 2.6, 2.89, 3.17, 3.49, 3.77, 4.06, 4.38, 4.66, 4.98, 5.27, 5.55, 5.87, 6.15, 6.44, 6.76, 7.04, 7.33, 7.64, 7.93, 8.22, 8.53, 8.82]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.03, 0.1, 0.17, 0.26, 0.37, 0.49, 0.61, 0.76, 0.9, 1.05, 1.22, 1.38, 1.55, 1.75, 1.93, 2.14, 2.33, 2.54, 2.77, 2.98, 3.2, 3.44, 3.67, 3.91, 4.17, 4.41, 4.66, 4.94, 5.2]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.0, -0.03, -0.07, -0.13, -0.22, -0.32, -0.43, -0.56, -0.69, -0.81, -0.92, -0.98, -1.0, -0.94, -0.81, -0.57, -0.29, 0.05, 0.43, 0.74, 0.94, 0.99, 0.84, 0.52, 0.01, -0.47, -0.85, -1.0, -0.83]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.51, -0.41, -0.29, -0.16, -0.01, 0.16, 0.33, 0.51, 0.72, 0.92, 1.13, 1.37, 1.59, 1.82, 2.07, 2.3, 2.57, 2.81, 3.05, 3.32, 3.56, 3.81, 4.09, 4.34, 4.59, 4.87, 5.13, 5.39, 5.69, 5.96]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.08, 0.16, 0.23, 0.31, 0.38, 0.45, 0.52, 0.59, 0.65, 0.7, 0.76, 0.81, 0.85, 0.89, 0.92, 0.95, 0.97, 0.99, 1.0, 1.0, 1.0, 0.99, 0.97, 0.95, 0.92, 0.89, 0.85, 0.81, 0.76]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.18, 0.27, 0.32, 0.37, 0.42, 0.45, 0.49, 0.52, 0.55, 0.58, 0.61, 0.64, 0.66, 0.68, 0.71, 0.73, 0.75, 0.77, 0.79, 0.81, 0.83, 0.84, 0.86, 0.88, 0.89, 0.91, 0.92, 0.94, 0.95]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.52, -0.53, -0.51, -0.48, -0.42, -0.34, -0.26, -0.17, -0.06, 0.04, 0.14, 0.24, 0.31, 0.38, 0.43, 0.46, 0.47, 0.46, 0.42, 0.37, 0.3, 0.22, 0.12, 0.02, -0.08, -0.19, -0.28, -0.36, -0.43, -0.48]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.33, 0.13, 0.29, 0.41, 0.51, 0.6, 0.67, 0.74, 0.8, 0.85, 0.91, 0.96, 1.01, 1.05, 1.1, 1.14, 1.18, 1.22, 1.25, 1.29, 1.33, 1.36, 1.4, 1.43, 1.46, 1.49, 1.52, 1.55, 1.58, 1.61]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.03, 0.1, 0.17, 0.26, 0.37, 0.49, 0.61, 0.76, 0.9, 1.05, 1.22, 1.38, 1.55, 1.75, 1.93, 2.14, 2.33, 2.54, 2.77, 2.98, 3.2, 3.44, 3.67, 3.91, 4.17, 4.41, 4.66, 4.94, 5.2]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.75, 0.73, 0.72, 0.7, 0.69, 0.67, 0.65, 0.64, 0.62, 0.6, 0.58, 0.56, 0.53, 0.51, 0.49, 0.46, 0.43, 0.4, 0.37, 0.33, 0.3, 0.25, 0.19, 0.11, 0.11, 0.2, 0.25, 0.3, 0.34, 0.37]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.84, 0.74, 0.6, 0.45, 0.22, 0.36, 0.54, 0.67, 0.79, 0.88, 0.97, 1.06, 1.13, 1.2, 1.27, 1.33, 1.39, 1.45, 1.5, 1.56, 1.61, 1.66, 1.71, 1.76, 1.8, 1.85, 1.89, 1.93, 1.98, 2.02]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.31, 0.41, 0.52, 0.62, 0.72, 0.83, 0.93, 1.03, 1.14, 1.24, 1.34, 1.45, 1.55, 1.66, 1.76, 1.86, 1.97, 2.07, 2.17, 2.28, 2.38, 2.48, 2.59, 2.69, 2.79, 2.9, 3.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.02, -0.05, -0.07, -0.09, -0.12, -0.14, -0.16, -0.19, -0.21, -0.23, -0.25, -0.27, -0.3, -0.32, -0.34, -0.36, -0.39, -0.41, -0.43, -0.45, -0.47, -0.49, -0.51, -0.53, -0.55, -0.57, -0.59, -0.61, -0.62]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.06, 0.11, 0.14, 0.16, 0.16, 0.15, 0.12, 0.07, 0.01, -0.07, -0.17, -0.27, -0.39, -0.54, -0.68, -0.86, -1.03, -1.21, -1.41, -1.61, -1.81, -2.03, -2.24, -2.45, -2.68, -2.89, -3.1, -3.32, -3.52]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.13, 0.19, 0.23, 0.27, 0.3, 0.32, 0.35, 0.37, 0.39, 0.41, 0.43, 0.45, 0.47, 0.48, 0.5, 0.51, 0.53, 0.54, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61, 0.63, 0.64, 0.64, 0.66, 0.66]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.16, 0.26, 0.36, 0.44, 0.52, 0.59, 0.65, 0.7, 0.74, 0.78, 0.8, 0.82, 0.83, 0.84, 0.84, 0.84, 0.82, 0.81, 0.78, 0.75, 0.71, 0.66, 0.6, 0.53, 0.46, 0.37, 0.28, 0.19, 0.08, -0.02]<EOS_Y><SOS_EQ>', '<SOS_Y>[-1.23, -1.06, -0.87, -0.7, -0.52, -0.33, -0.16, 0.01, 0.2, 0.38, 0.55, 0.74, 0.91, 1.09, 1.28, 1.45, 1.64, 1.81, 1.98, 2.17, 2.35, 2.52, 2.71, 2.88, 3.06, 3.25, 3.42, 3.59, 3.78, 3.96]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.0, 0.01, 0.02, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.11, 0.12, 0.14, 0.15, 0.17, 0.19, 0.21, 0.23, 0.25, 0.27, 0.29, 0.31, 0.33, 0.36, 0.38, 0.41, 0.43, 0.46]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.53, 0.64, 0.7, 0.75, 0.8, 0.84, 0.87, 0.9, 0.92, 0.95, 0.97, 0.99, 1.01, 1.03, 1.05, 1.07, 1.08, 1.1, 1.12, 1.13, 1.14, 1.16, 1.17, 1.18, 1.19, 1.21, 1.22, 1.23, 1.24]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.32, 0.46, 0.55, 0.63, 0.7, 0.76, 0.81, 0.86, 0.9, 0.93, 0.95, 0.97, 0.99, 1.0, 1.0, 1.0, 0.99, 0.98, 0.96, 0.94, 0.91, 0.87, 0.83, 0.78, 0.72, 0.66, 0.59, 0.49, 0.38]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.46, 0.65, 0.51, 0.87, 1.08, 1.28, 1.43, 1.56, 1.7, 1.81, 1.92, 2.03, 2.13, 2.22, 2.32, 2.4, 2.49, 2.57, 2.65, 2.73, 2.8, 2.87, 2.95, 3.02, 3.08, 3.15, 3.21, 3.28, 3.34, 3.4]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.43, 0.62, 0.76, 0.87, 0.98, 1.07, 1.15, 1.24, 1.31, 1.38, 1.45, 1.51, 1.57, 1.63, 1.69, 1.75, 1.8, 1.85, 1.9, 1.95, 2.0, 2.05, 2.09, 2.14, 2.18, 2.22, 2.27, 2.31, 2.35]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.01, -0.01, -0.01, -0.0, 0.01, 0.02, 0.05, 0.08, 0.12, 0.17, 0.24, 0.31, 0.4, 0.51, 0.62, 0.76, 0.91, 1.08, 1.28, 1.48, 1.71, 1.98, 2.24, 2.53, 2.88, 3.22, 3.59, 4.02, 4.44]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.32, 0.46, 0.55, 0.63, 0.7, 0.76, 0.81, 0.86, 0.9, 0.93, 0.95, 0.97, 0.99, 1.0, 1.0, 1.0, 0.99, 0.98, 0.96, 0.94, 0.91, 0.87, 0.83, 0.78, 0.72, 0.66, 0.59, 0.49, 0.38]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.07, 0.01, 0.1, 0.2, 0.31, 0.45, 0.6, 0.77, 0.97, 1.17, 1.39, 1.65, 1.91, 2.19, 2.51, 2.83, 3.2, 3.56, 3.93, 4.37, 4.78, 5.22, 5.72, 6.2, 6.69, 7.26, 7.8, 8.35, 8.99, 9.58]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.84, 0.83, 0.83, 0.83, 0.82, 0.82, 0.82, 0.81, 0.81, 0.8, 0.8, 0.8, 0.79, 0.79, 0.78, 0.78, 0.77, 0.77, 0.77, 0.76, 0.76, 0.75, 0.75, 0.75, 0.74, 0.74, 0.73, 0.73, 0.72, 0.72]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.69, -0.61, -0.52, -0.44, -0.34, -0.24, -0.14, -0.04, 0.07, 0.17, 0.27, 0.37, 0.46, 0.55, 0.64, 0.71, 0.78, 0.84, 0.89, 0.94, 0.97, 0.99, 1.0, 1.0, 0.99, 0.97, 0.94, 0.9, 0.84, 0.79]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.3, 0.44, 0.53, 0.61, 0.69, 0.75, 0.81, 0.87, 0.92, 0.97, 1.02, 1.07, 1.11, 1.15, 1.19, 1.23, 1.27, 1.3, 1.34, 1.38, 1.41, 1.44, 1.48, 1.51, 1.54, 1.57, 1.6, 1.63, 1.66]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.8, -0.67, -0.53, -0.39, -0.26, -0.12, 0.01, 0.14, 0.28, 0.42, 0.55, 0.69, 0.82, 0.95, 1.09, 1.23, 1.37, 1.5, 1.63, 1.77, 1.9, 2.04, 2.18, 2.31, 2.44, 2.58, 2.71, 2.85, 2.99, 3.12]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.01, -0.04, -0.09, -0.16, -0.25, -0.35, -0.46, -0.6, -0.72, -0.83, -0.93, -0.99, -1.0, -0.93, -0.79, -0.55, -0.27, 0.07, 0.44, 0.74, 0.94, 0.99, 0.86, 0.55, 0.06, -0.41, -0.8, -1.0, -0.88]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.3, 0.46, 0.59, 0.71, 0.83, 0.94, 1.05, 1.17, 1.27, 1.38, 1.49, 1.6, 1.7, 1.81, 1.91, 2.03, 2.13, 2.23, 2.34, 2.44, 2.54, 2.66, 2.76, 2.86, 2.97, 3.07, 3.17, 3.28, 3.38]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.07, 0.15, 0.22, 0.3, 0.38, 0.45, 0.52, 0.6, 0.67, 0.74, 0.82, 0.88, 0.95, 1.03, 1.1, 1.17, 1.24, 1.3, 1.37, 1.44, 1.5, 1.57, 1.63, 1.69, 1.76, 1.82, 1.88, 1.94, 2.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.04, 0.08, 0.12, 0.15, 0.19, 0.23, 0.27, 0.31, 0.34, 0.38, 0.41, 0.45, 0.48, 0.52, 0.55, 0.58, 0.61, 0.64, 0.67, 0.7, 0.72, 0.75, 0.78, 0.8, 0.82, 0.84, 0.86, 0.88, 0.9]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.22, 0.39, 0.51, 0.6, 0.68, 0.75, 0.82, 0.88, 0.94, 0.99, 1.04, 1.09, 1.14, 1.18, 1.22, 1.26, 1.31, 1.34, 1.38, 1.42, 1.46, 1.49, 1.53, 1.56, 1.59, 1.62, 1.65, 1.68, 1.72, 1.75]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.32, 0.46, 0.55, 0.63, 0.7, 0.76, 0.81, 0.86, 0.9, 0.93, 0.95, 0.97, 0.99, 1.0, 1.0, 1.0, 0.99, 0.98, 0.96, 0.94, 0.91, 0.87, 0.83, 0.78, 0.72, 0.66, 0.59, 0.49, 0.38]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.89, 0.95, 1.0, 1.05, 1.1, 1.15, 1.19, 1.23, 1.28, 1.31, 1.35, 1.39, 1.43, 1.46, 1.5, 1.53, 1.57, 1.6, 1.63, 1.66, 1.69, 1.72, 1.75, 1.78, 1.81, 1.84, 1.87, 1.89, 1.92, 1.95]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.51, 0.87, 1.16, 1.45, 1.74, 2.01, 2.27, 2.55, 2.8, 3.05, 3.32, 3.57, 3.81, 4.08, 4.32, 4.58, 4.82, 5.05, 5.31, 5.55, 5.78, 6.04, 6.27, 6.5, 6.75, 6.98, 7.21, 7.46, 7.69]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.8, -0.58, -0.33, -0.1, 0.12, 0.37, 0.6, 0.83, 1.08, 1.31, 1.53, 1.78, 2.01, 2.24, 2.49, 2.72, 2.97, 3.2, 3.42, 3.67, 3.9, 4.13, 4.38, 4.6, 4.83, 5.07, 5.3, 5.52, 5.76, 5.98]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.03, 0.06, 0.09, 0.12, 0.15, 0.18, 0.21, 0.24, 0.27, 0.3, 0.33, 0.36, 0.39, 0.42, 0.45, 0.48, 0.51, 0.54, 0.57, 0.6, 0.63, 0.66, 0.69, 0.72, 0.75, 0.78, 0.8, 0.84, 0.86]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.12, -0.24, -0.35, -0.45, -0.56, -0.65, -0.73, -0.82, -0.88, -0.94, -0.99, -1.02, -1.04, -1.05, -1.06, -1.04, -1.02, -0.99, -0.95, -0.89, -0.84, -0.76, -0.69, -0.61, -0.51, -0.43, -0.33, -0.23, -0.13]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.08, 0.15, 0.22, 0.3, 0.39, 0.48, 0.58, 0.69, 0.8, 0.91, 1.04, 1.16, 1.29, 1.43, 1.56, 1.72, 1.86, 2.01, 2.17, 2.32, 2.48, 2.66, 2.82, 2.99, 3.18, 3.35, 3.53, 3.73, 3.91]<EOS_Y><SOS_EQ>', '<SOS_Y>[1.3, 1.36, 1.43, 1.48, 1.54, 1.59, 1.63, 1.67, 1.71, 1.75, 1.77, 1.8, 1.82, 1.83, 1.84, 1.84, 1.84, 1.84, 1.82, 1.81, 1.79, 1.76, 1.73, 1.7, 1.67, 1.62, 1.58, 1.53, 1.48, 1.43]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.03, -0.06, -0.08, -0.08, -0.04, -0.14, -0.23, -0.35, -0.46, -0.59, -0.75, -0.91, -1.08, -1.29, -1.5, -1.74, -1.98, -2.24, -2.54, -2.83, -3.14, -3.5, -3.85, -4.22, -4.65, -5.06, -5.48, -5.98, -6.45]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.31, 0.44, 0.53, 0.6, 0.66, 0.71, 0.75, 0.79, 0.82, 0.85, 0.88, 0.9, 0.92, 0.93, 0.95, 0.96, 0.97, 0.98, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 0.99]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.02, 0.07, 0.13, 0.22, 0.33, 0.44, 0.57, 0.71, 0.83, 0.93, 0.99, 0.99, 0.93, 0.76, 0.52, 0.18, -0.17, -0.52, -0.83, -0.98, -0.97, -0.72, -0.33, 0.17, 0.67, 0.96, 0.96, 0.62, 0.06]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.63, 0.92, 1.11, 1.28, 1.44, 1.57, 1.7, 1.82, 1.93, 2.03, 2.14, 2.23, 2.32, 2.41, 2.49, 2.58, 2.65, 2.73, 2.81, 2.88, 2.95, 3.02, 3.09, 3.15, 3.22, 3.28, 3.34, 3.41, 3.46]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.04, 0.08, 0.12, 0.17, 0.23, 0.29, 0.35, 0.42, 0.49, 0.56, 0.64, 0.72, 0.8, 0.89, 0.98, 1.08, 1.17, 1.26, 1.37, 1.47, 1.57, 1.69, 1.79, 1.9, 2.02, 2.14, 2.25, 2.38, 2.5]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.24, 0.11, -0.03, -0.15, -0.27, -0.41, -0.53, -0.64, -0.77, -0.89, -1.0, -1.12, -1.23, -1.34, -1.46, -1.57, -1.68, -1.78, -1.88, -1.99, -2.09, -2.19, -2.29, -2.39, -2.48, -2.58, -2.67, -2.76, -2.85, -2.94]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.14, 0.31, 0.48, 0.68, 0.93, 1.17, 1.43, 1.74, 2.03, 2.34, 2.7, 3.04, 3.39, 3.79, 4.17, 4.6, 5.0, 5.41, 5.88, 6.31, 6.76, 7.26, 7.73, 8.2, 8.74, 9.23, 9.73, 10.3, 10.82]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.0, 0.0, 0.01, 0.01, 0.02, 0.03, 0.03, 0.03, 0.03, 0.01, -0.03, -0.08, -0.16, -0.28, -0.43, -0.65, -0.91, -1.23, -1.66, -2.14, -2.71, -3.46, -4.26, -5.19, -6.37, -7.6, -9.0, -10.76, -12.56]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.56, 0.68, 0.75, 0.8, 0.85, 0.89, 0.92, 0.95, 0.98, 1.01, 1.03, 1.06, 1.08, 1.1, 1.12, 1.14, 1.15, 1.17, 1.18, 1.2, 1.21, 1.23, 1.24, 1.25, 1.27, 1.28, 1.29, 1.3, 1.32]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.37, -0.36, -0.34, -0.32, -0.3, -0.28, -0.27, -0.25, -0.23, -0.21, -0.19, -0.17, -0.15, -0.14, -0.12, -0.1, -0.08, -0.06, -0.04, -0.02, -0.0, 0.01, 0.03, 0.05, 0.07, 0.09, 0.11, 0.13, 0.15, 0.16]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.02, -0.01, 0.02, 0.09, 0.19, 0.31, 0.46, 0.65, 0.86, 1.09, 1.38, 1.67, 1.98, 2.36, 2.74, 3.18, 3.61, 4.07, 4.61, 5.12, 5.67, 6.29, 6.89, 7.52, 8.24, 8.93, 9.64, 10.45, 11.22]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.08, -0.17, -0.25, -0.33, -0.42, -0.5, -0.57, -0.65, -0.71, -0.78, -0.84, -0.9, -0.95, -1.0, -1.04, -1.07, -1.1, -1.13, -1.15, -1.16, -1.16, -1.16, -1.16, -1.14, -1.13, -1.1, -1.08, -1.04, -1.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.92, 0.9, 0.87, 0.84, 0.81, 0.78, 0.74, 0.7, 0.65, 0.6, 0.54, 0.47, 0.4, 0.3, 0.12, 0.23, 0.36, 0.44, 0.51, 0.57, 0.63, 0.67, 0.72, 0.76, 0.79, 0.83, 0.86, 0.88, 0.91, 0.93]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.55, 0.62, 0.68, 0.72, 0.76, 0.8, 0.83, 0.86, 0.88, 0.9, 0.92, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 0.99, 0.99, 0.98, 0.97, 0.97]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.51, 0.61, 0.72, 0.82, 0.92, 1.03, 1.13, 1.23, 1.34, 1.44, 1.54, 1.65, 1.75, 1.85, 1.96, 2.06, 2.17, 2.27, 2.37, 2.48, 2.57, 2.67, 2.78, 2.88, 2.98, 3.09, 3.19, 3.29, 3.4, 3.5]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.53, 0.53, 0.53, 0.54, 0.54, 0.55, 0.55, 0.55, 0.56, 0.56, 0.56, 0.57, 0.57, 0.57, 0.58, 0.58, 0.59, 0.59, 0.59, 0.6, 0.6, 0.6, 0.61, 0.61, 0.61, 0.62, 0.62, 0.62, 0.63, 0.63]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.01, -0.02, -0.05, -0.09, -0.14, -0.2, -0.26, -0.35, -0.43, -0.52, -0.62, -0.71, -0.8, -0.88, -0.94, -0.99, -1.0, -0.98, -0.91, -0.81, -0.67, -0.46, -0.24, 0.01, 0.29, 0.54, 0.75, 0.92, 1.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.5, 0.38, 0.19, 0.25, 0.4, 0.52, 0.61, 0.69, 0.76, 0.83, 0.88, 0.94, 1.0, 1.05, 1.1, 1.14, 1.19, 1.23, 1.27, 1.31, 1.35, 1.39, 1.43, 1.46, 1.49, 1.53, 1.56, 1.59, 1.63, 1.66]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.05, -0.11, -0.18, -0.25, -0.33, -0.4, -0.47, -0.54, -0.59, -0.63, -0.67, -0.68, -0.69, -0.67, -0.65, -0.61, -0.56, -0.51, -0.44, -0.37, -0.3, -0.22, -0.16, -0.1, -0.04, 0.0, 0.03, 0.04, 0.03]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.9, 0.92, 0.94, 0.96, 0.97, 0.98, 0.99, 1.0, 1.0, 1.0, 1.0, 0.99, 0.98, 0.97, 0.96, 0.94, 0.92, 0.9, 0.88, 0.84, 0.81, 0.78, 0.74, 0.69, 0.64, 0.58, 0.52, 0.45, 0.36, 0.23]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.68, 0.85, 1.03, 1.18, 1.32, 1.45, 1.56, 1.65, 1.74, 1.8, 1.84, 1.86, 1.86, 1.84, 1.8, 1.75, 1.66, 1.57, 1.46, 1.33, 1.19, 1.04, 0.87, 0.7, 0.53, 0.33, 0.14, -0.04, -0.25, -0.43]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.36, 0.55, 0.75, 0.93, 1.11, 1.29, 1.45, 1.6, 1.76, 1.89, 2.01, 2.14, 2.24, 2.33, 2.42, 2.49, 2.56, 2.61, 2.65, 2.69, 2.72, 2.74, 2.76, 2.77, 2.77, 2.78, 2.78, 2.78, 2.78, 2.78]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.43, 0.31, 0.1, 0.32, 0.44, 0.54, 0.6, 0.66, 0.71, 0.75, 0.79, 0.82, 0.85, 0.88, 0.9, 0.92, 0.93, 0.95, 0.96, 0.97, 0.98, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.54, 0.58, 0.62, 0.65, 0.67, 0.69, 0.71, 0.72, 0.72, 0.72, 0.72, 0.71, 0.69, 0.67, 0.64, 0.61, 0.57, 0.53, 0.48, 0.43, 0.37, 0.31, 0.24, 0.17, 0.09, -0.0, -0.09, -0.18, -0.29, -0.39]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.06, 0.13, 0.19, 0.25, 0.31, 0.37, 0.42, 0.47, 0.52, 0.56, 0.61, 0.64, 0.67, 0.71, 0.73, 0.76, 0.78, 0.79, 0.81, 0.82, 0.83, 0.83, 0.84, 0.84, 0.84, 0.84, 0.83, 0.83, 0.82]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.83, 0.95, 1.06, 1.15, 1.23, 1.32, 1.39, 1.46, 1.53, 1.6, 1.66, 1.72, 1.78, 1.84, 1.9, 1.95, 2.0, 2.05, 2.1, 2.15, 2.2, 2.24, 2.29, 2.34, 2.38, 2.42, 2.46, 2.5, 2.55, 2.59]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.42, 0.32, 0.22, 0.13, 0.04, -0.07, -0.16, -0.25, -0.35, -0.45, -0.54, -0.64, -0.73, -0.83, -0.93, -1.02, -1.12, -1.22, -1.31, -1.41, -1.51, -1.6, -1.7, -1.79, -1.89, -1.99, -2.08, -2.17, -2.28, -2.37]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.38, 0.4, 0.43, 0.46, 0.49, 0.52, 0.54, 0.57, 0.6, 0.63, 0.65, 0.68, 0.71, 0.74, 0.77, 0.79, 0.82, 0.85, 0.88, 0.91, 0.93, 0.96, 0.99, 1.02, 1.04, 1.07, 1.1, 1.13, 1.16, 1.18]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.06, -0.13, -0.19, -0.25, -0.32, -0.37, -0.43, -0.48, -0.53, -0.57, -0.61, -0.65, -0.68, -0.71, -0.74, -0.76, -0.78, -0.8, -0.81, -0.82, -0.83, -0.84, -0.84, -0.84, -0.84, -0.84, -0.83, -0.82, -0.81]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.6, -0.44, -0.27, -0.11, 0.04, 0.2, 0.35, 0.48, 0.63, 0.75, 0.87, 0.98, 1.08, 1.16, 1.25, 1.31, 1.37, 1.42, 1.45, 1.48, 1.5, 1.5, 1.5, 1.49, 1.48, 1.45, 1.42, 1.39, 1.35, 1.31]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.65, 0.62, 0.59, 0.55, 0.52, 0.48, 0.45, 0.41, 0.37, 0.34, 0.3, 0.26, 0.22, 0.18, 0.14, 0.1, 0.05, 0.01, -0.02, -0.07, -0.11, -0.15, -0.19, -0.23, -0.27, -0.31, -0.35, -0.38, -0.42, -0.46]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.09, 0.12, 0.15, 0.17, 0.19, 0.21, 0.23, 0.24, 0.26, 0.27, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.41, 0.42, 0.43, 0.44, 0.45, 0.45]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.0, -0.0, -0.01, -0.01, -0.03, -0.04, -0.07, -0.1, -0.14, -0.19, -0.26, -0.33, -0.41, -0.51, -0.62, -0.75, -0.89, -1.03, -1.21, -1.38, -1.57, -1.79, -2.0, -2.22, -2.48, -2.72, -2.97, -3.26, -3.52]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.81, -0.8, -0.79, -0.78, -0.77, -0.76, -0.75, -0.74, -0.73, -0.72, -0.71, -0.7, -0.69, -0.68, -0.67, -0.66, -0.65, -0.64, -0.63, -0.62, -0.61, -0.6, -0.59, -0.58, -0.58, -0.57, -0.56, -0.55, -0.54, -0.53]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.02, 0.07, 0.13, 0.22, 0.36, 0.52, 0.72, 0.99, 1.28, 1.62, 2.06, 2.53, 3.05, 3.71, 4.38, 5.2, 6.04, 6.96, 8.07, 9.17, 10.37, 11.81, 13.22, 14.75, 16.55, 18.31, 20.2, 22.41, 24.56]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.2, 0.23, 0.25, 0.28, 0.3, 0.33, 0.35, 0.37, 0.4, 0.42, 0.44, 0.46, 0.48, 0.5, 0.52, 0.54, 0.56, 0.57, 0.59, 0.61, 0.62, 0.64, 0.65, 0.67, 0.68, 0.69, 0.7, 0.71, 0.72, 0.73]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.84, -0.6, -0.5, -0.43, -0.36, -0.3, -0.25, -0.21, -0.16, -0.12, -0.08, -0.04, -0.0, 0.03, 0.07, 0.1, 0.13, 0.16, 0.19, 0.22, 0.25, 0.28, 0.31, 0.33, 0.36, 0.39, 0.41, 0.44, 0.46, 0.48]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.58, 0.61, 0.66, 0.72, 0.79, 0.89, 1.0, 1.12, 1.28, 1.44, 1.62, 1.84, 2.06, 2.3, 2.59, 2.86, 3.19, 3.51, 3.85, 4.24, 4.62, 5.01, 5.47, 5.91, 6.37, 6.89, 7.39, 7.91, 8.5, 9.06]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.32, 0.34, 0.34, 0.29, 0.15, 0.3, 0.49, 0.67, 0.86, 1.04, 1.22, 1.43, 1.63, 1.83, 2.06, 2.27, 2.51, 2.74, 2.97, 3.23, 3.47, 3.71, 3.99, 4.25, 4.51, 4.8, 5.08, 5.35, 5.66, 5.95]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.48, 0.7, 0.85, 0.97, 1.09, 1.2, 1.29, 1.38, 1.46, 1.54, 1.62, 1.69, 1.76, 1.83, 1.89, 1.96, 2.01, 2.07, 2.13, 2.18, 2.24, 2.29, 2.34, 2.39, 2.44, 2.49, 2.54, 2.59, 2.63]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.58, 0.76, 0.95, 1.11, 1.27, 1.44, 1.6, 1.75, 1.91, 2.05, 2.2, 2.35, 2.49, 2.63, 2.79, 2.92, 3.07, 3.21, 3.34, 3.49, 3.62, 3.75, 3.9, 4.03, 4.16, 4.3, 4.43, 4.56, 4.7, 4.83]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.98, 0.99, 1.01, 1.02, 1.03, 1.05, 1.06, 1.07, 1.08, 1.09, 1.1, 1.11, 1.12, 1.13, 1.14, 1.15, 1.16, 1.17, 1.17, 1.18, 1.19, 1.2, 1.21, 1.21, 1.22, 1.23, 1.24, 1.24, 1.25, 1.26]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.69, 0.71, 0.72, 0.74, 0.75, 0.76, 0.78, 0.79, 0.8, 0.81, 0.82, 0.84, 0.85, 0.86, 0.87, 0.88, 0.88, 0.89, 0.9, 0.91, 0.92, 0.92, 0.93, 0.94, 0.94, 0.95, 0.95, 0.96, 0.96, 0.97]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.31, 0.4, 0.5, 0.58, 0.66, 0.74, 0.8, 0.86, 0.91, 0.95, 0.97, 0.99, 1.0, 1.0, 0.98, 0.96, 0.92, 0.88, 0.83, 0.76, 0.69, 0.61, 0.52, 0.44, 0.34, 0.24, 0.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.31, 0.41, 0.52, 0.62, 0.72, 0.83, 0.93, 1.03, 1.14, 1.24, 1.34, 1.45, 1.55, 1.66, 1.76, 1.86, 1.97, 2.07, 2.17, 2.28, 2.38, 2.48, 2.59, 2.69, 2.79, 2.9, 3.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.32, 0.51, 0.67, 0.84, 1.04, 1.23, 1.44, 1.69, 1.94, 2.2, 2.5, 2.8, 3.12, 3.49, 3.85, 4.26, 4.66, 5.07, 5.55, 6.0, 6.48, 7.02, 7.54, 8.07, 8.68, 9.25, 9.85, 10.52, 11.16]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.32, 0.46, 0.56, 0.64, 0.72, 0.79, 0.85, 0.91, 0.96, 1.01, 1.07, 1.11, 1.16, 1.2, 1.24, 1.29, 1.33, 1.36, 1.4, 1.44, 1.47, 1.51, 1.54, 1.57, 1.61, 1.64, 1.67, 1.7, 1.73]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.74, -0.71, -0.68, -0.64, -0.61, -0.57, -0.54, -0.5, -0.46, -0.42, -0.38, -0.34, -0.3, -0.26, -0.21, -0.17, -0.12, -0.08, -0.04, 0.01, 0.05, 0.09, 0.14, 0.18, 0.22, 0.27, 0.31, 0.35, 0.39, 0.43]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.02, 0.05, 0.07, 0.09, 0.11, 0.13, 0.16, 0.18, 0.2, 0.22, 0.24, 0.26, 0.29, 0.31, 0.33, 0.35, 0.37, 0.39, 0.41, 0.42, 0.44, 0.46, 0.48, 0.49, 0.51, 0.53, 0.54, 0.56, 0.57]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.09, 0.22, 0.35, 0.49, 0.65, 0.79, 0.9, 0.98, 1.0, 0.94, 0.78, 0.54, 0.22, -0.17, -0.53, -0.84, -0.99, -0.95, -0.68, -0.26, 0.24, 0.73, 0.98, 0.93, 0.52, -0.06, -0.64, -0.99, -0.87]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.14, 0.16, 0.18, 0.2, 0.21, 0.22, 0.23, 0.23, 0.23, 0.23, 0.23, 0.22, 0.22, 0.21, 0.19, 0.17, 0.15, 0.12, 0.07, 0.07, 0.13, 0.17, 0.21, 0.24, 0.27, 0.3, 0.33, 0.36]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.41, 0.53, 0.66, 0.78, 0.9, 1.03, 1.15, 1.27, 1.4, 1.52, 1.64, 1.77, 1.89, 2.01, 2.14, 2.26, 2.39, 2.51, 2.63, 2.77, 2.88, 3.0, 3.14, 3.26, 3.37, 3.51, 3.63, 3.75, 3.88, 4.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.5, 0.57, 0.64, 0.69, 0.73, 0.77, 0.8, 0.82, 0.83, 0.84, 0.84, 0.84, 0.83, 0.81, 0.79, 0.76, 0.72, 0.67, 0.62, 0.55, 0.48, 0.39, 0.3, 0.21, 0.11, -0.0, -0.1, -0.2, -0.3, -0.39]<EOS_Y><SOS_EQ>', '<SOS_Y>[1.22, 1.52, 1.85, 2.15, 2.45, 2.78, 3.08, 3.38, 3.71, 4.01, 4.31, 4.64, 4.94, 5.24, 5.57, 5.87, 6.2, 6.5, 6.8, 7.13, 7.43, 7.73, 8.06, 8.36, 8.66, 8.99, 9.29, 9.59, 9.92, 10.22]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.62, 0.6, 0.56, 0.52, 0.47, 0.4, 0.33, 0.25, 0.15, 0.06, -0.05, -0.18, -0.3, -0.44, -0.59, -0.74, -0.92, -1.09, -1.27, -1.48, -1.67, -1.88, -2.12, -2.34, -2.57, -2.84, -3.09, -3.35, -3.64, -3.92]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.42, 0.67, 0.87, 1.05, 1.24, 1.41, 1.57, 1.74, 1.89, 2.04, 2.21, 2.35, 2.5, 2.65, 2.79, 2.95, 3.09, 3.22, 3.37, 3.51, 3.64, 3.79, 3.92, 4.05, 4.2, 4.33, 4.46, 4.6, 4.73]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.08, 0.14, 0.21, 0.27, 0.34, 0.41, 0.48, 0.55, 0.63, 0.7, 0.76, 0.82, 0.88, 0.92, 0.96, 0.99, 1.0, 1.0, 0.98, 0.94, 0.89, 0.82, 0.73, 0.63, 0.51, 0.36, 0.22, 0.06, -0.11, -0.27]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.47, 0.54, 0.6, 0.66, 0.71, 0.76, 0.79, 0.83, 0.86, 0.88, 0.9, 0.92, 0.93, 0.93, 0.93, 0.92, 0.91, 0.89, 0.87, 0.84, 0.81, 0.77, 0.72, 0.67, 0.62, 0.56, 0.49, 0.43, 0.35, 0.27]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.59, 0.69, 0.8, 0.9, 1.0, 1.11, 1.21, 1.31, 1.42, 1.52, 1.62, 1.73, 1.83, 1.93, 2.04, 2.14, 2.25, 2.35, 2.45, 2.56, 2.66, 2.76, 2.87, 2.97, 3.07, 3.18, 3.28, 3.38, 3.49, 3.59]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.84, 1.04, 1.26, 1.46, 1.66, 1.88, 2.08, 2.28, 2.5, 2.7, 2.9, 3.12, 3.32, 3.52, 3.74, 3.94, 4.16, 4.36, 4.56, 4.78, 4.98, 5.18, 5.4, 5.6, 5.8, 6.02, 6.22, 6.42, 6.64, 6.84]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.31, 0.4, 0.5, 0.58, 0.66, 0.74, 0.8, 0.86, 0.91, 0.95, 0.97, 0.99, 1.0, 1.0, 0.98, 0.96, 0.92, 0.88, 0.83, 0.76, 0.69, 0.61, 0.52, 0.44, 0.34, 0.24, 0.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.66, 0.8, 0.91, 0.97, 1.0, 0.98, 0.92, 0.83, 0.69, 0.53, 0.35, 0.14, -0.06, -0.26, -0.46, -0.63, -0.78, -0.89, -0.96, -1.0, -0.99, -0.94, -0.84, -0.72, -0.57, -0.37, -0.18, 0.02, 0.24, 0.42]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.56, -0.56, -0.57, -0.57, -0.57, -0.58, -0.58, -0.59, -0.59, -0.59, -0.6, -0.6, -0.6, -0.61, -0.61, -0.61, -0.62, -0.62, -0.62, -0.63, -0.63, -0.63, -0.64, -0.64, -0.64, -0.64, -0.65, -0.65, -0.65, -0.66]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.86, 0.89, 0.93, 0.97, 1.0, 1.04, 1.07, 1.1, 1.13, 1.16, 1.19, 1.22, 1.24, 1.27, 1.3, 1.32, 1.35, 1.37, 1.39, 1.42, 1.44, 1.47, 1.49, 1.51, 1.53, 1.56, 1.58, 1.6, 1.62, 1.64]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.06, -0.1, -0.11, -0.11, -0.08, -0.04, 0.03, 0.13, 0.23, 0.36, 0.53, 0.7, 0.89, 1.12, 1.35, 1.63, 1.91, 2.2, 2.55, 2.88, 3.24, 3.65, 4.05, 4.47, 4.95, 5.41, 5.89, 6.44, 6.97]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.02, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.1, 0.11, 0.12, 0.14, 0.16, 0.18, 0.19, 0.21, 0.24, 0.26, 0.28, 0.3, 0.33, 0.35, 0.38, 0.41]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.0, -0.01, -0.03, -0.04, -0.07, -0.1, -0.13, -0.18, -0.22, -0.27, -0.33, -0.39, -0.45, -0.52, -0.59, -0.66, -0.72, -0.78, -0.85, -0.9, -0.94, -0.98, -1.0, -1.0, -0.98, -0.95, -0.9, -0.81, -0.72]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.67, 0.73, 0.79, 0.84, 0.88, 0.91, 0.94, 0.96, 0.98, 0.99, 1.0, 1.0, 1.0, 0.99, 0.97, 0.95, 0.92, 0.89, 0.85, 0.8, 0.75, 0.69, 0.62, 0.54, 0.44, 0.29, 0.13, 0.34, 0.47, 0.57]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.43, 0.41, 0.4, 0.39, 0.37, 0.36, 0.35, 0.33, 0.32, 0.31, 0.3, 0.28, 0.27, 0.26, 0.24, 0.23, 0.22, 0.2, 0.19, 0.18, 0.16, 0.15, 0.14, 0.13, 0.11, 0.1, 0.09, 0.07, 0.06, 0.05]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.1, -0.1, -0.09, -0.05, 0.01, 0.09, 0.19, 0.31, 0.46, 0.62, 0.8, 1.02, 1.24, 1.49, 1.78, 2.06, 2.4, 2.72, 3.07, 3.47, 3.86, 4.27, 4.74, 5.19, 5.66, 6.2, 6.72, 7.25, 7.86, 8.43]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.13, 0.27, 0.4, 0.53, 0.67, 0.79, 0.91, 1.04, 1.15, 1.25, 1.37, 1.46, 1.55, 1.64, 1.72, 1.8, 1.86, 1.92, 1.97, 2.01, 2.05, 2.08, 2.1, 2.12, 2.13, 2.13, 2.13, 2.12, 2.11]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.01, 0.04, 0.08, 0.14, 0.22, 0.31, 0.42, 0.56, 0.7, 0.85, 1.04, 1.22, 1.42, 1.66, 1.89, 2.16, 2.42, 2.69, 3.0, 3.31, 3.62, 3.98, 4.32, 4.67, 5.07, 5.45, 5.84, 6.29, 6.7]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.43, 0.48, 0.54, 0.58, 0.63, 0.67, 0.71, 0.75, 0.79, 0.82, 0.85, 0.88, 0.91, 0.93, 0.95, 0.97, 0.98, 0.99, 1.0, 1.0, 1.0, 1.0, 0.99, 0.98, 0.97, 0.95, 0.93, 0.91, 0.88, 0.85]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.72, 0.81, 0.9, 0.99, 1.08, 1.17, 1.26, 1.35, 1.44, 1.53, 1.62, 1.71, 1.8, 1.89, 1.99, 2.07, 2.17, 2.26, 2.34, 2.44, 2.53, 2.61, 2.71, 2.8, 2.88, 2.98, 3.07, 3.15, 3.25, 3.34]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.32, 0.46, 0.56, 0.64, 0.72, 0.79, 0.85, 0.91, 0.96, 1.01, 1.07, 1.11, 1.16, 1.2, 1.24, 1.29, 1.33, 1.36, 1.4, 1.44, 1.47, 1.51, 1.54, 1.57, 1.61, 1.64, 1.67, 1.7, 1.73]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.56, -0.38, -0.17, 0.03, 0.22, 0.43, 0.6, 0.75, 0.88, 0.95, 0.99, 0.99, 0.95, 0.87, 0.74, 0.59, 0.4, 0.21, 0.01, -0.2, -0.39, -0.57, -0.73, -0.85, -0.94, -0.99, -1.0, -0.96, -0.88, -0.77]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.23, 0.42, 0.63, 0.82, 1.01, 1.2, 1.37, 1.53, 1.7, 1.85, 1.98, 2.12, 2.23, 2.34, 2.44, 2.53, 2.61, 2.67, 2.73, 2.78, 2.82, 2.85, 2.87, 2.89, 2.9, 2.91, 2.91, 2.91, 2.91, 2.91]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.15, -0.22, -0.27, -0.31, -0.36, -0.4, -0.43, -0.47, -0.51, -0.54, -0.58, -0.61, -0.64, -0.68, -0.71, -0.75, -0.78, -0.81, -0.85, -0.88, -0.91, -0.95, -0.98, -1.01, -1.05, -1.08, -1.11, -1.15, -1.18]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.31, 0.4, 0.5, 0.58, 0.66, 0.74, 0.8, 0.86, 0.91, 0.95, 0.97, 0.99, 1.0, 1.0, 0.98, 0.96, 0.92, 0.88, 0.83, 0.76, 0.69, 0.61, 0.52, 0.44, 0.34, 0.24, 0.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.19, 0.35, 0.49, 0.6, 0.7, 0.81, 0.91, 1.01, 1.11, 1.2, 1.3, 1.4, 1.49, 1.58, 1.67, 1.76, 1.86, 1.95, 2.04, 2.14, 2.23, 2.31, 2.41, 2.5, 2.59, 2.68, 2.77, 2.86, 2.96, 3.04]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.03, 0.08, 0.12, 0.18, 0.25, 0.32, 0.4, 0.5, 0.59, 0.7, 0.82, 0.94, 1.07, 1.21, 1.36, 1.52, 1.68, 1.85, 2.04, 2.22, 2.41, 2.63, 2.83, 3.05, 3.29, 3.52, 3.76, 4.03, 4.28]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.3, 0.08, 0.3, 0.42, 0.51, 0.6, 0.67, 0.73, 0.79, 0.85, 0.9, 0.95, 0.99, 1.04, 1.08, 1.12, 1.16, 1.2, 1.24, 1.27, 1.31, 1.34, 1.38, 1.41, 1.44, 1.47, 1.5, 1.53, 1.56, 1.59]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.32, 0.46, 0.56, 0.64, 0.72, 0.79, 0.85, 0.91, 0.96, 1.01, 1.07, 1.11, 1.16, 1.2, 1.24, 1.29, 1.33, 1.36, 1.4, 1.44, 1.47, 1.51, 1.54, 1.57, 1.61, 1.64, 1.67, 1.7, 1.73]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.24, 0.34, 0.41, 0.48, 0.54, 0.59, 0.63, 0.68, 0.72, 0.76, 0.8, 0.83, 0.86, 0.9, 0.93, 0.96, 0.99, 1.02, 1.05, 1.07, 1.1, 1.12, 1.15, 1.17, 1.2, 1.22, 1.24, 1.27, 1.29]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.14, 0.11, 0.09, 0.06, 0.04, 0.01, -0.01, -0.03, -0.06, -0.08, -0.11, -0.14, -0.16, -0.18, -0.21, -0.23, -0.26, -0.28, -0.3, -0.33, -0.35, -0.37, -0.4, -0.42, -0.44, -0.47, -0.49, -0.51, -0.53, -0.55]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.58, -0.39, -0.17, 0.02, 0.21, 0.41, 0.59, 0.76, 0.94, 1.1, 1.25, 1.41, 1.54, 1.66, 1.79, 1.89, 1.99, 2.07, 2.14, 2.21, 2.26, 2.31, 2.34, 2.37, 2.39, 2.4, 2.41, 2.41, 2.41, 2.41]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.0, -0.0, -0.0, 0.0, 0.01, 0.01, 0.03, 0.05, 0.08, 0.11, 0.16, 0.21, 0.27, 0.34, 0.42, 0.52, 0.62, 0.73, 0.86, 0.99, 1.12, 1.28, 1.44, 1.59, 1.78, 1.94, 2.11, 2.31, 2.48]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.31, -0.19, -0.06, 0.06, 0.18, 0.31, 0.43, 0.55, 0.69, 0.81, 0.93, 1.06, 1.18, 1.3, 1.43, 1.55, 1.69, 1.81, 1.93, 2.06, 2.18, 2.3, 2.43, 2.55, 2.67, 2.81, 2.93, 3.05, 3.18, 3.3]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.2, 0.41, 0.58, 0.73, 0.86, 0.95, 0.99, 1.0, 0.96, 0.88, 0.76, 0.61, 0.45, 0.24, 0.04, -0.18, -0.37, -0.55, -0.72, -0.84, -0.93, -0.99, -1.0, -0.97, -0.89, -0.79, -0.65, -0.46, -0.28]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.83, 0.84, 0.86, 0.88, 0.9, 0.92, 0.93, 0.95, 0.97, 0.98, 1.0, 1.01, 1.03, 1.04, 1.06, 1.07, 1.09, 1.1, 1.11, 1.13, 1.14, 1.16, 1.17, 1.18, 1.2, 1.21, 1.22, 1.23, 1.25, 1.26]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.09, -0.19, -0.27, -0.36, -0.45, -0.53, -0.6, -0.67, -0.74, -0.8, -0.85, -0.89, -0.93, -0.96, -0.98, -1.0, -1.0, -1.0, -0.98, -0.96, -0.93, -0.89, -0.85, -0.8, -0.74, -0.68, -0.61, -0.53, -0.45]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.54, 0.51, 0.47, 0.43, 0.4, 0.36, 0.32, 0.28, 0.23, 0.19, 0.15, 0.1, 0.06, 0.01, -0.04, -0.08, -0.13, -0.17, -0.21, -0.26, -0.3, -0.34, -0.38, -0.42, -0.45, -0.49, -0.52, -0.55, -0.59, -0.61]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.33, 0.53, 0.68, 0.8, 0.9, 1.0, 1.08, 1.15, 1.23, 1.3, 1.36, 1.43, 1.49, 1.54, 1.6, 1.65, 1.71, 1.76, 1.81, 1.86, 1.9, 1.95, 1.99, 2.04, 2.08, 2.12, 2.16, 2.2, 2.24, 2.28]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.71, 0.55, 0.65, 0.81, 0.94, 1.06, 1.15, 1.24, 1.33, 1.41, 1.48, 1.56, 1.63, 1.7, 1.77, 1.83, 1.9, 1.96, 2.01, 2.08, 2.13, 2.19, 2.25, 2.3, 2.35, 2.41, 2.46, 2.51, 2.57, 2.62]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.57, 0.57, 0.57, 0.57, 0.57, 0.57, 0.58, 0.58, 0.58, 0.58, 0.58, 0.58, 0.58, 0.59, 0.59, 0.59, 0.59, 0.59, 0.59, 0.6, 0.6, 0.6, 0.6, 0.6]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.69, -0.51, -0.31, -0.12, 0.07, 0.29, 0.48, 0.68, 0.9, 1.1, 1.3, 1.51, 1.71, 1.89, 2.09, 2.26, 2.45, 2.6, 2.75, 2.91, 3.04, 3.16, 3.28, 3.38, 3.47, 3.56, 3.62, 3.68, 3.74, 3.78]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.01, 0.02, 0.03, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.21, 0.22, 0.23, 0.24, 0.25]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.05, 0.14, 0.25, 0.38, 0.55, 0.71, 0.89, 1.1, 1.31, 1.52, 1.77, 2.01, 2.26, 2.54, 2.81, 3.12, 3.4, 3.7, 4.03, 4.34, 4.66, 5.02, 5.35, 5.69, 6.07, 6.43, 6.79, 7.2, 7.57]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.9, 0.87, 0.83, 0.8, 0.75, 0.7, 0.63, 0.52, 0.34, 0.55, 0.65, 0.72, 0.77, 0.81, 0.85, 0.88, 0.91, 0.93, 0.96, 0.98, 1.0, 1.02, 1.04, 1.06, 1.08, 1.09, 1.11, 1.12, 1.14, 1.15]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.52, 0.59, 0.65, 0.7, 0.74, 0.78, 0.8, 0.82, 0.83, 0.84, 0.84, 0.84, 0.82, 0.81, 0.78, 0.75, 0.71, 0.66, 0.6, 0.53, 0.46, 0.37, 0.28, 0.18, 0.08, -0.03, -0.13, -0.22, -0.32, -0.41]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.04, 0.14, 0.25, 0.35, 0.46, 0.56, 0.66, 0.77, 0.87, 0.97, 1.08, 1.18, 1.28, 1.39, 1.49, 1.6, 1.7, 1.8, 1.91, 2.01, 2.11, 2.22, 2.32, 2.42, 2.53, 2.63, 2.73, 2.84, 2.94]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.31, 0.4, 0.5, 0.58, 0.66, 0.74, 0.8, 0.86, 0.91, 0.95, 0.97, 0.99, 1.0, 1.0, 0.98, 0.96, 0.92, 0.88, 0.83, 0.76, 0.69, 0.61, 0.52, 0.44, 0.34, 0.24, 0.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.34, 0.49, 0.6, 0.69, 0.78, 0.85, 0.92, 0.98, 1.04, 1.09, 1.15, 1.2, 1.25, 1.3, 1.34, 1.39, 1.43, 1.47, 1.51, 1.55, 1.59, 1.63, 1.66, 1.7, 1.74, 1.77, 1.8, 1.84, 1.87]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.32, 0.46, 0.56, 0.64, 0.72, 0.79, 0.85, 0.91, 0.96, 1.01, 1.07, 1.11, 1.16, 1.2, 1.24, 1.29, 1.33, 1.36, 1.4, 1.44, 1.47, 1.51, 1.54, 1.57, 1.61, 1.64, 1.67, 1.7, 1.73]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.13, 0.17, 0.21, 0.26, 0.31, 0.36, 0.42, 0.48, 0.56, 0.63, 0.7, 0.79, 0.87, 0.96, 1.06, 1.15, 1.26, 1.37, 1.48, 1.6, 1.72, 1.84, 1.98, 2.11, 2.24, 2.39, 2.54, 2.68, 2.85, 3.01]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.31, 0.4, 0.5, 0.58, 0.66, 0.74, 0.8, 0.86, 0.91, 0.95, 0.97, 0.99, 1.0, 1.0, 0.98, 0.96, 0.92, 0.88, 0.83, 0.76, 0.69, 0.61, 0.52, 0.44, 0.34, 0.24, 0.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.11, 0.29, 0.45, 0.57, 0.67, 0.78, 0.87, 0.96, 1.06, 1.15, 1.23, 1.32, 1.4, 1.49, 1.58, 1.66, 1.74, 1.82, 1.9, 1.99, 2.07, 2.15, 2.23, 2.31, 2.39, 2.47, 2.55, 2.63, 2.72, 2.79]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.2, 0.3, 0.39, 0.5, 0.6, 0.69, 0.8, 0.89, 0.99, 1.1, 1.19, 1.29, 1.4, 1.49, 1.6, 1.69, 1.79, 1.9, 1.99, 2.09, 2.19, 2.29, 2.39, 2.49, 2.59, 2.68, 2.79, 2.89]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.01, 0.04, 0.08, 0.14, 0.22, 0.3, 0.39, 0.49, 0.59, 0.68, 0.77, 0.84, 0.9, 0.95, 0.98, 0.99, 0.98, 0.96, 0.91, 0.85, 0.78, 0.68, 0.59, 0.5, 0.39, 0.3, 0.21, 0.13, 0.07]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.92, 0.89, 0.83, 0.74, 0.64, 0.5, 0.36, 0.19, -0.02, -0.23, -0.46, -0.74, -1.02, -1.31, -1.66, -1.99, -2.39, -2.77, -3.17, -3.63, -4.07, -4.53, -5.06, -5.56, -6.08, -6.68, -7.24, -7.83, -8.49, -9.12]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.01, 0.03, 0.05, 0.07, 0.08, 0.09, 0.08, 0.06, 0.03, -0.03, -0.12, -0.22, -0.36, -0.54, -0.75, -1.02, -1.31, -1.65, -2.07, -2.51, -3.0, -3.61, -4.22, -4.9, -5.72, -6.54, -7.44, -8.51, -9.56]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.75, -0.4, -0.22, -0.08, 0.04, 0.17, 0.27, 0.37, 0.48, 0.58, 0.67, 0.76, 0.85, 0.94, 1.03, 1.11, 1.2, 1.28, 1.36, 1.44, 1.52, 1.6, 1.68, 1.75, 1.83, 1.91, 1.98, 2.05, 2.13, 2.2]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.65, -0.55, -0.44, -0.34, -0.24, -0.13, -0.03, 0.07, 0.18, 0.28, 0.38, 0.49, 0.59, 0.69, 0.8, 0.9, 1.01, 1.11, 1.21, 1.32, 1.42, 1.52, 1.63, 1.73, 1.83, 1.94, 2.04, 2.14, 2.25, 2.35]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.31, 0.41, 0.52, 0.62, 0.72, 0.83, 0.93, 1.03, 1.14, 1.24, 1.34, 1.45, 1.55, 1.66, 1.76, 1.86, 1.97, 2.07, 2.17, 2.28, 2.38, 2.48, 2.59, 2.69, 2.79, 2.9, 3.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.3, 0.39, 0.48, 0.55, 0.61, 0.67, 0.72, 0.76, 0.79, 0.81, 0.83, 0.84, 0.84, 0.84, 0.83, 0.82, 0.8, 0.77, 0.74, 0.69, 0.64, 0.58, 0.5, 0.42, 0.34, 0.24, 0.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[-1.72, -1.52, -1.3, -1.1, -0.9, -0.68, -0.48, -0.28, -0.06, 0.14, 0.34, 0.56, 0.76, 0.96, 1.18, 1.38, 1.6, 1.8, 2.0, 2.22, 2.42, 2.62, 2.84, 3.04, 3.24, 3.46, 3.66, 3.86, 4.08, 4.28]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.45, 0.65, 0.79, 0.91, 1.02, 1.11, 1.2, 1.29, 1.36, 1.44, 1.51, 1.57, 1.64, 1.7, 1.76, 1.82, 1.88, 1.93, 1.98, 2.03, 2.08, 2.14, 2.18, 2.23, 2.28, 2.32, 2.36, 2.41, 2.45]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.24, -0.03, 0.15, 0.3, 0.45, 0.62, 0.76, 0.91, 1.07, 1.21, 1.36, 1.51, 1.65, 1.79, 1.95, 2.09, 2.24, 2.38, 2.52, 2.67, 2.81, 2.95, 3.1, 3.24, 3.38, 3.53, 3.67, 3.81, 3.96, 4.09]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.31, 0.4, 0.5, 0.58, 0.66, 0.74, 0.8, 0.86, 0.91, 0.95, 0.97, 0.99, 1.0, 1.0, 0.98, 0.96, 0.92, 0.88, 0.83, 0.76, 0.69, 0.61, 0.52, 0.44, 0.34, 0.24, 0.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.27, -0.07, 0.15, 0.35, 0.55, 0.77, 0.97, 1.17, 1.39, 1.59, 1.79, 2.01, 2.21, 2.41, 2.63, 2.83, 3.05, 3.25, 3.45, 3.67, 3.87, 4.07, 4.29, 4.49, 4.69, 4.91, 5.11, 5.31, 5.53, 5.73]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.31, 0.4, 0.5, 0.58, 0.66, 0.74, 0.8, 0.86, 0.91, 0.95, 0.97, 0.99, 1.0, 1.0, 0.98, 0.96, 0.92, 0.88, 0.83, 0.76, 0.69, 0.61, 0.52, 0.44, 0.34, 0.24, 0.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.15, 0.18, 0.2, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.27, 0.28, 0.28, 0.28, 0.28, 0.27, 0.27, 0.26, 0.25, 0.24, 0.23, 0.21, 0.19, 0.17, 0.14, 0.1, 0.04, 0.12, 0.16]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.21, -0.41, -0.66, -0.9, -1.17, -1.49, -1.8, -2.13, -2.52, -2.89, -3.29, -3.74, -4.18, -4.64, -5.17, -5.68, -6.25, -6.8, -7.37, -8.01, -8.62, -9.26, -9.97, -10.65, -11.35, -12.13, -12.87, -13.63, -14.49, -15.3]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.16, 0.33, 0.48, 0.61, 0.74, 0.84, 0.91, 0.97, 1.0, 1.0, 0.97, 0.91, 0.84, 0.73, 0.61, 0.46, 0.31, 0.16, -0.02, -0.18, -0.33, -0.49, -0.63, -0.74, -0.85, -0.92, -0.97, -1.0, -0.99]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.33, 0.49, 0.65, 0.77, 0.86, 0.94, 0.99, 1.0, 0.96, 0.87, 0.68, 0.09, 0.77, 1.17, 1.55, 1.9, 2.27, 2.61, 2.96, 3.35, 3.71, 4.07, 4.49, 4.87, 5.26, 5.7, 6.1, 6.51, 6.98, 7.4]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.03, 0.07, 0.1, 0.14, 0.17, 0.21, 0.24, 0.28, 0.31, 0.34, 0.38, 0.42, 0.45, 0.49, 0.52, 0.56, 0.59, 0.62, 0.66, 0.69, 0.73, 0.76, 0.8, 0.83, 0.87, 0.9, 0.93, 0.97, 1.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.95, 1.08, 1.21, 1.33, 1.45, 1.58, 1.68, 1.78, 1.89, 1.97, 2.05, 2.12, 2.18, 2.23, 2.27, 2.29, 2.31, 2.32, 2.31, 2.29, 2.27, 2.24, 2.19, 2.14, 2.08, 2.01, 1.93, 1.86, 1.77, 1.69]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.09, 0.29, 0.49, 0.65, 0.79, 0.9, 0.97, 1.0, 0.98, 0.93, 0.84, 0.7, 0.54, 0.36, 0.15, -0.05, -0.26, -0.45, -0.62, -0.78, -0.89, -0.96, -1.0, -0.99, -0.94, -0.85, -0.73, -0.58, -0.38, -0.19]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.13, 0.28, 0.41, 0.54, 0.69, 0.82, 0.95, 1.1, 1.23, 1.36, 1.5, 1.64, 1.77, 1.91, 2.05, 2.19, 2.32, 2.45, 2.6, 2.73, 2.86, 3.01, 3.14, 3.27, 3.42, 3.55, 3.68, 3.83, 3.96]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, -0.0, -0.01, -0.03, -0.06, -0.12, -0.2, -0.32, -0.49, -0.69, -0.93, -1.26, -1.63, -2.05, -2.6, -3.18, -3.9, -4.65, -5.49, -6.53, -7.57, -8.72, -10.12, -11.51, -13.02, -14.83, -16.62, -18.54, -20.82, -23.05]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.88, 0.97, 1.05, 1.13, 1.19, 1.26, 1.32, 1.38, 1.44, 1.5, 1.55, 1.6, 1.65, 1.7, 1.75, 1.79, 1.84, 1.88, 1.92, 1.97, 2.01, 2.04, 2.09, 2.12, 2.16, 2.2, 2.23, 2.27, 2.31, 2.34]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.07, 0.12, 0.19, 0.25, 0.33, 0.42, 0.51, 0.61, 0.73, 0.85, 0.98, 1.14, 1.29, 1.46, 1.65, 1.84, 2.07, 2.28, 2.51, 2.78, 3.03, 3.31, 3.62, 3.92, 4.24, 4.61, 4.96, 5.33, 5.75, 6.15]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.05, 0.12, 0.2, 0.29, 0.39, 0.5, 0.62, 0.75, 0.88, 1.01, 1.17, 1.32, 1.47, 1.65, 1.82, 2.01, 2.18, 2.36, 2.57, 2.76, 2.96, 3.18, 3.38, 3.59, 3.83, 4.04, 4.27, 4.51, 4.74]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.9, 0.93, 0.96, 0.97, 0.99, 1.0, 1.0, 1.0, 0.99, 0.98, 0.96, 0.93, 0.9, 0.87, 0.82, 0.78, 0.72, 0.65, 0.58, 0.48, 0.36, 0.17, 0.29, 0.43, 0.53, 0.62, 0.69, 0.75, 0.8, 0.85]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.04, 0.1, 0.17, 0.24, 0.33, 0.42, 0.52, 0.63, 0.73, 0.82, 0.9, 0.96, 1.0, 0.99, 0.95, 0.85, 0.72, 0.53, 0.29, 0.03, -0.23, -0.52, -0.74, -0.91, -1.0, -0.97, -0.84, -0.57, -0.24]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.39, -0.25, -0.09, 0.06, 0.21, 0.37, 0.51, 0.66, 0.82, 0.97, 1.11, 1.27, 1.42, 1.57, 1.73, 1.87, 2.04, 2.18, 2.33, 2.49, 2.64, 2.78, 2.94, 3.09, 3.24, 3.4, 3.54, 3.69, 3.85, 4.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.51, 0.57, 0.64, 0.7, 0.75, 0.8, 0.85, 0.89, 0.92, 0.95, 0.97, 0.99, 1.0, 1.0, 1.0, 0.99, 0.97, 0.95, 0.92, 0.88, 0.85, 0.8, 0.75, 0.7, 0.64, 0.57, 0.5, 0.44, 0.36, 0.28]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.19, 0.28, 0.34, 0.39, 0.43, 0.47, 0.5, 0.53, 0.56, 0.59, 0.61, 0.63, 0.66, 0.68, 0.7, 0.71, 0.73, 0.75, 0.76, 0.78, 0.79, 0.8, 0.81, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.43, 0.31, 0.11, 0.33, 0.45, 0.54, 0.61, 0.66, 0.71, 0.76, 0.79, 0.83, 0.85, 0.88, 0.9, 0.92, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.08, -0.12, -0.17, -0.22, -0.28, -0.34, -0.4, -0.47, -0.55, -0.62, -0.69, -0.76, -0.82, -0.88, -0.93, -0.97, -0.99, -1.0, -0.99, -0.95, -0.9, -0.82, -0.71, -0.58, -0.43, -0.25, -0.07, 0.12, 0.32, 0.5]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.31, 0.41, 0.52, 0.62, 0.72, 0.83, 0.93, 1.03, 1.14, 1.24, 1.34, 1.45, 1.55, 1.66, 1.76, 1.86, 1.97, 2.07, 2.17, 2.28, 2.38, 2.48, 2.59, 2.69, 2.79, 2.9, 3.0]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.07, 0.11, 0.13, 0.15, 0.17, 0.18, 0.2, 0.21, 0.22, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.33, 0.34, 0.35, 0.36, 0.37, 0.37, 0.38, 0.39, 0.4, 0.4]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.0, 0.01, 0.01, 0.02, 0.04, 0.06, 0.09, 0.13, 0.17, 0.22, 0.29, 0.36, 0.44, 0.54, 0.64, 0.77, 0.9, 1.04, 1.22, 1.39, 1.58, 1.81, 2.03, 2.27, 2.56, 2.84, 3.14, 3.5, 3.84]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.1, 0.21, 0.31, 0.4, 0.5, 0.58, 0.66, 0.74, 0.8, 0.86, 0.91, 0.95, 0.97, 0.99, 1.0, 1.0, 0.98, 0.96, 0.92, 0.88, 0.83, 0.76, 0.69, 0.61, 0.52, 0.44, 0.34, 0.24, 0.14]<EOS_Y><SOS_EQ>', '<SOS_Y>[-1.15, -1.06, -0.96, -0.87, -0.77, -0.67, -0.58, -0.48, -0.38, -0.29, -0.2, -0.09, -0.0, 0.09, 0.19, 0.29, 0.39, 0.48, 0.57, 0.68, 0.77, 0.86, 0.96, 1.06, 1.15, 1.25, 1.35, 1.44, 1.54, 1.63]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.51, -0.48, -0.44, -0.4, -0.36, -0.32, -0.29, -0.25, -0.21, -0.18, -0.14, -0.1, -0.06, -0.03, 0.01, 0.05, 0.09, 0.13, 0.16, 0.2, 0.24, 0.28, 0.32, 0.35, 0.39, 0.43, 0.47, 0.5, 0.54, 0.58]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.32, 0.46, 0.56, 0.64, 0.72, 0.79, 0.85, 0.91, 0.96, 1.01, 1.07, 1.11, 1.16, 1.2, 1.24, 1.29, 1.33, 1.36, 1.4, 1.44, 1.47, 1.51, 1.54, 1.57, 1.61, 1.64, 1.67, 1.7, 1.73]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.58, -0.48, -0.36, -0.26, -0.15, -0.04, 0.07, 0.17, 0.29, 0.39, 0.5, 0.61, 0.71, 0.82, 0.93, 1.04, 1.15, 1.26, 1.36, 1.48, 1.58, 1.69, 1.8, 1.9, 2.01, 2.12, 2.23, 2.33, 2.45, 2.55]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.74, -0.75, -0.77, -0.78, -0.79, -0.8, -0.8, -0.79, -0.78, -0.77, -0.76, -0.74, -0.71, -0.69, -0.65, -0.62, -0.57, -0.53, -0.48, -0.42, -0.37, -0.31, -0.24, -0.17, -0.1, -0.02, 0.06, 0.15, 0.24, 0.34]<EOS_Y><SOS_EQ>', '<SOS_Y>[1.51, 1.47, 1.42, 1.37, 1.32, 1.26, 1.2, 1.14, 1.07, 0.99, 0.9, 0.76, 0.72, 0.84, 0.92, 0.98, 1.03, 1.07, 1.11, 1.15, 1.17, 1.2, 1.23, 1.25, 1.27, 1.29, 1.3, 1.32, 1.33, 1.34]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.38, 0.5, 0.63, 0.74, 0.85, 0.97, 1.07, 1.18, 1.29, 1.39, 1.5, 1.61, 1.71, 1.81, 1.92, 2.03, 2.14, 2.24, 2.34, 2.45, 2.55, 2.65, 2.76, 2.86, 2.96, 3.07, 3.18, 3.28, 3.39, 3.49]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.96, 0.98, 1.01, 1.03, 1.05, 1.07, 1.08, 1.1, 1.12, 1.14, 1.16, 1.18, 1.19, 1.21, 1.23, 1.24, 1.26, 1.28, 1.29, 1.31, 1.33, 1.34, 1.36, 1.37, 1.39, 1.4, 1.42, 1.43, 1.45, 1.46]<EOS_Y><SOS_EQ>', '<SOS_Y>[-0.56, -0.52, -0.48, -0.45, -0.41, -0.37, -0.33, -0.29, -0.25, -0.21, -0.17, -0.13, -0.09, -0.05, -0.0, 0.04, 0.08, 0.12, 0.16, 0.21, 0.25, 0.29, 0.33, 0.37, 0.4, 0.44, 0.48, 0.51, 0.55, 0.59]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.23, 0.33, 0.43, 0.52, 0.6, 0.69, 0.76, 0.82, 0.88, 0.92, 0.95, 0.98, 1.0, 1.0, 0.99, 0.98, 0.95, 0.91, 0.87, 0.8, 0.74, 0.67, 0.59, 0.5, 0.41, 0.31, 0.21, 0.11, 0.01, -0.09]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.16, 0.19, 0.21, 0.24, 0.26, 0.29, 0.31, 0.34, 0.36, 0.39, 0.41, 0.43, 0.46, 0.48, 0.5, 0.53, 0.55, 0.57, 0.59, 0.61, 0.63, 0.65, 0.67, 0.69, 0.71, 0.73, 0.75, 0.76, 0.78, 0.8]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.95, 0.97, 1.0, 1.03, 1.05, 1.07, 1.09, 1.11, 1.13, 1.15, 1.16, 1.18, 1.2, 1.21, 1.22, 1.24, 1.25, 1.27, 1.28, 1.29, 1.3, 1.31, 1.32, 1.34, 1.35, 1.36, 1.37, 1.38, 1.39, 1.4]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.56, 0.68, 0.75, 0.8, 0.85, 0.89, 0.92, 0.95, 0.98, 1.01, 1.03, 1.06, 1.08, 1.1, 1.12, 1.14, 1.15, 1.17, 1.18, 1.2, 1.21, 1.23, 1.24, 1.25, 1.27, 1.28, 1.29, 1.3, 1.32]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.82, 0.87, 0.91, 0.94, 0.97, 1.0, 1.02, 1.04, 1.07, 1.09, 1.1, 1.12, 1.14, 1.16, 1.18, 1.19, 1.21, 1.22, 1.23, 1.25, 1.26, 1.27, 1.29, 1.3, 1.31, 1.32, 1.33, 1.34, 1.35, 1.36]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.81, 0.81, 0.81, 0.81, 0.81, 0.81, 0.81, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.78, 0.78, 0.78, 0.78]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.87, 0.88, 0.9, 0.91, 0.91, 0.92, 0.93, 0.94, 0.95, 0.95, 0.96, 0.97, 0.97, 0.98, 0.98, 0.99, 0.99, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 0.99]<EOS_Y><SOS_EQ>', '<SOS_Y>[0.0, 0.09, 0.19, 0.28, 0.37, 0.47, 0.55, 0.62, 0.7, 0.77, 0.83, 0.88, 0.92, 0.96, 0.98, 1.0, 1.0, 0.99, 0.98, 0.95, 0.91, 0.87, 0.81, 0.75, 0.68, 0.59, 0.51, 0.42, 0.31, 0.21]<EOS_Y><SOS_EQ>']\n",
            "WARNING:tensorflow:From /content/symbolicgpt2/modeling.py:143: dense (from tensorflow.python.keras.legacy_tf_layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
            "Instructions for updating:\n",
            "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
            "INFO:tensorflow:Restoring parameters from expSymbolic_Mesh_Simple_GPT2_256_base_model.ckpt-128000\n",
            "🍺Model loaded. \n",
            "\n",
            "0/1000->eq:-sin(1.07*x1+0.55)\n",
            "\n",
            "1/1000->eq:0.86-1.09*x1\n",
            "\n",
            "2/1000->eq:sqrt(-sin(0.1\n",
            "9*x1-0.01))\n",
            "\n",
            "3/1000->eq:sin(sqrt(x1-0.1))<\n",
            "EOS_EQ>\n",
            "\n",
            "4/1000->eq:0.86*x1*\n",
            "*2-0.27*x1+1.42\n",
            "\n",
            "5/1000->eq:0.28*sqrt(x1*\n",
            "*2)\n",
            "\n",
            "6/1000->eq:sin(0.33*x1\n",
            "-0.03)\n",
            "\n",
            "7/1000->eq:sin(x1-0.1)<EOS\n",
            "_EQ>x112)\n",
            "\n",
            "8/1000->eq:0.81*sqrt(\n",
            "x1**2+0.88*x1-0.12)\n",
            "\n",
            "9/1000->eq:sin(x1+0.\n",
            "27)\n",
            "\n",
            "10/1000->eq:<SOS_Y>[0.0, -0.01, -0.02, -0.02, 0.0, 0.06, 0.16, 0.31, 0.55, 0.84, 1\n",
            ".22, 1.74, 2.33, 3.03, 3.94, 4.92, 6.16, 7.46, 8.92, 10.73, 12.58, 14.\n",
            "63, 17.13, 19.63, 22.36, 25.65, 28.9, 32.41, 36.59, 40.68]<EOS_Y><SOS_\n",
            "EQ>-0.6*x1**2+1.39*x1\n",
            "\n",
            "\n",
            "11/1000->eq:0.91*x1**2+s\n",
            "qrt(x1-0.1)\n",
            "\n",
            "12/1000->eq:1.72*x1+0.7<EO\n",
            "S_EQ>\n",
            "\n",
            "13/1000->eq:sin(x\n",
            "1**2-0.51*x1+0.03)\n",
            "\n",
            "14/1000->eq:0.69*sqrt(x1-0\n",
            ".61)\n",
            "\n",
            "15/1000->eq:sqrt(x1**2+0\n",
            ".1*x1-0.06)\n",
            "\n",
            "16/1000->eq:4*\n",
            "x1-0.57\n",
            "\n",
            "17/1000->eq:0.7\n",
            "7*x1\n",
            "\n",
            "18/1000->eq:0.8*sqrt(\n",
            "1-0.54*x1)\n",
            "\n",
            "19/1000->eq:0.\n",
            "63*x1**2+1.24*x1-0.13\n",
            "\n",
            "20/1000->eq:0.82*x1**2\n",
            "-0.03*x1+sin(x1+0.88)\n",
            "\n",
            "21/1000->eq:0.88*sqrt(-\n",
            "0.65*x1-1)\n",
            "\n",
            "22/1000->eq:2*x1+s\n",
            "in(x1)-1.25\n",
            "\n",
            "23/1000->eq:x1*sin(0.95*x1\n",
            "+0.07)-0.03\n",
            "\n",
            "24/1000->eq:-sin(sin(0.33*x1+0.13))\n",
            "\n",
            "25/1000->eq:0.05*x1**3<EOS\n",
            "_EQ>\n",
            "\n",
            "26/1000->eq:0.79*sqrt(x1\n",
            "-0.1)\n",
            "\n",
            "27/1000->eq:sqrt(x1)+0\n",
            ".9*x1-0.37\n",
            "\n",
            "28/1000->eq:1.82*\n",
            "x1-1.53\n",
            "\n",
            "29/1000->eq:1\n",
            ".35*x1**3\n",
            "\n",
            "30/1000->eq:-0.41*x1-sin(0.97*x1-0.42)\n",
            "\n",
            "31/1000->eq:sqrt(sin(x1\n",
            "-0.86))\n",
            "\n",
            "32/1000->eq:0.\n",
            "38*x1**2-0.16*x1-0.07\n",
            "\n",
            "33/1000->eq:sqrt(2)*sqr\n",
            "t(x1-0.1)\n",
            "\n",
            "34/1000->eq:x1**2+0.1*x1\n",
            "+0.67\n",
            "\n",
            "35/1000->eq:0.96*sqrt(0.\n",
            "1-x1)\n",
            "\n",
            "36/1000->eq:-0.11*x1**2+\n",
            "0.49*x1-0.03\n",
            "\n",
            "37/1000->eq:0.85*sqrt(\n",
            "0.1*x1-1)\n",
            "\n",
            "38/1000->eq:sin(0.56*sq\n",
            "rt(-x1-0.1))\n",
            "\n",
            "39/1000->eq:2*x1+0.34<EOS_\n",
            "EQ>\n",
            "\n",
            "40/1000->eq:sin(sin(0.\n",
            "1*x1+0.78))\n",
            "\n",
            "41/1000->eq:0.46*x1**2-\n",
            "0.02*x1\n",
            "\n",
            "42/1000->eq:<SOS_Y>[0.0, -0.02, -0.06, -0.09, -0.09, -0.06, 0.01, 0.13, 0.35, 0.64\n",
            ", 1.01, 1.55, 2.16, 2.91, 3.89, 4.94, 6.3, 7.72, 9.33, 11.35, 13.4, 15\n",
            ".69, 18.49, 21.3, 24.37, 28.08, 31.76, 35.74, 40.49, 45.15]<EOS_Y><SOS\n",
            "_EQ>-0.29*x1**2+1.48*x1-0.03\n",
            "\n",
            "\n",
            "43/1000->eq:sqrt(x1**2-0.5\n",
            "6*x1-0.31)\n",
            "\n",
            "44/1000->eq:(x1-0.25)**\n",
            "(1/4)\n",
            "\n",
            "45/1000->eq:-sin(sin(0.11*x1-0.03))\n",
            "\n",
            "46/1000->eq:2*x1-1\n",
            ".69\n",
            "\n",
            "47/1000->eq:0.72*sqrt(x1-\n",
            "0.1)\n",
            "\n",
            "48/1000->eq:-0.14\n",
            "*x1**2+0.14*x1\n",
            "\n",
            "49/1000->eq:0.89*(-x1-0.\n",
            "1)**(1/4)\n",
            "\n",
            "50/1000->eq:0.79*x1**2-\n",
            "1.06*x1+0.33\n",
            "\n",
            "51/1000->eq:sqrt(-sin(0.0\n",
            "3*x1))\n",
            "\n",
            "52/1000->eq:(x1+0.44)**\n",
            "(1/4)\n",
            "\n",
            "53/1000->eq:1.79*\n",
            "x1-0.75\n",
            "\n",
            "54/1000->eq:sin(0.13*x\n",
            "1+0.59)\n",
            "\n",
            "55/1000->eq:sqrt(x1-0.9\n",
            "9)\n",
            "\n",
            "56/1000->eq:0.06*x1**2\n",
            "-0.14*x1\n",
            "\n",
            "57/1000->eq:<SOS_Y>[0.0, -0.0, -0.0, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.\n",
            "01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.\n",
            "01, -0.01, -0.0, -0.0, 0.0, 0.0, 0.01, 0.01, 0.02, 0.02, 0.03]<EOS_Y><\n",
            "SOS_EQ>0.04*x1-0.03\n",
            "\n",
            "\n",
            "58/1000->eq:sin(sin(x1-0.\n",
            "1))\n",
            "\n",
            "59/1000->eq:1\n",
            ".34*x1**2\n",
            "\n",
            "60/1000->eq:sin(sqrt(x1+0.7\n",
            "3))\n",
            "\n",
            "61/1000->eq:<SOS_Y>[-0.04, -0.08, -0.11, -0.13, -0.15, -0.16, -0.16, -0.16, -0.15,\n",
            " -0.13, -0.11, -0.07, -0.03, 0.01, 0.07, 0.13, 0.21, 0.28, 0.36, 0.45,\n",
            " 0.54, 0.64, 0.76, 0.87, 0.98, 1.11, 1.23, 1.36, 1.51, 1.64]<EOS_Y><SO\n",
            "S_EQ>0.35*x1**2-0.45*x1\n",
            "\n",
            "\n",
            "62/1000->eq:sqrt(sin(x1\n",
            "-0.96))\n",
            "\n",
            "63/1000->eq:sqrt(-sin(0.\n",
            "1*x1-0.03))\n",
            "\n",
            "64/1000->eq:2*x1-0.36<EOS\n",
            "_EQ>\n",
            "\n",
            "65/1000->eq:(x1-0.86)**\n",
            "(1/4)\n",
            "\n",
            "66/1000->eq:2.64*x1-0.1\n",
            "1\n",
            "\n",
            "67/1000->eq:-0.85*x1+sqrt(x1-0.95)+0.12\n",
            "\n",
            "68/1000->eq:x1**2-0.66*x1+0.\n",
            "93*sqrt(-x1)-0.24\n",
            "\n",
            "69/1000->eq:sin(sin(x1-0.\n",
            "1))\n",
            "\n",
            "70/1000->eq:0.79*x1**2-0.\n",
            "04*x1\n",
            "\n",
            "71/1000->eq:sin(0.64*sq\n",
            "rt(x1-0.1))\n",
            "\n",
            "72/1000->eq:-sin(0.76*x1-0.06)*sin(x1-0.93)\n",
            "\n",
            "73/1000->eq:(x1-0.1)**(1/\n",
            "4)\n",
            "\n",
            "74/1000->eq:0.04*x1**2+0.\n",
            "61*sqrt(-x1)-0.19\n",
            "\n",
            "75/1000->eq:-0.38*x1**\n",
            "2-0.37*x1-0.18\n",
            "\n",
            "76/1000->eq:0.59*sqrt(0\n",
            ".85*x1+1)\n",
            "\n",
            "77/1000->eq:x1**2+0.6\n",
            "8*x1+0.08*sqrt(0.84*x1+1)+0.06\n",
            "\n",
            "78/1000->eq:<SOS_Y>[0.0, 0.25, 0.33, 0.38, 0.4, 0.41, 0.4, 0.38, 0.35, 0.31, 0.26,\n",
            " 0.2, 0.14, 0.06, -0.03, -0.12, -0.22, -0.33, -0.44, -0.58, -0.71, -0.\n",
            "84, -1.0, -1.15, -1.31, -1.49, -1.66, -1.84, -2.05, -2.25]<EOS_Y><SOS_\n",
            "EQ>-0.46*x1**2+0.48*x1+0.97*sqrt(x1+0.1)-0.18\n",
            "\n",
            "\n",
            "79/1000->eq:\n",
            "-0.17*x1**2-0.61*x1+0.03*sqrt(x1-0.81)\n",
            "\n",
            "80/1000->eq:0.36*\n",
            "x1**2+0.2*x1-0.36\n",
            "\n",
            "81/1000->eq:0.31*sqrt(x1\n",
            ")*sqrt(0.04*x1-1)\n",
            "\n",
            "82/1000->eq:x1**(5/2\n",
            ")-0.33*x1+0.03\n",
            "\n",
            "83/1000->eq:-sin(0.88*x1-0.68)\n",
            "\n",
            "84/1000->eq:<SOS_Y>[0.39, 0.37, 0.34, 0.32, 0.29, 0.27, 0.24, 0.22, 0.19, 0.16, 0.\n",
            "14, 0.11, 0.09, 0.06, 0.03, 0.01, -0.02, -0.05, -0.07, -0.1, -0.12, -0\n",
            ".15, -0.18, -0.2, -0.23, -0.25, -0.28, -0.3, -0.33, -0.35]<EOS_Y><SOS_\n",
            "EQ>0.41-0.24*x1\n",
            "\n",
            "\n",
            "85/1000->eq:<SOS_Y>[0.0, 0.2, 0.41, 0.58, 0.73, 0.86, 0.95, 0.99, 1.0, 0.96, 0.88,\n",
            " 0.76, 0.61, 0.45, 0.24, 0.04, -0.18, -0.37, -0.55, -0.72, -0.84, -0.9\n",
            "3, -0.99, -1.0, -0.97, -0.89, -0.79, -0.65, -0.46, -0.28]<EOS_Y><SOS_E\n",
            "Q>sin(2*x1-0.2)\n",
            "\n",
            "\n",
            "86/1000->eq:0.75*x1**2*s\n",
            "in(0.7*x1-0.63)-0.07*x1\n",
            "\n",
            "87/1000->eq:x1-0.31<\n",
            "EOS_EQ>\n",
            "\n",
            "88/1000->eq:0.68*x1\n",
            "**2-1.39*x1+0.66\n",
            "\n",
            "89/1000->eq:sqrt(x1-0.\n",
            "2)\n",
            "\n",
            "90/1000->eq:x1**2+0\n",
            ".65*x1-0.36\n",
            "\n",
            "91/1000->eq:-0.04*x1**2+\n",
            "0.41*x1-0.02*sqrt(-x1)\n",
            "\n",
            "92/1000->eq:sqrt(x1-0.1)-s\n",
            "in(0.1*x1)\n",
            "\n",
            "93/1000->eq:sin(x1)+sin\n",
            "(x1-0.57)\n",
            "\n",
            "94/1000->eq:0.92*sqrt(\n",
            "0.65*x1+1)\n",
            "\n",
            "95/1000->eq:-2*x1*sin(0.55*x1-0.07)+0.83\n",
            "\n",
            "96/1000->eq:sin(sqrt(x1-0.08\n",
            "))\n",
            "\n",
            "97/1000->eq:(x1-0.1)**(1/\n",
            "4)\n",
            "\n",
            "98/1000->eq:0\n",
            "\n",
            "99/1000->eq:2*x1*sin(0.8\n",
            "8*x1-0.06)\n",
            "\n",
            "100/1000->eq:sqrt(x1+\n",
            "0.12)\n",
            "\n",
            "101/1000->eq:sin(x1-0.1)<EOS\n",
            "_EQ>)\n",
            "\n",
            "102/1000->eq:sqrt(x1)+si\n",
            "n(x1+0.2)\n",
            "\n",
            "103/1000->eq:<SOS_Y>[0.0, -0.11, -0.24, -0.37, -0.51, -0.67, -0.8, -0.9, -0.98, -1.\n",
            "0, -0.95, -0.82, -0.62, -0.35, 0.01, 0.34, 0.68, 0.9, 1.0, 0.92, 0.66,\n",
            " 0.28, -0.23, -0.66, -0.94, -0.98, -0.73, -0.27, 0.34, 0.81]<EOS_Y><SO\n",
            "S_EQ>-sin(0.83*x1**2+0.77*x1-0.1)\n",
            "\n",
            "\n",
            "104/1000->eq:sqrt(x1**2+0\n",
            ".49*x1-0.06)\n",
            "\n",
            "105/1000->eq:0.94*sqrt(x1\n",
            "**2-0.1*x1)\n",
            "\n",
            "106/1000->eq:sin(sin(x1-0.\n",
            "1))\n",
            "\n",
            "107/1000->eq:sin(x1-0.1)<EOS\n",
            "_EQ>x1)\n",
            "\n",
            "108/1000->eq:sin(sqrt(x1-0.29\n",
            "))\n",
            "\n",
            "109/1000->eq:0.04*sqrt(\n",
            "x1)+1.28*sqrt(0.09-x1)\n",
            "\n",
            "110/1000->eq:x1+0.39<EOS\n",
            "_EQ>\n",
            "\n",
            "111/1000->eq:1.69*x1-0.13\n",
            "\n",
            "112/1000->eq:-0.49*x1*sqrt(0.56*x1-1)+0.04\n",
            "\n",
            "113/1000->eq:0.55*sqrt(\n",
            "x1**2-0.1*x1)\n",
            "\n",
            "114/1000->eq:0.44*sqrt(0.84\n",
            "*x1-1)\n",
            "\n",
            "115/1000->eq:0.19-1.55*x1\n",
            "\n",
            "116/1000->eq:-0.59*x1*sqrt(-x1)+0.44\n",
            "\n",
            "117/1000->eq:0.83*sqrt(x1\n",
            "**2-0.1*x1)\n",
            "\n",
            "118/1000->eq:sin(sin(x1-0.\n",
            "1))\n",
            "\n",
            "119/1000->eq:2*x1+0\n",
            ".88*sin(x1+0.65)\n",
            "\n",
            "120/1000->eq:0.76*sqrt(-\n",
            "x1**2+0.11*x1)\n",
            "\n",
            "121/1000->eq:-0.08*x1\n",
            "**3+0.33*x1\n",
            "\n",
            "122/1000->eq:1.28*sqrt(\n",
            "0.49*x1**2+x1+0.49)\n",
            "\n",
            "123/1000->eq:sin(sin(0.48\n",
            "*x1-0.04))\n",
            "\n",
            "124/1000->eq:-0.05*x1**\n",
            "2+0.77*x1+0.22\n",
            "\n",
            "125/1000->eq:0.79*sqrt(x1\n",
            "+0.67)\n",
            "\n",
            "126/1000->eq:<SOS_Y>[0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.0, -0.01, -0.02, -0.0\n",
            "4, -0.07, -0.1, -0.14, -0.2, -0.26, -0.34, -0.43, -0.53, -0.65, -0.78,\n",
            " -0.92, -1.09, -1.27, -1.46, -1.7, -1.93, -2.19, -2.49, -2.79]<EOS_Y><\n",
            "SOS_EQ>-0.06*x1**2\n",
            "\n",
            "\n",
            "127/1000->eq:sin(0.82*\n",
            "x1-0.28)\n",
            "\n",
            "128/1000->eq:sin(s\n",
            "in(x1-0.63))\n",
            "\n",
            "129/1000->eq:sin(0.\n",
            "42*x1**2+0.08*x1-0.03)\n",
            "\n",
            "130/1000->eq:-0.03*x1-0.31\n",
            "\n",
            "131/1000->eq:<SOS_Y>[-0.33, -0.13, 0.08, 0.28, 0.47, 0.65, 0.79, 0.89, 0.97, 1.0, 0\n",
            ".99, 0.93, 0.84, 0.71, 0.55, 0.37, 0.16, -0.04, -0.24, -0.45, -0.62, -\n",
            "0.76, -0.88, -0.96, -1.0, -0.99, -0.95, -0.86, -0.73, -0.58]<EOS_Y><SO\n",
            "S_EQ>sin(2*x1-0.53)\n",
            "\n",
            "\n",
            "132/1000->eq:0.44-0.\n",
            "14*x1\n",
            "\n",
            "133/1000->eq:0.88*sqrt\n",
            "(1-0.52*x1)\n",
            "\n",
            "134/1000->eq:-sin(0.3*x1**2+0.05*x1)\n",
            "\n",
            "135/1000->eq:0.93*sqrt(x1-\n",
            "0.1)\n",
            "\n",
            "136/1000->eq:1.2*sqrt(0.\n",
            "79*x1+1)\n",
            "\n",
            "137/1000->eq:0.14*sqrt(-\n",
            "x1**2)\n",
            "\n",
            "138/1000->eq:-0.87*x1**2+0.08*x1*sqrt(x1+0.09)\n",
            "\n",
            "139/1000->eq:2*x1+0.53*sqrt\n",
            "(-x1)+0.17\n",
            "\n",
            "140/1000->eq:x1**2+0\n",
            ".55*x1-0.06\n",
            "\n",
            "141/1000->eq:-0.58*x1**2+0.13*x1\n",
            "\n",
            "142/1000->eq:0.87*x1-0.\n",
            "05\n",
            "\n",
            "143/1000->eq:x1**2+0.4\n",
            "3*x1-0.04\n",
            "\n",
            "144/1000->eq:0.39*\n",
            "x1**2-0.79*x1+0.13\n",
            "\n",
            "145/1000->eq:0.41*sqrt(x1*\n",
            "*2-0.07*x1)\n",
            "\n",
            "146/1000->eq:x1-0.1<EOS_E\n",
            "Q>\n",
            "\n",
            "147/1000->eq:0.39*sqrt(x\n",
            "1-0.1)\n",
            "\n",
            "148/1000->eq:sin(0.36*x1-0.86)\n",
            "\n",
            "149/1000->eq:-0.14\n",
            "*x1**2+2.08*x1-0.95\n",
            "\n",
            "150/1000->eq:x1**2-0.17*x1\n",
            "+sqrt(x1+0.12)-0.24\n",
            "\n",
            "151/1000->eq:sqrt(x1-0.09)\n",
            "*sin(x1-0.12)\n",
            "\n",
            "152/1000->eq:1.29*x1-0.46\n",
            "\n",
            "\n",
            "153/1000->eq:0.59*sqrt(\n",
            "x1-0.31)\n",
            "\n",
            "154/1000->eq:sin(0.72*x1-0.0\n",
            "7)\n",
            "\n",
            "155/1000->eq:0.82*(x1-0.\n",
            "96)**(1/4)\n",
            "\n",
            "156/1000->eq:0.57*sqrt(x\n",
            "1-0.48)\n",
            "\n",
            "157/1000->eq:sin(x1-0.1)<EOS\n",
            "_EQ>x1)\n",
            "\n",
            "158/1000->eq:0.85*(-0.1\n",
            "9*x1-1)**(1/4)\n",
            "\n",
            "159/1000->eq:-0.17*x1**2+0.03*x1*sqrt(x1+0.85)\n",
            "\n",
            "160/1000->eq:0.14*x1*sqr\n",
            "t(-x1)\n",
            "\n",
            "161/1000->eq:0.19*x1**(3/2)-0.99*x1**2\n",
            "\n",
            "162/1000->eq:sqrt(x1-0.\n",
            "99)*sqrt(x1-0.09)\n",
            "\n",
            "163/1000->eq:0.8*sqrt(0\n",
            ".09*x1-1)\n",
            "\n",
            "164/1000->eq:-sin(0.13*x1-0.02)\n",
            "\n",
            "165/1000->eq:0.16*x1-0.71*sqrt(1-0.05*x1)\n",
            "\n",
            "166/1000->eq:0.41*sqrt(x1**\n",
            "2-0.11*x1)\n",
            "\n",
            "167/1000->eq:-0.47*x1*sin(x1-0.12)\n",
            "\n",
            "168/1000->eq:0.76*sqrt(\n",
            "x1-0.1)\n",
            "\n",
            "169/1000->eq:<SOS_Y>[0.18, 0.21, 0.23, 0.24, 0.24, 0.24, 0.22, 0.2, 0.17, 0.14, 0.1\n",
            ", 0.05, 0.0, -0.05, -0.12, -0.18, -0.25, -0.32, -0.38, -0.46, -0.53, -\n",
            "0.6, -0.67, -0.73, -0.79, -0.86, -0.91, -0.96, -1.01, -1.05]<EOS_Y><SO\n",
            "S_EQ>-sin(0.25*x1**2-0.31*x1-0.17)\n",
            "\n",
            "\n",
            "170/1000->eq:sin(0.87*x1)\n",
            "\n",
            "\n",
            "171/1000->eq:1.39*x1*\n",
            "sqrt(x1-0.17)+0.44\n",
            "\n",
            "172/1000->eq:sin(sqrt(x1-0.1))<\n",
            "EOS_EQ>x1)\n",
            "\n",
            "173/1000->eq:sin(0.64*sqr\n",
            "t(0.1-x1))\n",
            "\n",
            "174/1000->eq:sin(0.75*\n",
            "x1-0.37)\n",
            "\n",
            "175/1000->eq:(x1-0.1)**(1/\n",
            "4)\n",
            "\n",
            "176/1000->eq:1.01*x1+1.27<\n",
            "EOS_EQ>\n",
            "\n",
            "177/1000->eq:sin(x1-0.1)<EOS\n",
            "_EQ>x108)\n",
            "\n",
            "178/1000->eq:<SOS_Y>[0.0, 0.01, -0.0, -0.02, -0.06, -0.11, -0.17, -0.24, -0.34, -0.\n",
            "43, -0.53, -0.65, -0.75, -0.84, -0.93, -0.98, -1.0, -0.97, -0.9, -0.75\n",
            ", -0.57, -0.33, -0.03, 0.26, 0.54, 0.79, 0.95, 1.0, 0.91, 0.7]<EOS_Y><\n",
            "SOS_EQ>-sin(0.66*x1**2-0.18*x1)\n",
            "\n",
            "\n",
            "179/1000->eq:-sin(0.4*x1-0.06)\n",
            "\n",
            "180/1000->eq:x1**2\n",
            "+0.8*x1-0.22\n",
            "\n",
            "181/1000->eq:2.22*x1-1.\n",
            "05\n",
            "\n",
            "182/1000->eq:0.09*x1+\n",
            "sin(0.89*x1-0.95)+0.85\n",
            "\n",
            "183/1000->eq:0.37*x\n",
            "1**2-0.39*x1+0.03\n",
            "\n",
            "184/1000->eq:sin(0.4*x1+0.\n",
            "63)\n",
            "\n",
            "185/1000->eq:0.09*x1**2\n",
            "-0.4\n",
            "\n",
            "186/1000->eq:2*x1-0.64<E\n",
            "OS_EQ>\n",
            "\n",
            "187/1000->eq:x1**2\n",
            "-0.99*x1+0.17\n",
            "\n",
            "188/1000->eq:0.08-0.81*x1\n",
            "\n",
            "189/1000->eq:0.32*sqrt(x1*\n",
            "*2)\n",
            "\n",
            "190/1000->eq:0.09*x1**2+0.93*x1\n",
            "\n",
            "191/1000->eq:sqrt(sin(x1-0.\n",
            "1))\n",
            "\n",
            "192/1000->eq:sin(0.95*sqrt(x1\n",
            "-0.1))\n",
            "\n",
            "193/1000->eq:sqrt(-sin(0.\n",
            "05*x1))\n",
            "\n",
            "194/1000->eq:x1-0.1<EOS_E\n",
            "Q>\n",
            "\n",
            "195/1000->eq:sqrt(x1-0.1)\n",
            "\n",
            "\n",
            "196/1000->eq:0.1-0.12*x1\n",
            "\n",
            "197/1000->eq:0.57*x1**2<E\n",
            "OS_EQ>\n",
            "\n",
            "198/1000->eq:0.96*sqrt(-x1\n",
            "-0.71)\n",
            "\n",
            "199/1000->eq:-0.14*x1**(3/2)\n",
            "\n",
            "200/1000->eq:2*x1*sin(x\n",
            "1-0.19)\n",
            "\n",
            "201/1000->eq:0.74*sqrt(\n",
            "x1)+2*x1\n",
            "\n",
            "202/1000->eq:0.87*sqrt(\n",
            "-x1**2+0.09*x1)\n",
            "\n",
            "203/1000->eq:2*sin(x1-0.19\n",
            ")\n",
            "\n",
            "204/1000->eq:-sin(0.04*x1**2-0.01*x1)\n",
            "\n",
            "205/1000->eq:sin(sin(x1+0\n",
            ".35))\n",
            "\n",
            "206/1000->eq:0.47*x1-0.\n",
            "03\n",
            "\n",
            "207/1000->eq:sin(1.38\n",
            "*x1-0.11)\n",
            "\n",
            "208/1000->eq:1.0*sqrt(x\n",
            "1-0.1)\n",
            "\n",
            "209/1000->eq:(x1-0.15)*\n",
            "*(1/4)\n",
            "\n",
            "210/1000->eq:<SOS_Y>[0.0, 0.01, 0.02, 0.04, 0.05, 0.06, 0.06, 0.07, 0.06, 0.06, 0.0\n",
            "5, 0.03, 0.01, -0.02, -0.06, -0.11, -0.17, -0.23, -0.31, -0.4, -0.5, -\n",
            "0.61, -0.75, -0.89, -1.05, -1.23, -1.42, -1.62, -1.86, -2.1]<EOS_Y><SO\n",
            "S_EQ>-0.21*x1**2*sqrt(-x1)+0.43*x1-0.03\n",
            "\n",
            "\n",
            "211/1000->eq:sin(sqrt(x1-0.1))<\n",
            "EOS_EQ>0.1)\n",
            "\n",
            "212/1000->eq:sin(s\n",
            "in(x1+0.68))\n",
            "\n",
            "213/1000->eq:0.98-0.84*x1\n",
            "\n",
            "214/1000->eq:sqrt(x1)+0.\n",
            "66*sqrt(-x1-0.93)\n",
            "\n",
            "215/1000->eq:2*x1-0.2<EOS_E\n",
            "Q>\n",
            "\n",
            "216/1000->eq:<SOS_Y>[-0.4, -0.21, 0.01, 0.2, 0.39, 0.59, 0.74, 0.86, 0.95, 0.99, 1.\n",
            "0, 0.96, 0.88, 0.77, 0.61, 0.44, 0.23, 0.04, -0.16, -0.37, -0.55, -0.7\n",
            "1, -0.84, -0.93, -0.99, -1.0, -0.97, -0.9, -0.78, -0.64]<EOS_Y><SOS_EQ\n",
            ">sin(2*x1-0.61)\n",
            "\n",
            "\n",
            "217/1000->eq:0.03*x1*sqrt\n",
            "(-x1)\n",
            "\n",
            "218/1000->eq:0.86*sqrt(\n",
            "-x1**2-0.74*x1+0.38)\n",
            "\n",
            "219/1000->eq:<SOS_Y>[-0.56, -0.38, -0.17, 0.03, 0.23, 0.43, 0.6, 0.75, 0.88, 0.96, \n",
            "0.99, 0.99, 0.95, 0.87, 0.74, 0.59, 0.4, 0.21, 0.01, -0.21, -0.4, -0.5\n",
            "7, -0.74, -0.86, -0.94, -0.99, -1.0, -0.96, -0.88, -0.77]<EOS_Y><SOS_E\n",
            "Q>sin(2*x1-0.79)\n",
            "\n",
            "\n",
            "220/1000->eq:<SOS_Y>[0.0, 0.05, 0.09, 0.12, 0.14, 0.16, 0.17, 0.17, 0.16, 0.15, 0.1\n",
            "3, 0.1, 0.06, 0.02, -0.04, -0.1, -0.17, -0.25, -0.33, -0.43, -0.52, -0\n",
            ".63, -0.75, -0.87, -0.99, -1.14, -1.28, -1.43, -1.6, -1.77]<EOS_Y><SOS\n",
            "_EQ>-0.35*x1**2+sin(0.52*x1-0.04)\n",
            "\n",
            "\n",
            "221/1000->eq:x1**2-0.1*x1+\n",
            "sqrt(x1+0.12)-0.24\n",
            "\n",
            "222/1000->eq:2*x1+0.62<EOS_\n",
            "EQ>\n",
            "\n",
            "223/1000->eq:sin(sin(x1-0.\n",
            "1))\n",
            "\n",
            "224/1000->eq:-0.31*x1-0.01\n",
            "\n",
            "225/1000->eq:0.96*sqrt(\n",
            "-0.51*x1**2+x1+0.4)\n",
            "\n",
            "226/1000->eq:0.86*x1+0.2\n",
            "1\n",
            "\n",
            "227/1000->eq:sin(x1*\n",
            "*2-0.06*x1)\n",
            "\n",
            "228/1000->eq:sqrt(-sin(0.97\n",
            "*x1-0.1))\n",
            "\n",
            "229/1000->eq:0.93*x1-0.0\n",
            "9*sqrt(x1-0.08)\n",
            "\n",
            "230/1000->eq:<SOS_Y>[0.04, 0.01, -0.03, -0.07, -0.1, -0.14, -0.16, -0.19, -0.2, -0.\n",
            "21, -0.21, -0.2, -0.17, -0.14, -0.08, -0.01, 0.08, 0.19, 0.32, 0.48, 0\n",
            ".65, 0.84, 1.08, 1.33, 1.61, 1.94, 2.28, 2.65, 3.09, 3.53]<EOS_Y><SOS_\n",
            "EQ>0.55*x1**2-0.79*x1+0.58\n",
            "\n",
            "\n",
            "231/1000->eq:0.66*x1-0.0\n",
            "4\n",
            "\n",
            "232/1000->eq:0.37*x1*sqrt(-\n",
            "x1)-0.02\n",
            "\n",
            "233/1000->eq:0.63*sqrt(x1\n",
            "-0.1)\n",
            "\n",
            "234/1000->eq:-sin(sin(0.55*x1-0.05))\n",
            "\n",
            "235/1000->eq:sin(sin(0.76*x\n",
            "1-0.06))\n",
            "\n",
            "236/1000->eq:sqrt(x1-0.\n",
            "27)\n",
            "\n",
            "237/1000->eq:<SOS_Y>[0.0, -0.09, -0.18, -0.24, -0.3, -0.34, -0.37, -0.39, -0.4, -0.\n",
            "4, -0.38, -0.35, -0.31, -0.26, -0.19, -0.11, -0.02, 0.08, 0.19, 0.32, \n",
            "0.46, 0.6, 0.78, 0.95, 1.13, 1.34, 1.54, 1.76, 2.01, 2.25]<EOS_Y><SOS_\n",
            "EQ>0.63*x1**2-1.08*x1+0.1\n",
            "\n",
            "\n",
            "238/1000->eq:0.91*x1-0.1\n",
            "2\n",
            "\n",
            "239/1000->eq:0.75*sqrt(x\n",
            "1)*sqrt(0.11-x1)\n",
            "\n",
            "240/1000->eq:sin(x1+0.\n",
            "18)\n",
            "\n",
            "241/1000->eq:sqrt(sin(\n",
            "0.55*x1-0.76))\n",
            "\n",
            "242/1000->eq:0.25*x1**2+1.\n",
            "03*x1+0.33\n",
            "\n",
            "243/1000->eq:sin(x\n",
            "1**2-0.08*x1)\n",
            "\n",
            "244/1000->eq:sin(0.25*x1**2-0\n",
            ".02*x1)\n",
            "\n",
            "245/1000->eq:-sin(0.04*x1)*sin(x1-0.13)\n",
            "\n",
            "246/1000->eq:-0.91*x1**(5/2)+0.44*x1-0.02\n",
            "\n",
            "247/1000->eq:<SOS_Y>[0.0, -0.0, -0.01, -0.02, -0.03, -0.05, -0.07, -0.08, -0.1, -0.\n",
            "11, -0.12, -0.12, -0.12, -0.11, -0.1, -0.08, -0.04, -0.0, 0.05, 0.12, \n",
            "0.2, 0.28, 0.4, 0.52, 0.66, 0.83, 1.0, 1.19, 1.42, 1.66]<EOS_Y><SOS_EQ\n",
            ">0.05*x1**2+1.02*x1\n",
            "\n",
            "\n",
            "248/1000->eq:0.14*x1-\n",
            "0.05\n",
            "\n",
            "249/1000->eq:1.68*x1+0.5\n",
            "8\n",
            "\n",
            "250/1000->eq:1.05*\n",
            "x1**2+0.08*x1-0.68\n",
            "\n",
            "251/1000->eq:0.11*x1-0.6\n",
            "\n",
            "252/1000->eq:-0.06*x1+sin(x1)-0.1\n",
            "\n",
            "253/1000->eq:0.2*sqrt(0.33*x\n",
            "1-1)\n",
            "\n",
            "254/1000->eq:-0.59*x1**3-0.77*x1\n",
            "\n",
            "255/1000->eq:sin(\n",
            "x1**2+0.18*x1-0.02)\n",
            "\n",
            "256/1000->eq:0.24*x1**2*\n",
            "sqrt(x1-0.27)\n",
            "\n",
            "257/1000->eq:0.11*x1**3<\n",
            "EOS_EQ>\n",
            "\n",
            "258/1000->eq:sqrt(x1)-0.\n",
            "25*x1-0.34\n",
            "\n",
            "259/1000->eq:-0.75*x1+0.06*sqrt(-x1)+0.27\n",
            "\n",
            "260/1000->eq:0.33*sqrt(x\n",
            "1**2-0.04*x1)\n",
            "\n",
            "261/1000->eq:2*x1**(3/4)\n",
            "-0.61\n",
            "\n",
            "262/1000->eq:sin(x1-0.1)<EOS\n",
            "_EQ>x108)\n",
            "\n",
            "263/1000->eq:si\n",
            "n(0.31*x1**2-0.57*x1+0.03)\n",
            "\n",
            "264/1000->eq:sqrt(x1**2+0\n",
            ".08*x1-0.06)\n",
            "\n",
            "265/1000->eq:0.39*x1**2-1.03*x1+0.1\n",
            "\n",
            "266/1000->eq:x1+\n",
            "0.82*sin(x1+0.37)\n",
            "\n",
            "267/1000->eq:-sin(sin(0.53*x1-0.05))\n",
            "\n",
            "268/1000->eq:sqrt(x1)+x1\n",
            "**(x1-0.27\n",
            "\n",
            "269/1000->eq:sin(0.12*x1**\n",
            "2)\n",
            "\n",
            "270/1000->eq:sqrt(x1-0.1)\n",
            "\n",
            "\n",
            "271/1000->eq:sin(0.48*x1+0\n",
            ".3)\n",
            "\n",
            "272/1000->eq:0.65*x1-0.\n",
            "04\n",
            "\n",
            "273/1000->eq:-0.05*x1**2-0.16*x1-0.16\n",
            "\n",
            "274/1000->eq:0.\n",
            "28*x1**2-0.47*x1-0.04\n",
            "\n",
            "275/1000->eq:0.27*x1**2\n",
            "+0.01*x1\n",
            "\n",
            "276/1000->eq:0.16*x1**\n",
            "2-0.06*x1+0.02\n",
            "\n",
            "277/1000->eq:sin(x1-0.1)<EOS\n",
            "_EQ>x112)\n",
            "\n",
            "278/1000->eq:-0.42*x1-0.22\n",
            "\n",
            "279/1000->eq:sin(x1-0.1)<EOS\n",
            "_EQ>x1)\n",
            "\n",
            "280/1000->eq:0.87*(x1-0.1)\n",
            "**(1/4)\n",
            "\n",
            "281/1000->eq:si\n",
            "n(sin(x1+0.82))\n",
            "\n",
            "282/1000->eq:0.93*(-x1-0\n",
            ".1)**(1/4)\n",
            "\n",
            "283/1000->eq:sqrt(x1)-0.\n",
            "13*x1\n",
            "\n",
            "284/1000->eq:0.02*x1+0.7\n",
            "5\n",
            "\n",
            "285/1000->eq:-0.02*x1**3\n",
            "\n",
            "286/1000->eq:0.56*sqrt(\n",
            "x1)-sin(0.29*x1-0.29)\n",
            "\n",
            "287/1000->eq:sin(0.16*x1\n",
            "**2)\n",
            "\n",
            "288/1000->eq:(x1-0.1)**(1/\n",
            "4)\n",
            "\n",
            "289/1000->eq:sqrt(x1)+0.\n",
            "8*x1**2-0.3*x1-0.61\n",
            "\n",
            "290/1000->eq:-sin(0.02*x1-0.02)\n",
            "\n",
            "291/1000->eq:<SOS_Y>[-0.61, -0.46, -0.28, -0.1, 0.08, 0.27, 0.44, 0.59, 0.74, 0.84,\n",
            " 0.93, 0.98, 1.0, 0.99, 0.93, 0.86, 0.74, 0.61, 0.46, 0.27, 0.1, -0.08\n",
            ", -0.27, -0.44, -0.59, -0.74, -0.85, -0.93, -0.98, -1.0]<EOS_Y><SOS_EQ\n",
            ">sin(1.77*x1-0.8)\n",
            "\n",
            "\n",
            "292/1000->eq:-sin(\n",
            "0.31*x1-0.78)\n",
            "\n",
            "293/1000->eq:sin(x1-0.06)<E\n",
            "OS_EQ>\n",
            "\n",
            "294/1000->eq:sin(sin(x\n",
            "1+0.25))\n",
            "\n",
            "295/1000->eq:sqrt(x1)+si\n",
            "n(x1-0.38)\n",
            "\n",
            "296/1000->eq:-0.84*x1**2-1.62*x1-1.0\n",
            "\n",
            "297/1000->eq:1.49*x1-0.\n",
            "25\n",
            "\n",
            "298/1000->eq:0.82*sqrt(\n",
            "0.79*x1**2-x1+0.09)\n",
            "\n",
            "299/1000->eq:0.69*sqrt(\n",
            "x1+0.91)\n",
            "\n",
            "300/1000->eq:0.91*sqrt(x1-\n",
            "0.1)\n",
            "\n",
            "301/1000->eq:sin(sin(x1-0.\n",
            "1))\n",
            "\n",
            "302/1000->eq:sin(s\n",
            "in(x1-0.49))\n",
            "\n",
            "303/1000->eq:sin(sin(x1-0.\n",
            "1))\n",
            "\n",
            "304/1000->eq:sin(0.05*x1\n",
            ")\n",
            "\n",
            "305/1000->eq:1.75*x1-0.1\n",
            "5\n",
            "\n",
            "306/1000->eq:0.15\n",
            "*x1**(3/2)+x1**2\n",
            "\n",
            "307/1000->eq:1.1*x1**2-0.54*\n",
            "x1+0.03*sin(0.84*x1-0.12)\n",
            "\n",
            "308/1000->eq:-0.72*x1*sqrt(-x1)+0.12\n",
            "\n",
            "309/1000->eq:0.26*x1**2+\n",
            "0.42*x1-0.03\n",
            "\n",
            "310/1000->eq:x1-0.1<EOS_E\n",
            "Q>\n",
            "\n",
            "311/1000->eq:x1**2-0\n",
            ".44*x1+0.03\n",
            "\n",
            "312/1000->eq:1.96*x1+0.9\n",
            "9*sqrt(0.68-x1)+0.2\n",
            "\n",
            "313/1000->eq:sin(0.64*x1-0.0\n",
            "6)\n",
            "\n",
            "314/1000->eq:-0.81*s\n",
            "qrt(x1-0.91)+sin(0.21*x1)\n",
            "\n",
            "315/1000->eq:sqrt(x1+0.4\n",
            "1)\n",
            "\n",
            "316/1000->eq:(x1+0.72)**(\n",
            "1/4)\n",
            "\n",
            "317/1000->eq:-0.\n",
            "19*x1**2+0.47*x1+0.03\n",
            "\n",
            "318/1000->eq:sqrt(-sin(\n",
            "0.19*x1+0.55))\n",
            "\n",
            "319/1000->eq:x1-0.5\n",
            "9\n",
            "\n",
            "320/1000->eq:0.19*x1-0.0\n",
            "2\n",
            "\n",
            "321/1000->eq:sin(0.88*x1-\n",
            "0.09)\n",
            "\n",
            "322/1000->eq:0.94*(-x1-0.1)\n",
            "**(1/4)\n",
            "\n",
            "323/1000->eq:0.89*x1**(3\n",
            "/2)-0.21\n",
            "\n",
            "324/1000->eq:-sin(0.32*x1-0.03)\n",
            "\n",
            "325/1000->eq:<SOS_Y>[0.0, 0.28, 0.38, 0.42, 0.43, 0.4, 0.35, 0.27, 0.16, 0.03, -0.1\n",
            "2, -0.3, -0.5, -0.72, -0.98, -1.24, -1.55, -1.86, -2.18, -2.57, -2.94,\n",
            " -3.33, -3.78, -4.22, -4.67, -5.2, -5.7, -6.21, -6.81, -7.37]<EOS_Y><S\n",
            "OS_EQ>-0.98*x1**2+0.77*sqrt(x1-0.1)\n",
            "\n",
            "\n",
            "326/1000->eq:0.98*sqrt(0.1\n",
            "-x1)\n",
            "\n",
            "327/1000->eq:sin(0.08*x\n",
            "1+0.26)\n",
            "\n",
            "328/1000->eq:<SOS_Y>[-0.75, -0.7, -0.64, -0.59, -0.52, -0.45, -0.39, -0.32, -0.24, \n",
            "-0.17, -0.1, -0.01, 0.06, 0.13, 0.21, 0.28, 0.36, 0.43, 0.49, 0.56, 0.\n",
            "62, 0.68, 0.73, 0.78, 0.83, 0.87, 0.9, 0.93, 0.96, 0.98]<EOS_Y><SOS_EQ\n",
            ">sin(0.76*x1-0.93)\n",
            "\n",
            "\n",
            "329/1000->eq:2*x1-\n",
            "0.81\n",
            "\n",
            "330/1000->eq:-sin(0.74*x1-0.09)\n",
            "\n",
            "331/1000->eq:2*x1*si\n",
            "n(x1-0.06)-0.83\n",
            "\n",
            "332/1000->eq:0.1*x1+0.12\n",
            "\n",
            "\n",
            "333/1000->eq:x1-0.1<EOS_E\n",
            "Q>\n",
            "\n",
            "334/1000->eq:2*sin(x1-0.19\n",
            ")\n",
            "\n",
            "335/1000->eq:sin(x1-0.\n",
            "18)\n",
            "\n",
            "336/1000->eq:sqrt(x1-0.1)\n",
            "\n",
            "\n",
            "337/1000->eq:0.89*x1*\n",
            "*2+0.37*x1+0.21\n",
            "\n",
            "338/1000->eq:-0.09*sqrt(x\n",
            "1)+x1\n",
            "\n",
            "339/1000->eq:sin(0.79*s\n",
            "qrt(x1-0.1))\n",
            "\n",
            "340/1000->eq:0.59*sqrt(x1)\n",
            "+sin(x1-0.31)\n",
            "\n",
            "341/1000->eq:-sin(0.82*x1-0.09)\n",
            "\n",
            "342/1000->eq:-sin(0.3*x1**2-0.04*x1)\n",
            "\n",
            "343/1000->eq:sin(0.49*sqr\n",
            "t(x1-0.1))\n",
            "\n",
            "344/1000->eq:0.88*(-0.09*\n",
            "x1-1)**(1/4)\n",
            "\n",
            "345/1000->eq:sin(si\n",
            "n(x1+0.42))\n",
            "\n",
            "346/1000->eq:x1-0.1<EOS_E\n",
            "Q>\n",
            "\n",
            "347/1000->eq:-0.76*x1**2+0.82*x1-0.06\n",
            "\n",
            "348/1000->eq:1.72*x1+0.7\n",
            "3*sqrt(x1+0.91)-0.03\n",
            "\n",
            "349/1000->eq:0.17*sqrt(x1**\n",
            "2)\n",
            "\n",
            "350/1000->eq:-0.81*x1**2-0.13*x1+0.01\n",
            "\n",
            "351/1000->eq:0.13\n",
            "*x1**2-0.3*x1+0.33\n",
            "\n",
            "352/1000->eq:\n",
            "sin(x1-0.99)*sin(x1-0.09)\n",
            "\n",
            "353/1000->eq:0.79*x1**2-0.04\n",
            "*x1\n",
            "\n",
            "354/1000->eq:0.82*(x1-0.\n",
            "21)**(1/4)\n",
            "\n",
            "355/1000->eq:-0.21*x1**2+0.\n",
            "58*x1+sqrt(x1-0.1)-0.09\n",
            "\n",
            "356/1000->eq:-sin(0.07*\n",
            "x1-0.45)\n",
            "\n",
            "357/1000->eq:0.16*x\n",
            "1**2+0.75*x1-0.3\n",
            "\n",
            "358/1000->eq:sin(0.83*x1\n",
            "+0.48)\n",
            "\n",
            "359/1000->eq:0.44*x1**2\n",
            "+1.36*x1-0.14\n",
            "\n",
            "360/1000->eq:(x1-0.1)**(1/\n",
            "4)\n",
            "\n",
            "361/1000->eq:0.88*sqrt(x\n",
            "1)+sin(x1-0.27)\n",
            "\n",
            "362/1000->eq:sin(x1*\n",
            "*2-0.06*x1)\n",
            "\n",
            "363/1000->eq:<SOS_Y>[1.06, 0.98, 0.9, 0.83, 0.75, 0.67, 0.59, 0.52, 0.44, 0.36, 0.2\n",
            "8, 0.2, 0.13, 0.05, -0.03, -0.11, -0.19, -0.26, -0.34, -0.42, -0.5, -0\n",
            ".57, -0.66, -0.73, -0.81, -0.89, -0.96, -1.04, -1.12, -1.2]<EOS_Y><SOS\n",
            "_EQ>1.16-0.74*x1\n",
            "\n",
            "\n",
            "364/1000->eq:sin(0.73*s\n",
            "qrt(1-0.21*x1))\n",
            "\n",
            "365/1000->eq:sqrt(sin(x1-0.\n",
            "1))\n",
            "\n",
            "366/1000->eq:sqrt(x1)-sin(\n",
            "0.73*x1+0.24)\n",
            "\n",
            "367/1000->eq:x1-0.18<EO\n",
            "S_EQ>\n",
            "\n",
            "368/1000->eq:2.0\n",
            "*x1-1.07\n",
            "\n",
            "369/1000->eq:-0.1*x1**2+0.04*x1\n",
            "\n",
            "370/1000->eq:-0.73*x1**2-0.83*x1-sin(0.73*x1)+0.12\n",
            "\n",
            "371/1000->eq:(x1-0.1)**(1/\n",
            "4)\n",
            "\n",
            "372/1000->eq:-sin(0.04*x1+0.83)\n",
            "\n",
            "373/1000->eq:-0.58*x1*sin(0.3*x1-0.05)\n",
            "\n",
            "374/1000->eq:0.25*\n",
            "x1**2-0.13*x1\n",
            "\n",
            "375/1000->eq:-0.36*sqr\n",
            "t(x1)+x1\n",
            "\n",
            "376/1000->eq:-0.72*x1**2-1.03*x1-0.63\n",
            "\n",
            "377/1000->eq:x1+sin(x1)\n",
            "+0.37\n",
            "\n",
            "378/1000->eq:<SOS_Y>[-0.12, -0.07, 0.01, 0.11, 0.22, 0.37, 0.51, 0.65, 0.8, 0.91, 0\n",
            ".98, 0.99, 0.93, 0.77, 0.51, 0.19, -0.21, -0.56, -0.84, -1.0, -0.94, -\n",
            "0.68, -0.21, 0.29, 0.73, 0.99, 0.91, 0.52, -0.12, -0.69]<EOS_Y><SOS_EQ\n",
            ">sin(x1**2+0.22*x1-0.15)\n",
            "\n",
            "\n",
            "379/1000->eq:-sin(0.91*x1-0.64)\n",
            "\n",
            "380/1000->eq:-sin(sin(0.58*x1+0.54))\n",
            "\n",
            "381/1000->eq:0.31*x1+sin(x\n",
            "1-0.1)-0.1\n",
            "\n",
            "382/1000->eq:0.5*sqrt(x1-\n",
            "0.1)\n",
            "\n",
            "383/1000->eq:-sin(sin(0.57*x1-0.05))\n",
            "\n",
            "384/1000->eq:sin(x1-0.02)\n",
            "\n",
            "\n",
            "385/1000->eq:sqrt(-sin(0.85*x1\n",
            "-0.1))\n",
            "\n",
            "386/1000->eq:x1-0.1<EOS_E\n",
            "Q>\n",
            "\n",
            "387/1000->eq:0.91*sqrt(x1-\n",
            "0.1)\n",
            "\n",
            "388/1000->eq:x1-0.05<EO\n",
            "S_EQ>\n",
            "\n",
            "389/1000->eq:sqrt(x1)+si\n",
            "n(x1-0.31)\n",
            "\n",
            "390/1000->eq:x1**2+0.28\n",
            "*x1+sqrt(x1-0.93)-0.19\n",
            "\n",
            "391/1000->eq:sin(1.2\n",
            "6*x1-0.09)\n",
            "\n",
            "392/1000->eq:-sin(sin(0.53*x1-0.06))\n",
            "\n",
            "393/1000->eq:1.44*x1*sin(\n",
            "0.88*x1-0.06)\n",
            "\n",
            "394/1000->eq:sqrt(x1)+1.\n",
            "13*x1-0.67\n",
            "\n",
            "395/1000->eq:sqrt(x1-0.1)\n",
            "\n",
            "\n",
            "396/1000->eq:sqrt(x1-0.\n",
            "83)\n",
            "\n",
            "397/1000->eq:-0.22*x\n",
            "1+sin(0.43*x1+0.33)+0.58\n",
            "\n",
            "398/1000->eq:1.16-0.86*x1**2\n",
            "\n",
            "399/1000->eq:0.47*x1**2-0.04*\n",
            "x1\n",
            "\n",
            "400/1000->eq:-0.48*x1-0.72\n",
            "\n",
            "401/1000->eq:sin\n",
            "(x1-0.95)\n",
            "\n",
            "402/1000->eq:sin(0.05*x1\n",
            ")\n",
            "\n",
            "403/1000->eq:0.37*x1-0.81\n",
            "\n",
            "404/1000->eq:1.6*x1+0.3\n",
            "*sin(x1+0.2)\n",
            "\n",
            "405/1000->eq:0.2*sqrt(x1**\n",
            "2-0.33*x1+0.01)\n",
            "\n",
            "406/1000->eq:x1**2-0.53\n",
            "*x1+0.03\n",
            "\n",
            "407/1000->eq:0.86*x1-0.08\n",
            "\n",
            "\n",
            "408/1000->eq:<SOS_Y>[0.39, 0.4, 0.42, 0.43, 0.43, 0.42, 0.4, 0.38, 0.34, 0.3, 0.25,\n",
            " 0.18, 0.1, 0.02, -0.08, -0.19, -0.31, -0.44, -0.57, -0.72, -0.87, -1.\n",
            "02, -1.19, -1.36, -1.53, -1.71, -1.88, -2.06, -2.24, -2.41]<EOS_Y><SOS\n",
            "_EQ>-0.78*x1+sin(x1+0.34)\n",
            "\n",
            "\n",
            "409/1000->eq:0.89*x1**2+0.\n",
            "05\n",
            "\n",
            "410/1000->eq:0.88*sqrt(x\n",
            "1-0.1)\n",
            "\n",
            "411/1000->eq:-sqrt(x1-0.12)*sin(0.45*x1-0.04)\n",
            "\n",
            "412/1000->eq:x1**2+0.03*\n",
            "x1\n",
            "\n",
            "413/1000->eq:x1**2+0.58*\n",
            "x1-0.04\n",
            "\n",
            "414/1000->eq:0.92*sqrt(x1\n",
            "-0.1)\n",
            "\n",
            "415/1000->eq:sin(x1-0.1)<EOS\n",
            "_EQ>x194)\n",
            "\n",
            "416/1000->eq:sqrt(sin(x1-\n",
            "0.22))\n",
            "\n",
            "417/1000->eq:-sin(0.52*x1+0.98)\n",
            "\n",
            "418/1000->eq:0.95*x1-0.08<\n",
            "EOS_EQ>\n",
            "\n",
            "419/1000->eq:0.4*sqrt(x1\n",
            "-0.8)\n",
            "\n",
            "420/1000->eq:0.15*x1**2+0.9\n",
            "5*x1\n",
            "\n",
            "421/1000->eq:sin(sin(0.21*x1-0.44))\n",
            "\n",
            "422/1000->eq:sin(sqrt(x1+0.8\n",
            "3))\n",
            "\n",
            "423/1000->eq:sqrt(x1**2-0\n",
            ".37*x1+0.03)\n",
            "\n",
            "424/1000->eq:sin(0.69*sqrt\n",
            "(0.48-x1))\n",
            "\n",
            "425/1000->eq:sin(sin(x1\n",
            "))\n",
            "\n",
            "426/1000->eq:sin(sin(x1-0.\n",
            "1))\n",
            "\n",
            "427/1000->eq:0.84*sqrt(0.1-\n",
            "x1)\n",
            "\n",
            "428/1000->eq:0.6\n",
            "4*x1-0.58\n",
            "\n",
            "429/1000->eq:-0.08*x1**2-0.36*x1+0.03\n",
            "\n",
            "430/1000->eq:0.1*x1+si\n",
            "n(x1)-0.32\n",
            "\n",
            "431/1000->eq:x1**2-0.25*x1+0.01\n",
            "\n",
            "432/1000->eq:x1-0.1<EOS_E\n",
            "Q>\n",
            "\n",
            "433/1000->eq:sin(0.43\n",
            "*x1**2)\n",
            "\n",
            "434/1000->eq:sin(x1-0.1)<EOS\n",
            "_EQ>x1)\n",
            "\n",
            "435/1000->eq:2*x1-1.\n",
            "54\n",
            "\n",
            "436/1000->eq:x1-0.17*\n",
            "sin(x1-0.27)\n",
            "\n",
            "437/1000->eq:sin(\n",
            "0.59*x1**2+0.4*x1+0.05)\n",
            "\n",
            "438/1000->eq:sqrt(x1-0.88\n",
            ")-sin(0.34*x1)\n",
            "\n",
            "439/1000->eq:0.8*x1**2-\n",
            "0.39*x1+0.71*sqrt(0.66*x1-1)\n",
            "\n",
            "440/1000->eq:x1**2+0.09\n",
            "*x1-0.02\n",
            "\n",
            "441/1000->eq:0.06*x1+sin(x\n",
            "1+0.08)\n",
            "\n",
            "442/1000->eq:sin(sin(0.\n",
            "56*x1+0.4))\n",
            "\n",
            "443/1000->eq:0.42*x1+0.\n",
            "71\n",
            "\n",
            "444/1000->eq:(x1+0.29)**\n",
            "(1/4)\n",
            "\n",
            "445/1000->eq:0.58*sqrt(\n",
            "0.74*x1**2+0.07*x1-1)\n",
            "\n",
            "446/1000->eq:0.5*x1**2+sin(x1-0.\n",
            "1)\n",
            "\n",
            "447/1000->eq:<SOS_Y>[0.0, -0.1, -0.22, -0.3, -0.36, -0.38, -0.35, -0.25, -0.05, 0.2\n",
            "2, 0.6, 1.14, 1.77, 2.53, 3.54, 4.64, 6.04, 7.52, 9.2, 11.29, 13.42, 1\n",
            "5.8, 18.7, 21.62, 24.81, 28.65, 32.45, 36.57, 41.48, 46.29]<EOS_Y><SOS\n",
            "_EQ>0.26*x1**2+0.59\n",
            "\n",
            "\n",
            "448/1000->eq:2*x1-0.2<EOS_E\n",
            "Q>\n",
            "\n",
            "449/1000->eq:sin(sin(x1-0.\n",
            "1))\n",
            "\n",
            "450/1000->eq:sqrt(x1-0.13)\n",
            "\n",
            "\n",
            "451/1000->eq:<SOS_Y>[-0.91, -0.84, -0.76, -0.69, -0.62, -0.54, -0.47, -0.4, -0.32, \n",
            "-0.24, -0.17, -0.09, -0.02, 0.06, 0.14, 0.21, 0.29, 0.37, 0.44, 0.52, \n",
            "0.6, 0.68, 0.76, 0.84, 0.92, 1.0, 1.08, 1.16, 1.25, 1.33]<EOS_Y><SOS_E\n",
            "Q>0.76*x1-0.96\n",
            "\n",
            "\n",
            "452/1000->eq:-sin(sin(0.83*x1+0.53))\n",
            "\n",
            "453/1000->eq:<SOS_Y>[0.0, 0.2, 0.41, 0.58, 0.73, 0.86, 0.95, 0.99, 1.0, 0.96, 0.88,\n",
            " 0.76, 0.61, 0.45, 0.24, 0.04, -0.18, -0.37, -0.55, -0.72, -0.84, -0.9\n",
            "3, -0.99, -1.0, -0.97, -0.89, -0.79, -0.65, -0.46, -0.28]<EOS_Y><SOS_E\n",
            "Q>sin(2*x1-0.2)\n",
            "\n",
            "\n",
            "454/1000->eq:2*x1\n",
            "+0.44*sqrt(-x1-0.87)\n",
            "\n",
            "455/1000->eq:0.88*sqrt(0.\n",
            "84-x1)\n",
            "\n",
            "456/1000->eq:sqrt(-sin(\n",
            "0.28*x1-0.57))\n",
            "\n",
            "457/1000->eq:x1+0.86<EOS\n",
            "_EQ>\n",
            "\n",
            "458/1000->eq:-sin(0.91*x1+0.47)\n",
            "\n",
            "459/1000->eq:0.99*(0.37*x\n",
            "1+1)**(1/4)\n",
            "\n",
            "460/1000->eq:sqrt(sin(x1-0.\n",
            "1))\n",
            "\n",
            "461/1000->eq:sin(sin(0.\n",
            "25*x1-0.03))\n",
            "\n",
            "462/1000->eq:-sin(\n",
            "sin(0.37*x1-0.81))\n",
            "\n",
            "463/1000->eq:0.88*x\n",
            "1+sin(x1-0.42)\n",
            "\n",
            "464/1000->eq:x1-sin(\n",
            "0.38*x1+0.31)\n",
            "\n",
            "465/1000->eq:x1+0.3*sin\n",
            "(0.91*x1+0.07)\n",
            "\n",
            "466/1000->eq:-0.47*x1*sin(0.4*x1-0.05)+0.02\n",
            "\n",
            "467/1000->eq:\n",
            "-sin(0.17*x1-0.31)\n",
            "\n",
            "468/1000->eq:<SOS_Y>[0.0, 0.04, 0.08, 0.1, 0.12, 0.12, 0.12, 0.1, 0.07, 0.04, -0.0,\n",
            " -0.06, -0.13, -0.2, -0.29, -0.38, -0.5, -0.61, -0.73, -0.88, -1.02, -\n",
            "1.17, -1.34, -1.51, -1.69, -1.9, -2.1, -2.31, -2.55, -2.78]<EOS_Y><SOS\n",
            "_EQ>-0.49*x1**2+0.48*x1-0.04\n",
            "\n",
            "\n",
            "469/1000->eq:0.7*x1**2+0\n",
            ".42*x1+0.45\n",
            "\n",
            "470/1000->eq:0.89*sqrt(0\n",
            ".95*x1**2+0.92*x1-1)\n",
            "\n",
            "471/1000->eq:-0.82*x1**2-0.1*x1+0.04\n",
            "\n",
            "472/1000->eq:sqrt(x1-0.1)\n",
            "\n",
            "\n",
            "473/1000->eq:-sin(0.11*x1-0.02)\n",
            "\n",
            "474/1000->eq:sqrt(-sin(0.\n",
            "44*x1-0.07))\n",
            "\n",
            "475/1000->eq:0.06*x1*sqr\n",
            "t(-x1-0.92)\n",
            "\n",
            "476/1000->eq:x1**(5\n",
            "/2)-0.03*x1\n",
            "\n",
            "477/1000->eq:sin(0.38*\n",
            "x1-0.14)\n",
            "\n",
            "478/1000->eq:0.98*sqrt(\n",
            "0.28-x1)\n",
            "\n",
            "479/1000->eq:0.68*sqrt\n",
            "(0.57*x1+1)\n",
            "\n",
            "480/1000->eq:0.96*sqrt(0\n",
            ".09*x1+1)\n",
            "\n",
            "481/1000->eq:0.95*sqrt(x\n",
            "1+0.9)\n",
            "\n",
            "482/1000->eq:0.88*sqrt(x1\n",
            ")*sqrt(x1-0.1)\n",
            "\n",
            "483/1000->eq:0.89*sqrt(0.\n",
            "96*x1-1)\n",
            "\n",
            "484/1000->eq:x1-0.\n",
            "64\n",
            "\n",
            "485/1000->eq:sin(sin(0.7\n",
            "1*x1-0.06))\n",
            "\n",
            "486/1000->eq:0.87*sqrt(\n",
            "0.84*x1+1)\n",
            "\n",
            "487/1000->eq:0.25*x1**2*si\n",
            "n(x1)\n",
            "\n",
            "488/1000->eq:-0.92*x1\n",
            "+sqrt(x1+0.87)\n",
            "\n",
            "489/1000->eq:sqrt(x1)+2*x\n",
            "1-0.56\n",
            "\n",
            "490/1000->eq:-sin(0.85*x1-0.17)\n",
            "\n",
            "491/1000->eq:sin(x1-0.1)<EOS\n",
            "_EQ>x1+0.1)\n",
            "\n",
            "492/1000->eq:2*x1+0.4\n",
            "5\n",
            "\n",
            "493/1000->eq:0.56*x1-0.1\n",
            "9\n",
            "\n",
            "494/1000->eq:0.24*sqrt(x1\n",
            ")-0.08*x1\n",
            "\n",
            "495/1000->eq:<SOS_Y>[0.57, 0.64, 0.69, 0.72, 0.73, 0.71, 0.67, 0.6, 0.49, 0.37, 0.2\n",
            "2, 0.02, -0.19, -0.43, -0.72, -1.02, -1.39, -1.75, -2.14, -2.6, -3.05,\n",
            " -3.53, -4.08, -4.62, -5.18, -5.83, -6.44, -7.08, -7.8, -8.49]<EOS_Y><\n",
            "SOS_EQ>-1.36*x1**2+0.66*x1+0.46\n",
            "\n",
            "\n",
            "496/1000->eq:-sin(0.33*x1)*sin(x1-0.13)\n",
            "\n",
            "497/1000->eq:sin(1.1*\n",
            "x1+0.28)\n",
            "\n",
            "498/1000->eq:sqrt(x1-0.1)\n",
            "\n",
            "\n",
            "499/1000->eq:sin(sin(x1-0.\n",
            "1))\n",
            "\n",
            "500/1000->eq:sin(0.85*sq\n",
            "rt(0.09-x1))\n",
            "\n",
            "501/1000->eq:0.93*sqrt(0.3\n",
            "7*x1-1)\n",
            "\n",
            "502/1000->eq:2*x1+0.62*s\n",
            "qrt(-x1)+0.38\n",
            "\n",
            "503/1000->eq:sin\n",
            "(x1-0.86)\n",
            "\n",
            "504/1000->eq:0.13*sqrt(x\n",
            "1)\n",
            "\n",
            "505/1000->eq:2*x1*\n",
            "sin(0.74*x1-0.51)+0.23\n",
            "\n",
            "506/1000->eq:<SOS_Y>[0.15, 0.33, 0.52, 0.67, 0.8, 0.9, 0.97, 1.0, 0.99, 0.95, 0.87,\n",
            " 0.75, 0.62, 0.46, 0.27, 0.08, -0.12, -0.31, -0.48, -0.65, -0.78, -0.8\n",
            "8, -0.96, -1.0, -1.0, -0.96, -0.88, -0.78, -0.64, -0.48]<EOS_Y><SOS_EQ\n",
            ">sin(1.87*x1-0.03)\n",
            "\n",
            "\n",
            "507/1000->eq:sin(0.61*x1\n",
            ")*sin(x1+0.05)\n",
            "\n",
            "508/1000->eq:-0.58*x1**2+0.05*x1\n",
            "\n",
            "509/1000->eq:sqrt(x1-0.1)+s\n",
            "in(0.61*x1-0.3)\n",
            "\n",
            "510/1000->eq:x1-0.1<EOS_E\n",
            "Q>\n",
            "\n",
            "511/1000->eq:sin(0.9*sqrt\n",
            "(0.47*x1-1))\n",
            "\n",
            "512/1000->eq:0.89*sqrt(0.01*\n",
            "x1-1)\n",
            "\n",
            "513/1000->eq:0.1*sqrt(x1)+\n",
            "0.39*x1-0.13\n",
            "\n",
            "514/1000->eq:0.61*sqrt(x\n",
            "1-0.11)\n",
            "\n",
            "515/1000->eq:sqrt(sin(x1+\n",
            "0.18))\n",
            "\n",
            "516/1000->eq:sqrt(\n",
            "x1-0.1)*sin(0.94*x1+0.28)\n",
            "\n",
            "517/1000->eq:0.63*sqrt(x1-\n",
            "0.1)\n",
            "\n",
            "518/1000->eq:0.79*sqrt(-\n",
            "x1)+sin(x1+0.23)\n",
            "\n",
            "519/1000->eq:0.98*sqr\n",
            "t(0.07-x1)\n",
            "\n",
            "520/1000->eq:sin(0.79*\n",
            "x1-0.29)\n",
            "\n",
            "521/1000->eq:sin(0.67*x1-0\n",
            ".06)\n",
            "\n",
            "522/1000->eq:sqrt(x1+\n",
            "0.12)\n",
            "\n",
            "523/1000->eq:-0.14*x1**2+0.04*x1\n",
            "\n",
            "524/1000->eq:-0.24*x1**2\n",
            "\n",
            "525/1000->eq:0.04*x1**2-0.58*x1+0.06\n",
            "\n",
            "526/1000->eq:sqrt(x1-0.1)\n",
            "\n",
            "\n",
            "527/1000->eq:-sin(\n",
            "0.15*x1-0.32)\n",
            "\n",
            "528/1000->eq:0.67*x1*sqrt\n",
            "(-x1)+0.99\n",
            "\n",
            "529/1000->eq:0.62*sqrt(x\n",
            "1-0.1)\n",
            "\n",
            "530/1000->eq:sqrt(sin(\n",
            "0.39*x1-0.64))\n",
            "\n",
            "531/1000->eq:0.91*x1*s\n",
            "qrt(-x1)-0.1\n",
            "\n",
            "532/1000->eq:-0.27*x1+0.7\n",
            "8*sqrt(1-0.1*x1)-0.19\n",
            "\n",
            "533/1000->eq:0.96*sqrt\n",
            "(0.19-x1)\n",
            "\n",
            "534/1000->eq:<SOS_Y>[-0.01, 0.16, 0.34, 0.49, 0.63, 0.77, 0.86, 0.94, 0.99, 1.0, 0.\n",
            "99, 0.94, 0.86, 0.77, 0.63, 0.49, 0.32, 0.16, -0.01, -0.2, -0.36, -0.5\n",
            "2, -0.67, -0.78, -0.88, -0.95, -0.99, -1.0, -0.98, -0.93]<EOS_Y><SOS_E\n",
            "Q>sin(1.74*x1-0.18)\n",
            "\n",
            "\n",
            "535/1000->eq:0.56-0.65*x1\n",
            "\n",
            "536/1000->eq:sin(sin(0.\n",
            "76*x1-0.06))\n",
            "\n",
            "537/1000->eq:0.23-0.2*x1\n",
            "\n",
            "538/1000->eq:\n",
            "sqrt(x1-0.63)*sin(x1+0.66)\n",
            "\n",
            "539/1000->eq:0.16*x1**2+1.9\n",
            "4*x1-0.2\n",
            "\n",
            "540/1000->eq:sin(0.92*x1\n",
            "-0.09)\n",
            "\n",
            "541/1000->eq:0.44*sqrt(x1**\n",
            "2-0.1*x1)\n",
            "\n",
            "542/1000->eq:0.96*sqrt(\n",
            "-x1)+sqrt(x1-0.68)\n",
            "\n",
            "543/1000->eq:x1**2+0.38*x1+0.56\n",
            "\n",
            "544/1000->eq:sqrt(x1**2+0\n",
            ".88*x1-0.1)\n",
            "\n",
            "545/1000->eq:0.92*x1+sin(x1)\n",
            "-0.19\n",
            "\n",
            "546/1000->eq:0.91*(1-0.8*x1\n",
            ")**(1/4)\n",
            "\n",
            "547/1000->eq:0.79*(-0.79*x1-1)**(1/4)<EOS_EQ\n",
            ">\n",
            "\n",
            "548/1000->eq:sqrt(x1-0.1)\n",
            "\n",
            "\n",
            "549/1000->eq:sqrt(x1)+x1-\n",
            "0.39\n",
            "\n",
            "550/1000->eq:0.95*(x1+0\n",
            ".3)**(1/4)\n",
            "\n",
            "551/1000->eq:x1**2-0.04*\n",
            "x1*sin(x1)\n",
            "\n",
            "552/1000->eq:sqrt(x1)+s\n",
            "qrt(x1-0.3)\n",
            "\n",
            "553/1000->eq:-sin(0.67*x1-0.07)\n",
            "\n",
            "554/1000->eq:x1**2-1.\n",
            "2*x1+0.26\n",
            "\n",
            "555/1000->eq:sin(sin(x1-\n",
            "0.31))\n",
            "\n",
            "556/1000->eq:sqrt(x1-0.1)\n",
            "\n",
            "\n",
            "557/1000->eq:0.58*x1**2+\n",
            "0.34*x1+sin(x1+0.29)\n",
            "\n",
            "558/1000->eq:2*x1+0.5\n",
            "5\n",
            "\n",
            "559/1000->eq:0.72*sqrt(x1-\n",
            "0.1)\n",
            "\n",
            "560/1000->eq:sin(sqrt(x1-0\n",
            ".47))\n",
            "\n",
            "561/1000->eq:2*x1-0.\n",
            "13*sin(x1-0.32)\n",
            "\n",
            "562/1000->eq:-0.24*x1+sqrt\n",
            "(x1+0.38)+0.03\n",
            "\n",
            "563/1000->eq:sin(sqrt(x1-0.39\n",
            "))\n",
            "\n",
            "564/1000->eq:sin(0\n",
            ".79*x1**2-0.06*x1)\n",
            "\n",
            "565/1000->eq:<SOS_Y>[0.84, 0.9, 0.95, 0.98, 1.0, 1.0, 0.99, 0.97, 0.92, 0.87, 0.81,\n",
            " 0.73, 0.64, 0.55, 0.44, 0.33, 0.21, 0.09, -0.02, -0.15, -0.26, -0.38,\n",
            " -0.49, -0.59, -0.68, -0.77, -0.84, -0.89, -0.94, -0.98]<EOS_Y><SOS_EQ\n",
            ">sin(1.13*x1+0.91)\n",
            "\n",
            "\n",
            "566/1000->eq:sqrt(x1)+0\n",
            ".9*x1**2-0.3*x1-0.25\n",
            "\n",
            "567/1000->eq:-0.24*x1**2+1.77*x1+0.23\n",
            "\n",
            "568/1000->eq:sqrt(-sin(0.41*x1\n",
            "+0.66))\n",
            "\n",
            "569/1000->eq:0.92*(x1+0.6\n",
            "1)**(1/4)\n",
            "\n",
            "570/1000->eq:sqrt(x1-\n",
            "0.21)+0.84*sqrt(x1+0.67)\n",
            "\n",
            "571/1000->eq:sin(x1-0.1)<EOS\n",
            "_EQ>x194)\n",
            "\n",
            "572/1000->eq:sqrt(2)*sq\n",
            "rt(x1-0.54)\n",
            "\n",
            "573/1000->eq:sqrt(sin(x1-0.9\n",
            "4))\n",
            "\n",
            "574/1000->eq:sqrt(x1+0.62\n",
            ")\n",
            "\n",
            "575/1000->eq:0.47*sqrt(0.\n",
            "96*x1-1)\n",
            "\n",
            "576/1000->eq:<SOS_Y>[0.0, 0.25, 0.35, 0.41, 0.44, 0.46, 0.45, 0.43, 0.4, 0.35, 0.28\n",
            ", 0.2, 0.11, 0.01, -0.12, -0.25, -0.41, -0.57, -0.73, -0.93, -1.13, -1\n",
            ".33, -1.57, -1.8, -2.05, -2.33, -2.59, -2.87, -3.19, -3.5]<EOS_Y><SOS_\n",
            "EQ>-0.39*x1**2-0.09*x1+0.97*sqrt(x1-0.1)\n",
            "\n",
            "\n",
            "577/1000->eq:0.14*x1**2\n",
            "+x1-0.08\n",
            "\n",
            "578/1000->eq:sqrt(2)*sqr\n",
            "t(x1-0.1)\n",
            "\n",
            "579/1000->eq:3.5\n",
            "6*x1-2.06\n",
            "\n",
            "580/1000->eq:-0.29*x1**2-0.38*x1-0.44\n",
            "\n",
            "581/1000->eq:0.72*x1-0.07<EO\n",
            "S_EQ>\n",
            "\n",
            "582/1000->eq:0.1-0.47*x1\n",
            "\n",
            "583/1000->eq:sqrt(x1+0.29)\n",
            "\n",
            "\n",
            "584/1000->eq:sin(0.64*x1\n",
            "-0.26)\n",
            "\n",
            "585/1000->eq:0.1\n",
            "8*x1**2-0.09*x1+0.05\n",
            "\n",
            "586/1000->eq:<SOS_Y>[-0.65, -0.49, -0.29, -0.09, 0.11, 0.32, 0.5, 0.66, 0.81, 0.91,\n",
            " 0.97, 1.0, 0.98, 0.92, 0.82, 0.69, 0.51, 0.33, 0.13, -0.08, -0.28, -0\n",
            ".47, -0.65, -0.79, -0.89, -0.97, -1.0, -0.99, -0.93, -0.84]<EOS_Y><SOS\n",
            "_EQ>sin(2*x1-0.91)\n",
            "\n",
            "\n",
            "587/1000->eq:0.85*sqrt(0\n",
            ".11*x1-1)\n",
            "\n",
            "588/1000->eq:sqrt(2)*sqr\n",
            "t(x1-0.12)\n",
            "\n",
            "589/1000->eq:-0.47*x1**2+sin(x1-0.99)\n",
            "\n",
            "590/1000->eq:<SOS_Y>[0.24, 0.27, 0.3, 0.31, 0.3, 0.27, 0.22, 0.14, 0.04, -0.07, -0.\n",
            "2, -0.36, -0.51, -0.66, -0.82, -0.96, -1.1, -1.2, -1.27, -1.31, -1.3, \n",
            "-1.25, -1.12, -0.95, -0.71, -0.37, 0.0, 0.44, 1.01, 1.58]<EOS_Y><SOS_E\n",
            "Q>x1**2+0.05*x1-0.16*sin(x1-0.84)\n",
            "\n",
            "\n",
            "591/1000->eq:sqrt(x1)-si\n",
            "n(0.15*x1-0.23)\n",
            "\n",
            "592/1000->eq:-sin(sin(0.55*x1-0.07))\n",
            "\n",
            "593/1000->eq:sin(0.94*sqrt(x\n",
            "1-0.1))\n",
            "\n",
            "594/1000->eq:0.83*sqr\n",
            "t(x1**2+0.11*x1-0.63)\n",
            "\n",
            "595/1000->eq:sin(sqrt(x1+0.2\n",
            "6))\n",
            "\n",
            "596/1000->eq:-sin(0.64*x1)-sin(0.98*x1-0.12)\n",
            "\n",
            "597/1000->eq:s\n",
            "in(0.79*x1-0.84)\n",
            "\n",
            "598/1000->eq:0.98*(x1-0.85\n",
            ")**(1/4)\n",
            "\n",
            "599/1000->eq:-0.58*x1**2+0.21*x1+0.04\n",
            "\n",
            "600/1000->eq:si\n",
            "n(x1-1.0)\n",
            "\n",
            "601/1000->eq:<SOS_Y>[0.41, 0.58, 0.75, 0.86, 0.95, 0.99, 1.0, 0.96, 0.87, 0.76, 0.6\n",
            "1, 0.42, 0.24, 0.04, -0.18, -0.37, -0.57, -0.72, -0.84, -0.94, -0.99, \n",
            "-1.0, -0.96, -0.89, -0.78, -0.63, -0.46, -0.28, -0.06, 0.14]<EOS_Y><SO\n",
            "S_EQ>sin(2*x1+0.22)\n",
            "\n",
            "\n",
            "602/1000->eq:-0.1*x1**(3/2)-0.1*x1+0.02\n",
            "\n",
            "603/1000->eq:-0.47*x1+sin(x1+0.82)-0.48\n",
            "\n",
            "604/1000->eq:sin(x1-0.1)<EOS\n",
            "_EQ>x112)\n",
            "\n",
            "605/1000->eq:sqrt(x1-0.4\n",
            ")*sin(0.98*x1-0.06)\n",
            "\n",
            "606/1000->eq:0.55*x1\n",
            "**2-0.68*x1+0.03*sin(x1)\n",
            "\n",
            "607/1000->eq:0.52*sqrt(0.5\n",
            "3-x1)\n",
            "\n",
            "608/1000->eq:0.36*\n",
            "x1**2-1.*(x1-0.93)-0.12\n",
            "\n",
            "609/1000->eq:2.16*x1-0.32<\n",
            "EOS_EQ>\n",
            "\n",
            "610/1000->eq:x1+sqrt(x1\n",
            "-0.38)-0.17\n",
            "\n",
            "611/1000->eq:sqrt(sin(x1+\n",
            "0.88))\n",
            "\n",
            "612/1000->eq:2.88*x1-\n",
            "0.23\n",
            "\n",
            "613/1000->eq:1.27*x1-0.\n",
            "06\n",
            "\n",
            "614/1000->eq:1.55*x1-\n",
            "0.48\n",
            "\n",
            "615/1000->eq:-0.71*x1**2-0.21*x1+0.91*sqrt(0.77-x1)\n",
            "\n",
            "616/1000->eq:1.82*x1-0.1\n",
            "7\n",
            "\n",
            "617/1000->eq:-sin(0.9*x1-0.1)\n",
            "\n",
            "618/1000->eq:0.5*sqrt(x1\n",
            ")*sqrt(x1-0.08)\n",
            "\n",
            "619/1000->eq:0.51*\n",
            "x1**2-0.78*x1+0.07\n",
            "\n",
            "620/1000->eq:sqrt(x1-0.\n",
            "82)\n",
            "\n",
            "621/1000->eq:sqrt(x1-0.7\n",
            "7)\n",
            "\n",
            "622/1000->eq:0.81*\n",
            "x1**2+0.81*x1+sin(x1-0.86)\n",
            "\n",
            "623/1000->eq:0.48*x1\n",
            "**2+0.81*x1\n",
            "\n",
            "624/1000->eq:-0.32*x1-0.02\n",
            "\n",
            "625/1000->eq:0.13*x1**\n",
            "2+0.72*x1-0.06\n",
            "\n",
            "626/1000->eq:-0.23*x1**2+0.23*x1\n",
            "\n",
            "627/1000->eq:-0.09*x1**2-0.41*x1+sin(0.2*x1-0.76)\n",
            "\n",
            "628/1000->eq:0.53*x1**\n",
            "2+0.88*x1-0.65\n",
            "\n",
            "629/1000->eq:0.34*x1+sin(x\n",
            "1+0.12)\n",
            "\n",
            "630/1000->eq:sqrt(x1**2+0\n",
            ".08*x1-0.06)\n",
            "\n",
            "631/1000->eq:0.4*sqrt(\n",
            "x1)+1.17*x1-0.61\n",
            "\n",
            "632/1000->eq:0.85*sqrt(x\n",
            "1+0.96)\n",
            "\n",
            "633/1000->eq:<SOS_Y>[-0.67, -0.65, -0.61, -0.55, -0.48, -0.37, -0.25, -0.1, 0.08, 0\n",
            ".27, 0.47, 0.67, 0.84, 0.95, 1.0, 0.95, 0.76, 0.49, 0.13, -0.3, -0.66,\n",
            " -0.92, -1.0, -0.84, -0.47, 0.08, 0.58, 0.93, 0.97, 0.65]<EOS_Y><SOS_E\n",
            "Q>-sin(-x1**2+0.18*x1+0.72)\n",
            "\n",
            "\n",
            "634/1000->eq:sqrt(x1**2-0.\n",
            "96*x1+0.06)\n",
            "\n",
            "635/1000->eq:0.87*sqrt(x\n",
            "1**2-0.1*x1)\n",
            "\n",
            "636/1000->eq:sin(sin(x1-0.\n",
            "1))\n",
            "\n",
            "637/1000->eq:sin(\n",
            "sin(0.72*x1-0.58))\n",
            "\n",
            "638/1000->eq:0.18*x1**2+\n",
            "0.02*x1\n",
            "\n",
            "639/1000->eq:0.24*sqrt(-\n",
            "x1)-sin(0.09*x1)\n",
            "\n",
            "640/1000->eq:x1-0.1<EOS_E\n",
            "Q>\n",
            "\n",
            "641/1000->eq:0.49*sqrt(-\n",
            "x1-0.65)\n",
            "\n",
            "642/1000->eq:1.23*x1+0\n",
            ".65\n",
            "\n",
            "643/1000->eq:<SOS_Y>[-0.12, 0.05, 0.24, 0.41, 0.56, 0.71, 0.82, 0.91, 0.97, 1.0, 0.\n",
            "99, 0.95, 0.89, 0.79, 0.66, 0.52, 0.35, 0.18, 0.0, -0.19, -0.36, -0.51\n",
            ", -0.67, -0.79, -0.88, -0.96, -0.99, -1.0, -0.97, -0.91]<EOS_Y><SOS_EQ\n",
            ">sin(1.75*x1-0.29)\n",
            "\n",
            "\n",
            "644/1000->eq:<SOS_Y>[-0.76, -0.82, -0.88, -0.92, -0.96, -0.98, -1.0, -1.0, -0.99, -\n",
            "0.98, -0.95, -0.91, -0.86, -0.81, -0.74, -0.66, -0.58, -0.49, -0.41, -\n",
            "0.3, -0.21, -0.11, 0.0, 0.1, 0.2, 0.31, 0.4, 0.49, 0.58, 0.66]<EOS_Y><\n",
            "SOS_EQ>-sin(x1+0.66)\n",
            "\n",
            "\n",
            "645/1000->eq:0.67*sqrt(\n",
            "x1-0.1)\n",
            "\n",
            "646/1000->eq:0.16*x1+sq\n",
            "rt(x1-0.39)\n",
            "\n",
            "647/1000->eq:(x1-0.47)**(1\n",
            "/4)\n",
            "\n",
            "648/1000->eq:1.05*x1-0.01\n",
            "\n",
            "\n",
            "649/1000->eq:0.95*(-x1)*\n",
            "*(1/4)\n",
            "\n",
            "650/1000->eq:0.7*x1*sqrt(x1\n",
            "-0.62)-0.04\n",
            "\n",
            "651/1000->eq:0.69*sqr\n",
            "t(-x1-0.37)*sin(0.78*x1-0.47)\n",
            "\n",
            "652/1000->eq:sqrt(x1)+2*x\n",
            "1-0.36\n",
            "\n",
            "653/1000->eq:0.94*(x1+0.\n",
            "39)**(1/4)\n",
            "\n",
            "654/1000->eq:0.29*x1**2*sqrt(\n",
            "-x1)-0.03*x1\n",
            "\n",
            "655/1000->eq:x1+sin(x1-0.\n",
            "19)\n",
            "\n",
            "656/1000->eq:1.36*x1+0.3\n",
            "4\n",
            "\n",
            "657/1000->eq:1.37*sqrt\n",
            "(x1-0.37)\n",
            "\n",
            "658/1000->eq:0.18*sqrt(x\n",
            "1**2-0.33*x1)\n",
            "\n",
            "659/1000->eq:sqrt(sin(x1-0.\n",
            "1))\n",
            "\n",
            "660/1000->eq:x1**2+s\n",
            "in(x1-0.37)\n",
            "\n",
            "661/1000->eq:(x1-0.07)**(1/\n",
            "4)\n",
            "\n",
            "662/1000->eq:sin(sqrt(x1-0.1))<\n",
            "EOS_EQ>\n",
            "\n",
            "663/1000->eq:-0.5*x1**2+0.61*x1-0.05\n",
            "\n",
            "664/1000->eq:0.13-1.33*x1\n",
            "\n",
            "665/1000->eq:sin(0.74*sqr\n",
            "t(x1-0.1))\n",
            "\n",
            "666/1000->eq:-0.96*x1+0.12*sqrt(-x1)\n",
            "\n",
            "667/1000->eq:sin(sqrt(x1-0.1))<\n",
            "EOS_EQ>\n",
            "\n",
            "668/1000->eq:sqrt(sin(x1+0.\n",
            "6))\n",
            "\n",
            "669/1000->eq:sqrt(2)*sqr\n",
            "t(x1+0.16)\n",
            "\n",
            "670/1000->eq:0.16*x1+0.67*s\n",
            "qrt(0.88*x1+1)\n",
            "\n",
            "671/1000->eq:x\n",
            "1**2+0.64*x1-0.91\n",
            "\n",
            "672/1000->eq:2*x1*\n",
            "*2-0.47*x1\n",
            "\n",
            "673/1000->eq:0.13*x1**(3/2)-0.12*x1**2\n",
            "\n",
            "674/1000->eq:sqrt(x1+0.\n",
            "35)\n",
            "\n",
            "675/1000->eq:0.05*x1<EOS\n",
            "_EQ>\n",
            "\n",
            "676/1000->eq:sqrt(sin(x1-0.\n",
            "97))\n",
            "\n",
            "677/1000->eq:-0.95*x1**2+sin(0.77*x1+0.39)\n",
            "\n",
            "678/1000->eq:-0.1*x1\n",
            "**2*sin(x1+0.49)+0.58*x1-0.61\n",
            "\n",
            "679/1000->eq:2*x1*sin(x\n",
            "1-0.07)\n",
            "\n",
            "680/1000->eq:0.72*\n",
            "x1-0.81*sin(0.31*x1-0.13)\n",
            "\n",
            "681/1000->eq:<SOS_Y>[-0.84, -0.78, -0.71, -0.64, -0.56, -0.47, -0.38, -0.28, -0.17,\n",
            " -0.06, 0.06, 0.2, 0.33, 0.46, 0.62, 0.77, 0.94, 1.09, 1.26, 1.44, 1.6\n",
            "1, 1.78, 1.98, 2.15, 2.33, 2.53, 2.71, 2.89, 3.09, 3.27]<EOS_Y><SOS_EQ\n",
            ">0.23*x1**2+0.62*x1-0.91\n",
            "\n",
            "\n",
            "682/1000->eq:0\n",
            "\n",
            "683/1000->eq:sin(0.83*sq\n",
            "rt(0.95-x1))\n",
            "\n",
            "684/1000->eq:sin(sin(x1\n",
            "+0.14))\n",
            "\n",
            "685/1000->eq:0.9*x1-0\n",
            ".22*sin(0.98*x1)\n",
            "\n",
            "686/1000->eq:0.71*x1**2+\n",
            "0.74*x1+0.46\n",
            "\n",
            "687/1000->eq:0.27*x1**2+2*x1\n",
            "\n",
            "688/1000->eq:-0.71*x1**2-0.71*x1-0.12\n",
            "\n",
            "689/1000->eq:0.46*sqrt(x\n",
            "1)*sqrt(x1-0.08)\n",
            "\n",
            "690/1000->eq:\n",
            "sin(1.6*x1-0.06)\n",
            "\n",
            "691/1000->eq:sqrt(x1)+s\n",
            "qrt(x1-0.3)\n",
            "\n",
            "692/1000->eq:0.72*sqrt(x1\n",
            "-0.1)\n",
            "\n",
            "693/1000->eq:0.65*x1\n",
            "**2-0.28*x1-0.09\n",
            "\n",
            "694/1000->eq:0.73*sqrt\n",
            "(x1+0.13)\n",
            "\n",
            "695/1000->eq:x1*\n",
            "*2+0.55*x1-0.43\n",
            "\n",
            "696/1000->eq:sin(\n",
            "sin(x1-0.69))\n",
            "\n",
            "697/1000->eq:-1.06*x1**3+0.17*x1\n",
            "\n",
            "698/1000->eq:0.72*sqrt(x\n",
            "1)+x1-0.39\n",
            "\n",
            "699/1000->eq:0.82*x1*\n",
            "*2-0.71*x1+0.06\n",
            "\n",
            "700/1000->eq:sqrt(x1)+\n",
            "sin(x1-0.04)\n",
            "\n",
            "701/1000->eq:-0.59*x1**2*sqrt(x1-0.61)-0.24*x1+0.15\n",
            "\n",
            "702/1000->eq:(x1+0.49)**\n",
            "(1/4)\n",
            "\n",
            "703/1000->eq:sin(sqrt(x1+0.45\n",
            "))\n",
            "\n",
            "704/1000->eq:sqrt(x1+0.\n",
            "54)\n",
            "\n",
            "705/1000->eq:sqrt(x1)+0.3\n",
            "6*x1**2-0.27*x1-0.18\n",
            "\n",
            "706/1000->eq:sin(0.81*x1+0.\n",
            "54)\n",
            "\n",
            "707/1000->eq:sin(0.39*x1**2-0\n",
            ".1*x1)\n",
            "\n",
            "708/1000->eq:sqrt(x1+0.18)<E\n",
            "OS_EQ>\n",
            "\n",
            "709/1000->eq:<SOS_Y>[0.16, -0.03, -0.24, -0.42, -0.59, -0.75, -0.86, -0.94, -0.99, \n",
            "-1.0, -0.97, -0.89, -0.79, -0.66, -0.48, -0.3, -0.1, 0.1, 0.29, 0.48, \n",
            "0.64, 0.78, 0.89, 0.96, 1.0, 0.99, 0.95, 0.87, 0.75, 0.6]<EOS_Y><SOS_E\n",
            "Q>-sin(1.85*x1-0.33)\n",
            "\n",
            "\n",
            "710/1000->eq:(x1-0.86)**\n",
            "(1/4)\n",
            "\n",
            "711/1000->eq:sin(0.61*\n",
            "sqrt(x1-0.1))\n",
            "\n",
            "712/1000->eq:1.03*x1-0.1\n",
            "\n",
            "\n",
            "713/1000->eq:0\n",
            ".49*x1**2*sin(0.4*x1-0.89)-0.02*x1\n",
            "\n",
            "714/1000->eq:sin\n",
            "(x1-0.88)\n",
            "\n",
            "715/1000->eq:0.72*(x1-0.43\n",
            ")**(1/4)\n",
            "\n",
            "716/1000->eq:0.76*x1**2*s\n",
            "qrt(x1-0.99)\n",
            "\n",
            "717/1000->eq:-sin(sin(0.94*x1-0.1))\n",
            "\n",
            "718/1000->eq:sin(0.93*x\n",
            "1)*sin(x1-0.06)\n",
            "\n",
            "719/1000->eq:sqrt(sin(x1-0.\n",
            "1))\n",
            "\n",
            "720/1000->eq:0.13*x1**2*sin\n",
            "(0.68*x1)\n",
            "\n",
            "721/1000->eq:sin(x1-0\n",
            ".4)\n",
            "\n",
            "722/1000->eq:1.83*x1+0.36\n",
            "\n",
            "\n",
            "723/1000->eq:0.28*x1**3+x1**2\n",
            "\n",
            "724/1000->eq:-0.58*x1**2+0.07*x1*sin(0.7*x1+0.34)\n",
            "\n",
            "725/1000->eq:-0.61*sqrt(x1)-1.59*x1**2-1.01*x1-0.12\n",
            "\n",
            "726/1000->eq:0.66*x1**\n",
            "(5/2)\n",
            "\n",
            "727/1000->eq:0.5*sqrt(0.2\n",
            "6*x1-1)\n",
            "\n",
            "728/1000->eq:-sin(0.28*x1-0.63)*sin(0.4*x1-0.04)\n",
            "\n",
            "729/1000->eq:1.03*x1-0.1<E\n",
            "OS_EQ>\n",
            "\n",
            "730/1000->eq:0.82*sqrt(x\n",
            "1-0.63)\n",
            "\n",
            "731/1000->eq:sqrt(sin(x1+0\n",
            ".12))\n",
            "\n",
            "732/1000->eq:x1-0.1<EOS_E\n",
            "Q>\n",
            "\n",
            "733/1000->eq:0.04*x1*sqr\n",
            "t(0.35*x1+1)+0.37\n",
            "\n",
            "734/1000->eq:0.47*x1+0.3\n",
            "\n",
            "\n",
            "735/1000->eq:0.59*sqrt(x\n",
            "1-0.97)\n",
            "\n",
            "736/1000->eq:0.51*x1**2+0.9\n",
            "3*x1+0.89*sqrt(-x1)-0.24\n",
            "\n",
            "737/1000->eq:0.93*sqrt(\n",
            "-x1**2+0.1*x1)\n",
            "\n",
            "738/1000->eq:0.91*sqrt(\n",
            "x1)-0.1\n",
            "\n",
            "739/1000->eq:0.34\n",
            "*x1**3+x1**2\n",
            "\n",
            "740/1000->eq:-sin(0.06*x1-0.02)\n",
            "\n",
            "741/1000->eq:sin(0.84*x1-0.\n",
            "09)\n",
            "\n",
            "742/1000->eq:-0.27*x1**2+0.08*x1\n",
            "\n",
            "743/1000->eq:sin(0.74*x1+0\n",
            ".57)\n",
            "\n",
            "744/1000->eq:x1-0\n",
            ".9\n",
            "\n",
            "745/1000->eq:x1**2\n",
            "+0.28*x1-1.01\n",
            "\n",
            "746/1000->eq:x1**2-0.02*x1<EOS\n",
            "_EQ>\n",
            "\n",
            "747/1000->eq:-sin(0.07*\n",
            "x1-0.27)\n",
            "\n",
            "748/1000->eq:sqrt(x\n",
            "1)+0.46*x1-0.99\n",
            "\n",
            "749/1000->eq:sin(0.47\n",
            "*x1**2-0.02*x1)\n",
            "\n",
            "750/1000->eq:-sin(0.03*x1-0.02)\n",
            "\n",
            "751/1000->eq:sin(sin(0.\n",
            "28*x1-0.03))\n",
            "\n",
            "752/1000->eq:<SOS_Y>[0.18, 0.37, 0.57, 0.72, 0.84, 0.94, 0.99, 1.0, 0.96, 0.89, 0.7\n",
            "8, 0.63, 0.46, 0.28, 0.06, -0.14, -0.35, -0.53, -0.69, -0.83, -0.92, -\n",
            "0.98, -1.0, -0.97, -0.91, -0.8, -0.66, -0.5, -0.3, -0.1]<EOS_Y><SOS_EQ\n",
            ">sin(2*x1-0.02)\n",
            "\n",
            "\n",
            "753/1000->eq:0.98*sqrt(0\n",
            ".35*x1-1)\n",
            "\n",
            "754/1000->eq:sin(0.49*sq\n",
            "rt(x1+0.33))\n",
            "\n",
            "755/1000->eq:-0.51*x1**2*sin(0.48*x1-0.7)-0.05*x1\n",
            "\n",
            "756/1000->eq:sqrt(x1-0.54\n",
            ")\n",
            "\n",
            "757/1000->eq:sqrt(2)*sqr\n",
            "t(x1-0.5)\n",
            "\n",
            "758/1000->eq:sin(0.11*x1\n",
            "**2)\n",
            "\n",
            "759/1000->eq:0.88*sqrt(x\n",
            "1+0.69)\n",
            "\n",
            "760/1000->eq:sqrt(x1**2+\n",
            "0.36*x1-0.06)\n",
            "\n",
            "761/1000->eq:sin(0.94*sq\n",
            "rt(0.95-x1))\n",
            "\n",
            "762/1000->eq:sin(sqrt(x1-0.08\n",
            "))\n",
            "\n",
            "763/1000->eq:0.2*x1**3-0.66*x1**2\n",
            "\n",
            "764/1000->eq:sqrt(x1-0\n",
            ".41)+sin(x1)\n",
            "\n",
            "765/1000->eq:x1*sin(\n",
            "x1-0.75)-0.08\n",
            "\n",
            "766/1000->eq:0.91*x1*sq\n",
            "rt(-x1-0.05)-0.34\n",
            "\n",
            "767/1000->eq:0.25\n",
            "*x1**4\n",
            "\n",
            "768/1000->eq:0.89*sqrt(0\n",
            ".71*x1+1)\n",
            "\n",
            "769/1000->eq:1.1*x1\n",
            "-0.13*sqrt(x1-0.82)\n",
            "\n",
            "770/1000->eq:0.74*sqrt(x1\n",
            "-0.1)\n",
            "\n",
            "771/1000->eq:(x1-0.1)**(1/\n",
            "4)\n",
            "\n",
            "772/1000->eq:0.29*sqrt(x1*\n",
            "*2-0.5*x1+0.1)\n",
            "\n",
            "773/1000->eq:2.27\n",
            "*x1-1.18\n",
            "\n",
            "774/1000->eq:2*x1-0.2<EOS_E\n",
            "Q>\n",
            "\n",
            "775/1000->eq:2*x1-0.2<EOS_E\n",
            "Q>\n",
            "\n",
            "776/1000->eq:-0.03*x\n",
            "1**2+0.93*x1\n",
            "\n",
            "777/1000->eq:sin(sin(x1-0.\n",
            "1))\n",
            "\n",
            "778/1000->eq:2*x1*sqrt(x1\n",
            "-0.98)+0.82\n",
            "\n",
            "779/1000->eq:x1+sin(0.7\n",
            "8*x1)-0.12\n",
            "\n",
            "780/1000->eq:sqrt(x1-0.1)\n",
            "\n",
            "\n",
            "781/1000->eq:-0.22*x1-0.33*sin(0.24*x1-0.02)\n",
            "\n",
            "782/1000->eq:x1**2+\n",
            "0.78*x1-sin(0.01*x1-0.74)\n",
            "\n",
            "783/1000->eq:-0.14*\n",
            "x1**2+0.9*x1-0.67\n",
            "\n",
            "784/1000->eq:-0.01*x1+sin(x1-0.53)-0.12\n",
            "\n",
            "785/1000->eq:-0.9*x1**2+0.06*x1\n",
            "\n",
            "786/1000->eq:0.37*sqrt(\n",
            "0.29*x1+1)\n",
            "\n",
            "787/1000->eq:sin(0.44*\n",
            "x1-0.13)\n",
            "\n",
            "788/1000->eq:0.66*sqrt(\n",
            "-0.67*x1-1)\n",
            "\n",
            "789/1000->eq:x1-sin(0.37*\n",
            "x1)-0.04\n",
            "\n",
            "790/1000->eq:sin(x1-0.1)<EOS\n",
            "_EQ>x194)\n",
            "\n",
            "791/1000->eq:-1.48*x1*sin(0.95*x1+0.09)\n",
            "\n",
            "792/1000->eq:x1**\n",
            "2+1.52*x1-0.12\n",
            "\n",
            "793/1000->eq:0.04-0.65*x1\n",
            "\n",
            "794/1000->eq:0.93*sqrt(0.1-\n",
            "x1)\n",
            "\n",
            "795/1000->eq:2*x1-1.12\n",
            "\n",
            "\n",
            "796/1000->eq:2.86*x1-0.0\n",
            "7\n",
            "\n",
            "797/1000->eq:x1*sqrt(x1-0.\n",
            "1)-0.06\n",
            "\n",
            "798/1000->eq:-sin(0.95*x1**2-0.15*x1)\n",
            "\n",
            "799/1000->eq:0.39\n",
            "*x1**2+0.47*x1+sin(0.85*x1-0.65)\n",
            "\n",
            "800/1000->eq:sin(0.76*x1-0\n",
            ".06)\n",
            "\n",
            "801/1000->eq:0.97*sqrt\n",
            "(x1)-0.1)**(1)\n",
            "\n",
            "802/1000->eq:<SOS_Y>[-0.52, -0.53, -0.51, -0.48, -0.42, -0.34, -0.26, -0.17, -0.06,\n",
            " 0.04, 0.14, 0.24, 0.31, 0.38, 0.43, 0.46, 0.47, 0.46, 0.42, 0.37, 0.3\n",
            ", 0.22, 0.12, 0.02, -0.08, -0.19, -0.28, -0.36, -0.43, -0.48]<EOS_Y><S\n",
            "OS_EQ>sin(x1-0.96)*sin(x1+0.67)\n",
            "\n",
            "\n",
            "803/1000->eq:0.96*sqrt(0.\n",
            "22-x1)\n",
            "\n",
            "804/1000->eq:x1*sqrt(x1-0.\n",
            "1)-0.08\n",
            "\n",
            "805/1000->eq:sqrt(sin(0.21*\n",
            "x1-0.67))\n",
            "\n",
            "806/1000->eq:1.27*sqrt(0.\n",
            "54-x1)\n",
            "\n",
            "807/1000->eq:x1-0.1<EOS_E\n",
            "Q>\n",
            "\n",
            "808/1000->eq:-0.24*x1+0.03*sqrt(-x1)\n",
            "\n",
            "809/1000->eq:-0.69*x1**2+x1+0.06*sqrt(x1-0.74)\n",
            "\n",
            "810/1000->eq:sin(0.42*sqr\n",
            "t(x1-0.1))\n",
            "\n",
            "811/1000->eq:sin(sin(x1\n",
            "+0.06))\n",
            "\n",
            "812/1000->eq:1.7\n",
            "4*x1-1.42\n",
            "\n",
            "813/1000->eq:-0.39*x1+0\n",
            ".5*sin(0.05*x1)\n",
            "\n",
            "814/1000->eq:0.94*(-x1-0.1\n",
            ")**(1/4)\n",
            "\n",
            "815/1000->eq:sqrt(sin(x1-0.\n",
            "1))\n",
            "\n",
            "816/1000->eq:sqrt(x1)+sqr\n",
            "t(x1-0.21)\n",
            "\n",
            "817/1000->eq:1.36*sqrt(x1\n",
            "-0.1)\n",
            "\n",
            "818/1000->eq:0.22*x1\n",
            "**2-0.92\n",
            "\n",
            "819/1000->eq:sqrt(sin(x1-0.\n",
            "1))\n",
            "\n",
            "820/1000->eq:x1**2-0.18*x1\n",
            "+sin(0.43*x1-0.14)\n",
            "\n",
            "821/1000->eq:sin(0.99*sq\n",
            "rt(0.12*x1-1))\n",
            "\n",
            "822/1000->eq:sin\n",
            "(x1-0.86)\n",
            "\n",
            "823/1000->eq:sin(0.76\n",
            "*sqrt(0.04*x1-1))\n",
            "\n",
            "824/1000->eq:0.96*sqrt(0.\n",
            "1-x1)\n",
            "\n",
            "825/1000->eq:1.31*\n",
            "x1-0.9\n",
            "\n",
            "826/1000->eq:-sin(0.93*x1**2-0.1*x1)\n",
            "\n",
            "827/1000->eq:sqrt(x1**2+0\n",
            ".84*x1-0.1)\n",
            "\n",
            "828/1000->eq:0.35*x1+sin(0.4\n",
            "*x1)-0.06\n",
            "\n",
            "829/1000->eq:sin(0.37*x1-\n",
            "0.02)\n",
            "\n",
            "830/1000->eq:sqrt(x1-0\n",
            ".05)\n",
            "\n",
            "831/1000->eq:sqrt(sin(x1-0.\n",
            "1))\n",
            "\n",
            "832/1000->eq:sqrt(x1+0.7)\n",
            "\n",
            "\n",
            "833/1000->eq:sqrt(x1)+sq\n",
            "rt(x1-0.27)\n",
            "\n",
            "834/1000->eq:2.25*x1-0.9\n",
            "7\n",
            "\n",
            "835/1000->eq:0.27*sqrt(x1\n",
            "**2-0.1*x1)\n",
            "\n",
            "836/1000->eq:-sin(1.03*x1-0.1)\n",
            "\n",
            "837/1000->eq:0.72*x1**(3\n",
            "/2)-0.07\n",
            "\n",
            "838/1000->eq:0.82*sqrt(x\n",
            "1+0.25)+0.91*sqrt(1-0.96*x1)\n",
            "\n",
            "839/1000->eq:-0.81*x1**2+0.72*x1-0.03\n",
            "\n",
            "840/1000->eq:sin(sqrt(x1-0.1))<\n",
            "EOS_EQ>\n",
            "\n",
            "841/1000->eq:si\n",
            "n(x1**2-0.06*x1)\n",
            "\n",
            "842/1000->eq:sqrt(x1)+s\n",
            "qrt(x1-0.3)\n",
            "\n",
            "843/1000->eq:0.47*x1*sqrt\n",
            "(-x1)-0.1\n",
            "\n",
            "844/1000->eq:0.45-0.75*x1\n",
            "\n",
            "845/1000->eq:x1**2+0.52*x\n",
            "1+sin(x1-0.09)\n",
            "\n",
            "846/1000->eq:0.28*x1**3-0.15*x1**2\n",
            "\n",
            "847/1000->eq:(x1-0.1)**(1/\n",
            "4)\n",
            "\n",
            "848/1000->eq:0.17*x1-0.38\n",
            "\n",
            "849/1000->eq:1.37*\n",
            "x1**2-0.47*x1+0.04\n",
            "\n",
            "850/1000->eq:-0.9*sqrt(x1-0.11)*sin(0.76*x1-0.12)\n",
            "\n",
            "851/1000->eq:sqrt(sin(0.65\n",
            "*x1-0.98))\n",
            "\n",
            "852/1000->eq:sin(sqrt(x1+0.24\n",
            "))\n",
            "\n",
            "853/1000->eq:x1+0.4<EOS\n",
            "_EQ>\n",
            "\n",
            "854/1000->eq:0.54*sqrt(0\n",
            ".1*x1+1)\n",
            "\n",
            "855/1000->eq:-sin(0.51*x1**2-0.08*x1)\n",
            "\n",
            "856/1000->eq:sqrt(x1-0.35\n",
            ")\n",
            "\n",
            "857/1000->eq:0.01*x1-1.05*sin(x1-0.09)\n",
            "\n",
            "858/1000->eq:sqrt(sin(0.7*x\n",
            "1+0.87))\n",
            "\n",
            "859/1000->eq:sin(x1)+\n",
            "sin(x1+0.52)\n",
            "\n",
            "860/1000->eq:0.94*x1+s\n",
            "in(x1+0.19)\n",
            "\n",
            "861/1000->eq:sin(sqrt(x1-0.3))\n",
            "\n",
            "\n",
            "862/1000->eq:-0.2\n",
            "3*x1**2+0.17*x1+0.47\n",
            "\n",
            "863/1000->eq:sin(sin(0\n",
            ".62*x1-0.06))\n",
            "\n",
            "864/1000->eq:sqrt(2)*sqrt(x\n",
            "1+0.25)\n",
            "\n",
            "865/1000->eq:0.49-0.93*x1\n",
            "\n",
            "866/1000->eq:0.31*x1+0.3\n",
            "3\n",
            "\n",
            "867/1000->eq:-sin(sin(0.61*x1-0.07))\n",
            "\n",
            "868/1000->eq:0.34*x1+s\n",
            "in(x1-0.53)-0.18\n",
            "\n",
            "869/1000->eq:<SOS_Y>[0.65, 0.62, 0.59, 0.55, 0.52, 0.48, 0.45, 0.41, 0.37, 0.34, 0.\n",
            "3, 0.26, 0.22, 0.18, 0.14, 0.1, 0.05, 0.01, -0.02, -0.07, -0.11, -0.15\n",
            ", -0.19, -0.23, -0.27, -0.31, -0.35, -0.38, -0.42, -0.46]<EOS_Y><SOS_E\n",
            "Q>-sin(0.37*x1-0.74)\n",
            "\n",
            "\n",
            "870/1000->eq:sin(0.27*sq\n",
            "rt(x1-0.1))\n",
            "\n",
            "871/1000->eq:-0.28*x1**2*sqrt(x1-0.2)\n",
            "\n",
            "872/1000->eq:sin(0.11*x1-0.97)\n",
            "\n",
            "873/1000->eq:0.\n",
            "95*x1**2+0.37\n",
            "\n",
            "874/1000->eq:sin(sin(0.25*\n",
            "x1+0.2))\n",
            "\n",
            "875/1000->eq:\n",
            "0.52*x1-0.92\n",
            "\n",
            "876/1000->eq:x1**2-0.76*\n",
            "x1+0.85*sqrt(-x1)+0.34\n",
            "\n",
            "877/1000->eq:1.07*x1*sq\n",
            "rt(x1-0.54)+0.39\n",
            "\n",
            "878/1000->eq:1.62*sqrt(x\n",
            "1-0.1)\n",
            "\n",
            "879/1000->eq:x1+sqrt(x1+0.\n",
            "35)-0.13\n",
            "\n",
            "880/1000->eq:0.95*(0.59\n",
            "*x1+1)**(1/4)\n",
            "\n",
            "881/1000->eq:sin(0.19*x\n",
            "1+0.73)\n",
            "\n",
            "882/1000->eq:sin(x1-0.1)<EOS\n",
            "_EQ>x1)\n",
            "\n",
            "883/1000->eq:x1-0.1<EOS_E\n",
            "Q>\n",
            "\n",
            "884/1000->eq:sqrt(x1)+x1\n",
            "**2+0.2\n",
            "\n",
            "885/1000->eq:sqrt(x1-0.1)\n",
            "\n",
            "\n",
            "886/1000->eq:sin(0.39*x1-0.88)\n",
            "\n",
            "887/1000->eq:0.9*sqrt(0\n",
            ".09-x1)*sin(0.09*x1)\n",
            "\n",
            "888/1000->eq:\n",
            "sin(x1**2+0.59*x1-0.06)\n",
            "\n",
            "889/1000->eq:0.48*sqrt(1-\n",
            "0.1*x1)*sqrt(x1-0.1)\n",
            "\n",
            "890/1000->eq:1.18*x1+0.28\n",
            "\n",
            "\n",
            "891/1000->eq:sin(sin(x1\n",
            "+0.45))\n",
            "\n",
            "892/1000->eq:3*x1+0.92<\n",
            "EOS_EQ>\n",
            "\n",
            "893/1000->eq:-0.39*x1**2-0.09*x1+0.66\n",
            "\n",
            "894/1000->eq:sqrt(x1)+x1-\n",
            "0.39\n",
            "\n",
            "895/1000->eq:sin(0.25*\n",
            "x1**2+0.63*x1+0.02)\n",
            "\n",
            "896/1000->eq:0.9*sqrt(0\n",
            ".17*x1**2+x1+0.23)\n",
            "\n",
            "897/1000->eq:x1+0.49<EOS\n",
            "_EQ>\n",
            "\n",
            "898/1000->eq:2*x1+0.64<EOS_\n",
            "EQ>\n",
            "\n",
            "899/1000->eq:sin(x1-0.1)<EOS\n",
            "_EQ>x1)\n",
            "\n",
            "900/1000->eq:<SOS_Y>[0.66, 0.8, 0.91, 0.97, 1.0, 0.98, 0.92, 0.83, 0.69, 0.53, 0.35\n",
            ", 0.14, -0.06, -0.26, -0.46, -0.63, -0.78, -0.89, -0.96, -1.0, -0.99, \n",
            "-0.94, -0.84, -0.72, -0.57, -0.37, -0.18, 0.02, 0.24, 0.42]<EOS_Y><SOS\n",
            "_EQ>sin(2*x1+0.52)\n",
            "\n",
            "\n",
            "901/1000->eq:-sin(sin(0.06*x1+0.64))\n",
            "\n",
            "902/1000->eq:0.86*sqrt(-x\n",
            "1-0.96)\n",
            "\n",
            "903/1000->eq:1.03*x\n",
            "1-0.05\n",
            "\n",
            "904/1000->eq:0.04*x1**2<EOS\n",
            "_EQ>\n",
            "\n",
            "905/1000->eq:-sin(0.23*x1**2-0.04*x1)\n",
            "\n",
            "906/1000->eq:sqrt(sin(x1+\n",
            "0.37))\n",
            "\n",
            "907/1000->eq:-sin(0.14*x1\n",
            "-0.45)\n",
            "\n",
            "908/1000->eq:x1**2-0.3\n",
            "9*x1-0.09\n",
            "\n",
            "909/1000->eq:0.22*x1**2+s\n",
            "in(x1-0.09)\n",
            "\n",
            "910/1000->eq:0.7*x1**2-0.\n",
            "04*x1\n",
            "\n",
            "911/1000->eq:sin(0.58*x1+\n",
            "0.39)\n",
            "\n",
            "912/1000->eq:0.86*x1+0.6\n",
            "2\n",
            "\n",
            "913/1000->eq:sqrt(x1-0.1)\n",
            "\n",
            "\n",
            "914/1000->eq:<SOS_Y>[-0.56, -0.38, -0.17, 0.03, 0.22, 0.43, 0.6, 0.75, 0.88, 0.95, \n",
            "0.99, 0.99, 0.95, 0.87, 0.74, 0.59, 0.4, 0.21, 0.01, -0.2, -0.39, -0.5\n",
            "7, -0.73, -0.85, -0.94, -0.99, -1.0, -0.96, -0.88, -0.77]<EOS_Y><SOS_E\n",
            "Q>sin(2*x1-0.79)\n",
            "\n",
            "\n",
            "915/1000->eq:0.84*x1+sin\n",
            "(x1+0.03)\n",
            "\n",
            "916/1000->eq:0.13-0.37*x1\n",
            "\n",
            "917/1000->eq:sin(x1-0.1)<EOS\n",
            "_EQ>x1)\n",
            "\n",
            "918/1000->eq:0.88*sqrt(x1**\n",
            "2+0.87*x1-0.05)\n",
            "\n",
            "919/1000->eq:0.36*x1**2+0\n",
            ".37*x1-0.02\n",
            "\n",
            "920/1000->eq:0.93*sqrt(x1-0\n",
            ".19)\n",
            "\n",
            "921/1000->eq:sqrt(x1-0.1)\n",
            "\n",
            "\n",
            "922/1000->eq:0.75*sqrt(x1-\n",
            "0.1)\n",
            "\n",
            "923/1000->eq:-sin(0.25*x1-0.19)\n",
            "\n",
            "924/1000->eq:x1+sin(\n",
            "x1)-0.76\n",
            "\n",
            "925/1000->eq:0.38*x1**2\n",
            "-0.22\n",
            "\n",
            "926/1000->eq:x1+sin(0\n",
            ".2*x1-0.44)\n",
            "\n",
            "927/1000->eq:<SOS_Y>[0.0, 0.2, 0.41, 0.58, 0.73, 0.86, 0.95, 0.99, 1.0, 0.96, 0.88,\n",
            " 0.76, 0.61, 0.45, 0.24, 0.04, -0.18, -0.37, -0.55, -0.72, -0.84, -0.9\n",
            "3, -0.99, -1.0, -0.97, -0.89, -0.79, -0.65, -0.46, -0.28]<EOS_Y><SOS_E\n",
            "Q>sin(2*x1-0.2)\n",
            "\n",
            "\n",
            "928/1000->eq:0.81*sqrt(0.\n",
            "55*x1+1)\n",
            "\n",
            "929/1000->eq:-sin(0.88*x1-0.1)\n",
            "\n",
            "930/1000->eq:<SOS_Y>[0.54, 0.51, 0.47, 0.43, 0.4, 0.36, 0.32, 0.28, 0.23, 0.19, 0.1\n",
            "5, 0.1, 0.06, 0.01, -0.04, -0.08, -0.13, -0.17, -0.21, -0.26, -0.3, -0\n",
            ".34, -0.38, -0.42, -0.45, -0.49, -0.52, -0.55, -0.59, -0.61]<EOS_Y><SO\n",
            "S_EQ>-sin(0.41*x1-0.61)\n",
            "\n",
            "\n",
            "931/1000->eq:1.31*sqrt(x1-0.\n",
            "05)\n",
            "\n",
            "932/1000->eq:sqrt(x1)+0.\n",
            "3*x1+0.39\n",
            "\n",
            "933/1000->eq:sin(0.61*sqrt\n",
            "(0.05*x1+1))\n",
            "\n",
            "934/1000->eq:x1+sin(x\n",
            "1-0.97)\n",
            "\n",
            "935/1000->eq:0.08*x1<EOS\n",
            "_EQ>\n",
            "\n",
            "936/1000->eq:1.5*x1**(3/2)\n",
            "-0.12\n",
            "\n",
            "937/1000->eq:0.96*(x1-0.9\n",
            "2)**(1/4)\n",
            "\n",
            "938/1000->eq:sin(si\n",
            "n(x1+0.48))\n",
            "\n",
            "939/1000->eq:sqrt(x1**2-0\n",
            ".1*x1)\n",
            "\n",
            "940/1000->eq:sin(x1-0.1)<EOS\n",
            "_EQ>x1+0.1)\n",
            "\n",
            "941/1000->eq:1.08*sqrt(x1-0\n",
            ".1)\n",
            "\n",
            "942/1000->eq:sqrt(x1-0.1)\n",
            "\n",
            "\n",
            "943/1000->eq:0.2*x1**2+\n",
            "0.29*x1+0.1\n",
            "\n",
            "944/1000->eq:sin(x1-0.1)<EOS\n",
            "_EQ>x1)\n",
            "\n",
            "945/1000->eq:0.44*x1+sq\n",
            "rt(x1-0.11)\n",
            "\n",
            "946/1000->eq:0.95*x1-0.1\n",
            "\n",
            "947/1000->eq:sin(0.83*x1)*\n",
            "sin(x1-0.06)\n",
            "\n",
            "948/1000->eq:-0.89*x1**2-0.31*x1+0.94*sqrt(-0.83*x1-1)\n",
            "\n",
            "949/1000->eq:0.49*x1**2-0.45*x1\n",
            "\n",
            "950/1000->eq:sqrt(x1)\n",
            "+0.41*x1-0.97\n",
            "\n",
            "951/1000->eq:x1-\n",
            "0.75\n",
            "\n",
            "952/1000->eq:x1-0.1<EOS_E\n",
            "Q>\n",
            "\n",
            "953/1000->eq:sin(sin(x1-0.\n",
            "1))\n",
            "\n",
            "954/1000->eq:2*x1-\n",
            "1.92\n",
            "\n",
            "955/1000->eq:sqrt(2)*sqr\n",
            "t(x1-0.1)\n",
            "\n",
            "956/1000->eq:1.36*x1-\n",
            "0.43\n",
            "\n",
            "957/1000->eq:sin(x1-0.1)<EOS\n",
            "_EQ>x1)\n",
            "\n",
            "958/1000->eq:2*x1-0\n",
            ".47\n",
            "\n",
            "959/1000->eq:sin(x1-0.1)<EOS\n",
            "_EQ>x1)\n",
            "\n",
            "960/1000->eq:0.3*sqrt(0.0\n",
            "4*x1**2-x1+0.08)\n",
            "\n",
            "961/1000->eq:-2.16*x1**2-0.41\n",
            "\n",
            "962/1000->eq:s\n",
            "in(1.58*x1-0.13)\n",
            "\n",
            "963/1000->eq:1.89*x1*sqrt(\n",
            "-0.42*x1-1)+0.19\n",
            "\n",
            "964/1000->eq:0.36*sqrt(x1*\n",
            "*2-0.03*x1)\n",
            "\n",
            "965/1000->eq:0.55*x1+\n",
            "sin(x1+0.08)+0.77\n",
            "\n",
            "966/1000->eq:<SOS_Y>[0.09, 0.29, 0.49, 0.65, 0.79, 0.9, 0.97, 1.0, 0.98, 0.93, 0.84\n",
            ", 0.7, 0.54, 0.36, 0.15, -0.05, -0.26, -0.45, -0.62, -0.78, -0.89, -0.\n",
            "96, -1.0, -0.99, -0.94, -0.85, -0.73, -0.58, -0.38, -0.19]<EOS_Y><SOS_\n",
            "EQ>sin(2*x1-0.11)\n",
            "\n",
            "\n",
            "967/1000->eq:1.34*x1-0.12\n",
            "\n",
            "\n",
            "968/1000->eq:-0.81*x1**3-0.18\n",
            "\n",
            "969/1000->eq:1.25*sqrt(x1\n",
            "+0.41)\n",
            "\n",
            "970/1000->eq:0.58*x1*\n",
            "*2+0.24*x1+0.03\n",
            "\n",
            "971/1000->eq:0.9*x1*sqrt\n",
            "(-x1)-0.1\n",
            "\n",
            "972/1000->eq:sqrt(sin(x1+0.\n",
            "84))\n",
            "\n",
            "973/1000->eq:sin(\n",
            "0.55*x1**2+0.04*x1-0.02)\n",
            "\n",
            "974/1000->eq:1.5*x1-\n",
            "0.55\n",
            "\n",
            "975/1000->eq:sin(0.81*x1+0.45\n",
            ")\n",
            "\n",
            "976/1000->eq:sin(0.62*sqr\n",
            "t(x1-0.11))\n",
            "\n",
            "977/1000->eq:sin(sqrt(x1-0.3\n",
            "))\n",
            "\n",
            "978/1000->eq:-sin(0.26*x1**2+0.26*x1+0.04)\n",
            "\n",
            "979/1000->eq:x1-0.1<EOS_E\n",
            "Q>\n",
            "\n",
            "980/1000->eq:sqrt(sin(0.05\n",
            "*x1-0.02))\n",
            "\n",
            "981/1000->eq:0.12*x1**3+0\n",
            ".12*x1\n",
            "\n",
            "982/1000->eq:sin(x1-0.1)<EOS\n",
            "_EQ>x1)\n",
            "\n",
            "983/1000->eq:<SOS_Y>[-1.15, -1.06, -0.96, -0.87, -0.77, -0.67, -0.58, -0.48, -0.38,\n",
            " -0.29, -0.2, -0.09, -0.0, 0.09, 0.19, 0.29, 0.39, 0.48, 0.57, 0.68, 0\n",
            ".77, 0.86, 0.96, 1.06, 1.15, 1.25, 1.35, 1.44, 1.54, 1.63]<EOS_Y><SOS_\n",
            "EQ>0.6*x1-1.22\n",
            "\n",
            "\n",
            "984/1000->eq:<SOS_Y>[-0.51, -0.48, -0.44, -0.4, -0.36, -0.32, -0.29, -0.25, -0.21, \n",
            "-0.18, -0.14, -0.1, -0.06, -0.03, 0.01, 0.05, 0.09, 0.13, 0.16, 0.2, 0\n",
            ".24, 0.28, 0.32, 0.35, 0.39, 0.43, 0.47, 0.5, 0.54, 0.58]<EOS_Y><SOS_E\n",
            "Q>sin(0.38*x1-0.58)\n",
            "\n",
            "\n",
            "985/1000->eq:sqrt(x1-0.1)\n",
            "\n",
            "\n",
            "986/1000->eq:1.04*\n",
            "x1-0.69\n",
            "\n",
            "987/1000->eq:0.06*x1**2+0.17*x1-0.81\n",
            "\n",
            "988/1000->eq:sqrt(x1-0.68\n",
            ")-sin(0.12*x1-0.68)\n",
            "\n",
            "989/1000->eq:sqrt(x1**2\n",
            "+0.85*x1+0.05)\n",
            "\n",
            "990/1000->eq:0.92*sqrt(\n",
            "0.48*x1+1)\n",
            "\n",
            "991/1000->eq:<SOS_Y>[-0.56, -0.52, -0.48, -0.45, -0.41, -0.37, -0.33, -0.29, -0.25,\n",
            " -0.21, -0.17, -0.13, -0.09, -0.05, -0.0, 0.04, 0.08, 0.12, 0.16, 0.21\n",
            ", 0.25, 0.29, 0.33, 0.37, 0.4, 0.44, 0.48, 0.51, 0.55, 0.59]<EOS_Y><SO\n",
            "S_EQ>sin(0.42*x1-0.64)\n",
            "\n",
            "\n",
            "992/1000->eq:sin(x1+0.14)\n",
            "\n",
            "\n",
            "993/1000->eq:0.2*x1+0.1\n",
            "4\n",
            "\n",
            "994/1000->eq:(x1+0.7)**(1\n",
            "/4)\n",
            "\n",
            "995/1000->eq:(x1-0.1)**(1/\n",
            "4)\n",
            "\n",
            "996/1000->eq:(x1+0.36)**\n",
            "(1/4)\n",
            "\n",
            "997/1000->eq:0.82*sqrt(0.03\n",
            "*x1-1)\n",
            "\n",
            "998/1000->eq:sqrt(-sin(0.3*x1+0\n",
            ".82))\n",
            "\n",
            "999/1000->eq:sin(0.94*x1-\n",
            "0.09)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75b1d39decf248f0bfc3948c45a8a8ab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Test case 0/1000.\n",
            "True equation: -sin(1.1*x1+0.64)\n",
            "GPT2 function:  -sin(1.07*x1+0.55)\n",
            " ---> GPT2 Test Error: 0.02535\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 4.48657\n",
            "Genetic Model function:  sin(add(mul(-0.568, add(X0, X0)), -0.568))\n",
            " ---> GP Test Error: 0.00714\n",
            "Test case 1/1000.\n",
            "True equation: -1.42*x1+sqrt(x1+0.53)\n",
            "GPT2 function:  0.86-1.09*x1\n",
            " ---> GPT2 Test Error: 0.02547\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 5.56718\n",
            "Genetic Model function:  add(div(X0, -0.949), 0.844)\n",
            " ---> GP Test Error: 0.09322\n",
            "Test case 2/1000.\n",
            "True equation: sqrt(-sin(0.2*x1))\n",
            "GPT2 function:  sqrt(-sin(0.19*x1-0.01))\n",
            " ---> GPT2 Test Error: 0.00022\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.01939\n",
            "Genetic Model function:  mul(sqrt(X0), exp(-0.819))\n",
            " ---> GP Test Error: 0.00475\n",
            "Test case 3/1000.\n",
            "True equation: sin(sqrt(x1))\n",
            "GPT2 function:  sin(sqrt(x1-0.1))\n",
            " ---> GPT2 Test Error: 0.00016\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.01131\n",
            "Genetic Model function:  sin(sqrt(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 4/1000.\n",
            "True equation: 0.86*x1**2-0.59*x1+1.36\n",
            "GPT2 function:  0.86*x1**2-0.27*x1+1.42\n",
            " ---> GPT2 Test Error: 2.62420\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 27.92246\n",
            "Genetic Model function:  add(sqrt(-0.602), exp(mul(log(X0), sqrt(X0))))\n",
            " ---> GP Test Error: 471.49726\n",
            "Test case 5/1000.\n",
            "True equation: 0.28*sqrt(-x1**2)\n",
            "GPT2 function:  0.28*sqrt(x1**2)\n",
            " ---> GPT2 Test Error: 0.00041\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.24139\n",
            "Genetic Model function:  mul(add(exp(log(0.044)), sqrt(mul(-0.264, 0.221))), add(log(exp(X0)), sin(log(-0.002))))\n",
            " ---> GP Test Error: 0.00093\n",
            "Test case 6/1000.\n",
            "True equation: sin(0.07*x1**2+0.28*x1)\n",
            "GPT2 function:  sin(0.33*x1-0.03)\n",
            " ---> GPT2 Test Error: 1.06848\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 4.22495\n",
            "Genetic Model function:  mul(X0, 0.367)\n",
            " ---> GP Test Error: 3.16630\n",
            "Test case 7/1000.\n",
            "<class 'TypeError'> \n",
            "\n",
            " Error: sin(3.1-0.1)3.112), EQ:sin(x1-0.1)x112)\n",
            "Not calculated\n",
            "Test case 8/1000.\n",
            "True equation: 0.81*sqrt(-x1**2-0.95*x1+0.12)\n",
            "GPT2 function:  0.81*sqrt(x1**2+0.88*x1-0.12)\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.17520\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  X0\n",
            " ---> GP Test Error: 0.30699\n",
            "Test case 9/1000.\n",
            "True equation: sin(x1+0.37)\n",
            "GPT2 function:  sin(x1+0.27)\n",
            " ---> GPT2 Test Error: 0.00462\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.08676\n",
            "Genetic Model function:  sin(add(X0, 0.386))\n",
            " ---> GP Test Error: 0.00016\n",
            "Test case 10/1000.\n",
            "True equation: -0.68*x1**2+1.77*x1\n",
            "GPT2 function:  -0.6*x1**2+1.39*x1\n",
            " ---> GPT2 Test Error: 38171.22525\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 17628.47520\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  mul(mul(X0, X0), add(add(log(X0), 0.434), add(div(X0, 0.905), log(-0.634))))\n",
            " ---> GP Test Error: 430.46805\n",
            "Test case 11/1000.\n",
            "True equation: sqrt(x1)+0.51*x1**2-0.17*x1\n",
            "GPT2 function:  0.91*x1**2+sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 97.62105\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 35.64707\n",
            "Genetic Model function:  mul(sqrt(X0), add(0.250, X0))\n",
            " ---> GP Test Error: 5.42645\n",
            "Test case 12/1000.\n",
            "True equation: 1.25*x1+0.85*sqrt(-0.68*x1-1)\n",
            "GPT2 function:  1.72*x1+0.7\n",
            " ---> GPT2 Test Error: 1.34479\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00170\n",
            "Genetic Model function:  add(-0.339, exp(sqrt(X0)))\n",
            " ---> GP Test Error: 0.89777\n",
            "Test case 13/1000.\n",
            "True equation: sin(x1**2-0.11*x1)\n",
            "GPT2 function:  sin(x1**2-0.51*x1+0.03)\n",
            " ---> GPT2 Test Error: 1.22013\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 7.21363\n",
            "Genetic Model function:  sin(add(mul(X0, X0), -0.173))\n",
            " ---> GP Test Error: 0.06229\n",
            "Test case 14/1000.\n",
            "True equation: 0.7*sqrt(x1-0.51)\n",
            "GPT2 function:  0.69*sqrt(x1-0.61)\n",
            " ---> GPT2 Test Error: 0.00090\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.11381\n",
            "Genetic Model function:  sqrt(mul(add(X0, -0.485), exp(-0.750)))\n",
            " ---> GP Test Error: 0.00019\n",
            "Test case 15/1000.\n",
            "True equation: sqrt(x1**2+0.31*x1)\n",
            "GPT2 function:  sqrt(x1**2+0.1*x1-0.06)\n",
            " ---> GPT2 Test Error: 0.01146\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.01918\n",
            "Genetic Model function:  log(mul(exp(X0), exp(0.150)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 16/1000.\n",
            "True equation: 4*x1-0.25\n",
            "GPT2 function:  4*x1-0.57\n",
            " ---> GPT2 Test Error: 0.10240\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.30935\n",
            "Genetic Model function:  add(sin(-0.256), add(add(X0, X0), add(X0, X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 17/1000.\n",
            "True equation: 1.64*x1**2-0.31*x1-0.13\n",
            "GPT2 function:  0.77*x1\n",
            " ---> GPT2 Test Error: 1053.41570\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 217.52684\n",
            "Genetic Model function:  mul(exp(sqrt(mul(X0, 0.068))), mul(X0, X0))\n",
            " ---> GP Test Error: 29.16801\n",
            "Test case 18/1000.\n",
            "True equation: sqrt(-sin(0.37*x1-0.65))\n",
            "GPT2 function:  0.8*sqrt(1-0.54*x1)\n",
            " ---> GPT2 Test Error: 0.00769\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.30668\n",
            "Genetic Model function:  sin(exp(sin(mul(-0.978, X0))))\n",
            " ---> GP Test Error: 0.08313\n",
            "Test case 19/1000.\n",
            "True equation: 1.48*x1**2+0.55\n",
            "GPT2 function:  0.63*x1**2+1.24*x1-0.13\n",
            " ---> GPT2 Test Error: 15188.43852\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 11151.59689\n",
            "Genetic Model function:  mul(X0, add(mul(X0, X0), add(0.336, X0)))\n",
            " ---> GP Test Error: 0.16370\n",
            "Test case 20/1000.\n",
            "True equation: 0.56*x1**2+0.69*x1+0.82\n",
            "GPT2 function:  0.82*x1**2-0.03*x1+sin(x1+0.88)\n",
            " ---> GPT2 Test Error: 4.85382\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 23.01382\n",
            "Genetic Model function:  sqrt(add(exp(X0), mul(mul(X0, X0), div(X0, 0.658))))\n",
            " ---> GP Test Error: 0.46975\n",
            "Test case 21/1000.\n",
            "True equation: 0.93*sqrt(0.62*x1+1)\n",
            "GPT2 function:  0.88*sqrt(-0.65*x1-1)\n",
            " ---> GPT2 Test Error: 0.00385\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00066\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  exp(mul(0.158, X0))\n",
            " ---> GP Test Error: 0.09189\n",
            "Test case 22/1000.\n",
            "True equation: 2*x1+sin(x1)-0.89\n",
            "GPT2 function:  2*x1+sin(x1)-1.25\n",
            " ---> GPT2 Test Error: 0.13288\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 9.65501\n",
            "Genetic Model function:  add(sin(X0), add(X0, add(X0, -0.893)))\n",
            " ---> GP Test Error: 0.00006\n",
            "Test case 23/1000.\n",
            "True equation: 0.93*x1*sin(0.85*x1+0.49)\n",
            "GPT2 function:  x1*sin(0.95*x1+0.07)-0.03\n",
            " ---> GPT2 Test Error: 0.09368\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.11562\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  mul(sin(X0), sqrt(mul(X0, sqrt(X0))))\n",
            " ---> GP Test Error: 1.87381\n",
            "Test case 24/1000.\n",
            "True equation: -sin(sin(0.4*x1+0.16))\n",
            "GPT2 function:  -sin(sin(0.33*x1+0.13))\n",
            " ---> GPT2 Test Error: 0.01149\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.15929\n",
            "Genetic Model function:  mul(-0.513, sqrt(X0))\n",
            " ---> GP Test Error: 0.15520\n",
            "Test case 25/1000.\n",
            "True equation: 0.1*x1**3\n",
            "GPT2 function:  0.05*x1**3\n",
            " ---> GPT2 Test Error: 27.63742\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 43.03234\n",
            "Genetic Model function:  mul(log(exp(mul(0.397, X0))), mul(mul(0.263, X0), mul(X0, 0.910)))\n",
            " ---> GP Test Error: 0.00644\n",
            "Test case 26/1000.\n",
            "True equation: 0.8*sqrt(x1)\n",
            "GPT2 function:  0.79*sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00250\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00995\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  sqrt(mul(-0.649, X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 27/1000.\n",
            "True equation: 0.83*sqrt(x1)+x1\n",
            "GPT2 function:  sqrt(x1)+0.9*x1-0.37\n",
            " ---> GPT2 Test Error: 0.20814\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.18207\n",
            "Genetic Model function:  add(sqrt(mul(X0, 0.709)), add(X0, -0.008))\n",
            " ---> GP Test Error: 0.00077\n",
            "Test case 28/1000.\n",
            "True equation: 1.83*x1-1.34\n",
            "GPT2 function:  1.82*x1-1.53\n",
            " ---> GPT2 Test Error: 0.05388\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00016\n",
            "Genetic Model function:  add(div(-0.956, 0.608), add(X0, X0))\n",
            " ---> GP Test Error: 0.31796\n",
            "Test case 29/1000.\n",
            "True equation: 1.79*x1**2\n",
            "GPT2 function:  1.35*x1**3\n",
            " ---> GPT2 Test Error: 565.42709\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 5858.41433\n",
            "Genetic Model function:  mul(add(0.015, X0), add(mul(X0, X0), mul(0.766, X0)))\n",
            " ---> GP Test Error: 0.00298\n",
            "Test case 30/1000.\n",
            "True equation: -0.53*x1-0.76*sin(x1-0.43)\n",
            "GPT2 function:  -0.41*x1-sin(0.97*x1-0.42)\n",
            " ---> GPT2 Test Error: 12.66179\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 3.32095\n",
            "Genetic Model function:  mul(sin(mul(0.965, X0)), mul(mul(-0.707, X0), sqrt(X0)))\n",
            " ---> GP Test Error: 10.52680\n",
            "Test case 31/1000.\n",
            "True equation: sqrt(sin(x1-0.76))\n",
            "GPT2 function:  sqrt(sin(x1-0.86))\n",
            " ---> GPT2 Test Error: 0.00866\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.07041\n",
            "Genetic Model function:  sqrt(sin(add(add(X0, -0.128), -0.607)))\n",
            " ---> GP Test Error: 0.00050\n",
            "Test case 32/1000.\n",
            "True equation: 0.34*x1**2-0.05*x1-0.08\n",
            "GPT2 function:  0.38*x1**2-0.16*x1-0.07\n",
            " ---> GPT2 Test Error: 0.20012\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 14.77150\n",
            "Genetic Model function:  mul(mul(X0, 0.392), add(-0.515, X0))\n",
            " ---> GP Test Error: 0.36279\n",
            "Test case 33/1000.\n",
            "True equation: sqrt(2)*sqrt(x1)\n",
            "GPT2 function:  sqrt(2)*sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00121\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.01057\n",
            "Genetic Model function:  sqrt(add(X0, X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 34/1000.\n",
            "True equation: x1**2+0.09*x1+0.69\n",
            "GPT2 function:  x1**2+0.1*x1+0.67\n",
            " ---> GPT2 Test Error: 0.00022\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 42.40274\n",
            "Genetic Model function:  add(mul(X0, X0), 0.830)\n",
            " ---> GP Test Error: 0.08567\n",
            "Test case 35/1000.\n",
            "True equation: 0.97*sqrt(-x1)\n",
            "GPT2 function:  0.96*sqrt(0.1-x1)\n",
            " ---> GPT2 Test Error: 0.00234\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.09627\n",
            "Genetic Model function:  exp(add(log(sqrt(X0)), mul(sin(-0.612), mul(-0.052, -0.773))))\n",
            " ---> GP Test Error: 0.00014\n",
            "Test case 36/1000.\n",
            "True equation: -sin(0.14*x1**2-0.53*x1)\n",
            "GPT2 function:  -0.11*x1**2+0.49*x1-0.03\n",
            " ---> GPT2 Test Error: 0.12546\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.10090\n",
            "Genetic Model function:  mul(sin(mul(X0, 0.902)), 0.454)\n",
            " ---> GP Test Error: 0.11192\n",
            "Test case 37/1000.\n",
            "True equation: 0.85*sqrt(0.1*x1-1)\n",
            "GPT2 function:  0.85*sqrt(0.1*x1-1)\n",
            " ---> GPT2 Test Error: 0.00092\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.01206\n",
            "Genetic Model function:  0.789\n",
            " ---> GP Test Error: 0.01988\n",
            "Test case 38/1000.\n",
            "True equation: sin(0.56*sqrt(x1))\n",
            "GPT2 function:  sin(0.56*sqrt(-x1-0.1))\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00125\n",
            "Genetic Model function:  sin(mul(sqrt(X0), sqrt(-0.313)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 39/1000.\n",
            "True equation: 1.99*x1+0.57\n",
            "GPT2 function:  2*x1+0.34\n",
            " ---> GPT2 Test Error: 0.03226\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 6.40177\n",
            "Genetic Model function:  add(add(0.573, X0), mul(0.982, X0))\n",
            " ---> GP Test Error: 0.00096\n",
            "Test case 40/1000.\n",
            "True equation: sqrt(sin(0.06*x1+0.44))\n",
            "GPT2 function:  sin(sin(0.1*x1+0.78))\n",
            " ---> GPT2 Test Error: 0.00016\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00006\n",
            "Genetic Model function:  0.723\n",
            " ---> GP Test Error: 0.00931\n",
            "Test case 41/1000.\n",
            "True equation: 0.45*x1**2\n",
            "GPT2 function:  0.46*x1**2-0.02*x1\n",
            " ---> GPT2 Test Error: 0.00276\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 16.12204\n",
            "Genetic Model function:  mul(mul(0.456, X0), X0)\n",
            " ---> GP Test Error: 0.00239\n",
            "Test case 42/1000.\n",
            "True equation: x1**2-0.65*x1-0.02\n",
            "GPT2 function:  -0.29*x1**2+1.48*x1-0.03\n",
            " ---> GPT2 Test Error: 46269.00555\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 31401.70570\n",
            "Genetic Model function:  mul(mul(X0, add(sqrt(exp(-0.637)), add(X0, X0))), add(-0.756, X0))\n",
            " ---> GP Test Error: 2.24063\n",
            "Test case 43/1000.\n",
            "True equation: 0.97*sqrt(x1**2-0.28*x1-0.35)\n",
            "GPT2 function:  sqrt(x1**2-0.56*x1-0.31)\n",
            " ---> GPT2 Test Error: 0.00090\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.07343\n",
            "Genetic Model function:  exp(log(add(-0.316, X0)))\n",
            " ---> GP Test Error: 0.00049\n",
            "Test case 44/1000.\n",
            "True equation: (x1-0.15)**(1/4)\n",
            "GPT2 function:  (x1-0.25)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00007\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.13533\n",
            "Genetic Model function:  sqrt(sqrt(add(X0, sin(add(0.445, -0.572)))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 45/1000.\n",
            "True equation: -sin(0.11*x1)\n",
            "GPT2 function:  -sin(sin(0.11*x1-0.03))\n",
            " ---> GPT2 Test Error: 0.00372\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00804\n",
            "Genetic Model function:  mul(sin(log(-0.048)), X0)\n",
            " ---> GP Test Error: 0.00051\n",
            "Test case 46/1000.\n",
            "True equation: 2*x1-1.48\n",
            "GPT2 function:  2*x1-1.69\n",
            " ---> GPT2 Test Error: 0.04410\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.96879\n",
            "Genetic Model function:  div(add(X0, -0.707), exp(-0.678))\n",
            " ---> GP Test Error: 0.00277\n",
            "Test case 47/1000.\n",
            "True equation: 0.73*sqrt(x1)\n",
            "GPT2 function:  0.72*sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00092\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.15573\n",
            "Genetic Model function:  sqrt(mul(-0.536, X0))\n",
            " ---> GP Test Error: 0.00016\n",
            "Test case 48/1000.\n",
            "True equation: 0.14*x1\n",
            "GPT2 function:  -0.14*x1**2+0.14*x1\n",
            " ---> GPT2 Test Error: 1.38880\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.31531\n",
            "Genetic Model function:  0.084\n",
            " ---> GP Test Error: 2.17066\n",
            "Test case 49/1000.\n",
            "True equation: 0.88*(-x1)**(1/4)\n",
            "GPT2 function:  0.89*(-x1-0.1)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.02344\n",
            "Genetic Model function:  sqrt(sqrt(mul(0.602, X0)))\n",
            " ---> GP Test Error: 0.00009\n",
            "Test case 50/1000.\n",
            "True equation: 0.82*x1**2-0.84*x1+0.22\n",
            "GPT2 function:  0.79*x1**2-1.06*x1+0.33\n",
            " ---> GPT2 Test Error: 2.57538\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 193.59566\n",
            "Genetic Model function:  mul(mul(mul(0.539, X0), X0), sqrt(log(X0)))\n",
            " ---> GP Test Error: 0.35336\n",
            "Test case 51/1000.\n",
            "True equation: sqrt(sin(0.03*x1))\n",
            "GPT2 function:  sqrt(-sin(0.03*x1))\n",
            " ---> GPT2 Test Error: 0.00030\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00093\n",
            "Genetic Model function:  sqrt(exp(add(sin(log(div(0.066, -0.333))), log(mul(0.090, X0)))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 52/1000.\n",
            "True equation: (x1+0.54)**(1/4)\n",
            "GPT2 function:  (x1+0.44)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00006\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00504\n",
            "Genetic Model function:  sqrt(sqrt(add(X0, sqrt(0.287))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 53/1000.\n",
            "True equation: 1.8*x1-0.56\n",
            "GPT2 function:  1.79*x1-0.75\n",
            " ---> GPT2 Test Error: 0.04577\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 7.72360\n",
            "Genetic Model function:  mul(exp(exp(-0.496)), add(-0.354, X0))\n",
            " ---> GP Test Error: 0.01306\n",
            "Test case 54/1000.\n",
            "True equation: sin(0.62*sqrt(0.63*x1+1))\n",
            "GPT2 function:  sin(0.13*x1+0.59)\n",
            " ---> GPT2 Test Error: 0.00046\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00005\n",
            "Genetic Model function:  sin(sin(sqrt(X0)))\n",
            " ---> GP Test Error: 0.05027\n",
            "Test case 55/1000.\n",
            "True equation: sqrt(x1-0.89)\n",
            "GPT2 function:  sqrt(x1-0.99)\n",
            " ---> GPT2 Test Error: 0.00081\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.32348\n",
            "Genetic Model function:  sqrt(add(X0, -0.882))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 56/1000.\n",
            "True equation: sin(0.08*x1**2-0.04*x1)\n",
            "GPT2 function:  0.06*x1**2-0.14*x1\n",
            " ---> GPT2 Test Error: 0.17759\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.05435\n",
            "Genetic Model function:  mul(add(log(-0.732), add(0.139, X0)), mul(X0, 0.065))\n",
            " ---> GP Test Error: 0.51612\n",
            "Test case 57/1000.\n",
            "True equation: -0.70\n",
            "GPT2 function:  0.04*x1-0.03\n",
            " ---> GPT2 Test Error: 0.00823\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.02622\n",
            "Genetic Model function:  mul(div(mul(X0, -0.019), exp(X0)), sin(add(X0, -0.308)))\n",
            " ---> GP Test Error: 0.04854\n",
            "Test case 58/1000.\n",
            "True equation: sin(sin(x1))\n",
            "GPT2 function:  sin(sin(x1-0.1))\n",
            " ---> GPT2 Test Error: 0.00366\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.62502\n",
            "Genetic Model function:  sin(sin(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 59/1000.\n",
            "True equation: x1**3+0.71*x1\n",
            "GPT2 function:  1.34*x1**2\n",
            " ---> GPT2 Test Error: 10856.15392\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 6578.66205\n",
            "Genetic Model function:  mul(mul(0.582, X0), add(mul(exp(0.682), mul(X0, X0)), sqrt(X0)))\n",
            " ---> GP Test Error: 57.03764\n",
            "Test case 60/1000.\n",
            "True equation: sin(sqrt(x1+0.83))\n",
            "GPT2 function:  sin(sqrt(x1+0.73))\n",
            " ---> GPT2 Test Error: 0.00023\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.03616\n",
            "Genetic Model function:  sin(sqrt(exp(sin(add(-0.172, X0)))))\n",
            " ---> GP Test Error: 0.01339\n",
            "Test case 61/1000.\n",
            "True equation: 0.92*x1+0.09*sin(0.37*x1-0.48)\n",
            "GPT2 function:  0.35*x1**2-0.45*x1\n",
            " ---> GPT2 Test Error: 4.19014\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.95068\n",
            "Genetic Model function:  mul(log(mul(X0, 0.794)), mul(0.551, X0))\n",
            " ---> GP Test Error: 0.35344\n",
            "Test case 62/1000.\n",
            "True equation: sqrt(sin(x1-0.86))\n",
            "GPT2 function:  sqrt(sin(x1-0.96))\n",
            " ---> GPT2 Test Error: 0.00847\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.28354\n",
            "Genetic Model function:  sqrt(sin(add(-0.875, X0)))\n",
            " ---> GP Test Error: 0.00041\n",
            "Test case 63/1000.\n",
            "True equation: sqrt(-sin(0.11*x1))\n",
            "GPT2 function:  sqrt(-sin(0.1*x1-0.03))\n",
            " ---> GPT2 Test Error: 0.00190\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.01107\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  log(log(mul(exp(sin(exp(0.044))), sqrt(div(add(0.962, X0), add(log(sqrt(-0.938)), sqrt(sin(0.531))))))))\n",
            " ---> GP Test Error: 0.00178\n",
            "Test case 64/1000.\n",
            "True equation: 2*x1-0.16\n",
            "GPT2 function:  2*x1-0.36\n",
            " ---> GPT2 Test Error: 0.04000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.61028\n",
            "Genetic Model function:  add(add(X0, X0), mul(sqrt(sin(mul(-0.547, 0.817))), -0.241))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 65/1000.\n",
            "True equation: (x1-0.76)**(1/4)\n",
            "GPT2 function:  (x1-0.86)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00010\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.05475\n",
            "Genetic Model function:  sqrt(sqrt(add(sin(-0.855), X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 66/1000.\n",
            "True equation: 2.64*x1+0.2\n",
            "GPT2 function:  2.64*x1-0.11\n",
            " ---> GPT2 Test Error: 0.10241\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00005\n",
            "Genetic Model function:  div(X0, 0.365)\n",
            " ---> GP Test Error: 0.07010\n",
            "Test case 67/1000.\n",
            "True equation: -0.93*x1+sqrt(x1-0.91)\n",
            "GPT2 function:  -0.85*x1+sqrt(x1-0.95)+0.12\n",
            " ---> GPT2 Test Error: 0.21125\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 3.59566\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  sin(log(mul(-0.065, X0)))\n",
            " ---> GP Test Error: 2.33167\n",
            "Test case 68/1000.\n",
            "True equation: 0.91*sqrt(x1)+x1**2-0.86*x1\n",
            "GPT2 function:  x1**2-0.66*x1+0.93*sqrt(-x1)-0.24\n",
            " ---> GPT2 Test Error: 0.55829\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 125.61206\n",
            "Genetic Model function:  mul(mul(0.889, X0), X0)\n",
            " ---> GP Test Error: 0.25369\n",
            "Test case 69/1000.\n",
            "True equation: sin(sin(x1))\n",
            "GPT2 function:  sin(sin(x1-0.1))\n",
            " ---> GPT2 Test Error: 0.00366\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.66223\n",
            "Genetic Model function:  sin(sin(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 70/1000.\n",
            "True equation: 0.78*x1**2\n",
            "GPT2 function:  0.79*x1**2-0.04*x1\n",
            " ---> GPT2 Test Error: 0.00741\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 26.21843\n",
            "Genetic Model function:  mul(X0, mul(0.773, X0))\n",
            " ---> GP Test Error: 0.01715\n",
            "Test case 71/1000.\n",
            "True equation: sin(0.68*sqrt(-x1))\n",
            "GPT2 function:  sin(0.64*sqrt(x1-0.1))\n",
            " ---> GPT2 Test Error: 0.00043\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00922\n",
            "Genetic Model function:  sin(sqrt(mul(add(0.807, 0.633), mul(X0, 0.319))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 72/1000.\n",
            "True equation: -sin(0.8*x1)*sin(x1-0.87)\n",
            "GPT2 function:  -sin(0.76*x1-0.06)*sin(x1-0.93)\n",
            " ---> GPT2 Test Error: 0.01460\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.27833\n",
            "Genetic Model function:  sin(mul(X0, log(sqrt(div(sqrt(div(-0.712, X0)), X0)))))\n",
            " ---> GP Test Error: 0.40472\n",
            "Test case 73/1000.\n",
            "True equation: x1**(1/4)\n",
            "GPT2 function:  (x1-0.1)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00010\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.67852\n",
            "Genetic Model function:  sqrt(sqrt(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 74/1000.\n",
            "True equation: 0.41*sqrt(x1**2+0.94*x1)\n",
            "GPT2 function:  0.04*x1**2+0.61*sqrt(-x1)-0.19\n",
            " ---> GPT2 Test Error: 0.01485\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.03498\n",
            "Genetic Model function:  mul(0.492, add(X0, 0.089))\n",
            " ---> GP Test Error: 0.05991\n",
            "Test case 75/1000.\n",
            "True equation: 0.5*x1**2-0.43*x1-0.57\n",
            "GPT2 function:  -0.38*x1**2-0.37*x1-0.18\n",
            " ---> GPT2 Test Error: 3185.90659\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1107.40066\n",
            "Genetic Model function:  mul(add(X0, -0.984), mul(0.405, mul(X0, X0)))\n",
            " ---> GP Test Error: 51.99852\n",
            "Test case 76/1000.\n",
            "True equation: 0.62*sqrt(0.87*x1+1)\n",
            "GPT2 function:  0.59*sqrt(0.85*x1+1)\n",
            " ---> GPT2 Test Error: 0.00949\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.01396\n",
            "Genetic Model function:  sqrt(sqrt(mul(X0, -0.582)))\n",
            " ---> GP Test Error: 0.01735\n",
            "Test case 77/1000.\n",
            "True equation: 0.97*x1**2+0.54*x1+1.11\n",
            "GPT2 function:  x1**2+0.68*x1+0.08*sqrt(0.84*x1+1)+0.06\n",
            " ---> GPT2 Test Error: 0.27045\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 447.62237\n",
            "Genetic Model function:  add(mul(X0, X0), add(sqrt(X0), 0.662))\n",
            " ---> GP Test Error: 0.03035\n",
            "Test case 78/1000.\n",
            "True equation: -0.33*x1**2-0.29*x1+0.89*sqrt(-x1)\n",
            "GPT2 function:  -0.46*x1**2+0.48*x1+0.97*sqrt(x1+0.1)-0.18\n",
            " ---> GPT2 Test Error: 0.52909\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 25.14446\n",
            "Genetic Model function:  mul(log(log(mul(mul(0.331, X0), -0.779))), sqrt(X0))\n",
            " ---> GP Test Error: 21.85540\n",
            "Test case 79/1000.\n",
            "True equation: 0.18*x1**2-0.27*x1\n",
            "GPT2 function:  -0.17*x1**2-0.61*x1+0.03*sqrt(x1-0.81)\n",
            " ---> GPT2 Test Error: 92.48773\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.81546\n",
            "Genetic Model function:  mul(log(X0), mul(X0, mul(0.086, X0)))\n",
            " ---> GP Test Error: 0.04732\n",
            "Test case 80/1000.\n",
            "True equation: 0.88*x1-0.64\n",
            "GPT2 function:  0.36*x1**2+0.2*x1-0.36\n",
            " ---> GPT2 Test Error: 0.13471\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 33.97589\n",
            "Genetic Model function:  mul(sqrt(add(X0, -0.604)), add(X0, -0.576))\n",
            " ---> GP Test Error: 0.60556\n",
            "Test case 81/1000.\n",
            "True equation: -0.04*x1*sin(0.74*x1+0.23)+0.42\n",
            "GPT2 function:  0.31*sqrt(x1)*sqrt(0.04*x1-1)\n",
            " ---> GPT2 Test Error: 0.45312\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.14143\n",
            "Genetic Model function:  0.296\n",
            " ---> GP Test Error: 0.13955\n",
            "Test case 82/1000.\n",
            "True equation: 0.95*x1**2*sqrt(-x1)-0.12*x1\n",
            "GPT2 function:  x1**(5/2)-0.33*x1+0.03\n",
            " ---> GPT2 Test Error: 4.30935\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 757.34900\n",
            "Genetic Model function:  mul(mul(X0, X0), sqrt(add(X0, -0.417)))\n",
            " ---> GP Test Error: 1.91508\n",
            "Test case 83/1000.\n",
            "True equation: -sin(0.87*x1-0.58)\n",
            "GPT2 function:  -sin(0.88*x1-0.68)\n",
            " ---> GPT2 Test Error: 0.00095\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.27576\n",
            "Genetic Model function:  sin(mul(-0.889, add(X0, log(mul(log(0.242), add(0.787, -0.427))))))\n",
            " ---> GP Test Error: 0.00413\n",
            "Test case 84/1000.\n",
            "True equation: -sin(0.25*x1-0.4)\n",
            "GPT2 function:  0.41-0.24*x1\n",
            " ---> GPT2 Test Error: 0.00295\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.02165\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  log(log(log(mul(X0, 0.044))))\n",
            " ---> GP Test Error: 0.02326\n",
            "Test case 85/1000.\n",
            "True equation: sin(2*x1)\n",
            "GPT2 function:  sin(2*x1-0.2)\n",
            " ---> GPT2 Test Error: 0.01955\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.14873\n",
            "Genetic Model function:  sin(add(X0, X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 86/1000.\n",
            "True equation: 0.75*x1**2*sin(0.67*x1)-0.33*x1\n",
            "GPT2 function:  0.75*x1**2*sin(0.7*x1-0.63)-0.07*x1\n",
            " ---> GPT2 Test Error: 42.97097\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 104.88432\n",
            "Genetic Model function:  mul(add(-0.584, X0), mul(X0, 0.779))\n",
            " ---> GP Test Error: 452.95095\n",
            "Test case 87/1000.\n",
            "True equation: x1-0.21\n",
            "GPT2 function:  x1-0.31\n",
            " ---> GPT2 Test Error: 0.01000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.36674\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  add(add(mul(-0.904, -0.722), add(X0, -0.631)), log(sin(-0.907)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 88/1000.\n",
            "True equation: 0.33*x1-0.98\n",
            "GPT2 function:  0.68*x1**2-1.39*x1+0.66\n",
            " ---> GPT2 Test Error: 2.36579\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 26.94968\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  mul(mul(sin(log(X0)), add(X0, -0.929)), sqrt(X0))\n",
            " ---> GP Test Error: 11.29547\n",
            "Test case 89/1000.\n",
            "True equation: sqrt(x1-0.1)\n",
            "GPT2 function:  sqrt(x1-0.2)\n",
            " ---> GPT2 Test Error: 0.00063\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.06879\n",
            "Genetic Model function:  sqrt(add(add(-0.059, X0), -0.039))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 90/1000.\n",
            "True equation: 1.42*x1+0.77\n",
            "GPT2 function:  x1**2+0.65*x1-0.36\n",
            " ---> GPT2 Test Error: 0.19026\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 234.68296\n",
            "Genetic Model function:  mul(add(-0.118, X0), add(0.866, X0))\n",
            " ---> GP Test Error: 0.96736\n",
            "Test case 91/1000.\n",
            "True equation: sin(0.34*x1)\n",
            "GPT2 function:  -0.04*x1**2+0.41*x1-0.02*sqrt(-x1)\n",
            " ---> GPT2 Test Error: 0.00099\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.22609\n",
            "Genetic Model function:  sin(mul(0.347, X0))\n",
            " ---> GP Test Error: 0.00013\n",
            "Test case 92/1000.\n",
            "True equation: 0.83*sqrt(-x1)\n",
            "GPT2 function:  sqrt(x1-0.1)-sin(0.1*x1)\n",
            " ---> GPT2 Test Error: 0.01002\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.78774\n",
            "Genetic Model function:  sqrt(mul(0.692, X0))\n",
            " ---> GP Test Error: 0.00017\n",
            "Test case 93/1000.\n",
            "True equation: sin(x1)+sin(x1-0.38)\n",
            "GPT2 function:  sin(x1)+sin(x1-0.57)\n",
            " ---> GPT2 Test Error: 0.01844\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.35659\n",
            "Genetic Model function:  add(sin(add(-0.363, X0)), sin(X0))\n",
            " ---> GP Test Error: 0.00010\n",
            "Test case 94/1000.\n",
            "True equation: 0.94*sqrt(-0.65*x1-1)\n",
            "GPT2 function:  0.92*sqrt(0.65*x1+1)\n",
            " ---> GPT2 Test Error: 0.00127\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.09659\n",
            "Genetic Model function:  exp(mul(0.173, X0))\n",
            " ---> GP Test Error: 0.17064\n",
            "Test case 95/1000.\n",
            "True equation: -2*x1*sin(0.58*x1)+1.0\n",
            "GPT2 function:  -2*x1*sin(0.55*x1-0.07)+0.83\n",
            " ---> GPT2 Test Error: 2.20168\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 48.32110\n",
            "Genetic Model function:  add(div(X0, -0.356), sqrt(sqrt(sqrt(sqrt(X0)))))\n",
            " ---> GP Test Error: 106.16673\n",
            "Test case 96/1000.\n",
            "True equation: sin(sqrt(x1+0.02))\n",
            "GPT2 function:  sin(sqrt(x1-0.08))\n",
            " ---> GPT2 Test Error: 0.00015\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.07000\n",
            "Genetic Model function:  sin(sqrt(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 97/1000.\n",
            "True equation: x1**(1/4)\n",
            "GPT2 function:  (x1-0.1)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00010\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.01377\n",
            "Genetic Model function:  sqrt(sqrt(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 98/1000.\n",
            "True equation: 0\n",
            "GPT2 function:  0\n",
            " ---> GPT2 Test Error: 0.00436\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00045\n",
            "Genetic Model function:  mul(mul(X0, 0.766), mul(0.036, 0.218))\n",
            " ---> GP Test Error: 0.00149\n",
            "Test case 99/1000.\n",
            "True equation: 2*x1*sin(0.88*x1)+0.35\n",
            "GPT2 function:  2*x1*sin(0.88*x1-0.06)\n",
            " ---> GPT2 Test Error: 0.16444\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 69.32097\n",
            "Genetic Model function:  mul(add(exp(-0.978), sin(sin(X0))), add(add(-0.331, X0), X0))\n",
            " ---> GP Test Error: 30.78193\n",
            "Test case 100/1000.\n",
            "True equation: sqrt(x1+0.22)\n",
            "GPT2 function:  sqrt(x1+0.12)\n",
            " ---> GPT2 Test Error: 0.00052\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.41711\n",
            "Genetic Model function:  sqrt(add(X0, 0.227))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 101/1000.\n",
            "<class 'TypeError'> \n",
            "\n",
            " Error: sin(3.1-0.1)), EQ:sin(x1-0.1))\n",
            "Not calculated\n",
            "Test case 102/1000.\n",
            "True equation: sqrt(x1)+sin(x1+0.65)\n",
            "GPT2 function:  sqrt(x1)+sin(x1+0.2)\n",
            " ---> GPT2 Test Error: 0.09684\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.44225\n",
            "Genetic Model function:  add(sin(X0), exp(0.026))\n",
            " ---> GP Test Error: 1.77452\n",
            "Test case 103/1000.\n",
            "True equation: -sin(0.83*x1**2+0.97*x1)\n",
            "GPT2 function:  -sin(0.83*x1**2+0.77*x1-0.1)\n",
            " ---> GPT2 Test Error: 0.44361\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 3.96526\n",
            "Genetic Model function:  sin(mul(log(add(mul(X0, 0.393), add(X0, -0.995))), add(X0, X0)))\n",
            " ---> GP Test Error: 0.97052\n",
            "Test case 104/1000.\n",
            "True equation: sqrt(x1**2+0.7*x1)\n",
            "GPT2 function:  sqrt(x1**2+0.49*x1-0.06)\n",
            " ---> GPT2 Test Error: 0.01124\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.01528\n",
            "Genetic Model function:  sqrt(add(mul(X0, X0), mul(X0, exp(-0.345))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 105/1000.\n",
            "True equation: 0.94*sqrt(-x1**2-0.16*x1)\n",
            "GPT2 function:  0.94*sqrt(x1**2-0.1*x1)\n",
            " ---> GPT2 Test Error: 0.01621\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.46778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  X0\n",
            " ---> GP Test Error: 0.03984\n",
            "Test case 106/1000.\n",
            "True equation: sin(sin(x1))\n",
            "GPT2 function:  sin(sin(x1-0.1))\n",
            " ---> GPT2 Test Error: 0.00366\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.50049\n",
            "Genetic Model function:  sin(sin(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 107/1000.\n",
            "<class 'TypeError'> \n",
            "\n",
            " Error: sin(3.1-0.1)3.1), EQ:sin(x1-0.1)x1)\n",
            "Not calculated\n",
            "Test case 108/1000.\n",
            "True equation: sin(sqrt(x1-0.19))\n",
            "GPT2 function:  sin(sqrt(x1-0.29))\n",
            " ---> GPT2 Test Error: 0.00012\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.20481\n",
            "Genetic Model function:  sin(sqrt(add(-0.203, X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 109/1000.\n",
            "True equation: sqrt(x1)+0.05*x1**2-0.17*x1+0.12\n",
            "GPT2 function:  0.04*sqrt(x1)+1.28*sqrt(0.09-x1)\n",
            " ---> GPT2 Test Error: 0.13132\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00367\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  mul(sqrt(add(0.107, X0)), sin(div(-0.731, -0.581)))\n",
            " ---> GP Test Error: 0.21117\n",
            "Test case 110/1000.\n",
            "True equation: x1+0.49\n",
            "GPT2 function:  x1+0.39\n",
            " ---> GPT2 Test Error: 0.01000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00174\n",
            "Genetic Model function:  add(log(exp(X0)), div(log(0.368), div(0.500, -0.249)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 111/1000.\n",
            "True equation: 0.03-0.78*x1**2\n",
            "GPT2 function:  1.69*x1-0.13\n",
            " ---> GPT2 Test Error: 497.09325\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 75.61406\n",
            "Genetic Model function:  add(sin(X0), mul(sqrt(X0), mul(-0.960, X0)))\n",
            " ---> GP Test Error: 20.46019\n",
            "Test case 112/1000.\n",
            "True equation: -0.07*x1**2-0.46*x1*sqrt(1-0.6*x1)\n",
            "GPT2 function:  -0.49*x1*sqrt(0.56*x1-1)+0.04\n",
            " ---> GPT2 Test Error: 2.25970\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.98182\n",
            "Genetic Model function:  mul(log(0.922), exp(X0))\n",
            " ---> GP Test Error: 100.64485\n",
            "Test case 113/1000.\n",
            "True equation: 0.55*x1\n",
            "GPT2 function:  0.55*sqrt(x1**2-0.1*x1)\n",
            " ---> GPT2 Test Error: 0.00022\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.04523\n",
            "Genetic Model function:  mul(0.551, X0)\n",
            " ---> GP Test Error: 0.00028\n",
            "Test case 114/1000.\n",
            "True equation: 0.42*sqrt(1-0.89*x1)\n",
            "GPT2 function:  0.44*sqrt(0.84*x1-1)\n",
            " ---> GPT2 Test Error: 0.00013\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.04850\n",
            "Genetic Model function:  mul(0.191, X0)\n",
            " ---> GP Test Error: 0.02110\n",
            "Test case 115/1000.\n",
            "True equation: -1.65*x1+0.68*sqrt(-0.21*x1-1)-0.62\n",
            "GPT2 function:  0.19-1.55*x1\n",
            " ---> GPT2 Test Error: 0.08615\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.36462\n",
            "Genetic Model function:  div(X0, -0.651)\n",
            " ---> GP Test Error: 0.03030\n",
            "Test case 116/1000.\n",
            "True equation: 0.55*sqrt(x1)-0.61*x1\n",
            "GPT2 function:  -0.59*x1*sqrt(-x1)+0.44\n",
            " ---> GPT2 Test Error: 0.31801\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.66245\n",
            "Genetic Model function:  mul(log(X0), mul(-0.667, X0))\n",
            " ---> GP Test Error: 0.03811\n",
            "Test case 117/1000.\n",
            "True equation: 0.58*sqrt(x1**2+0.53*x1)\n",
            "GPT2 function:  0.83*sqrt(x1**2-0.1*x1)\n",
            " ---> GPT2 Test Error: 0.91214\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.08371\n",
            "Genetic Model function:  mul(0.651, X0)\n",
            " ---> GP Test Error: 0.02805\n",
            "Test case 118/1000.\n",
            "True equation: sin(sin(x1))\n",
            "GPT2 function:  sin(sin(x1-0.1))\n",
            " ---> GPT2 Test Error: 0.00366\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.31579\n",
            "Genetic Model function:  sin(sin(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 119/1000.\n",
            "True equation: 2*x1+1.23*sin(x1+0.72)\n",
            "GPT2 function:  2*x1+0.88*sin(x1+0.65)\n",
            " ---> GPT2 Test Error: 198.54478\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 26.86571\n",
            "Genetic Model function:  div(add(sin(add(X0, 0.763)), mul(add(X0, 0.763), sin(div(X0, 0.763)))), sin(exp(0.763)))\n",
            " ---> GP Test Error: 24.23625\n",
            "Test case 120/1000.\n",
            "True equation: 0.75*sqrt(-x1**2-0.25*x1)\n",
            "GPT2 function:  0.76*sqrt(-x1**2+0.11*x1)\n",
            " ---> GPT2 Test Error: 0.00866\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00026\n",
            "Genetic Model function:  mul(0.786, X0)\n",
            " ---> GP Test Error: 0.00539\n",
            "Test case 121/1000.\n",
            "True equation: 0.12*x1**2+0.13\n",
            "GPT2 function:  -0.08*x1**3+0.33*x1\n",
            " ---> GPT2 Test Error: 16.22008\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 17.71440\n",
            "Genetic Model function:  mul(mul(0.222, sin(X0)), sin(X0))\n",
            " ---> GP Test Error: 17.07425\n",
            "Test case 122/1000.\n",
            "True equation: 0.92*x1+0.98\n",
            "GPT2 function:  1.28*sqrt(0.49*x1**2+x1+0.49)\n",
            " ---> GPT2 Test Error: 0.03871\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 8.69665\n",
            "Genetic Model function:  add(mul(0.911, X0), 0.996)\n",
            " ---> GP Test Error: 0.00206\n",
            "Test case 123/1000.\n",
            "True equation: sin(sin(0.47*x1))\n",
            "GPT2 function:  sin(sin(0.48*x1-0.04))\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.29974\n",
            "Genetic Model function:  sin(sin(mul(X0, 0.482)))\n",
            " ---> GP Test Error: 0.00079\n",
            "Test case 124/1000.\n",
            "True equation: -0.12*x1**2+0.63*x1+0.29\n",
            "GPT2 function:  -0.05*x1**2+0.77*x1+0.22\n",
            " ---> GPT2 Test Error: 4.84532\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.10568\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  sqrt(log(add(0.947, X0)))\n",
            " ---> GP Test Error: 0.77721\n",
            "Test case 125/1000.\n",
            "True equation: 0.82*sqrt(x1+0.77)\n",
            "GPT2 function:  0.79*sqrt(x1+0.67)\n",
            " ---> GPT2 Test Error: 0.00856\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.11483\n",
            "Genetic Model function:  sqrt(mul(log(0.496), add(0.693, X0)))\n",
            " ---> GP Test Error: 0.00036\n",
            "Test case 126/1000.\n",
            "True equation: -0.14*x1**3-0.76\n",
            "GPT2 function:  -0.06*x1**2\n",
            " ---> GPT2 Test Error: 159.94827\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 89.93397\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  mul(log(X0), mul(mul(X0, -0.268), X0))\n",
            " ---> GP Test Error: 16.69239\n",
            "Test case 127/1000.\n",
            "True equation: sin(0.79*x1-0.22)\n",
            "GPT2 function:  sin(0.82*x1-0.28)\n",
            " ---> GPT2 Test Error: 0.00435\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 4.93579\n",
            "Genetic Model function:  sin(mul(0.647, X0))\n",
            " ---> GP Test Error: 0.12476\n",
            "Test case 128/1000.\n",
            "True equation: sin(sin(x1-0.53))\n",
            "GPT2 function:  sin(sin(x1-0.63))\n",
            " ---> GPT2 Test Error: 0.00354\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.63906\n",
            "Genetic Model function:  add(sin(log(exp(sin(add(add(-0.115, X0), sin(-0.412)))))), div(-0.003, 0.827))\n",
            " ---> GP Test Error: 0.00024\n",
            "Test case 129/1000.\n",
            "True equation: sin(0.44*x1**2+0.2*x1)\n",
            "GPT2 function:  sin(0.42*x1**2+0.08*x1-0.03)\n",
            " ---> GPT2 Test Error: 0.49400\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 14.55361\n",
            "Genetic Model function:  mul(mul(X0, 0.763), sin(sin(div(X0, 0.790))))\n",
            " ---> GP Test Error: 5.46509\n",
            "Test case 130/1000.\n",
            "True equation: -sin(sin(0.04*x1+0.33))\n",
            "GPT2 function:  -0.03*x1-0.31\n",
            " ---> GPT2 Test Error: 0.00177\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.01023\n",
            "Genetic Model function:  -0.390\n",
            " ---> GP Test Error: 0.01044\n",
            "Test case 131/1000.\n",
            "True equation: sin(2*x1-0.33)\n",
            "GPT2 function:  sin(2*x1-0.53)\n",
            " ---> GPT2 Test Error: 0.01881\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.37232\n",
            "Genetic Model function:  sin(add(X0, add(-0.339, X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 132/1000.\n",
            "True equation: 0.41-0.16*x1\n",
            "GPT2 function:  0.44-0.14*x1\n",
            " ---> GPT2 Test Error: 0.00992\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.06489\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  div(0.565, exp(X0))\n",
            " ---> GP Test Error: 0.10890\n",
            "Test case 133/1000.\n",
            "True equation: 0.86*sqrt(1-0.52*x1)\n",
            "GPT2 function:  0.88*sqrt(1-0.52*x1)\n",
            " ---> GPT2 Test Error: 0.00055\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.14480\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  exp(sin(mul(-0.897, X0)))\n",
            " ---> GP Test Error: 1.18921\n",
            "Test case 134/1000.\n",
            "True equation: -sin(0.31*x1**2+0.11*x1)\n",
            "GPT2 function:  -sin(0.3*x1**2+0.05*x1)\n",
            " ---> GPT2 Test Error: 0.07982\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 3.78916\n",
            "Genetic Model function:  mul(mul(-0.530, X0), sin(X0))\n",
            " ---> GP Test Error: 3.81207\n",
            "Test case 135/1000.\n",
            "True equation: 0.91*sqrt(-x1)\n",
            "GPT2 function:  0.93*sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00095\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.17606\n",
            "Genetic Model function:  sqrt(mul(X0, 0.821))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 136/1000.\n",
            "True equation: 0.33*x1+1.22\n",
            "GPT2 function:  1.2*sqrt(0.79*x1+1)\n",
            " ---> GPT2 Test Error: 0.04113\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.30781\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  sqrt(add(X0, exp(0.370)))\n",
            " ---> GP Test Error: 0.10278\n",
            "Test case 137/1000.\n",
            "True equation: 0.13*x1\n",
            "GPT2 function:  0.14*sqrt(-x1**2)\n",
            " ---> GPT2 Test Error: 0.00387\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00585\n",
            "Genetic Model function:  add(mul(mul(0.514, X0), log(0.738)), mul(mul(X0, -0.451), sin(-0.671)))\n",
            " ---> GP Test Error: 0.00012\n",
            "Test case 138/1000.\n",
            "True equation: -0.68*x1**(5/2)\n",
            "GPT2 function:  -0.87*x1**2+0.08*x1*sqrt(x1+0.09)\n",
            " ---> GPT2 Test Error: 257.77325\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 197.08205\n",
            "Genetic Model function:  mul(sqrt(X0), mul(mul(X0, add(-0.307, -0.380)), sqrt(mul(mul(X0, X0), -0.970))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 139/1000.\n",
            "True equation: 2*x1+0.84*sqrt(0.81*x1+1)-0.3\n",
            "GPT2 function:  2*x1+0.53*sqrt(-x1)+0.17\n",
            " ---> GPT2 Test Error: 0.05208\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.44555\n",
            "Genetic Model function:  add(div(X0, 0.538), sqrt(X0))\n",
            " ---> GP Test Error: 0.00548\n",
            "Test case 140/1000.\n",
            "True equation: 1.04*x1**2+0.83*x1\n",
            "GPT2 function:  x1**2+0.55*x1-0.06\n",
            " ---> GPT2 Test Error: 4.75725\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 50.85031\n",
            "Genetic Model function:  add(mul(add(X0, -0.089), X0), X0)\n",
            " ---> GP Test Error: 0.21997\n",
            "Test case 141/1000.\n",
            "True equation: -0.44*x1**2\n",
            "GPT2 function:  -0.58*x1**2+0.13*x1\n",
            " ---> GPT2 Test Error: 1952.06727\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 847.11149\n",
            "Genetic Model function:  mul(mul(0.443, X0), add(mul(add(X0, X0), log(-0.353)), mul(X0, X0)))\n",
            " ---> GP Test Error: 0.00779\n",
            "Test case 142/1000.\n",
            "True equation: 0.95*x1**2-0.37*x1\n",
            "GPT2 function:  0.87*x1-0.05\n",
            " ---> GPT2 Test Error: 260.48608\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 99.95901\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  mul(add(-0.463, X0), X0)\n",
            " ---> GP Test Error: 0.50643\n",
            "Test case 143/1000.\n",
            "True equation: x1**2+0.65*x1\n",
            "GPT2 function:  x1**2+0.43*x1-0.04\n",
            " ---> GPT2 Test Error: 1.09092\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 133.61223\n",
            "Genetic Model function:  add(mul(X0, 0.649), mul(X0, X0))\n",
            " ---> GP Test Error: 0.00011\n",
            "Test case 144/1000.\n",
            "True equation: 0.38*x1**2-0.54*x1+0.07\n",
            "GPT2 function:  0.39*x1**2-0.79*x1+0.13\n",
            " ---> GPT2 Test Error: 0.95670\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 5.27102\n",
            "Genetic Model function:  mul(mul(log(X0), mul(X0, 0.490)), mul(X0, 0.402))\n",
            " ---> GP Test Error: 0.92582\n",
            "Test case 145/1000.\n",
            "True equation: 0.41*sqrt(-x1**2)\n",
            "GPT2 function:  0.41*sqrt(x1**2-0.07*x1)\n",
            " ---> GPT2 Test Error: 0.00154\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00005\n",
            "Genetic Model function:  exp(add(log(X0), log(0.420)))\n",
            " ---> GP Test Error: 0.00043\n",
            "Test case 146/1000.\n",
            "True equation: x1\n",
            "GPT2 function:  x1-0.1\n",
            " ---> GPT2 Test Error: 0.01000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.35270\n",
            "Genetic Model function:  sqrt(mul(X0, X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 147/1000.\n",
            "True equation: 0.39*sqrt(-x1)\n",
            "GPT2 function:  0.39*sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.01248\n",
            "Genetic Model function:  sqrt(sin(mul(0.150, X0)))\n",
            " ---> GP Test Error: 0.00149\n",
            "Test case 148/1000.\n",
            "True equation: 0.33*x1-0.73\n",
            "GPT2 function:  sin(0.36*x1-0.86)\n",
            " ---> GPT2 Test Error: 0.01837\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.35516\n",
            "Genetic Model function:  div(-0.896, exp(X0))\n",
            " ---> GP Test Error: 0.70535\n",
            "Test case 149/1000.\n",
            "True equation: -0.2*x1**2+2.13*x1-0.72\n",
            "GPT2 function:  -0.14*x1**2+2.08*x1-0.95\n",
            " ---> GPT2 Test Error: 0.75698\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.05099\n",
            "Genetic Model function:  add(X0, sin(log(add(0.299, X0))))\n",
            " ---> GP Test Error: 0.97287\n",
            "Test case 150/1000.\n",
            "True equation: x1**2+sin(x1)\n",
            "GPT2 function:  x1**2-0.17*x1+sqrt(x1+0.12)-0.24\n",
            " ---> GPT2 Test Error: 3.33213\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 63.30080\n",
            "Genetic Model function:  log(exp(add(sin(X0), mul(X0, X0))))\n",
            " ---> GP Test Error: 195.42381\n",
            "Test case 151/1000.\n",
            "True equation: sqrt(x1)*sin(x1-0.13)\n",
            "GPT2 function:  sqrt(x1-0.09)*sin(x1-0.12)\n",
            " ---> GPT2 Test Error: 0.00031\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.56805\n",
            "Genetic Model function:  mul(sin(add(-0.120, X0)), sqrt(X0))\n",
            " ---> GP Test Error: 0.00008\n",
            "Test case 152/1000.\n",
            "True equation: 1.28*x1-0.32\n",
            "GPT2 function:  1.29*x1-0.46\n",
            " ---> GPT2 Test Error: 0.00940\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.01724\n",
            "Genetic Model function:  div(add(div(-0.416, exp(X0)), X0), 0.858)\n",
            " ---> GP Test Error: 0.05382\n",
            "Test case 153/1000.\n",
            "True equation: 0.58*sqrt(x1-0.21)\n",
            "GPT2 function:  0.59*sqrt(x1-0.31)\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.23414\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  sqrt(mul(X0, 0.305))\n",
            " ---> GP Test Error: 0.00096\n",
            "Test case 154/1000.\n",
            "True equation: sin(0.72*x1)\n",
            "GPT2 function:  sin(0.72*x1-0.07)\n",
            " ---> GPT2 Test Error: 0.00473\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.15853\n",
            "Genetic Model function:  sin(add(mul(-0.263, X0), X0))\n",
            " ---> GP Test Error: 0.00256\n",
            "Test case 155/1000.\n",
            "True equation: 0.83*(x1-0.81)**(1/4)\n",
            "GPT2 function:  0.82*(x1-0.96)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00059\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.04112\n",
            "Genetic Model function:  div(sqrt(sqrt(add(X0, -0.780))), exp(0.194))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 156/1000.\n",
            "True equation: 0.59*sqrt(x1-0.39)\n",
            "GPT2 function:  0.57*sqrt(x1-0.48)\n",
            " ---> GPT2 Test Error: 0.00413\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.12586\n",
            "Genetic Model function:  sin(mul(0.442, X0))\n",
            " ---> GP Test Error: 0.21752\n",
            "Test case 157/1000.\n",
            "<class 'TypeError'> \n",
            "\n",
            " Error: sin(3.1-0.1)3.1), EQ:sin(x1-0.1)x1)\n",
            "Not calculated\n",
            "Test case 158/1000.\n",
            "True equation: sqrt(sin(0.12*x1+0.81))\n",
            "GPT2 function:  0.85*(-0.19*x1-1)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.01267\n",
            "Genetic Model function:  0.910\n",
            " ---> GP Test Error: 0.00561\n",
            "Test case 159/1000.\n",
            "True equation: -0.16*x1**3-0.08*x1\n",
            "GPT2 function:  -0.17*x1**2+0.03*x1*sqrt(x1+0.85)\n",
            " ---> GPT2 Test Error: 290.98126\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 85.22892\n",
            "Genetic Model function:  mul(mul(X0, 0.343), mul(mul(-0.456, X0), add(0.561, X0)))\n",
            " ---> GP Test Error: 0.01030\n",
            "Test case 160/1000.\n",
            "True equation: 0.14*x1*sqrt(x1+0.75)\n",
            "GPT2 function:  0.14*x1*sqrt(-x1)\n",
            " ---> GPT2 Test Error: 0.00398\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.11324\n",
            "Genetic Model function:  sin(mul(sqrt(X0), mul(0.166, X0)))\n",
            " ---> GP Test Error: 0.48720\n",
            "Test case 161/1000.\n",
            "True equation: 1.62-0.78*x1**2\n",
            "GPT2 function:  0.19*x1**(3/2)-0.99*x1**2\n",
            " ---> GPT2 Test Error: 642.11699\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 689.88088\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  mul(add(X0, X0), mul(-0.814, X0))\n",
            " ---> GP Test Error: 83.55027\n",
            "Test case 162/1000.\n",
            "True equation: sqrt(x1**2-0.9*x1)\n",
            "GPT2 function:  sqrt(x1-0.99)*sqrt(x1-0.09)\n",
            " ---> GPT2 Test Error: 0.00792\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00546\n",
            "Genetic Model function:  exp(log(exp(log(add(X0, -0.524)))))\n",
            " ---> GP Test Error: 0.00224\n",
            "Test case 163/1000.\n",
            "True equation: 0.79*(0.16*x1-1)**(1/4)\n",
            "GPT2 function:  0.8*sqrt(0.09*x1-1)\n",
            " ---> GPT2 Test Error: 0.00408\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00718\n",
            "Genetic Model function:  0.748\n",
            " ---> GP Test Error: 0.04028\n",
            "Test case 164/1000.\n",
            "True equation: -sin(0.13*x1)\n",
            "GPT2 function:  -sin(0.13*x1-0.02)\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.13143\n",
            "Genetic Model function:  mul(log(-0.886), X0)\n",
            " ---> GP Test Error: 0.00025\n",
            "Test case 165/1000.\n",
            "True equation: sin(0.16*x1-0.74)\n",
            "GPT2 function:  0.16*x1-0.71*sqrt(1-0.05*x1)\n",
            " ---> GPT2 Test Error: 0.00994\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00464\n",
            "Genetic Model function:  -0.476\n",
            " ---> GP Test Error: 0.25206\n",
            "Test case 166/1000.\n",
            "True equation: 0.39*sqrt(x1**2+0.6*x1)\n",
            "GPT2 function:  0.41*sqrt(x1**2-0.11*x1)\n",
            " ---> GPT2 Test Error: 0.00302\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00006\n",
            "Genetic Model function:  mul(add(sqrt(mul(0.335, X0)), div(X0, 0.791)), log(exp(0.266)))\n",
            " ---> GP Test Error: 0.00195\n",
            "Test case 167/1000.\n",
            "True equation: -0.6*x1+0.03*sin(x1)\n",
            "GPT2 function:  -0.47*x1*sin(x1-0.12)\n",
            " ---> GPT2 Test Error: 0.18989\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 7.94163\n",
            "Genetic Model function:  sin(mul(X0, sin(mul(X0, -0.416))))\n",
            " ---> GP Test Error: 1.70509\n",
            "Test case 168/1000.\n",
            "True equation: 0.77*sqrt(-x1)\n",
            "GPT2 function:  0.76*sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00149\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.02100\n",
            "Genetic Model function:  exp(add(log(sin(div(exp(0.841), sqrt(sin(-0.975))))), log(sqrt(mul(sqrt(0.906), add(X0, X0))))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 169/1000.\n",
            "True equation: -0.65*x1*sin(0.58*x1+0.22)+0.81\n",
            "GPT2 function:  -sin(0.25*x1**2-0.31*x1-0.17)\n",
            " ---> GPT2 Test Error: 0.77829\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 4.34947\n",
            "Genetic Model function:  add(mul(-0.945, X0), sqrt(X0))\n",
            " ---> GP Test Error: 5.86771\n",
            "Test case 170/1000.\n",
            "True equation: sin(0.85*x1+0.1)\n",
            "GPT2 function:  sin(0.87*x1)\n",
            " ---> GPT2 Test Error: 0.00053\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.51111\n",
            "Genetic Model function:  sin(mul(X0, 0.891))\n",
            " ---> GP Test Error: 0.00176\n",
            "Test case 171/1000.\n",
            "True equation: 1.43*x1*sqrt(x1-0.07)+0.68\n",
            "GPT2 function:  1.39*x1*sqrt(x1-0.17)+0.44\n",
            " ---> GPT2 Test Error: 2.52275\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 5.15581\n",
            "Genetic Model function:  mul(sqrt(sqrt(X0)), div(X0, 0.478))\n",
            " ---> GP Test Error: 2.68406\n",
            "Test case 172/1000.\n",
            "<class 'TypeError'> \n",
            "\n",
            " Error: sin(sqrt(3.1-0.1))3.1), EQ:sin(sqrt(x1-0.1))x1)\n",
            "Not calculated\n",
            "Test case 173/1000.\n",
            "True equation: sin(0.6*sqrt(x1))\n",
            "GPT2 function:  sin(0.64*sqrt(0.1-x1))\n",
            " ---> GPT2 Test Error: 0.00025\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.02275\n",
            "Genetic Model function:  sin(sqrt(mul(-0.361, X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 174/1000.\n",
            "True equation: sin(0.76*x1-0.31)\n",
            "GPT2 function:  sin(0.75*x1-0.37)\n",
            " ---> GPT2 Test Error: 0.00682\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.46642\n",
            "Genetic Model function:  sin(log(add(X0, 0.618)))\n",
            " ---> GP Test Error: 1.29291\n",
            "Test case 175/1000.\n",
            "True equation: x1**(1/4)\n",
            "GPT2 function:  (x1-0.1)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00010\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.03421\n",
            "Genetic Model function:  sqrt(sqrt(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 176/1000.\n",
            "True equation: 1.02*x1+1.36\n",
            "GPT2 function:  1.01*x1+1.27\n",
            " ---> GPT2 Test Error: 0.01691\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00050\n",
            "Genetic Model function:  add(add(X0, 0.453), 0.936)\n",
            " ---> GP Test Error: 0.00345\n",
            "Test case 177/1000.\n",
            "<class 'TypeError'> \n",
            "\n",
            " Error: sin(3.1-0.1)3.108), EQ:sin(x1-0.1)x108)\n",
            "Not calculated\n",
            "Test case 178/1000.\n",
            "True equation: -sin(0.65*x1**2-0.13*x1)\n",
            "GPT2 function:  -sin(0.66*x1**2-0.18*x1)\n",
            " ---> GPT2 Test Error: 0.00787\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.21435\n",
            "Genetic Model function:  sin(mul(mul(X0, X0), log(-0.552)))\n",
            " ---> GP Test Error: 0.30521\n",
            "Test case 179/1000.\n",
            "True equation: -sin(0.4*x1)\n",
            "GPT2 function:  -sin(0.4*x1-0.06)\n",
            " ---> GPT2 Test Error: 0.00033\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.29068\n",
            "Genetic Model function:  sin(mul(sin(-0.418), X0))\n",
            " ---> GP Test Error: 0.00032\n",
            "Test case 180/1000.\n",
            "True equation: x1**2+1.17*x1-0.12\n",
            "GPT2 function:  x1**2+0.8*x1-0.22\n",
            " ---> GPT2 Test Error: 3.31084\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 194.22937\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  add(add(sqrt(sin(0.219)), add(log(0.551), mul(X0, X0))), div(div(X0, 0.848), div(X0, X0)))\n",
            " ---> GP Test Error: 0.00060\n",
            "Test case 181/1000.\n",
            "True equation: 2.25*x1-0.82\n",
            "GPT2 function:  2.22*x1-1.05\n",
            " ---> GPT2 Test Error: 0.12467\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 16.11735\n",
            "Genetic Model function:  add(div(X0, 0.476), -0.568)\n",
            " ---> GP Test Error: 0.18735\n",
            "Test case 182/1000.\n",
            "True equation: 0.77*sqrt(0.35*x1+1)+sin(x1-0.89)\n",
            "GPT2 function:  0.09*x1+sin(0.89*x1-0.95)+0.85\n",
            " ---> GPT2 Test Error: 0.17781\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 5.25085\n",
            "Genetic Model function:  mul(X0, sqrt(sqrt(sin(X0))))\n",
            " ---> GP Test Error: 12.37091\n",
            "Test case 183/1000.\n",
            "True equation: 0.29*x1**2-0.24*x1\n",
            "GPT2 function:  0.37*x1**2-0.39*x1+0.03\n",
            " ---> GPT2 Test Error: 1.47805\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.65084\n",
            "Genetic Model function:  mul(add(X0, -0.832), mul(0.289, X0))\n",
            " ---> GP Test Error: 0.00012\n",
            "Test case 184/1000.\n",
            "True equation: sin(0.41*x1+0.67)\n",
            "GPT2 function:  sin(0.4*x1+0.63)\n",
            " ---> GPT2 Test Error: 0.00321\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.32065\n",
            "Genetic Model function:  sin(sqrt(add(X0, 0.312)))\n",
            " ---> GP Test Error: 0.08875\n",
            "Test case 185/1000.\n",
            "True equation: 0.08*x1**2-0.53\n",
            "GPT2 function:  0.09*x1**2-0.4\n",
            " ---> GPT2 Test Error: 0.01708\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.95755\n",
            "Genetic Model function:  mul(mul(log(add(sin(-0.765), exp(X0))), 0.062), X0)\n",
            " ---> GP Test Error: 0.03548\n",
            "Test case 186/1000.\n",
            "True equation: 2*x1-0.44\n",
            "GPT2 function:  2*x1-0.64\n",
            " ---> GPT2 Test Error: 0.04000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.15855\n",
            "Genetic Model function:  add(log(0.884), add(log(0.727), add(X0, X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 187/1000.\n",
            "True equation: 0.72*x1**2-0.06*x1-sin(0.71*x1)\n",
            "GPT2 function:  x1**2-0.99*x1+0.17\n",
            " ---> GPT2 Test Error: 4.55812\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 54.53010\n",
            "Genetic Model function:  mul(sqrt(add(X0, -0.336)), mul(X0, log(X0)))\n",
            " ---> GP Test Error: 0.28252\n",
            "Test case 188/1000.\n",
            "True equation: -0.81*x1\n",
            "GPT2 function:  0.08-0.81*x1\n",
            " ---> GPT2 Test Error: 0.00527\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.03331\n",
            "Genetic Model function:  add(X0, div(X0, -0.554))\n",
            " ---> GP Test Error: 0.00050\n",
            "Test case 189/1000.\n",
            "True equation: 0.33*sqrt(-x1**2)\n",
            "GPT2 function:  0.32*sqrt(x1**2)\n",
            " ---> GPT2 Test Error: 0.00086\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.21460\n",
            "Genetic Model function:  exp(log(mul(-0.325, X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 190/1000.\n",
            "True equation: -0.34*x1**3+0.02*x1\n",
            "GPT2 function:  0.09*x1**2+0.93*x1\n",
            " ---> GPT2 Test Error: 2051.23456\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 690.29492\n",
            "Genetic Model function:  mul(mul(log(add(0.827, 0.144)), add(div(X0, 0.099), log(mul(mul(exp(X0), mul(-0.605, X0)), sin(mul(-0.321, -0.966)))))), mul(X0, X0))\n",
            " ---> GP Test Error: 0.06880\n",
            "Test case 191/1000.\n",
            "True equation: sqrt(sin(x1))\n",
            "GPT2 function:  sqrt(sin(x1-0.1))\n",
            " ---> GPT2 Test Error: 0.00409\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.18589\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  sqrt(div(sin(X0), sqrt(-1.000)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 192/1000.\n",
            "True equation: sin(0.95*sqrt(-x1))\n",
            "GPT2 function:  sin(0.95*sqrt(x1-0.1))\n",
            " ---> GPT2 Test Error: 0.00014\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.12017\n",
            "Genetic Model function:  sin(sqrt(exp(log(mul(0.898, X0)))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 193/1000.\n",
            "True equation: 0.22*sqrt(x1)\n",
            "GPT2 function:  sqrt(-sin(0.05*x1))\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.09729\n",
            "Genetic Model function:  mul(sin(mul(0.821, sin(sqrt(0.074)))), sqrt(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 194/1000.\n",
            "True equation: sqrt(x1**2)\n",
            "GPT2 function:  x1-0.1\n",
            " ---> GPT2 Test Error: 0.01000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.51245\n",
            "Genetic Model function:  sqrt(mul(X0, X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 195/1000.\n",
            "True equation: sqrt(x1)\n",
            "GPT2 function:  sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00057\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.03595\n",
            "Genetic Model function:  sqrt(log(exp(X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 196/1000.\n",
            "True equation: -0.3*x1**(3/2)-0.33\n",
            "GPT2 function:  0.1-0.12*x1\n",
            " ---> GPT2 Test Error: 11.00231\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.58581\n",
            "Genetic Model function:  mul(X0, -0.666)\n",
            " ---> GP Test Error: 0.51219\n",
            "Test case 197/1000.\n",
            "True equation: 1.1*x1\n",
            "GPT2 function:  0.57*x1**2\n",
            " ---> GPT2 Test Error: 0.52548\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 40.78430\n",
            "Genetic Model function:  mul(mul(X0, X0), sqrt(0.390))\n",
            " ---> GP Test Error: 0.28234\n",
            "Test case 198/1000.\n",
            "True equation: 0.15*x1+0.84*sqrt(0.65*x1+1)\n",
            "GPT2 function:  0.96*sqrt(-x1-0.71)\n",
            " ---> GPT2 Test Error: 0.02881\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.02712\n",
            "Genetic Model function:  sqrt(add(X0, 0.546))\n",
            " ---> GP Test Error: 0.01332\n",
            "Test case 199/1000.\n",
            "True equation: -0.14*x1**(3/2)\n",
            "GPT2 function:  -0.14*x1**(3/2)\n",
            " ---> GPT2 Test Error: 0.00626\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.07625\n",
            "Genetic Model function:  sin(mul(mul(X0, -0.156), sqrt(X0)))\n",
            " ---> GP Test Error: 0.46646\n",
            "Test case 200/1000.\n",
            "True equation: 2*x1+0.48*sin(x1+0.03)\n",
            "GPT2 function:  2*x1*sin(x1-0.19)\n",
            " ---> GPT2 Test Error: 1.93092\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 67.21447\n",
            "Genetic Model function:  mul(add(add(X0, 0.502), X0), sin(X0))\n",
            " ---> GP Test Error: 0.03699\n",
            "Test case 201/1000.\n",
            "True equation: sqrt(x1)+1.77*x1+0.44\n",
            "GPT2 function:  0.74*sqrt(x1)+2*x1\n",
            " ---> GPT2 Test Error: 0.02304\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 44.08211\n",
            "Genetic Model function:  add(add(X0, X0), sqrt(sqrt(add(X0, X0))))\n",
            " ---> GP Test Error: 0.04854\n",
            "Test case 202/1000.\n",
            "True equation: 0.87*sqrt(-x1**2)\n",
            "GPT2 function:  0.87*sqrt(-x1**2+0.09*x1)\n",
            " ---> GPT2 Test Error: 0.00044\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.97756\n",
            "Genetic Model function:  sqrt(mul(log(log(0.212)), div(mul(X0, X0), sqrt(-0.347))))\n",
            " ---> GP Test Error: 0.00031\n",
            "Test case 203/1000.\n",
            "True equation: 2*sin(x1)\n",
            "GPT2 function:  2*sin(x1-0.19)\n",
            " ---> GPT2 Test Error: 0.06929\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.18232\n",
            "Genetic Model function:  add(sin(X0), sin(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 204/1000.\n",
            "True equation: -sqrt(x1+0.08)*sin(0.04*x1)\n",
            "GPT2 function:  -sin(0.04*x1**2-0.01*x1)\n",
            " ---> GPT2 Test Error: 0.10239\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.03407\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  mul(mul(X0, -0.029), sqrt(div(X0, 0.470)))\n",
            " ---> GP Test Error: 0.00083\n",
            "Test case 205/1000.\n",
            "True equation: sin(sin(x1+0.45))\n",
            "GPT2 function:  sin(sin(x1+0.35))\n",
            " ---> GPT2 Test Error: 0.00379\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.16790\n",
            "Genetic Model function:  sin(sin(add(0.231, add(0.231, X0))))\n",
            " ---> GP Test Error: 0.00006\n",
            "Test case 206/1000.\n",
            "True equation: 0.18*x1**2-0.09*x1\n",
            "GPT2 function:  0.47*x1-0.03\n",
            " ---> GPT2 Test Error: 2.60024\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.23966\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  mul(div(-0.075, -0.517), mul(add(add(X0, -0.891), add(0.113, 0.705)), X0))\n",
            " ---> GP Test Error: 0.17730\n",
            "Test case 207/1000.\n",
            "True equation: sin(1.33*x1)\n",
            "GPT2 function:  sin(1.38*x1-0.11)\n",
            " ---> GPT2 Test Error: 0.00607\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 5.66878\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  sin(mul(add(mul(-0.190, X0), add(X0, X0)), sqrt(div(exp(add(-0.165, -0.906)), -0.634))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 208/1000.\n",
            "True equation: 1.02*sqrt(x1)\n",
            "GPT2 function:  1.0*sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00570\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.27202\n",
            "Genetic Model function:  sqrt(div(X0, -0.941))\n",
            " ---> GP Test Error: 0.00022\n",
            "Test case 209/1000.\n",
            "True equation: (x1-0.05)**(1/4)\n",
            "GPT2 function:  (x1-0.15)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00007\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.04028\n",
            "Genetic Model function:  sqrt(add(sqrt(X0), log(-0.979)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 210/1000.\n",
            "True equation: -0.25*x1**2-0.85\n",
            "GPT2 function:  -0.21*x1**2*sqrt(-x1)+0.43*x1-0.03\n",
            " ---> GPT2 Test Error: 4.27927\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 76.27075\n",
            "Genetic Model function:  add(sin(sqrt(exp(X0))), -0.892)\n",
            " ---> GP Test Error: 105.50621\n",
            "Test case 211/1000.\n",
            "<class 'TypeError'> \n",
            "\n",
            " Error: sin(sqrt(3.1-0.1))0.1), EQ:sin(sqrt(x1-0.1))0.1)\n",
            "Not calculated\n",
            "Test case 212/1000.\n",
            "True equation: sin(sin(x1+0.78))\n",
            "GPT2 function:  sin(sin(x1+0.68))\n",
            " ---> GPT2 Test Error: 0.00406\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.01997\n",
            "Genetic Model function:  sin(sin(add(exp(-0.247), X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 213/1000.\n",
            "True equation: 0.89-0.83*x1\n",
            "GPT2 function:  0.98-0.84*x1\n",
            " ---> GPT2 Test Error: 0.00096\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.92699\n",
            "Genetic Model function:  add(mul(-0.807, X0), 0.861)\n",
            " ---> GP Test Error: 0.00396\n",
            "Test case 214/1000.\n",
            "True equation: 0.65*sqrt(-x1)+sqrt(x1+0.8)\n",
            "GPT2 function:  sqrt(x1)+0.66*sqrt(-x1-0.93)\n",
            " ---> GPT2 Test Error: 0.00024\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.07627\n",
            "Genetic Model function:  add(0.612, sqrt(div(X0, 0.512)))\n",
            " ---> GP Test Error: 0.01055\n",
            "Test case 215/1000.\n",
            "True equation: 2*x1\n",
            "GPT2 function:  2*x1-0.2\n",
            " ---> GPT2 Test Error: 0.04000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.84199\n",
            "Genetic Model function:  sqrt(mul(add(X0, X0), add(X0, X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 216/1000.\n",
            "True equation: sin(2*x1-0.41)\n",
            "GPT2 function:  sin(2*x1-0.61)\n",
            " ---> GPT2 Test Error: 0.01919\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.67859\n",
            "Genetic Model function:  sin(add(X0, add(-0.419, X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 217/1000.\n",
            "True equation: 0.03*x1**(3/2)\n",
            "GPT2 function:  0.03*x1*sqrt(-x1)\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00262\n",
            "Genetic Model function:  mul(0.040, X0)\n",
            " ---> GP Test Error: 0.01612\n",
            "Test case 218/1000.\n",
            "True equation: 0.87*sqrt(0.91*x1**2+x1-0.34)\n",
            "GPT2 function:  0.86*sqrt(-x1**2-0.74*x1+0.38)\n",
            " ---> GPT2 Test Error: 0.00051\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.28951\n",
            "Genetic Model function:  X0\n",
            " ---> GP Test Error: 0.15121\n",
            "Test case 219/1000.\n",
            "True equation: sin(2*x1-0.59)\n",
            "GPT2 function:  sin(2*x1-0.79)\n",
            " ---> GPT2 Test Error: 0.02021\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 8.33014\n",
            "Genetic Model function:  sin(mul(exp(sin(add(0.492, X0))), log(0.212)))\n",
            " ---> GP Test Error: 0.87419\n",
            "Test case 220/1000.\n",
            "True equation: -0.36*x1**2+0.5*x1\n",
            "GPT2 function:  -0.35*x1**2+sin(0.52*x1-0.04)\n",
            " ---> GPT2 Test Error: 2.22624\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 5.18434\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  mul(add(log(-0.241), X0), mul(X0, -0.376))\n",
            " ---> GP Test Error: 0.02510\n",
            "Test case 221/1000.\n",
            "True equation: 0.76*x1**2+0.57*x1\n",
            "GPT2 function:  x1**2-0.1*x1+sqrt(x1+0.12)-0.24\n",
            " ---> GPT2 Test Error: 19.08446\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 112.75422\n",
            "Genetic Model function:  log(add(exp(mul(X0, X0)), mul(X0, X0)))\n",
            " ---> GP Test Error: 134.24282\n",
            "Test case 222/1000.\n",
            "True equation: 2*x1+0.82\n",
            "GPT2 function:  2*x1+0.62\n",
            " ---> GPT2 Test Error: 0.04000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.34652\n",
            "Genetic Model function:  add(add(X0, X0), exp(-0.199))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 223/1000.\n",
            "True equation: sin(sin(x1))\n",
            "GPT2 function:  sin(sin(x1-0.1))\n",
            " ---> GPT2 Test Error: 0.00366\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.79182\n",
            "Genetic Model function:  sin(sin(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 224/1000.\n",
            "True equation: -0.3*x1\n",
            "GPT2 function:  -0.31*x1-0.01\n",
            " ---> GPT2 Test Error: 0.00437\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.54583\n",
            "Genetic Model function:  div(mul(mul(0.205, X0), exp(-0.875)), log(sin(log(-0.428))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 225/1000.\n",
            "True equation: 0.78*sqrt(-0.77*x1**2+x1+0.69)\n",
            "GPT2 function:  0.96*sqrt(-0.51*x1**2+x1+0.4)\n",
            " ---> GPT2 Test Error: 0.07968\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.21118\n",
            "Genetic Model function:  sin(sin(exp(sin(X0))))\n",
            " ---> GP Test Error: 4.69557\n",
            "Test case 226/1000.\n",
            "True equation: 0.85*x1+0.3\n",
            "GPT2 function:  0.86*x1+0.21\n",
            " ---> GPT2 Test Error: 0.00388\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.03227\n",
            "Genetic Model function:  sqrt(mul(add(0.810, X0), mul(X0, -0.721)))\n",
            " ---> GP Test Error: 0.00006\n",
            "Test case 227/1000.\n",
            "True equation: sin(x1**2)\n",
            "GPT2 function:  sin(x1**2-0.06*x1)\n",
            " ---> GPT2 Test Error: 0.03797\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.15723\n",
            "Genetic Model function:  sin(mul(X0, X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 228/1000.\n",
            "True equation: sqrt(-sin(0.97*x1))\n",
            "GPT2 function:  sqrt(-sin(0.97*x1-0.1))\n",
            " ---> GPT2 Test Error: 0.00479\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.10317\n",
            "Genetic Model function:  sqrt(sin(mul(-0.979, X0)))\n",
            " ---> GP Test Error: 0.00060\n",
            "Test case 229/1000.\n",
            "True equation: 0.93*sqrt(x1**2-0.19*x1)\n",
            "GPT2 function:  0.93*x1-0.09*sqrt(x1-0.08)\n",
            " ---> GPT2 Test Error: 0.00684\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.01965\n",
            "Genetic Model function:  mul(0.916, add(X0, -0.077))\n",
            " ---> GP Test Error: 0.00077\n",
            "Test case 230/1000.\n",
            "True equation: -0.33*x1**2+1.08*x1-0.11\n",
            "GPT2 function:  0.55*x1**2-0.79*x1+0.58\n",
            " ---> GPT2 Test Error: 126.22142\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 141.34765\n",
            "Genetic Model function:  mul(0.583, mul(log(mul(X0, 0.628)), mul(X0, X0)))\n",
            " ---> GP Test Error: 26.15403\n",
            "Test case 231/1000.\n",
            "True equation: 0.66*sqrt(x1**2)\n",
            "GPT2 function:  0.66*x1-0.04\n",
            " ---> GPT2 Test Error: 0.00017\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.43196\n",
            "Genetic Model function:  add(mul(0.205, X0), mul(X0, 0.449))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 232/1000.\n",
            "True equation: 0.36*x1**(3/2)\n",
            "GPT2 function:  0.37*x1*sqrt(-x1)-0.02\n",
            " ---> GPT2 Test Error: 0.00159\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.27005\n",
            "Genetic Model function:  mul(sqrt(mul(0.730, X0)), mul(X0, 0.425))\n",
            " ---> GP Test Error: 0.00023\n",
            "Test case 233/1000.\n",
            "True equation: 0.64*sqrt(x1)\n",
            "GPT2 function:  0.63*sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00167\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.02794\n",
            "Genetic Model function:  mul(sqrt(X0), sqrt(-0.420))\n",
            " ---> GP Test Error: 0.00015\n",
            "Test case 234/1000.\n",
            "True equation: -sin(sin(0.52*x1))\n",
            "GPT2 function:  -sin(sin(0.55*x1-0.05))\n",
            " ---> GPT2 Test Error: 0.00483\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.01057\n",
            "Genetic Model function:  sin(sin(mul(mul(-0.425, 0.628), add(X0, X0))))\n",
            " ---> GP Test Error: 0.00223\n",
            "Test case 235/1000.\n",
            "True equation: sin(sin(0.76*x1))\n",
            "GPT2 function:  sin(sin(0.76*x1-0.06))\n",
            " ---> GPT2 Test Error: 0.00197\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.31544\n",
            "Genetic Model function:  sin(sin(mul(mul(sqrt(-0.515), add(X0, X0)), div(sqrt(0.287), div(X0, X0)))))\n",
            " ---> GP Test Error: 0.00063\n",
            "Test case 236/1000.\n",
            "True equation: sqrt(x1-0.17)\n",
            "GPT2 function:  sqrt(x1-0.27)\n",
            " ---> GPT2 Test Error: 0.00064\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.34861\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  sqrt(add(X0, -0.172))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 237/1000.\n",
            "True equation: 0.57*x1**2-0.95\n",
            "GPT2 function:  0.63*x1**2-1.08*x1+0.1\n",
            " ---> GPT2 Test Error: 0.88567\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 13.80587\n",
            "Genetic Model function:  add(-0.329, mul(log(X0), mul(X0, mul(X0, 0.259))))\n",
            " ---> GP Test Error: 0.52479\n",
            "Test case 238/1000.\n",
            "True equation: 0.91*(-x1)**(1/4)\n",
            "GPT2 function:  0.91*x1-0.12\n",
            " ---> GPT2 Test Error: 7.78594\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.02623\n",
            "Genetic Model function:  sqrt(sqrt(log(exp(mul(X0, -0.685)))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 239/1000.\n",
            "True equation: 0.75*sqrt(x1**2)\n",
            "GPT2 function:  0.75*sqrt(x1)*sqrt(0.11-x1)\n",
            " ---> GPT2 Test Error: 0.00071\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.09904\n",
            "Genetic Model function:  log(exp(mul(X0, 0.749)))\n",
            " ---> GP Test Error: 0.00012\n",
            "Test case 240/1000.\n",
            "True equation: sin(x1+0.28)\n",
            "GPT2 function:  sin(x1+0.18)\n",
            " ---> GPT2 Test Error: 0.00477\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.43621\n",
            "Genetic Model function:  sin(log(exp(add(X0, 0.280))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 241/1000.\n",
            "True equation: sin(0.94*sqrt(0.72*x1-1))\n",
            "GPT2 function:  sqrt(sin(0.55*x1-0.76))\n",
            " ---> GPT2 Test Error: 0.00841\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.04020\n",
            "Genetic Model function:  sin(sin(exp(sqrt(sin(X0)))))\n",
            " ---> GP Test Error: 0.14361\n",
            "Test case 242/1000.\n",
            "True equation: x1*sqrt(x1+0.8)+0.51\n",
            "GPT2 function:  0.25*x1**2+1.03*x1+0.33\n",
            " ---> GPT2 Test Error: 2.09745\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 4.73437\n",
            "Genetic Model function:  mul(add(0.564, X0), sqrt(log(exp(add(0.672, X0)))))\n",
            " ---> GP Test Error: 0.00020\n",
            "Test case 243/1000.\n",
            "True equation: sin(x1**2+0.11*x1)\n",
            "GPT2 function:  sin(x1**2-0.08*x1)\n",
            " ---> GPT2 Test Error: 0.35340\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 33.27121\n",
            "Genetic Model function:  sin(mul(add(X0, 0.122), X0))\n",
            " ---> GP Test Error: 0.00140\n",
            "Test case 244/1000.\n",
            "True equation: sin(0.27*x1**2)\n",
            "GPT2 function:  sin(0.25*x1**2-0.02*x1)\n",
            " ---> GPT2 Test Error: 0.11082\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.88625\n",
            "Genetic Model function:  sin(mul(mul(X0, 0.266), X0))\n",
            " ---> GP Test Error: 0.00008\n",
            "Test case 245/1000.\n",
            "True equation: -0.04*x1*sin(0.82*x1)\n",
            "GPT2 function:  -sin(0.04*x1)*sin(x1-0.13)\n",
            " ---> GPT2 Test Error: 0.00607\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.25884\n",
            "Genetic Model function:  div(mul(X0, 0.050), log(-0.321))\n",
            " ---> GP Test Error: 0.11783\n",
            "Test case 246/1000.\n",
            "True equation: -0.94*x1**2+0.32*x1*sqrt(x1+0.31)\n",
            "GPT2 function:  -0.91*x1**(5/2)+0.44*x1-0.02\n",
            " ---> GPT2 Test Error: 3.71222\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 989.99994\n",
            "Genetic Model function:  mul(-0.790, add(exp(X0), log(mul(0.766, 0.263))))\n",
            " ---> GP Test Error: 8342.61453\n",
            "Test case 247/1000.\n",
            "True equation: 0.15*x1**3+0.71\n",
            "GPT2 function:  0.05*x1**2+1.02*x1\n",
            " ---> GPT2 Test Error: 42.35599\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 58.34148\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  mul(mul(exp(X0), mul(X0, 0.012)), add(X0, -0.563))\n",
            " ---> GP Test Error: 2174.64063\n",
            "Test case 248/1000.\n",
            "True equation: 0.14*x1-0.04\n",
            "GPT2 function:  0.14*x1-0.05\n",
            " ---> GPT2 Test Error: 0.00056\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.07058\n",
            "Genetic Model function:  mul(mul(0.102, X0), sqrt(sqrt(X0)))\n",
            " ---> GP Test Error: 0.00667\n",
            "Test case 249/1000.\n",
            "True equation: 1.7*x1+0.73\n",
            "GPT2 function:  1.68*x1+0.58\n",
            " ---> GPT2 Test Error: 0.04946\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.72059\n",
            "Genetic Model function:  add(sqrt(mul(add(X0, X0), mul(sqrt(log(-0.127)), X0))), 0.730)\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 250/1000.\n",
            "True equation: 0.25*x1+0.99\n",
            "GPT2 function:  1.05*x1**2+0.08*x1-0.68\n",
            " ---> GPT2 Test Error: 9.02849\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 56.21093\n",
            "Genetic Model function:  add(add(mul(0.567, X0), mul(mul(X0, X0), exp(0.039))), -0.836)\n",
            " ---> GP Test Error: 1.37510\n",
            "Test case 251/1000.\n",
            "True equation: 0.12*x1-0.59\n",
            "GPT2 function:  0.11*x1-0.6\n",
            " ---> GPT2 Test Error: 0.00650\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.01995\n",
            "Genetic Model function:  -0.400\n",
            " ---> GP Test Error: 0.15585\n",
            "Test case 252/1000.\n",
            "True equation: 0.03*x1-sin(0.89*x1)\n",
            "GPT2 function:  -0.06*x1+sin(x1)-0.1\n",
            " ---> GPT2 Test Error: 3.59759\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.14316\n",
            "Genetic Model function:  sin(mul(X0, -0.922))\n",
            " ---> GP Test Error: 0.02112\n",
            "Test case 253/1000.\n",
            "True equation: 0.06*x1**2-sin(0.17*x1-0.2)\n",
            "GPT2 function:  0.2*sqrt(0.33*x1-1)\n",
            " ---> GPT2 Test Error: 0.54682\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.44304\n",
            "Genetic Model function:  0.128\n",
            " ---> GP Test Error: 0.58424\n",
            "Test case 254/1000.\n",
            "True equation: -0.58*x1**3+0.22*x1+0.68\n",
            "GPT2 function:  -0.59*x1**3-0.77*x1\n",
            " ---> GPT2 Test Error: 185.78736\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1671.40800\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  mul(add(-0.895, X0), mul(mul(X0, X0), -0.642))\n",
            " ---> GP Test Error: 10.06455\n",
            "Test case 255/1000.\n",
            "True equation: sin(x1**2+0.51*x1)\n",
            "GPT2 function:  sin(x1**2+0.18*x1-0.02)\n",
            " ---> GPT2 Test Error: 0.95984\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.53930\n",
            "Genetic Model function:  sin(add(log(sqrt(exp(X0))), mul(X0, X0)))\n",
            " ---> GP Test Error: 0.00089\n",
            "Test case 256/1000.\n",
            "True equation: -0.3*x1**2-0.8*x1\n",
            "GPT2 function:  0.24*x1**2*sqrt(x1-0.27)\n",
            " ---> GPT2 Test Error: 4.69927\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 64.28405\n",
            "Genetic Model function:  mul(mul(sqrt(0.174), mul(X0, X0)), sqrt(mul(X0, 0.377)))\n",
            " ---> GP Test Error: 1.09708\n",
            "Test case 257/1000.\n",
            "True equation: 0.14*x1**(5/2)-0.01*x1\n",
            "GPT2 function:  0.11*x1**3\n",
            " ---> GPT2 Test Error: 32.68969\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 9.44306\n",
            "Genetic Model function:  mul(mul(X0, 0.330), add(X0, -0.792))\n",
            " ---> GP Test Error: 1.06015\n",
            "Test case 258/1000.\n",
            "True equation: sin(0.71*sqrt(-x1))\n",
            "GPT2 function:  sqrt(x1)-0.25*x1-0.34\n",
            " ---> GPT2 Test Error: 0.11759\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.25737\n",
            "Genetic Model function:  sin(sqrt(log(sqrt(exp(X0)))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 259/1000.\n",
            "True equation: 0.57-0.57*x1**(3/2)\n",
            "GPT2 function:  -0.75*x1+0.06*sqrt(-x1)+0.27\n",
            " ---> GPT2 Test Error: 2.83718\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 3.74057\n",
            "Genetic Model function:  mul(mul(X0, -0.629), log(X0))\n",
            " ---> GP Test Error: 0.01871\n",
            "Test case 260/1000.\n",
            "True equation: 0.33*sqrt(x1)*sqrt(-x1)\n",
            "GPT2 function:  0.33*sqrt(x1**2-0.04*x1)\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.29793\n",
            "Genetic Model function:  mul(X0, 0.334)\n",
            " ---> GP Test Error: 0.00080\n",
            "Test case 261/1000.\n",
            "True equation: 2*x1**(3/2)-0.61\n",
            "GPT2 function:  2*x1**(3/4)-0.61\n",
            " ---> GPT2 Test Error: 183.50755\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 14.22232\n",
            "Genetic Model function:  mul(add(0.228, X0), sqrt(div(sqrt(X0), div(0.619, X0))))\n",
            " ---> GP Test Error: 1.47506\n",
            "Test case 262/1000.\n",
            "<class 'TypeError'> \n",
            "\n",
            " Error: sin(3.1-0.1)3.108), EQ:sin(x1-0.1)x108)\n",
            "Not calculated\n",
            "Test case 263/1000.\n",
            "True equation: sin(0.33*x1**2-0.35*x1)\n",
            "GPT2 function:  sin(0.31*x1**2-0.57*x1+0.03)\n",
            " ---> GPT2 Test Error: 0.84975\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.24443\n",
            "Genetic Model function:  sin(mul(X0, log(sqrt(X0))))\n",
            " ---> GP Test Error: 1.16341\n",
            "Test case 264/1000.\n",
            "True equation: sqrt(x1**2+0.27*x1)\n",
            "GPT2 function:  sqrt(x1**2+0.08*x1-0.06)\n",
            " ---> GPT2 Test Error: 0.00941\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.37770\n",
            "Genetic Model function:  add(0.122, X0)\n",
            " ---> GP Test Error: 0.00007\n",
            "Test case 265/1000.\n",
            "True equation: 0.33*x1**2-0.86*x1\n",
            "GPT2 function:  0.39*x1**2-1.03*x1+0.1\n",
            " ---> GPT2 Test Error: 0.47496\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 11.42758\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  mul(-0.524, sin(div(X0, 0.839)))\n",
            " ---> GP Test Error: 13.31813\n",
            "Test case 266/1000.\n",
            "True equation: x1+0.78*sin(x1+0.73)\n",
            "GPT2 function:  x1+0.82*sin(x1+0.37)\n",
            " ---> GPT2 Test Error: 47.03817\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 5.54449\n",
            "Genetic Model function:  mul(sin(add(X0, 0.739)), add(X0, 0.783))\n",
            " ---> GP Test Error: 0.00292\n",
            "Test case 267/1000.\n",
            "True equation: -sin(sin(0.49*x1))\n",
            "GPT2 function:  -sin(sin(0.53*x1-0.05))\n",
            " ---> GPT2 Test Error: 0.01172\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.51306\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  sin(sin(div(mul(0.191, X0), log(0.666))))\n",
            " ---> GP Test Error: 0.00226\n",
            "Test case 268/1000.\n",
            "<class 'TypeError'> \n",
            "\n",
            " Error: sqrt(3.1)+3.1**(3.1-0.27, EQ:sqrt(x1)+x1**(x1-0.27\n",
            "Not calculated\n",
            "Test case 269/1000.\n",
            "True equation: sin(0.12*x1**2)\n",
            "GPT2 function:  sin(0.12*x1**2)\n",
            " ---> GPT2 Test Error: 0.00070\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.44321\n",
            "Genetic Model function:  sin(mul(mul(0.234, 0.507), mul(X0, X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 270/1000.\n",
            "True equation: sqrt(x1)\n",
            "GPT2 function:  sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00057\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.31670\n",
            "Genetic Model function:  sqrt(mul(sqrt(X0), sqrt(X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 271/1000.\n",
            "True equation: sin(0.51*x1+0.34)\n",
            "GPT2 function:  sin(0.48*x1+0.3)\n",
            " ---> GPT2 Test Error: 0.02719\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.47608\n",
            "Genetic Model function:  sin(sqrt(X0))\n",
            " ---> GP Test Error: 0.25477\n",
            "Test case 272/1000.\n",
            "True equation: 0.65*sqrt(-x1**2)\n",
            "GPT2 function:  0.65*x1-0.04\n",
            " ---> GPT2 Test Error: 0.00141\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00005\n",
            "Genetic Model function:  sqrt(mul(mul(X0, 0.614), mul(X0, -0.684)))\n",
            " ---> GP Test Error: 0.00006\n",
            "Test case 273/1000.\n",
            "True equation: -0.04*x1**2-0.18*x1-0.16\n",
            "GPT2 function:  -0.05*x1**2-0.16*x1-0.16\n",
            " ---> GPT2 Test Error: 0.02018\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.12952\n",
            "Genetic Model function:  mul(-0.342, X0)\n",
            " ---> GP Test Error: 0.10677\n",
            "Test case 274/1000.\n",
            "True equation: 0.38*x1-0.26*sqrt(-x1)\n",
            "GPT2 function:  0.28*x1**2-0.47*x1-0.04\n",
            " ---> GPT2 Test Error: 4.45971\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.99539\n",
            "Genetic Model function:  mul(div(log(X0), sqrt(0.234)), mul(X0, 0.134))\n",
            " ---> GP Test Error: 0.01679\n",
            "Test case 275/1000.\n",
            "True equation: x1-sin(0.8*x1)\n",
            "GPT2 function:  0.27*x1**2+0.01*x1\n",
            " ---> GPT2 Test Error: 1.48578\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.87897\n",
            "Genetic Model function:  mul(mul(0.598, X0), mul(X0, 0.424))\n",
            " ---> GP Test Error: 0.71072\n",
            "Test case 276/1000.\n",
            "True equation: 0.06*x1**(5/2)+0.06*x1-0.05\n",
            "GPT2 function:  0.16*x1**2-0.06*x1+0.02\n",
            " ---> GPT2 Test Error: 0.07739\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.43540\n",
            "Genetic Model function:  mul(mul(0.205, X0), mul(sqrt(X0), mul(0.373, X0)))\n",
            " ---> GP Test Error: 0.11134\n",
            "Test case 277/1000.\n",
            "<class 'TypeError'> \n",
            "\n",
            " Error: sin(3.1-0.1)3.112), EQ:sin(x1-0.1)x112)\n",
            "Not calculated\n",
            "Test case 278/1000.\n",
            "True equation: -0.45*x1-0.27\n",
            "GPT2 function:  -0.42*x1-0.22\n",
            " ---> GPT2 Test Error: 0.03383\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.06435\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  mul(log(0.657), add(0.729, X0))\n",
            " ---> GP Test Error: 0.00903\n",
            "Test case 279/1000.\n",
            "<class 'TypeError'> \n",
            "\n",
            " Error: sin(3.1-0.1)3.1), EQ:sin(x1-0.1)x1)\n",
            "Not calculated\n",
            "Test case 280/1000.\n",
            "True equation: 0.87*(-x1)**(1/4)\n",
            "GPT2 function:  0.87*(x1-0.1)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00012\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.03103\n",
            "Genetic Model function:  sqrt(sqrt(mul(X0, 0.573)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 281/1000.\n",
            "True equation: sin(sin(x1+0.92))\n",
            "GPT2 function:  sin(sin(x1+0.82))\n",
            " ---> GPT2 Test Error: 0.00397\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.24522\n",
            "Genetic Model function:  sin(sin(add(X0, sqrt(0.881))))\n",
            " ---> GP Test Error: 0.00015\n",
            "Test case 282/1000.\n",
            "True equation: 0.91*x1**(1/4)\n",
            "GPT2 function:  0.93*(-x1-0.1)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.38678\n",
            "Genetic Model function:  sqrt(sqrt(mul(mul(X0, -0.722), sqrt(exp(-0.118)))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 283/1000.\n",
            "True equation: 0.73*sqrt(-x1)\n",
            "GPT2 function:  sqrt(x1)-0.13*x1\n",
            " ---> GPT2 Test Error: 0.00378\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.01845\n",
            "Genetic Model function:  sqrt(mul(X0, -0.524))\n",
            " ---> GP Test Error: 0.00029\n",
            "Test case 284/1000.\n",
            "True equation: 0.75*sqrt(0.09*x1+1)\n",
            "GPT2 function:  0.02*x1+0.75\n",
            " ---> GPT2 Test Error: 0.00162\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00053\n",
            "Genetic Model function:  0.786\n",
            " ---> GP Test Error: 0.00950\n",
            "Test case 285/1000.\n",
            "True equation: -0.04*x1**2*sqrt(x1-0.54)-0.01*x1\n",
            "GPT2 function:  -0.02*x1**3\n",
            " ---> GPT2 Test Error: 0.12685\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.48299\n",
            "Genetic Model function:  div(mul(-0.143, X0), div(div(-0.739, X0), mul(log(0.824), sqrt(X0))))\n",
            " ---> GP Test Error: 0.00904\n",
            "Test case 286/1000.\n",
            "True equation: -0.13*x1**2+0.32*x1+sin(0.05*x1)+0.48\n",
            "GPT2 function:  0.56*sqrt(x1)-sin(0.29*x1-0.29)\n",
            " ---> GPT2 Test Error: 1.57766\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.22670\n",
            "Genetic Model function:  0.671\n",
            " ---> GP Test Error: 2.33389\n",
            "Test case 287/1000.\n",
            "True equation: sin(0.16*x1**2+0.08*x1)\n",
            "GPT2 function:  sin(0.16*x1**2)\n",
            " ---> GPT2 Test Error: 0.04611\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 3.58002\n",
            "Genetic Model function:  mul(X0, 0.347)\n",
            " ---> GP Test Error: 3.87962\n",
            "Test case 288/1000.\n",
            "True equation: x1**(1/4)\n",
            "GPT2 function:  (x1-0.1)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00010\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00560\n",
            "Genetic Model function:  sqrt(sqrt(sqrt(mul(X0, X0))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 289/1000.\n",
            "True equation: 0.52*sqrt(x1)+0.88*x1**2-0.02*x1\n",
            "GPT2 function:  sqrt(x1)+0.8*x1**2-0.3*x1-0.61\n",
            " ---> GPT2 Test Error: 7.36417\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 23.19261\n",
            "Genetic Model function:  add(0.273, mul(X0, X0))\n",
            " ---> GP Test Error: 4.02982\n",
            "Test case 290/1000.\n",
            "True equation: -sin(0.02*x1)\n",
            "GPT2 function:  -sin(0.02*x1-0.02)\n",
            " ---> GPT2 Test Error: 0.00155\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00005\n",
            "Genetic Model function:  mul(log(exp(X0)), mul(add(-0.646, -0.675), mul(-0.058, -0.239)))\n",
            " ---> GP Test Error: 0.00078\n",
            "Test case 291/1000.\n",
            "True equation: sin(1.79*x1-0.66)\n",
            "GPT2 function:  sin(1.77*x1-0.8)\n",
            " ---> GPT2 Test Error: 0.02771\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 4.72327\n",
            "Genetic Model function:  sin(div(add(X0, -0.362), sqrt(0.315)))\n",
            " ---> GP Test Error: 0.00018\n",
            "Test case 292/1000.\n",
            "True equation: -0.35*x1+0.7*sqrt(0.11*x1-1)\n",
            "GPT2 function:  -sin(0.31*x1-0.78)\n",
            " ---> GPT2 Test Error: 0.02842\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.01413\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  div(sin(add(0.636, X0)), exp(X0))\n",
            " ---> GP Test Error: 0.18774\n",
            "Test case 293/1000.\n",
            "True equation: sin(x1+0.04)\n",
            "GPT2 function:  sin(x1-0.06)\n",
            " ---> GPT2 Test Error: 0.00457\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.17537\n",
            "Genetic Model function:  sin(X0)\n",
            " ---> GP Test Error: 0.00069\n",
            "Test case 294/1000.\n",
            "True equation: sin(sin(x1+0.36))\n",
            "GPT2 function:  sin(sin(x1+0.25))\n",
            " ---> GPT2 Test Error: 0.00396\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.50281\n",
            "Genetic Model function:  sin(sin(add(add(0.225, X0), 0.136)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 295/1000.\n",
            "True equation: sqrt(x1)+sin(x1)\n",
            "GPT2 function:  sqrt(x1)+sin(x1-0.38)\n",
            " ---> GPT2 Test Error: 0.06897\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.26391\n",
            "Genetic Model function:  add(sqrt(X0), sin(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 296/1000.\n",
            "True equation: -0.93*x1**2-1.28*x1-sin(0.36*x1+0.8)-0.44\n",
            "GPT2 function:  -0.84*x1**2-1.62*x1-1.0\n",
            " ---> GPT2 Test Error: 0.24158\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 71.72213\n",
            "Genetic Model function:  add(mul(div(0.607, -0.173), add(sqrt(exp(X0)), -0.823)), -0.911)\n",
            " ---> GP Test Error: 132.57837\n",
            "Test case 297/1000.\n",
            "True equation: 1.48*x1-0.1\n",
            "GPT2 function:  1.49*x1-0.25\n",
            " ---> GPT2 Test Error: 0.01529\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 7.21905\n",
            "Genetic Model function:  div(X0, 0.698)\n",
            " ---> GP Test Error: 0.01881\n",
            "Test case 298/1000.\n",
            "True equation: 0.89*sqrt(-x1**2+0.95*x1)\n",
            "GPT2 function:  0.82*sqrt(0.79*x1**2-x1+0.09)\n",
            " ---> GPT2 Test Error: 0.63843\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.04963\n",
            "Genetic Model function:  exp(log(exp(log(add(-0.718, X0)))))\n",
            " ---> GP Test Error: 0.05557\n",
            "Test case 299/1000.\n",
            "True equation: 0.72*sqrt(0.95*x1+1)\n",
            "GPT2 function:  0.69*sqrt(x1+0.91)\n",
            " ---> GPT2 Test Error: 0.00157\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00079\n",
            "Genetic Model function:  sqrt(sqrt(add(X0, 0.110)))\n",
            " ---> GP Test Error: 0.03671\n",
            "Test case 300/1000.\n",
            "True equation: 0.88*sqrt(-x1)\n",
            "GPT2 function:  0.91*sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00096\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.10934\n",
            "Genetic Model function:  sqrt(mul(X0, exp(-0.264)))\n",
            " ---> GP Test Error: 0.00040\n",
            "Test case 301/1000.\n",
            "True equation: sin(sin(x1))\n",
            "GPT2 function:  sin(sin(x1-0.1))\n",
            " ---> GPT2 Test Error: 0.00366\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.39159\n",
            "Genetic Model function:  sin(sin(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 302/1000.\n",
            "True equation: sin(sin(x1-0.39))\n",
            "GPT2 function:  sin(sin(x1-0.49))\n",
            " ---> GPT2 Test Error: 0.00426\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.69514\n",
            "Genetic Model function:  sin(sin(add(X0, log(add(0.022, 0.654)))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 303/1000.\n",
            "True equation: sin(sin(x1))\n",
            "GPT2 function:  sin(sin(x1-0.1))\n",
            " ---> GPT2 Test Error: 0.00366\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.65679\n",
            "Genetic Model function:  sin(sin(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 304/1000.\n",
            "True equation: 0\n",
            "GPT2 function:  sin(0.05*x1)\n",
            " ---> GPT2 Test Error: 0.00068\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.16057\n",
            "Genetic Model function:  sin(mul(0.052, X0))\n",
            " ---> GP Test Error: 0.00031\n",
            "Test case 305/1000.\n",
            "True equation: 1.77*x1\n",
            "GPT2 function:  1.75*x1-0.15\n",
            " ---> GPT2 Test Error: 0.04941\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.86982\n",
            "Genetic Model function:  add(div(X0, 0.923), mul(X0, 0.687))\n",
            " ---> GP Test Error: 0.00055\n",
            "Test case 306/1000.\n",
            "True equation: -0.5*x1**2-0.58*x1\n",
            "GPT2 function:  0.15*x1**(3/2)+x1**2\n",
            " ---> GPT2 Test Error: 1630.12172\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1463.11895\n",
            "Genetic Model function:  mul(mul(X0, X0), sqrt(add(0.527, X0)))\n",
            " ---> GP Test Error: 108.72106\n",
            "Test case 307/1000.\n",
            "True equation: 0.74*x1**2*sqrt(0.74*x1-1)-0.07*x1\n",
            "GPT2 function:  1.1*x1**2-0.54*x1+0.03*sin(0.84*x1-0.12)\n",
            " ---> GPT2 Test Error: 31.48053\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 222.09817\n",
            "Genetic Model function:  mul(mul(X0, 0.263), mul(X0, X0))\n",
            " ---> GP Test Error: 12.07068\n",
            "Test case 308/1000.\n",
            "True equation: -0.69*x1**(3/2)\n",
            "GPT2 function:  -0.72*x1*sqrt(-x1)+0.12\n",
            " ---> GPT2 Test Error: 0.05121\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 13.42941\n",
            "Genetic Model function:  mul(sqrt(mul(X0, -0.181)), mul(add(X0, X0), sin(-0.948)))\n",
            " ---> GP Test Error: 0.00151\n",
            "Test case 309/1000.\n",
            "True equation: 1.02*x1*sin(0.11*x1+0.61)\n",
            "GPT2 function:  0.26*x1**2+0.42*x1-0.03\n",
            " ---> GPT2 Test Error: 12.83505\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.61472\n",
            "Genetic Model function:  mul(0.757, X0)\n",
            " ---> GP Test Error: 0.64178\n",
            "Test case 310/1000.\n",
            "True equation: x1\n",
            "GPT2 function:  x1-0.1\n",
            " ---> GPT2 Test Error: 0.01000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.21309\n",
            "Genetic Model function:  sqrt(mul(X0, X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 311/1000.\n",
            "True equation: x1**2-0.55*x1\n",
            "GPT2 function:  x1**2-0.44*x1+0.03\n",
            " ---> GPT2 Test Error: 0.27161\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 102.23765\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  mul(add(-0.545, X0), X0)\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 312/1000.\n",
            "True equation: 1.9*x1+sqrt(x1-0.27)+0.64\n",
            "GPT2 function:  1.96*x1+0.99*sqrt(0.68-x1)+0.2\n",
            " ---> GPT2 Test Error: 0.08142\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.40484\n",
            "Genetic Model function:  add(div(X0, 0.421), 0.985)\n",
            " ---> GP Test Error: 0.25056\n",
            "Test case 313/1000.\n",
            "True equation: sin(0.64*x1)\n",
            "GPT2 function:  sin(0.64*x1-0.06)\n",
            " ---> GPT2 Test Error: 0.00309\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.01826\n",
            "Genetic Model function:  sin(mul(0.635, X0))\n",
            " ---> GP Test Error: 0.00057\n",
            "Test case 314/1000.\n",
            "True equation: -0.42*x1+sqrt(x1-0.48)\n",
            "GPT2 function:  -0.81*sqrt(x1-0.91)+sin(0.21*x1)\n",
            " ---> GPT2 Test Error: 0.67626\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.04098\n",
            "Genetic Model function:  0.363\n",
            " ---> GP Test Error: 0.09735\n",
            "Test case 315/1000.\n",
            "True equation: sqrt(x1+0.51)\n",
            "GPT2 function:  sqrt(x1+0.41)\n",
            " ---> GPT2 Test Error: 0.00052\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00838\n",
            "Genetic Model function:  sqrt(add(0.463, div(X0, 0.972)))\n",
            " ---> GP Test Error: 0.00036\n",
            "Test case 316/1000.\n",
            "True equation: (x1+0.82)**(1/4)\n",
            "GPT2 function:  (x1+0.72)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00006\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.00569\n",
            "Genetic Model function:  exp(log(sqrt(sqrt(add(sqrt(sin(0.804)), X0)))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 317/1000.\n",
            "True equation: -0.19*x1**2+x1\n",
            "GPT2 function:  -0.19*x1**2+0.47*x1+0.03\n",
            " ---> GPT2 Test Error: 13534.34471\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 6167.07339\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  mul(add(log(sin(div(X0, X0))), X0), mul(add(add(X0, -0.391), sqrt(0.141)), X0))\n",
            " ---> GP Test Error: 0.00090\n",
            "Test case 318/1000.\n",
            "True equation: sin(0.85*sqrt(0.43*x1+1))\n",
            "GPT2 function:  sqrt(-sin(0.19*x1+0.55))\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.01273\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  0.891\n",
            " ---> GP Test Error: 0.00983\n",
            "Test case 319/1000.\n",
            "True equation: x1-0.49\n",
            "GPT2 function:  x1-0.59\n",
            " ---> GPT2 Test Error: 0.01000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00005\n",
            "Genetic Model function:  add(add(X0, -0.403), div(-0.035, 0.383))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 320/1000.\n",
            "True equation: 0.2*x1\n",
            "GPT2 function:  0.19*x1-0.02\n",
            " ---> GPT2 Test Error: 0.00711\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.27440\n",
            "Genetic Model function:  mul(sqrt(-0.575), mul(X0, 0.271))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 321/1000.\n",
            "True equation: sin(0.91*x1)\n",
            "GPT2 function:  sin(0.88*x1-0.09)\n",
            " ---> GPT2 Test Error: 0.02536\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.09018\n",
            "Genetic Model function:  sin(add(X0, mul(mul(-0.721, -0.178), mul(X0, -0.586))))\n",
            " ---> GP Test Error: 0.00076\n",
            "Test case 322/1000.\n",
            "True equation: 0.94*(-x1)**(1/4)\n",
            "GPT2 function:  0.94*(-x1-0.1)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.04259\n",
            "Genetic Model function:  sqrt(add(log(div(X0, X0)), sqrt(mul(X0, 0.779))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 323/1000.\n",
            "True equation: 0.86*x1*sqrt(x1+0.86)\n",
            "GPT2 function:  0.89*x1**(3/2)-0.21\n",
            " ---> GPT2 Test Error: 0.40355\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 23.87602\n",
            "Genetic Model function:  mul(X0, sqrt(X0))\n",
            " ---> GP Test Error: 0.53253\n",
            "Test case 324/1000.\n",
            "True equation: -sin(0.31*x1)\n",
            "GPT2 function:  -sin(0.32*x1-0.03)\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.02936\n",
            "Genetic Model function:  sin(log(exp(mul(-0.313, X0))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 325/1000.\n",
            "True equation: -1.0*x1**2+0.93*sqrt(-x1)\n",
            "GPT2 function:  -0.98*x1**2+0.77*sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.01283\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 73.10167\n",
            "Genetic Model function:  mul(mul(X0, add(X0, -0.882)), div(-0.509, 0.429))\n",
            " ---> GP Test Error: 2.10337\n",
            "Test case 326/1000.\n",
            "True equation: 0.98*sqrt(-x1)\n",
            "GPT2 function:  0.98*sqrt(0.1-x1)\n",
            " ---> GPT2 Test Error: 0.00095\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.02998\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  mul(sqrt(log(add(0.417, -0.798))), exp(log(sqrt(X0))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 327/1000.\n",
            "True equation: sin(0.08*x1+0.27)\n",
            "GPT2 function:  sin(0.08*x1+0.26)\n",
            " ---> GPT2 Test Error: 0.00028\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00319\n",
            "Genetic Model function:  0.391\n",
            " ---> GP Test Error: 0.04660\n",
            "Test case 328/1000.\n",
            "True equation: sin(0.74*x1-0.85)\n",
            "GPT2 function:  sin(0.76*x1-0.93)\n",
            " ---> GPT2 Test Error: 0.00127\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.67689\n",
            "Genetic Model function:  sin(sin(sin(add(add(-0.558, X0), -0.571))))\n",
            " ---> GP Test Error: 0.43469\n",
            "Test case 329/1000.\n",
            "True equation: 2*x1-0.61\n",
            "GPT2 function:  2*x1-0.81\n",
            " ---> GPT2 Test Error: 0.04000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 5.50255\n",
            "Genetic Model function:  add(add(mul(-0.896, 0.054), add(-0.561, X0)), log(exp(X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 330/1000.\n",
            "True equation: -sin(0.71*x1)\n",
            "GPT2 function:  -sin(0.74*x1-0.09)\n",
            " ---> GPT2 Test Error: 0.00159\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.86879\n",
            "Genetic Model function:  sin(mul(X0, div(-0.530, 0.746)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 331/1000.\n",
            "True equation: 2*x1-0.88*sin(x1)\n",
            "GPT2 function:  2*x1*sin(x1-0.06)-0.83\n",
            " ---> GPT2 Test Error: 2.22117\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 19.69847\n",
            "Genetic Model function:  mul(add(X0, add(X0, -0.876)), sin(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 332/1000.\n",
            "True equation: 0.11*x1+0.13\n",
            "GPT2 function:  0.1*x1+0.12\n",
            " ---> GPT2 Test Error: 0.00209\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.03386\n",
            "Genetic Model function:  sqrt(mul(0.064, X0))\n",
            " ---> GP Test Error: 0.00872\n",
            "Test case 333/1000.\n",
            "True equation: sqrt(x1**2)\n",
            "GPT2 function:  x1-0.1\n",
            " ---> GPT2 Test Error: 0.01000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.76032\n",
            "Genetic Model function:  sqrt(mul(X0, X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 334/1000.\n",
            "True equation: 2*sin(x1)\n",
            "GPT2 function:  2*sin(x1-0.19)\n",
            " ---> GPT2 Test Error: 0.06929\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.20537\n",
            "Genetic Model function:  log(exp(add(sin(X0), sin(X0))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 335/1000.\n",
            "True equation: sin(x1-0.08)\n",
            "GPT2 function:  sin(x1-0.18)\n",
            " ---> GPT2 Test Error: 0.00476\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.12466\n",
            "Genetic Model function:  sin(add(-0.069, X0))\n",
            " ---> GP Test Error: 0.00008\n",
            "Test case 336/1000.\n",
            "True equation: sqrt(x1)\n",
            "GPT2 function:  sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00057\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.24999\n",
            "Genetic Model function:  log(exp(sqrt(X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 337/1000.\n",
            "True equation: 0.78*x1**2+0.76*x1+0.28\n",
            "GPT2 function:  0.89*x1**2+0.37*x1+0.21\n",
            " ---> GPT2 Test Error: 0.64909\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 46.47181\n",
            "Genetic Model function:  add(sqrt(sin(sin(X0))), mul(X0, X0))\n",
            " ---> GP Test Error: 4.60444\n",
            "Test case 338/1000.\n",
            "True equation: -0.09*sqrt(x1)+x1\n",
            "GPT2 function:  -0.09*sqrt(x1)+x1\n",
            " ---> GPT2 Test Error: 31.52519\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 10.29445\n",
            "Genetic Model function:  mul(sqrt(X0), add(X0, -0.093))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 339/1000.\n",
            "True equation: sin(0.79*sqrt(x1))\n",
            "GPT2 function:  sin(0.79*sqrt(x1-0.1))\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.08769\n",
            "Genetic Model function:  sin(mul(sqrt(X0), log(log(log(exp(sin(-0.111)))))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 340/1000.\n",
            "True equation: 0.54*sqrt(-x1)+sin(x1)\n",
            "GPT2 function:  0.59*sqrt(x1)+sin(x1-0.31)\n",
            " ---> GPT2 Test Error: 0.06516\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.14622\n",
            "Genetic Model function:  add(sqrt(mul(X0, add(-0.909, 0.611))), sin(X0))\n",
            " ---> GP Test Error: 0.00007\n",
            "Test case 341/1000.\n",
            "True equation: -sin(0.79*x1)\n",
            "GPT2 function:  -sin(0.82*x1-0.09)\n",
            " ---> GPT2 Test Error: 0.00052\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.52539\n",
            "Genetic Model function:  sin(mul(X0, -0.789))\n",
            " ---> GP Test Error: 0.00008\n",
            "Test case 342/1000.\n",
            "True equation: -sin(0.3*x1**2)\n",
            "GPT2 function:  -sin(0.3*x1**2-0.04*x1)\n",
            " ---> GPT2 Test Error: 0.00429\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.96730\n",
            "Genetic Model function:  sin(mul(add(X0, -0.059), mul(-0.304, X0)))\n",
            " ---> GP Test Error: 0.00599\n",
            "Test case 343/1000.\n",
            "True equation: sin(0.49*sqrt(-x1))\n",
            "GPT2 function:  sin(0.49*sqrt(x1-0.1))\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.37398\n",
            "Genetic Model function:  sin(sqrt(sin(mul(-0.252, X0))))\n",
            " ---> GP Test Error: 0.00284\n",
            "Test case 344/1000.\n",
            "True equation: 0.88*sqrt(-0.06*x1-1)\n",
            "GPT2 function:  0.88*(-0.09*x1-1)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.62927\n",
            "Genetic Model function:  0.919\n",
            " ---> GP Test Error: 0.00472\n",
            "Test case 345/1000.\n",
            "True equation: sin(sin(x1+0.52))\n",
            "GPT2 function:  sin(sin(x1+0.42))\n",
            " ---> GPT2 Test Error: 0.00335\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.16731\n",
            "Genetic Model function:  sin(sin(add(0.524, X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 346/1000.\n",
            "True equation: x1\n",
            "GPT2 function:  x1-0.1\n",
            " ---> GPT2 Test Error: 0.01000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 3.80661\n",
            "Genetic Model function:  sqrt(mul(X0, X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 347/1000.\n",
            "True equation: -0.77*x1**2+0.69*x1\n",
            "GPT2 function:  -0.76*x1**2+0.82*x1-0.06\n",
            " ---> GPT2 Test Error: 0.54778\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 100.28601\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  mul(mul(-0.794, X0), add(-0.939, X0))\n",
            " ---> GP Test Error: 0.10599\n",
            "Test case 348/1000.\n",
            "True equation: 1.64*x1+sqrt(x1+0.71)\n",
            "GPT2 function:  1.72*x1+0.73*sqrt(x1+0.91)-0.03\n",
            " ---> GPT2 Test Error: 0.06326\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.47236\n",
            "Genetic Model function:  add(add(X0, X0), 0.893)\n",
            " ---> GP Test Error: 0.07523\n",
            "Test case 349/1000.\n",
            "True equation: 0.2*sqrt(-x1**2)\n",
            "GPT2 function:  0.17*sqrt(x1**2)\n",
            " ---> GPT2 Test Error: 0.01219\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.98397\n",
            "Genetic Model function:  mul(sqrt(0.940), mul(X0, sqrt(sin(-0.041))))\n",
            " ---> GP Test Error: 0.00006\n",
            "Test case 350/1000.\n",
            "True equation: -0.15*x1**2+0.1*x1\n",
            "GPT2 function:  -0.81*x1**2-0.13*x1+0.01\n",
            " ---> GPT2 Test Error: 2085.65749\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1201.39430\n",
            "Genetic Model function:  mul(add(exp(X0), sin(log(mul(X0, 0.360)))), sin(sin(mul(-0.551, X0))))\n",
            " ---> GP Test Error: 3162.12179\n",
            "Test case 351/1000.\n",
            "True equation: 0.21*x1**2-0.52*x1+0.29\n",
            "GPT2 function:  0.13*x1**2-0.3*x1+0.33\n",
            " ---> GPT2 Test Error: 0.68815\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.73662\n",
            "Genetic Model function:  0.113\n",
            " ---> GP Test Error: 6.94989\n",
            "Test case 352/1000.\n",
            "True equation: sin(x1)*sin(x1-0.98)\n",
            "GPT2 function:  sin(x1-0.99)*sin(x1-0.09)\n",
            " ---> GPT2 Test Error: 0.00209\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 3.33034\n",
            "Genetic Model function:  mul(sin(X0), sin(mul(log(X0), sqrt(X0))))\n",
            " ---> GP Test Error: 0.04243\n",
            "Test case 353/1000.\n",
            "True equation: 0.78*x1**2\n",
            "GPT2 function:  0.79*x1**2-0.04*x1\n",
            " ---> GPT2 Test Error: 0.00316\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 41.62479\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  mul(0.779, mul(X0, X0))\n",
            " ---> GP Test Error: 0.00064\n",
            "Test case 354/1000.\n",
            "True equation: 0.82*(x1-0.13)**(1/4)\n",
            "GPT2 function:  0.82*(x1-0.21)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00006\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.04461\n",
            "Genetic Model function:  sin(sqrt(X0))\n",
            " ---> GP Test Error: 0.15144\n",
            "Test case 355/1000.\n",
            "True equation: 0.68*sqrt(x1)*sqrt(0.31*x1-1)\n",
            "GPT2 function:  -0.21*x1**2+0.58*x1+sqrt(x1-0.1)-0.09\n",
            " ---> GPT2 Test Error: 2.41225\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.19099\n",
            "Genetic Model function:  sqrt(mul(0.412, sin(X0)))\n",
            " ---> GP Test Error: 0.28331\n",
            "Test case 356/1000.\n",
            "True equation: 0.43-0.06*x1\n",
            "GPT2 function:  -sin(0.07*x1-0.45)\n",
            " ---> GPT2 Test Error: 0.00040\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.05143\n",
            "Genetic Model function:  sqrt(sin(sin(mul(0.181, exp(mul(-0.344, X0))))))\n",
            " ---> GP Test Error: 0.00278\n",
            "Test case 357/1000.\n",
            "True equation: 0.84*x1-0.37\n",
            "GPT2 function:  0.16*x1**2+0.75*x1-0.3\n",
            " ---> GPT2 Test Error: 0.32576\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 15.77118\n",
            "Genetic Model function:  mul(sin(mul(X0, 0.459)), X0)\n",
            " ---> GP Test Error: 10.62168\n",
            "Test case 358/1000.\n",
            "True equation: sin(0.86*x1+0.57)\n",
            "GPT2 function:  sin(0.83*x1+0.48)\n",
            " ---> GPT2 Test Error: 0.02029\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.63600\n",
            "Genetic Model function:  sin(add(0.592, mul(X0, 0.849)))\n",
            " ---> GP Test Error: 0.00048\n",
            "Test case 359/1000.\n",
            "True equation: 0.76*x1**2+0.49*x1+sin(x1)\n",
            "GPT2 function:  0.44*x1**2+1.36*x1-0.14\n",
            " ---> GPT2 Test Error: 8.40729\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 49.07462\n",
            "Genetic Model function:  mul(sqrt(X0), add(sqrt(add(0.143, X0)), X0))\n",
            " ---> GP Test Error: 18.83974\n",
            "Test case 360/1000.\n",
            "True equation: x1**(1/4)\n",
            "GPT2 function:  (x1-0.1)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00010\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.31255\n",
            "Genetic Model function:  sqrt(sqrt(mul(sqrt(X0), sqrt(X0))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 361/1000.\n",
            "True equation: 0.87*sqrt(-x1)+sin(x1)\n",
            "GPT2 function:  0.88*sqrt(x1)+sin(x1-0.27)\n",
            " ---> GPT2 Test Error: 0.03630\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.13270\n",
            "Genetic Model function:  add(sqrt(mul(X0, -0.777)), sin(X0))\n",
            " ---> GP Test Error: 0.00032\n",
            "Test case 362/1000.\n",
            "True equation: sin(x1**2)\n",
            "GPT2 function:  sin(x1**2-0.06*x1)\n",
            " ---> GPT2 Test Error: 0.03797\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.49802\n",
            "Genetic Model function:  sin(mul(X0, X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 363/1000.\n",
            "True equation: 1.06-0.75*x1\n",
            "GPT2 function:  1.16-0.74*x1\n",
            " ---> GPT2 Test Error: 0.02446\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00005\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  add(mul(-0.737, X0), exp(0.028))\n",
            " ---> GP Test Error: 0.00171\n",
            "Test case 364/1000.\n",
            "True equation: -sin(0.1*x1-0.72)\n",
            "GPT2 function:  sin(0.73*sqrt(1-0.21*x1))\n",
            " ---> GPT2 Test Error: 0.01046\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00559\n",
            "Genetic Model function:  0.531\n",
            " ---> GP Test Error: 0.07266\n",
            "Test case 365/1000.\n",
            "True equation: sqrt(sin(x1))\n",
            "GPT2 function:  sqrt(sin(x1-0.1))\n",
            " ---> GPT2 Test Error: 0.00409\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.34940\n",
            "Genetic Model function:  log(exp(sqrt(sin(X0))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 366/1000.\n",
            "True equation: sqrt(x1)-sin(0.83*x1)\n",
            "GPT2 function:  sqrt(x1)-sin(0.73*x1+0.24)\n",
            " ---> GPT2 Test Error: 0.01649\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.16509\n",
            "Genetic Model function:  mul(X0, 0.250)\n",
            " ---> GP Test Error: 2.30593\n",
            "Test case 367/1000.\n",
            "True equation: x1-0.08\n",
            "GPT2 function:  x1-0.18\n",
            " ---> GPT2 Test Error: 0.01000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.97549\n",
            "Genetic Model function:  add(-0.079, X0)\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 368/1000.\n",
            "True equation: 2*x1-0.87\n",
            "GPT2 function:  2.0*x1-1.07\n",
            " ---> GPT2 Test Error: 0.04000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 42.16280\n",
            "Genetic Model function:  add(log(exp(add(X0, -0.385))), add(X0, -0.485))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 369/1000.\n",
            "True equation: -0.1*x1**2+0.02*x1\n",
            "GPT2 function:  -0.1*x1**2+0.04*x1\n",
            " ---> GPT2 Test Error: 0.03335\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.88445\n",
            "Genetic Model function:  sin(sin(mul(-0.055, exp(X0))))\n",
            " ---> GP Test Error: 5.39826\n",
            "Test case 370/1000.\n",
            "True equation: -0.94*x1-sin(0.76*x1)\n",
            "GPT2 function:  -0.73*x1**2-0.83*x1-sin(0.73*x1)+0.12\n",
            " ---> GPT2 Test Error: 261.01039\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.94709\n",
            "Genetic Model function:  mul(log(div(sqrt(-0.038), sqrt(X0))), sqrt(X0))\n",
            " ---> GP Test Error: 1.24848\n",
            "Test case 371/1000.\n",
            "True equation: x1**(1/4)\n",
            "GPT2 function:  (x1-0.1)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00010\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.33716\n",
            "Genetic Model function:  sqrt(sqrt(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 372/1000.\n",
            "True equation: -sin(sin(0.11*x1+0.98))\n",
            "GPT2 function:  -sin(0.04*x1+0.83)\n",
            " ---> GPT2 Test Error: 0.00032\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.38276\n",
            "Genetic Model function:  -0.792\n",
            " ---> GP Test Error: 0.00201\n",
            "Test case 373/1000.\n",
            "True equation: -0.41*x1*sin(0.5*x1)\n",
            "GPT2 function:  -0.58*x1*sin(0.3*x1-0.05)\n",
            " ---> GPT2 Test Error: 2.41325\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.12114\n",
            "Genetic Model function:  sin(mul(X0, mul(-0.199, X0)))\n",
            " ---> GP Test Error: 2.38593\n",
            "Test case 374/1000.\n",
            "True equation: -0.99*x1-0.52*sin(0.25*x1)\n",
            "GPT2 function:  0.25*x1**2-0.13*x1\n",
            " ---> GPT2 Test Error: 1.93311\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.22521\n",
            "Genetic Model function:  mul(mul(0.136, X0), add(X0, log(X0)))\n",
            " ---> GP Test Error: 0.13367\n",
            "Test case 375/1000.\n",
            "True equation: 1.0*x1**(3/2)-0.53\n",
            "GPT2 function:  -0.36*sqrt(x1)+x1\n",
            " ---> GPT2 Test Error: 27.23839\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 16.44711\n",
            "Genetic Model function:  mul(add(-0.531, X0), sqrt(X0))\n",
            " ---> GP Test Error: 0.00222\n",
            "Test case 376/1000.\n",
            "True equation: -0.76*x1**2-1.2*x1-0.73\n",
            "GPT2 function:  -0.72*x1**2-1.03*x1-0.63\n",
            " ---> GPT2 Test Error: 3.85742\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 188.53009\n",
            "Genetic Model function:  mul(sqrt(sqrt(exp(add(0.015, X0)))), add(-0.373, add(-0.257, div(X0, -0.645))))\n",
            " ---> GP Test Error: 15.60325\n",
            "Test case 377/1000.\n",
            "True equation: -0.45*x1**2+2.14*x1+0.77\n",
            "GPT2 function:  x1+sin(x1)+0.37\n",
            " ---> GPT2 Test Error: 17.23488\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 6.80197\n",
            "Genetic Model function:  add(sqrt(div(X0, -0.328)), sin(sin(X0)))\n",
            " ---> GP Test Error: 8.71767\n",
            "Test case 378/1000.\n",
            "True equation: sin(x1**2+0.43*x1-0.12)\n",
            "GPT2 function:  sin(x1**2+0.22*x1-0.15)\n",
            " ---> GPT2 Test Error: 0.47928\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 87.88570\n",
            "Genetic Model function:  sin(mul(add(X0, 0.361), X0))\n",
            " ---> GP Test Error: 0.02483\n",
            "Test case 379/1000.\n",
            "True equation: -sin(0.12*x1**2+0.63*x1-0.55)\n",
            "GPT2 function:  -sin(0.91*x1-0.64)\n",
            " ---> GPT2 Test Error: 0.89027\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.73252\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  sin(add(sqrt(-0.358), mul(X0, -0.838)))\n",
            " ---> GP Test Error: 0.99506\n",
            "Test case 380/1000.\n",
            "True equation: -sin(sin(0.61*x1+0.59))\n",
            "GPT2 function:  -sin(sin(0.58*x1+0.54))\n",
            " ---> GPT2 Test Error: 0.02182\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.75363\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  -0.788\n",
            " ---> GP Test Error: 1.11747\n",
            "Test case 381/1000.\n",
            "True equation: sin(0.2*x1)+sin(x1)\n",
            "GPT2 function:  0.31*x1+sin(x1-0.1)-0.1\n",
            " ---> GPT2 Test Error: 0.30357\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.19816\n",
            "Genetic Model function:  add(mul(0.201, X0), sin(X0))\n",
            " ---> GP Test Error: 0.02281\n",
            "Test case 382/1000.\n",
            "True equation: 0.5*sqrt(x1)\n",
            "GPT2 function:  0.5*sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00010\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00682\n",
            "Genetic Model function:  div(mul(sqrt(0.227), sqrt(X0)), sqrt(log(0.400)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 383/1000.\n",
            "True equation: -sin(sin(0.57*x1))\n",
            "GPT2 function:  -sin(sin(0.57*x1-0.05))\n",
            " ---> GPT2 Test Error: 0.00081\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.33030\n",
            "Genetic Model function:  sin(sin(mul(X0, -0.555)))\n",
            " ---> GP Test Error: 0.00227\n",
            "Test case 384/1000.\n",
            "True equation: sin(x1+0.08)\n",
            "GPT2 function:  sin(x1-0.02)\n",
            " ---> GPT2 Test Error: 0.00489\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.68431\n",
            "Genetic Model function:  sin(add(0.088, X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 385/1000.\n",
            "True equation: sqrt(sin(0.83*x1))\n",
            "GPT2 function:  sqrt(-sin(0.85*x1-0.1))\n",
            " ---> GPT2 Test Error: 0.00011\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.14547\n",
            "Genetic Model function:  sqrt(sin(mul(X0, -0.832)))\n",
            " ---> GP Test Error: 0.00050\n",
            "Test case 386/1000.\n",
            "True equation: x1\n",
            "GPT2 function:  x1-0.1\n",
            " ---> GPT2 Test Error: 0.01000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00005\n",
            "Genetic Model function:  sqrt(mul(X0, X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 387/1000.\n",
            "True equation: 0.9*sqrt(x1)\n",
            "GPT2 function:  0.91*sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00012\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.83305\n",
            "Genetic Model function:  sqrt(mul(X0, -0.815))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 388/1000.\n",
            "True equation: x1+0.05\n",
            "GPT2 function:  x1-0.05\n",
            " ---> GPT2 Test Error: 0.01000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.18953\n",
            "Genetic Model function:  exp(log(add(X0, 0.057)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 389/1000.\n",
            "True equation: sqrt(x1)+sin(x1)\n",
            "GPT2 function:  sqrt(x1)+sin(x1-0.31)\n",
            " ---> GPT2 Test Error: 0.04603\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.75193\n",
            "Genetic Model function:  add(sqrt(X0), sin(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 390/1000.\n",
            "True equation: x1**2+0.92*sqrt(x1-0.56)\n",
            "GPT2 function:  x1**2+0.28*x1+sqrt(x1-0.93)-0.19\n",
            " ---> GPT2 Test Error: 1.37327\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 124.30336\n",
            "Genetic Model function:  add(mul(X0, X0), sqrt(add(-0.660, X0)))\n",
            " ---> GP Test Error: 0.01656\n",
            "Test case 391/1000.\n",
            "True equation: sin(1.27*x1)\n",
            "GPT2 function:  sin(1.26*x1-0.09)\n",
            " ---> GPT2 Test Error: 0.01230\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.61349\n",
            "Genetic Model function:  sin(div(add(exp(-0.477), add(X0, -0.600)), 0.794))\n",
            " ---> GP Test Error: 0.00113\n",
            "Test case 392/1000.\n",
            "True equation: -sin(sin(0.5*x1))\n",
            "GPT2 function:  -sin(sin(0.53*x1-0.06))\n",
            " ---> GPT2 Test Error: 0.00265\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.26864\n",
            "Genetic Model function:  sin(sin(mul(X0, sin(-0.519))))\n",
            " ---> GP Test Error: 0.00048\n",
            "Test case 393/1000.\n",
            "True equation: 1.42*x1*sin(0.85*x1)\n",
            "GPT2 function:  1.44*x1*sin(0.88*x1-0.06)\n",
            " ---> GPT2 Test Error: 0.05286\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 90.08134\n",
            "Genetic Model function:  sqrt(mul(mul(sin(X0), mul(X0, X0)), X0))\n",
            " ---> GP Test Error: 179.25511\n",
            "Test case 394/1000.\n",
            "True equation: sqrt(x1)+1.09*x1-0.25\n",
            "GPT2 function:  sqrt(x1)+1.13*x1-0.67\n",
            " ---> GPT2 Test Error: 0.06971\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.13781\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  add(add(-0.117, X0), sqrt(X0))\n",
            " ---> GP Test Error: 0.09749\n",
            "Test case 395/1000.\n",
            "True equation: sqrt(x1)\n",
            "GPT2 function:  sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00057\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00112\n",
            "Genetic Model function:  mul(sqrt(X0), div(X0, X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 396/1000.\n",
            "True equation: sqrt(x1-0.73)\n",
            "GPT2 function:  sqrt(x1-0.83)\n",
            " ---> GPT2 Test Error: 0.00075\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.07560\n",
            "Genetic Model function:  sqrt(add(-0.710, X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 397/1000.\n",
            "True equation: -0.23*x1**2+0.25*x1+1.15\n",
            "GPT2 function:  -0.22*x1+sin(0.43*x1+0.33)+0.58\n",
            " ---> GPT2 Test Error: 9.97478\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.14595\n",
            "Genetic Model function:  div(sin(X0), mul(0.704, X0))\n",
            " ---> GP Test Error: 8.55594\n",
            "Test case 398/1000.\n",
            "True equation: -0.93*x1**2+0.07*x1+0.51\n",
            "GPT2 function:  1.16-0.86*x1**2\n",
            " ---> GPT2 Test Error: 3.31989\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 37.23700\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  div(add(mul(X0, X0), log(log(0.586))), log(-0.335))\n",
            " ---> GP Test Error: 0.00197\n",
            "Test case 399/1000.\n",
            "True equation: 1.78*x1\n",
            "GPT2 function:  0.47*x1**2-0.04*x1\n",
            " ---> GPT2 Test Error: 1.30281\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 21.08596\n",
            "Genetic Model function:  mul(mul(X0, X0), sqrt(0.277))\n",
            " ---> GP Test Error: 0.11322\n",
            "Test case 400/1000.\n",
            "True equation: -0.48*x1-0.76\n",
            "GPT2 function:  -0.48*x1-0.72\n",
            " ---> GPT2 Test Error: 0.00097\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00005\n",
            "Genetic Model function:  add(log(0.475), mul(-0.490, X0))\n",
            " ---> GP Test Error: 0.00146\n",
            "Test case 401/1000.\n",
            "True equation: sin(x1-0.85)\n",
            "GPT2 function:  sin(x1-0.95)\n",
            " ---> GPT2 Test Error: 0.00516\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.72006\n",
            "Genetic Model function:  sin(add(-0.853, X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 402/1000.\n",
            "True equation: sin(0.05*x1)\n",
            "GPT2 function:  sin(0.05*x1)\n",
            " ---> GPT2 Test Error: 0.00019\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.02260\n",
            "Genetic Model function:  sin(mul(0.055, X0))\n",
            " ---> GP Test Error: 0.00006\n",
            "Test case 403/1000.\n",
            "True equation: 0.4*x1-0.77\n",
            "GPT2 function:  0.37*x1-0.81\n",
            " ---> GPT2 Test Error: 0.02533\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00051\n",
            "Genetic Model function:  sin(sin(add(sqrt(X0), exp(exp(0.465)))))\n",
            " ---> GP Test Error: 0.22668\n",
            "Test case 404/1000.\n",
            "True equation: 1.62*x1*sin(x1+0.23)+0.66\n",
            "GPT2 function:  1.6*x1+0.3*sin(x1+0.2)\n",
            " ---> GPT2 Test Error: 160.11000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 19.84311\n",
            "Genetic Model function:  mul(sin(X0), exp(sqrt(sqrt(X0))))\n",
            " ---> GP Test Error: 7.25471\n",
            "Test case 405/1000.\n",
            "True equation: sin(0.21*x1)\n",
            "GPT2 function:  0.2*sqrt(x1**2-0.33*x1+0.01)\n",
            " ---> GPT2 Test Error: 0.00964\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00207\n",
            "Genetic Model function:  sin(sin(mul(mul(X0, -0.618), sin(-0.364))))\n",
            " ---> GP Test Error: 0.00703\n",
            "Test case 406/1000.\n",
            "True equation: 1.06*x1-0.4\n",
            "GPT2 function:  x1**2-0.53*x1+0.03\n",
            " ---> GPT2 Test Error: 0.68729\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 71.15231\n",
            "Genetic Model function:  mul(X0, add(X0, -0.345))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 407/1000.\n",
            "True equation: 0.86*x1\n",
            "GPT2 function:  0.86*x1-0.08\n",
            " ---> GPT2 Test Error: 0.00641\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00101\n",
            "Genetic Model function:  mul(mul(add(X0, X0), exp(-0.946)), sqrt(add(-0.365, -0.863)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 408/1000.\n",
            "True equation: -0.72*x1+sin(x1+0.4)\n",
            "GPT2 function:  -0.78*x1+sin(x1+0.34)\n",
            " ---> GPT2 Test Error: 0.08494\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.45560\n",
            "Genetic Model function:  mul(mul(X0, -0.912), log(mul(X0, 0.799)))\n",
            " ---> GP Test Error: 4.16324\n",
            "Test case 409/1000.\n",
            "True equation: 0.87*x1**2+0.43\n",
            "GPT2 function:  0.89*x1**2+0.05\n",
            " ---> GPT2 Test Error: 2.05734\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 59.38978\n",
            "Genetic Model function:  add(mul(X0, X0), 0.259)\n",
            " ---> GP Test Error: 1.77908\n",
            "Test case 410/1000.\n",
            "True equation: 0.87*sqrt(-x1)\n",
            "GPT2 function:  0.88*sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00007\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.03083\n",
            "Genetic Model function:  sqrt(mul(0.763, X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 411/1000.\n",
            "True equation: 0.06*x1**3-0.38*x1\n",
            "GPT2 function:  -sqrt(x1-0.12)*sin(0.45*x1-0.04)\n",
            " ---> GPT2 Test Error: 0.32359\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.42795\n",
            "Genetic Model function:  mul(mul(X0, -0.335), sqrt(X0))\n",
            " ---> GP Test Error: 6.10207\n",
            "Test case 412/1000.\n",
            "True equation: x1**2+0.24*x1\n",
            "GPT2 function:  x1**2+0.03*x1\n",
            " ---> GPT2 Test Error: 0.93809\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 64.84294\n",
            "Genetic Model function:  add(mul(X0, 0.233), mul(X0, X0))\n",
            " ---> GP Test Error: 0.00076\n",
            "Test case 413/1000.\n",
            "True equation: 0.97*x1**2+0.74*x1-sin(0.01*x1)+0.02\n",
            "GPT2 function:  x1**2+0.58*x1-0.04\n",
            " ---> GPT2 Test Error: 0.01960\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 108.54125\n",
            "Genetic Model function:  mul(add(0.680, X0), X0)\n",
            " ---> GP Test Error: 0.19587\n",
            "Test case 414/1000.\n",
            "True equation: 0.86*sqrt(x1)\n",
            "GPT2 function:  0.92*sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00955\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.20210\n",
            "Genetic Model function:  div(log(exp(sqrt(mul(0.907, X0)))), exp(0.094))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 415/1000.\n",
            "<class 'TypeError'> \n",
            "\n",
            " Error: sin(3.1-0.1)3.194), EQ:sin(x1-0.1)x194)\n",
            "Not calculated\n",
            "Test case 416/1000.\n",
            "True equation: sqrt(sin(x1-0.12))\n",
            "GPT2 function:  sqrt(sin(x1-0.22))\n",
            " ---> GPT2 Test Error: 0.00411\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.11604\n",
            "Genetic Model function:  sqrt(sin(add(-0.121, X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 417/1000.\n",
            "True equation: -sin(0.49*x1+1.04)\n",
            "GPT2 function:  -sin(0.52*x1+0.98)\n",
            " ---> GPT2 Test Error: 0.00260\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.99706\n",
            "Genetic Model function:  -0.938\n",
            " ---> GP Test Error: 1.31018\n",
            "Test case 418/1000.\n",
            "True equation: 0.95*x1\n",
            "GPT2 function:  0.95*x1-0.08\n",
            " ---> GPT2 Test Error: 0.00972\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.76703\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  log(exp(mul(X0, 0.953)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 419/1000.\n",
            "True equation: 0.76*(0.53-x1)**(1/4)\n",
            "GPT2 function:  0.4*sqrt(x1-0.8)\n",
            " ---> GPT2 Test Error: 0.09487\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.02185\n",
            "Genetic Model function:  sin(sqrt(log(add(X0, 0.579))))\n",
            " ---> GP Test Error: 0.01651\n",
            "Test case 420/1000.\n",
            "True equation: 1.66*x1-sin(0.71*x1)+0.1\n",
            "GPT2 function:  0.15*x1**2+0.95*x1\n",
            " ---> GPT2 Test Error: 0.04629\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 6.59524\n",
            "Genetic Model function:  sqrt(mul(sqrt(X0), mul(X0, add(0.182, X0))))\n",
            " ---> GP Test Error: 0.98328\n",
            "Test case 421/1000.\n",
            "True equation: sin(0.22*x1-0.42)\n",
            "GPT2 function:  sin(sin(0.21*x1-0.44))\n",
            " ---> GPT2 Test Error: 0.00732\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00161\n",
            "Genetic Model function:  div(-0.492, exp(X0))\n",
            " ---> GP Test Error: 0.32679\n",
            "Test case 422/1000.\n",
            "True equation: sin(sqrt(x1+0.94))\n",
            "GPT2 function:  sin(sqrt(x1+0.83))\n",
            " ---> GPT2 Test Error: 0.00025\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.18756\n",
            "Genetic Model function:  sin(sqrt(add(add(0.049, X0), sqrt(sqrt(0.665)))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 423/1000.\n",
            "True equation: sqrt(x1**2-0.36*x1)\n",
            "GPT2 function:  sqrt(x1**2-0.37*x1+0.03)\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.65683\n",
            "Genetic Model function:  sqrt(mul(add(-0.346, X0), X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 424/1000.\n",
            "True equation: sin(0.69*sqrt(x1-0.37))\n",
            "GPT2 function:  sin(0.69*sqrt(0.48-x1))\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.05079\n",
            "Genetic Model function:  sqrt(mul(X0, 0.285))\n",
            " ---> GP Test Error: 0.03149\n",
            "Test case 425/1000.\n",
            "True equation: sin(sin(x1+0.09))\n",
            "GPT2 function:  sin(sin(x1))\n",
            " ---> GPT2 Test Error: 0.00323\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.84438\n",
            "Genetic Model function:  sin(sin(add(add(X0, -0.292), sin(0.392))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 426/1000.\n",
            "True equation: sin(sin(x1))\n",
            "GPT2 function:  sin(sin(x1-0.1))\n",
            " ---> GPT2 Test Error: 0.00366\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.25414\n",
            "Genetic Model function:  sin(sin(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 427/1000.\n",
            "True equation: 0.83*sqrt(x1)\n",
            "GPT2 function:  0.84*sqrt(0.1-x1)\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00824\n",
            "Genetic Model function:  sqrt(mul(div(X0, 0.775), sqrt(0.287)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 428/1000.\n",
            "True equation: 0.63*x1-0.48\n",
            "GPT2 function:  0.64*x1-0.58\n",
            " ---> GPT2 Test Error: 0.00239\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 4.09506\n",
            "Genetic Model function:  div(add(X0, -0.785), exp(sin(0.472)))\n",
            " ---> GP Test Error: 0.00009\n",
            "Test case 429/1000.\n",
            "True equation: -0.4*x1-0.83*sin(0.32*x1)\n",
            "GPT2 function:  -0.08*x1**2-0.36*x1+0.03\n",
            " ---> GPT2 Test Error: 0.92068\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.24805\n",
            "Genetic Model function:  mul(-0.511, X0)\n",
            " ---> GP Test Error: 0.06099\n",
            "Test case 430/1000.\n",
            "True equation: 0.37*x1+sin(x1+0.35)-0.56\n",
            "GPT2 function:  0.1*x1+sin(x1)-0.32\n",
            " ---> GPT2 Test Error: 1.23420\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.58625\n",
            "Genetic Model function:  sin(add(-0.125, X0))\n",
            " ---> GP Test Error: 1.67248\n",
            "Test case 431/1000.\n",
            "True equation: -0.58*x1**(5/2)+0.34*x1\n",
            "GPT2 function:  x1**2-0.25*x1+0.01\n",
            " ---> GPT2 Test Error: 2352.75832\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 423.68630\n",
            "Genetic Model function:  mul(mul(X0, X0), sin(mul(-0.326, mul(0.968, X0))))\n",
            " ---> GP Test Error: 25.22569\n",
            "Test case 432/1000.\n",
            "True equation: x1\n",
            "GPT2 function:  x1-0.1\n",
            " ---> GPT2 Test Error: 0.01000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.56372\n",
            "Genetic Model function:  sqrt(mul(X0, X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 433/1000.\n",
            "True equation: sin(0.42*x1**2+0.11*x1)\n",
            "GPT2 function:  sin(0.43*x1**2)\n",
            " ---> GPT2 Test Error: 0.05691\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.65263\n",
            "Genetic Model function:  sin(mul(mul(0.473, X0), X0))\n",
            " ---> GP Test Error: 0.22143\n",
            "Test case 434/1000.\n",
            "<class 'TypeError'> \n",
            "\n",
            " Error: sin(3.1-0.1)3.1), EQ:sin(x1-0.1)x1)\n",
            "Not calculated\n",
            "Test case 435/1000.\n",
            "True equation: 2*x1-1.34\n",
            "GPT2 function:  2*x1-1.54\n",
            " ---> GPT2 Test Error: 0.04000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 12.86516\n",
            "Genetic Model function:  add(add(X0, -0.989), add(-0.350, X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 436/1000.\n",
            "True equation: x1*sin(x1)-0.36\n",
            "GPT2 function:  x1-0.17*sin(x1-0.27)\n",
            " ---> GPT2 Test Error: 60.60994\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 27.29159\n",
            "Genetic Model function:  mul(add(X0, -0.372), sin(X0))\n",
            " ---> GP Test Error: 0.00008\n",
            "Test case 437/1000.\n",
            "True equation: sin(0.63*x1**2+0.48*x1+0.09)\n",
            "GPT2 function:  sin(0.59*x1**2+0.4*x1+0.05)\n",
            " ---> GPT2 Test Error: 0.63551\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 12.04441\n",
            "Genetic Model function:  sin(mul(add(mul(X0, X0), X0), exp(-0.520)))\n",
            " ---> GP Test Error: 0.04788\n",
            "Test case 438/1000.\n",
            "True equation: sqrt(x1-0.7)-sin(0.45*x1)\n",
            "GPT2 function:  sqrt(x1-0.88)-sin(0.34*x1)\n",
            " ---> GPT2 Test Error: 0.06514\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00899\n",
            "Genetic Model function:  sin(sin(sqrt(mul(-0.210, log(X0)))))\n",
            " ---> GP Test Error: 0.52922\n",
            "Test case 439/1000.\n",
            "True equation: 0.96*x1**2-1.2*x1+sin(0.3*x1+0.38)+0.28\n",
            "GPT2 function:  0.8*x1**2-0.39*x1+0.71*sqrt(0.66*x1-1)\n",
            " ---> GPT2 Test Error: 0.14160\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 88.60140\n",
            "Genetic Model function:  mul(0.326, exp(X0))\n",
            " ---> GP Test Error: 1610.88200\n",
            "Test case 440/1000.\n",
            "True equation: x1**2+0.3*x1\n",
            "GPT2 function:  x1**2+0.09*x1-0.02\n",
            " ---> GPT2 Test Error: 0.96194\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 134.39209\n",
            "Genetic Model function:  mul(add(X0, 0.302), X0)\n",
            " ---> GP Test Error: 0.00042\n",
            "Test case 441/1000.\n",
            "True equation: -0.04*x1+sin(x1)+0.17\n",
            "GPT2 function:  0.06*x1+sin(x1+0.08)\n",
            " ---> GPT2 Test Error: 0.10939\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.10769\n",
            "Genetic Model function:  add(sin(add(0.042, X0)), 0.092)\n",
            " ---> GP Test Error: 0.01854\n",
            "Test case 442/1000.\n",
            "True equation: sin(sin(0.58*x1+0.49))\n",
            "GPT2 function:  sin(sin(0.56*x1+0.4))\n",
            " ---> GPT2 Test Error: 0.02224\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.48346\n",
            "Genetic Model function:  sin(log(exp(sin(sqrt(X0)))))\n",
            " ---> GP Test Error: 0.66150\n",
            "Test case 443/1000.\n",
            "True equation: 0.44*x1+0.74\n",
            "GPT2 function:  0.42*x1+0.71\n",
            " ---> GPT2 Test Error: 0.02060\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.34829\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  sqrt(add(0.485, X0))\n",
            " ---> GP Test Error: 0.31445\n",
            "Test case 444/1000.\n",
            "True equation: (x1+0.39)**(1/4)\n",
            "GPT2 function:  (x1+0.29)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00007\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.03884\n",
            "Genetic Model function:  sqrt(sqrt(add(0.404, X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 445/1000.\n",
            "True equation: 0.66*sqrt(-0.43*x1**2-x1+0.8)\n",
            "GPT2 function:  0.58*sqrt(0.74*x1**2+0.07*x1-1)\n",
            " ---> GPT2 Test Error: 0.02131\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.08525\n",
            "Genetic Model function:  sqrt(add(-0.648, X0))\n",
            " ---> GP Test Error: 0.18307\n",
            "Test case 446/1000.\n",
            "True equation: 0.96*x1*sqrt(-0.89*x1-1)\n",
            "GPT2 function:  0.5*x1**2+sin(x1-0.1)\n",
            " ---> GPT2 Test Error: 1.63231\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 5.87375\n",
            "Genetic Model function:  mul(add(X0, 0.292), sqrt(X0))\n",
            " ---> GP Test Error: 0.36017\n",
            "Test case 447/1000.\n",
            "True equation: x1**2-1.26*x1\n",
            "GPT2 function:  0.26*x1**2+0.59\n",
            " ---> GPT2 Test Error: 45824.16223\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 26191.19692\n",
            "Genetic Model function:  mul(div(X0, 0.887), mul(add(X0, -0.697), add(X0, X0)))\n",
            " ---> GP Test Error: 122.45770\n",
            "Test case 448/1000.\n",
            "True equation: 2*x1\n",
            "GPT2 function:  2*x1-0.2\n",
            " ---> GPT2 Test Error: 0.04000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.52047\n",
            "Genetic Model function:  log(exp(add(X0, X0)))\n",
            " ---> GP Test Error: 1.33891\n",
            "Test case 449/1000.\n",
            "True equation: sin(sin(x1))\n",
            "GPT2 function:  sin(sin(x1-0.1))\n",
            " ---> GPT2 Test Error: 0.00366\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.16917\n",
            "Genetic Model function:  sin(sin(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 450/1000.\n",
            "True equation: sqrt(x1-0.03)\n",
            "GPT2 function:  sqrt(x1-0.13)\n",
            " ---> GPT2 Test Error: 0.00059\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.32781\n",
            "Genetic Model function:  sqrt(add(add(X0, -0.837), exp(-0.221)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 451/1000.\n",
            "True equation: x1-sin(0.29*x1)-0.91\n",
            "GPT2 function:  0.76*x1-0.96\n",
            " ---> GPT2 Test Error: 0.06387\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.18947\n",
            "Genetic Model function:  add(-0.999, mul(X0, 0.787))\n",
            " ---> GP Test Error: 0.02935\n",
            "Test case 452/1000.\n",
            "True equation: -sin(sin(0.83*x1+0.6))\n",
            "GPT2 function:  -sin(sin(0.83*x1+0.53))\n",
            " ---> GPT2 Test Error: 0.00245\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.01440\n",
            "Genetic Model function:  -0.728\n",
            " ---> GP Test Error: 1.91912\n",
            "Test case 453/1000.\n",
            "True equation: sin(2*x1)\n",
            "GPT2 function:  sin(2*x1-0.2)\n",
            " ---> GPT2 Test Error: 0.01955\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 7.36424\n",
            "Genetic Model function:  sin(add(X0, X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 454/1000.\n",
            "True equation: 1.92*x1+0.89*sqrt(x1+0.48)\n",
            "GPT2 function:  2*x1+0.44*sqrt(-x1-0.87)\n",
            " ---> GPT2 Test Error: 151.88515\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 39.75523\n",
            "Genetic Model function:  add(add(add(mul(X0, X0), X0), sin(div(X0, 0.952))), 0.567)\n",
            " ---> GP Test Error: 27.53595\n",
            "Test case 455/1000.\n",
            "True equation: 0.88*sqrt(0.73-x1)\n",
            "GPT2 function:  0.88*sqrt(0.84-x1)\n",
            " ---> GPT2 Test Error: 0.00051\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.98562\n",
            "Genetic Model function:  mul(sqrt(add(X0, -0.724)), exp(log(-0.875)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 456/1000.\n",
            "True equation: 0.74*sqrt(1-0.45*x1)\n",
            "GPT2 function:  sqrt(-sin(0.28*x1-0.57))\n",
            " ---> GPT2 Test Error: 0.00117\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.27421\n",
            "Genetic Model function:  sin(sin(exp(mul(X0, -0.601))))\n",
            " ---> GP Test Error: 0.51060\n",
            "Test case 457/1000.\n",
            "True equation: x1+0.96\n",
            "GPT2 function:  x1+0.86\n",
            " ---> GPT2 Test Error: 0.01000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.57682\n",
            "Genetic Model function:  add(0.956, X0)\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 458/1000.\n",
            "True equation: -sin(0.92*x1+0.53)\n",
            "GPT2 function:  -sin(0.91*x1+0.47)\n",
            " ---> GPT2 Test Error: 0.00455\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.02244\n",
            "Genetic Model function:  sin(add(mul(X0, -0.953), -0.457))\n",
            " ---> GP Test Error: 0.00352\n",
            "Test case 459/1000.\n",
            "True equation: 1.0*sqrt(-0.15*x1-1)\n",
            "GPT2 function:  0.99*(0.37*x1+1)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00136\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.04619\n",
            "Genetic Model function:  sqrt(exp(mul(X0, 0.119)))\n",
            " ---> GP Test Error: 0.00045\n",
            "Test case 460/1000.\n",
            "True equation: sqrt(sin(x1))\n",
            "GPT2 function:  sqrt(sin(x1-0.1))\n",
            " ---> GPT2 Test Error: 0.00409\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.07417\n",
            "Genetic Model function:  sqrt(sin(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 461/1000.\n",
            "True equation: sin(sin(0.29*x1))\n",
            "GPT2 function:  sin(sin(0.25*x1-0.03))\n",
            " ---> GPT2 Test Error: 0.00220\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.01869\n",
            "Genetic Model function:  mul(X0, 0.253)\n",
            " ---> GP Test Error: 0.15538\n",
            "Test case 462/1000.\n",
            "True equation: -sin(sin(0.35*x1-0.84))\n",
            "GPT2 function:  -sin(sin(0.37*x1-0.81))\n",
            " ---> GPT2 Test Error: 0.00475\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00915\n",
            "Genetic Model function:  sqrt(exp(mul(exp(X0), -0.599)))\n",
            " ---> GP Test Error: 0.37543\n",
            "Test case 463/1000.\n",
            "True equation: 0.95*x1+sin(x1)-0.22\n",
            "GPT2 function:  0.88*x1+sin(x1-0.42)\n",
            " ---> GPT2 Test Error: 0.10923\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.54380\n",
            "Genetic Model function:  add(add(-0.197, mul(X0, 0.938)), sin(X0))\n",
            " ---> GP Test Error: 0.00106\n",
            "Test case 464/1000.\n",
            "True equation: x1-0.41*sin(0.11*x1+0.63)\n",
            "GPT2 function:  x1-sin(0.38*x1+0.31)\n",
            " ---> GPT2 Test Error: 0.01304\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.13299\n",
            "Genetic Model function:  mul(mul(X0, 0.424), sqrt(X0))\n",
            " ---> GP Test Error: 0.19287\n",
            "Test case 465/1000.\n",
            "True equation: 0.56*x1*sin(x1+0.17)+0.68\n",
            "GPT2 function:  x1+0.3*sin(0.91*x1+0.07)\n",
            " ---> GPT2 Test Error: 43.93224\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 4.15869\n",
            "Genetic Model function:  mul(sin(X0), exp(0.403))\n",
            " ---> GP Test Error: 1.59662\n",
            "Test case 466/1000.\n",
            "True equation: -sqrt(x1-0.06)*sin(0.35*x1)\n",
            "GPT2 function:  -0.47*x1*sin(0.4*x1-0.05)+0.02\n",
            " ---> GPT2 Test Error: 0.01063\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.03379\n",
            "Genetic Model function:  mul(mul(-0.504, X0), sqrt(sin(mul(mul(-0.504, X0), sqrt(0.815)))))\n",
            " ---> GP Test Error: 0.00411\n",
            "Test case 467/1000.\n",
            "True equation: -0.05*x1+0.99*sqrt(0.19*x1-1)-0.71\n",
            "GPT2 function:  -sin(0.17*x1-0.31)\n",
            " ---> GPT2 Test Error: 0.02646\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.03010\n",
            "Genetic Model function:  add(mul(-0.207, X0), 0.348)\n",
            " ---> GP Test Error: 0.00652\n",
            "Test case 468/1000.\n",
            "True equation: -0.47*x1**2+0.48*x1\n",
            "GPT2 function:  -0.49*x1**2+0.48*x1-0.04\n",
            " ---> GPT2 Test Error: 0.28090\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 18.45085\n",
            "Genetic Model function:  mul(add(-0.924, X0), mul(-0.436, X0))\n",
            " ---> GP Test Error: 0.15453\n",
            "Test case 469/1000.\n",
            "True equation: x1**2-0.29*x1+sin(x1+0.52)+0.01\n",
            "GPT2 function:  0.7*x1**2+0.42*x1+0.45\n",
            " ---> GPT2 Test Error: 8.69951\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 105.58563\n",
            "Genetic Model function:  sqrt(mul(exp(X0), add(0.114, X0)))\n",
            " ---> GP Test Error: 37.22473\n",
            "Test case 470/1000.\n",
            "True equation: 0.21*x1*sqrt(x1-0.95)+0.87\n",
            "GPT2 function:  0.89*sqrt(0.95*x1**2+0.92*x1-1)\n",
            " ---> GPT2 Test Error: 0.54925\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.10782\n",
            "Genetic Model function:  sqrt(mul(div(X0, 0.774), log(X0)))\n",
            " ---> GP Test Error: 0.38605\n",
            "Test case 471/1000.\n",
            "True equation: -0.75*x1-0.18\n",
            "GPT2 function:  -0.82*x1**2-0.1*x1+0.04\n",
            " ---> GPT2 Test Error: 0.32101\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 79.45129\n",
            "Genetic Model function:  mul(-0.906, mul(X0, X0))\n",
            " ---> GP Test Error: 1.03174\n",
            "Test case 472/1000.\n",
            "True equation: sqrt(x1)\n",
            "GPT2 function:  sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00057\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.03340\n",
            "Genetic Model function:  sqrt(log(exp(X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 473/1000.\n",
            "True equation: -sin(0.11*x1)\n",
            "GPT2 function:  -sin(0.11*x1-0.02)\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00019\n",
            "Genetic Model function:  log(sqrt(log(exp(exp(mul(X0, -0.219))))))\n",
            " ---> GP Test Error: 0.00155\n",
            "Test case 474/1000.\n",
            "True equation: sqrt(sin(0.44*x1))\n",
            "GPT2 function:  sqrt(-sin(0.44*x1-0.07))\n",
            " ---> GPT2 Test Error: 0.00045\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.45804\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  sqrt(sin(mul(-0.438, X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 475/1000.\n",
            "True equation: sin(0.06*x1)\n",
            "GPT2 function:  0.06*x1*sqrt(-x1-0.92)\n",
            " ---> GPT2 Test Error: 0.14739\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00990\n",
            "Genetic Model function:  sin(div(log(sqrt(exp(div(X0, X0)))), div(exp(exp(0.223)), add(mul(0.459, X0), mul(-0.028, 0.578)))))\n",
            " ---> GP Test Error: 0.00013\n",
            "Test case 476/1000.\n",
            "True equation: x1**2*sqrt(x1+0.73)\n",
            "GPT2 function:  x1**(5/2)-0.03*x1\n",
            " ---> GPT2 Test Error: 13.81396\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1698.02377\n",
            "Genetic Model function:  mul(add(mul(mul(-0.557, -0.087), log(log(0.324))), sqrt(add(0.695, X0))), mul(X0, X0))\n",
            " ---> GP Test Error: 0.00030\n",
            "Test case 477/1000.\n",
            "True equation: sin(0.4*x1-0.1)\n",
            "GPT2 function:  sin(0.38*x1-0.14)\n",
            " ---> GPT2 Test Error: 0.00172\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.23705\n",
            "Genetic Model function:  mul(0.315, X0)\n",
            " ---> GP Test Error: 0.35350\n",
            "Test case 478/1000.\n",
            "True equation: 0.98*sqrt(x1-0.18)\n",
            "GPT2 function:  0.98*sqrt(0.28-x1)\n",
            " ---> GPT2 Test Error: 0.00044\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00114\n",
            "Genetic Model function:  sqrt(add(-0.239, X0))\n",
            " ---> GP Test Error: 0.00099\n",
            "Test case 479/1000.\n",
            "True equation: 0.69*sqrt(-0.5*x1-1)\n",
            "GPT2 function:  0.68*sqrt(0.57*x1+1)\n",
            " ---> GPT2 Test Error: 0.00147\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.16639\n",
            "Genetic Model function:  sin(sqrt(sqrt(add(0.254, X0))))\n",
            " ---> GP Test Error: 0.07081\n",
            "Test case 480/1000.\n",
            "True equation: 0.97*(-0.18*x1-1)**(1/4)\n",
            "GPT2 function:  0.96*sqrt(0.09*x1+1)\n",
            " ---> GPT2 Test Error: 0.00025\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.02019\n",
            "Genetic Model function:  div(X0, X0)\n",
            " ---> GP Test Error: 0.01640\n",
            "Test case 481/1000.\n",
            "True equation: 0.95*sqrt(-x1-1)\n",
            "GPT2 function:  0.95*sqrt(x1+0.9)\n",
            " ---> GPT2 Test Error: 0.00095\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.26684\n",
            "Genetic Model function:  sqrt(log(add(add(exp(X0), exp(X0)), sqrt(exp(-0.854)))))\n",
            " ---> GP Test Error: 0.00192\n",
            "Test case 482/1000.\n",
            "True equation: 0.87*x1\n",
            "GPT2 function:  0.88*sqrt(x1)*sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00030\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.70047\n",
            "Genetic Model function:  sqrt(mul(mul(-0.773, X0), X0))\n",
            " ---> GP Test Error: 0.00068\n",
            "Test case 483/1000.\n",
            "True equation: 0.87*sqrt(x1-0.93)\n",
            "GPT2 function:  0.89*sqrt(0.96*x1-1)\n",
            " ---> GPT2 Test Error: 0.00095\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.07194\n",
            "Genetic Model function:  sin(sqrt(add(X0, -0.924)))\n",
            " ---> GP Test Error: 0.60131\n",
            "Test case 484/1000.\n",
            "True equation: x1-0.54\n",
            "GPT2 function:  x1-0.64\n",
            " ---> GPT2 Test Error: 0.01000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.20031\n",
            "Genetic Model function:  add(-0.534, X0)\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 485/1000.\n",
            "True equation: sin(sin(0.71*x1))\n",
            "GPT2 function:  sin(sin(0.71*x1-0.06))\n",
            " ---> GPT2 Test Error: 0.00192\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.46352\n",
            "Genetic Model function:  sin(sin(mul(0.703, X0)))\n",
            " ---> GP Test Error: 0.00044\n",
            "Test case 486/1000.\n",
            "True equation: 0.9*sqrt(-0.79*x1-1)\n",
            "GPT2 function:  0.87*sqrt(0.84*x1+1)\n",
            " ---> GPT2 Test Error: 0.00054\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00101\n",
            "Genetic Model function:  exp(mul(0.177, X0))\n",
            " ---> GP Test Error: 0.15219\n",
            "Test case 487/1000.\n",
            "True equation: 0.36*x1**2*sin(x1)\n",
            "GPT2 function:  0.25*x1**2*sin(x1)\n",
            " ---> GPT2 Test Error: 3.50471\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 16.54418\n",
            "Genetic Model function:  mul(X0, mul(sin(X0), mul(0.367, X0)))\n",
            " ---> GP Test Error: 0.00807\n",
            "Test case 488/1000.\n",
            "True equation: -0.06*x1**2-0.16*x1+0.91\n",
            "GPT2 function:  -0.92*x1+sqrt(x1+0.87)\n",
            " ---> GPT2 Test Error: 0.75879\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.32122\n",
            "Genetic Model function:  sqrt(exp(mul(-0.269, exp(X0))))\n",
            " ---> GP Test Error: 1.32301\n",
            "Test case 489/1000.\n",
            "True equation: 2*x1+sqrt(x1+0.1)-0.35\n",
            "GPT2 function:  sqrt(x1)+2*x1-0.56\n",
            " ---> GPT2 Test Error: 0.05435\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.18306\n",
            "Genetic Model function:  add(add(-0.299, sqrt(X0)), add(X0, X0))\n",
            " ---> GP Test Error: 0.00079\n",
            "Test case 490/1000.\n",
            "True equation: -sin(0.83*x1-0.08)\n",
            "GPT2 function:  -sin(0.85*x1-0.17)\n",
            " ---> GPT2 Test Error: 0.00040\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.80024\n",
            "Genetic Model function:  sin(mul(-0.798, X0))\n",
            " ---> GP Test Error: 0.00284\n",
            "Test case 491/1000.\n",
            "<class 'TypeError'> \n",
            "\n",
            " Error: sin(3.1-0.1)3.1+0.1), EQ:sin(x1-0.1)x1+0.1)\n",
            "Not calculated\n",
            "Test case 492/1000.\n",
            "True equation: 2*x1+0.65\n",
            "GPT2 function:  2*x1+0.45\n",
            " ---> GPT2 Test Error: 0.04000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 12.86657\n",
            "Genetic Model function:  add(sin(sqrt(mul(sqrt(-0.347), sqrt(0.752)))), add(X0, X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 493/1000.\n",
            "True equation: 0.58*x1-0.13\n",
            "GPT2 function:  0.56*x1-0.19\n",
            " ---> GPT2 Test Error: 0.01775\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.02810\n",
            "Genetic Model function:  mul(X0, 0.517)\n",
            " ---> GP Test Error: 0.02207\n",
            "Test case 494/1000.\n",
            "True equation: 0.25*sqrt(-x1)\n",
            "GPT2 function:  0.24*sqrt(x1)-0.08*x1\n",
            " ---> GPT2 Test Error: 0.15665\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00577\n",
            "Genetic Model function:  sqrt(mul(mul(sin(sqrt(-0.103)), X0), log(0.820)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 495/1000.\n",
            "True equation: -0.96*x1**2-0.18*x1+sin(x1)+0.57\n",
            "GPT2 function:  -1.36*x1**2+0.66*x1+0.46\n",
            " ---> GPT2 Test Error: 22.97699\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 159.35320\n",
            "Genetic Model function:  add(sqrt(-0.279), add(div(X0, div(sin(log(0.166)), X0)), sin(X0)))\n",
            " ---> GP Test Error: 0.48429\n",
            "Test case 496/1000.\n",
            "True equation: -sin(0.33*x1)*sin(x1)\n",
            "GPT2 function:  -sin(0.33*x1)*sin(x1-0.13)\n",
            " ---> GPT2 Test Error: 0.00679\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.17322\n",
            "Genetic Model function:  sin(mul(sin(mul(X0, -0.356)), sin(X0)))\n",
            " ---> GP Test Error: 0.00886\n",
            "Test case 497/1000.\n",
            "True equation: -0.07*x1**2+0.08*x1+sin(x1+0.4)\n",
            "GPT2 function:  sin(1.1*x1+0.28)\n",
            " ---> GPT2 Test Error: 1.80540\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.35623\n",
            "Genetic Model function:  sin(add(X0, 0.529))\n",
            " ---> GP Test Error: 1.38275\n",
            "Test case 498/1000.\n",
            "True equation: sqrt(x1)\n",
            "GPT2 function:  sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00057\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.19635\n",
            "Genetic Model function:  sqrt(log(exp(X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 499/1000.\n",
            "True equation: sin(sin(x1))\n",
            "GPT2 function:  sin(sin(x1-0.1))\n",
            " ---> GPT2 Test Error: 0.00398\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.63904\n",
            "Genetic Model function:  sin(sin(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 500/1000.\n",
            "True equation: sin(0.84*sqrt(-x1))\n",
            "GPT2 function:  sin(0.85*sqrt(0.09-x1))\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.06763\n",
            "Genetic Model function:  sin(sqrt(mul(X0, 0.727)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 501/1000.\n",
            "True equation: sqrt(sin(0.37*x1-0.97))\n",
            "GPT2 function:  0.93*sqrt(0.37*x1-1)\n",
            " ---> GPT2 Test Error: 0.00136\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.16595\n",
            "Genetic Model function:  sin(div(sin(X0), X0))\n",
            " ---> GP Test Error: 0.85732\n",
            "Test case 502/1000.\n",
            "True equation: 1.99*x1+0.55*sqrt(-x1)+0.92\n",
            "GPT2 function:  2*x1+0.62*sqrt(-x1)+0.38\n",
            " ---> GPT2 Test Error: 0.11196\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.40324\n",
            "Genetic Model function:  add(div(X0, 0.456), add(0.439, 0.832))\n",
            " ---> GP Test Error: 0.01761\n",
            "Test case 503/1000.\n",
            "True equation: sin(x1-0.76)\n",
            "GPT2 function:  sin(x1-0.86)\n",
            " ---> GPT2 Test Error: 0.00506\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.51440\n",
            "Genetic Model function:  sin(add(-0.761, X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 504/1000.\n",
            "True equation: 0\n",
            "GPT2 function:  0.13*sqrt(x1)\n",
            " ---> GPT2 Test Error: 0.00963\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.44132\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  mul(add(X0, 0.200), 0.088)\n",
            " ---> GP Test Error: 0.00259\n",
            "Test case 505/1000.\n",
            "True equation: 2*x1+0.34*sin(0.94*x1-0.61)\n",
            "GPT2 function:  2*x1*sin(0.74*x1-0.51)+0.23\n",
            " ---> GPT2 Test Error: 35.23171\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 130.75238\n",
            "Genetic Model function:  mul(mul(X0, X0), sqrt(sin(add(-0.185, X0))))\n",
            " ---> GP Test Error: 690.14336\n",
            "Test case 506/1000.\n",
            "True equation: sin(1.88*x1+0.15)\n",
            "GPT2 function:  sin(1.87*x1-0.03)\n",
            " ---> GPT2 Test Error: 0.02207\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.50252\n",
            "Genetic Model function:  sin(div(X0, 0.511))\n",
            " ---> GP Test Error: 0.01906\n",
            "Test case 507/1000.\n",
            "True equation: sin(0.62*x1)*sin(x1+0.22)\n",
            "GPT2 function:  sin(0.61*x1)*sin(x1+0.05)\n",
            " ---> GPT2 Test Error: 0.00551\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.11411\n",
            "Genetic Model function:  add(-0.215, sin(X0))\n",
            " ---> GP Test Error: 0.57659\n",
            "Test case 508/1000.\n",
            "True equation: -0.58*x1**2\n",
            "GPT2 function:  -0.58*x1**2+0.05*x1\n",
            " ---> GPT2 Test Error: 0.06808\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 33.04945\n",
            "Genetic Model function:  mul(log(0.560), mul(X0, X0))\n",
            " ---> GP Test Error: 0.00031\n",
            "Test case 509/1000.\n",
            "True equation: sqrt(x1)-0.2*x1**2+0.84*x1+0.05\n",
            "GPT2 function:  sqrt(x1-0.1)+sin(0.61*x1-0.3)\n",
            " ---> GPT2 Test Error: 1.06922\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.65856\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  add(sin(mul(0.777, X0)), sqrt(X0))\n",
            " ---> GP Test Error: 0.14636\n",
            "Test case 510/1000.\n",
            "True equation: x1\n",
            "GPT2 function:  x1-0.1\n",
            " ---> GPT2 Test Error: 0.01000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00045\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  sqrt(mul(X0, X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 511/1000.\n",
            "True equation: sin(0.88*sqrt(0.49*x1-1))\n",
            "GPT2 function:  sin(0.9*sqrt(0.47*x1-1))\n",
            " ---> GPT2 Test Error: 0.00016\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.12243\n",
            "Genetic Model function:  sin(exp(sin(mul(-0.607, X0))))\n",
            " ---> GP Test Error: 0.03498\n",
            "Test case 512/1000.\n",
            "True equation: 0.89\n",
            "GPT2 function:  0.89*sqrt(0.01*x1-1)\n",
            " ---> GPT2 Test Error: 0.00106\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.04915\n",
            "Genetic Model function:  exp(sin(log(0.892)))\n",
            " ---> GP Test Error: 0.00009\n",
            "Test case 513/1000.\n",
            "True equation: 0.35*x1**(3/2)+0.11\n",
            "GPT2 function:  0.1*sqrt(x1)+0.39*x1-0.13\n",
            " ---> GPT2 Test Error: 3.60579\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.92700\n",
            "Genetic Model function:  mul(sqrt(sqrt(X0)), mul(X0, 0.477))\n",
            " ---> GP Test Error: 0.26657\n",
            "Test case 514/1000.\n",
            "True equation: 0.6*sqrt(-x1)\n",
            "GPT2 function:  0.61*sqrt(x1-0.11)\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.09925\n",
            "Genetic Model function:  sqrt(mul(X0, -0.374))\n",
            " ---> GP Test Error: 0.00042\n",
            "Test case 515/1000.\n",
            "True equation: sqrt(sin(x1+0.28))\n",
            "GPT2 function:  sqrt(sin(x1+0.18))\n",
            " ---> GPT2 Test Error: 0.00449\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.25208\n",
            "Genetic Model function:  sqrt(sin(add(X0, 0.291)))\n",
            " ---> GP Test Error: 0.00010\n",
            "Test case 516/1000.\n",
            "True equation: -0.26*x1**2+0.15*x1+0.88*sqrt(-x1)\n",
            "GPT2 function:  sqrt(x1-0.1)*sin(0.94*x1+0.28)\n",
            " ---> GPT2 Test Error: 4.73154\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 3.27320\n",
            "Genetic Model function:  sin(sin(sin(add(X0, 0.466))))\n",
            " ---> GP Test Error: 9.74728\n",
            "Test case 517/1000.\n",
            "True equation: 0.65*sqrt(x1)\n",
            "GPT2 function:  0.63*sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00266\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.31005\n",
            "Genetic Model function:  exp(log(sqrt(mul(X0, 0.411))))\n",
            " ---> GP Test Error: 0.00018\n",
            "Test case 518/1000.\n",
            "True equation: 0.72*sqrt(x1+0.08)+sin(0.86*x1+0.37)\n",
            "GPT2 function:  0.79*sqrt(-x1)+sin(x1+0.23)\n",
            " ---> GPT2 Test Error: 0.14022\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.91524\n",
            "Genetic Model function:  add(sin(mul(X0, 0.862)), 0.927)\n",
            " ---> GP Test Error: 0.32326\n",
            "Test case 519/1000.\n",
            "True equation: 0.98*sqrt(x1+0.03)\n",
            "GPT2 function:  0.98*sqrt(0.07-x1)\n",
            " ---> GPT2 Test Error: 0.00087\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.08342\n",
            "Genetic Model function:  exp(sin(log(sqrt(X0))))\n",
            " ---> GP Test Error: 0.01807\n",
            "Test case 520/1000.\n",
            "True equation: sin(0.8*x1-0.2)\n",
            "GPT2 function:  sin(0.79*x1-0.29)\n",
            " ---> GPT2 Test Error: 0.01143\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.54199\n",
            "Genetic Model function:  sin(mul(exp(-0.236), add(-0.216, X0)))\n",
            " ---> GP Test Error: 0.00022\n",
            "Test case 521/1000.\n",
            "True equation: sin(0.69*x1)\n",
            "GPT2 function:  sin(0.67*x1-0.06)\n",
            " ---> GPT2 Test Error: 0.01225\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.91331\n",
            "Genetic Model function:  sin(mul(div(X0, -0.775), log(-0.590)))\n",
            " ---> GP Test Error: 0.00023\n",
            "Test case 522/1000.\n",
            "True equation: sqrt(x1+0.22)\n",
            "GPT2 function:  sqrt(x1+0.12)\n",
            " ---> GPT2 Test Error: 0.00052\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.23574\n",
            "Genetic Model function:  sqrt(add(X0, 0.217))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 523/1000.\n",
            "True equation: -0.15*x1**2+0.02*x1\n",
            "GPT2 function:  -0.14*x1**2+0.04*x1\n",
            " ---> GPT2 Test Error: 0.10599\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 4.57856\n",
            "Genetic Model function:  mul(div(mul(X0, 0.330), div(-0.992, X0)), sin(exp(-0.818)))\n",
            " ---> GP Test Error: 0.00807\n",
            "Test case 524/1000.\n",
            "True equation: 0.52*x1**2+0.82*x1\n",
            "GPT2 function:  -0.24*x1**2\n",
            " ---> GPT2 Test Error: 26.14988\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 59.83476\n",
            "Genetic Model function:  mul(add(-0.757, X0), mul(mul(X0, 0.373), mul(X0, -0.205)))\n",
            " ---> GP Test Error: 6.93296\n",
            "Test case 525/1000.\n",
            "True equation: -0.53*x1\n",
            "GPT2 function:  0.04*x1**2-0.58*x1+0.06\n",
            " ---> GPT2 Test Error: 0.12917\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.14899\n",
            "Genetic Model function:  mul(X0, -0.542)\n",
            " ---> GP Test Error: 0.19952\n",
            "Test case 526/1000.\n",
            "True equation: sqrt(x1)\n",
            "GPT2 function:  sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00057\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.08257\n",
            "Genetic Model function:  sqrt(log(exp(X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 527/1000.\n",
            "True equation: -sin(0.12*x1-0.3)\n",
            "GPT2 function:  -sin(0.15*x1-0.32)\n",
            " ---> GPT2 Test Error: 0.00907\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00011\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  div(0.354, sqrt(exp(add(mul(X0, X0), sqrt(0.472)))))\n",
            " ---> GP Test Error: 0.07919\n",
            "Test case 528/1000.\n",
            "True equation: 0.66*x1**2-0.29*x1+sin(x1+0.17)\n",
            "GPT2 function:  0.67*x1*sqrt(-x1)+0.99\n",
            " ---> GPT2 Test Error: 31.88518\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 78.12634\n",
            "Genetic Model function:  div(X0, 0.680)\n",
            " ---> GP Test Error: 45.06497\n",
            "Test case 529/1000.\n",
            "True equation: 0.6*sqrt(x1)\n",
            "GPT2 function:  0.62*sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00115\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.04336\n",
            "Genetic Model function:  sqrt(mul(div(X0, -0.543), mul(-0.596, 0.325)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 530/1000.\n",
            "True equation: sqrt(-sin(0.4*x1-0.6))\n",
            "GPT2 function:  sqrt(sin(0.39*x1-0.64))\n",
            " ---> GPT2 Test Error: 0.00062\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.44082\n",
            "Genetic Model function:  sin(sin(sqrt(sqrt(log(sqrt(sin(add(X0, 0.095))))))))\n",
            " ---> GP Test Error: 0.21978\n",
            "Test case 531/1000.\n",
            "True equation: 0.54*x1**2+0.6*x1\n",
            "GPT2 function:  0.91*x1*sqrt(-x1)-0.1\n",
            " ---> GPT2 Test Error: 35.21657\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 52.23152\n",
            "Genetic Model function:  mul(add(X0, X0), mul(sqrt(X0), 0.602))\n",
            " ---> GP Test Error: 8.38556\n",
            "Test case 532/1000.\n",
            "True equation: -0.45*x1+0.77*sqrt(-x1)\n",
            "GPT2 function:  -0.27*x1+0.78*sqrt(1-0.1*x1)-0.19\n",
            " ---> GPT2 Test Error: 0.19952\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.04387\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  div(sin(X0), exp(X0))\n",
            " ---> GP Test Error: 0.20862\n",
            "Test case 533/1000.\n",
            "True equation: 0.96*sqrt(0.09-x1)\n",
            "GPT2 function:  0.96*sqrt(0.19-x1)\n",
            " ---> GPT2 Test Error: 0.00079\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.03537\n",
            "Genetic Model function:  sqrt(mul(X0, -0.885))\n",
            " ---> GP Test Error: 0.00067\n",
            "Test case 534/1000.\n",
            "True equation: sin(1.7*x1-0.01)\n",
            "GPT2 function:  sin(1.74*x1-0.18)\n",
            " ---> GPT2 Test Error: 0.00070\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 4.12287\n",
            "Genetic Model function:  sin(div(X0, 0.589))\n",
            " ---> GP Test Error: 0.00007\n",
            "Test case 535/1000.\n",
            "True equation: 0.48-0.64*x1\n",
            "GPT2 function:  0.56-0.65*x1\n",
            " ---> GPT2 Test Error: 0.00033\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.63766\n",
            "Genetic Model function:  div(add(X0, -0.765), log(log(-0.816)))\n",
            " ---> GP Test Error: 0.00092\n",
            "Test case 536/1000.\n",
            "True equation: sin(sin(0.7*x1))\n",
            "GPT2 function:  sin(sin(0.76*x1-0.06))\n",
            " ---> GPT2 Test Error: 0.02770\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.92988\n",
            "Genetic Model function:  sin(sin(sqrt(mul(sin(0.487), mul(X0, X0)))))\n",
            " ---> GP Test Error: 0.00179\n",
            "Test case 537/1000.\n",
            "True equation: -0.5*x1+sin(0.46*x1+0.45)-0.22\n",
            "GPT2 function:  0.23-0.2*x1\n",
            " ---> GPT2 Test Error: 1.97058\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 3.90092\n",
            "Genetic Model function:  mul(mul(log(add(X0, -0.256)), -0.203), X0)\n",
            " ---> GP Test Error: 0.44955\n",
            "Test case 538/1000.\n",
            "True equation: -0.86*x1**2+1.8*x1+0.05\n",
            "GPT2 function:  sqrt(x1-0.63)*sin(x1+0.66)\n",
            " ---> GPT2 Test Error: 117.67507\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 72.06938\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  mul(X0, sin(add(X0, 0.982)))\n",
            " ---> GP Test Error: 129.15277\n",
            "Test case 539/1000.\n",
            "True equation: 0.2*x1**2+1.89*x1\n",
            "GPT2 function:  0.16*x1**2+1.94*x1-0.2\n",
            " ---> GPT2 Test Error: 0.57522\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 14.29122\n",
            "Genetic Model function:  add(div(X0, 0.422), -0.174)\n",
            " ---> GP Test Error: 5.94422\n",
            "Test case 540/1000.\n",
            "True equation: sin(0.92*x1)\n",
            "GPT2 function:  sin(0.92*x1-0.09)\n",
            " ---> GPT2 Test Error: 0.00291\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.07770\n",
            "Genetic Model function:  sin(mul(0.924, X0))\n",
            " ---> GP Test Error: 0.00035\n",
            "Test case 541/1000.\n",
            "True equation: 0.44*sqrt(x1**2+0.37*x1)\n",
            "GPT2 function:  0.44*sqrt(x1**2-0.1*x1)\n",
            " ---> GPT2 Test Error: 0.00704\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.64558\n",
            "Genetic Model function:  mul(X0, 0.476)\n",
            " ---> GP Test Error: 0.01191\n",
            "Test case 542/1000.\n",
            "True equation: 0.68*x1+0.75*sqrt(0.57-x1)+0.48\n",
            "GPT2 function:  0.96*sqrt(-x1)+sqrt(x1-0.68)\n",
            " ---> GPT2 Test Error: 1.30742\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.11012\n",
            "Genetic Model function:  add(X0, 0.730)\n",
            " ---> GP Test Error: 0.04991\n",
            "Test case 543/1000.\n",
            "True equation: 0.7*x1**2+0.82*x1+0.31\n",
            "GPT2 function:  x1**2+0.38*x1+0.56\n",
            " ---> GPT2 Test Error: 15405.18696\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 5799.71678\n",
            "Genetic Model function:  div(add(X0, add(-0.513, -0.347)), div(-0.967, mul(X0, X0)))\n",
            " ---> GP Test Error: 8.92379\n",
            "Test case 544/1000.\n",
            "True equation: sqrt(x1)*sqrt(x1+0.65)\n",
            "GPT2 function:  sqrt(x1**2+0.88*x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00876\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.93631\n",
            "Genetic Model function:  add(0.294, X0)\n",
            " ---> GP Test Error: 0.00052\n",
            "Test case 545/1000.\n",
            "True equation: 0.91*x1+sin(x1)\n",
            "GPT2 function:  0.92*x1+sin(x1)-0.19\n",
            " ---> GPT2 Test Error: 0.02731\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.38708\n",
            "Genetic Model function:  add(sin(X0), mul(X0, 0.915))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 546/1000.\n",
            "True equation: 0.89*(1-0.89*x1)**(1/4)\n",
            "GPT2 function:  0.91*(1-0.8*x1)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.93824\n",
            "Genetic Model function:  sqrt(sin(sqrt(sin(log(X0)))))\n",
            " ---> GP Test Error: 0.07077\n",
            "Test case 547/1000.\n",
            "True equation: 0.80\n",
            "GPT2 function:  0.79*(-0.79*x1-1)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.08967\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  sqrt(log(sin(exp(exp(div(X0, X0))))))\n",
            " ---> GP Test Error: 0.00009\n",
            "Test case 548/1000.\n",
            "True equation: sqrt(x1)\n",
            "GPT2 function:  sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00057\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.24812\n",
            "Genetic Model function:  exp(log(sqrt(X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 549/1000.\n",
            "True equation: sqrt(x1)+x1\n",
            "GPT2 function:  sqrt(x1)+x1-0.39\n",
            " ---> GPT2 Test Error: 0.15194\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 5.01337\n",
            "Genetic Model function:  add(X0, sqrt(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 550/1000.\n",
            "True equation: -0.21*x1+sqrt(x1+0.55)\n",
            "GPT2 function:  0.95*(x1+0.3)**(1/4)\n",
            " ---> GPT2 Test Error: 0.01576\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.02701\n",
            "Genetic Model function:  exp(mul(X0, 0.079))\n",
            " ---> GP Test Error: 0.02871\n",
            "Test case 551/1000.\n",
            "True equation: 0.67*x1**2+0.47*x1*sin(x1)\n",
            "GPT2 function:  x1**2-0.04*x1*sin(x1)\n",
            " ---> GPT2 Test Error: 1245.15428\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 161.63908\n",
            "Genetic Model function:  mul(sin(mul(0.560, X0)), mul(sin(X0), add(X0, X0)))\n",
            " ---> GP Test Error: 110.31173\n",
            "Test case 552/1000.\n",
            "True equation: 2*sqrt(x1)\n",
            "GPT2 function:  sqrt(x1)+sqrt(x1-0.3)\n",
            " ---> GPT2 Test Error: 0.00537\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.22339\n",
            "Genetic Model function:  div(add(X0, X0), sqrt(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 553/1000.\n",
            "True equation: -sin(0.65*x1)\n",
            "GPT2 function:  -sin(0.67*x1-0.07)\n",
            " ---> GPT2 Test Error: 0.00058\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.81171\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  sin(mul(X0, -0.652))\n",
            " ---> GP Test Error: 0.00009\n",
            "Test case 554/1000.\n",
            "True equation: x1**2-0.82*x1+0.16\n",
            "GPT2 function:  x1**2-1.2*x1+0.26\n",
            " ---> GPT2 Test Error: 2.72489\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 102.55549\n",
            "Genetic Model function:  mul(add(-0.411, X0), add(-0.411, X0))\n",
            " ---> GP Test Error: 0.00008\n",
            "Test case 555/1000.\n",
            "True equation: sin(sin(x1-0.2))\n",
            "GPT2 function:  sin(sin(x1-0.31))\n",
            " ---> GPT2 Test Error: 0.00468\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.80033\n",
            "Genetic Model function:  sin(sin(add(-0.096, add(-0.096, X0))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 556/1000.\n",
            "True equation: sqrt(x1)\n",
            "GPT2 function:  sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00057\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.21312\n",
            "Genetic Model function:  sqrt(log(exp(X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 557/1000.\n",
            "True equation: 0.16*x1**2+1.51*x1+0.45\n",
            "GPT2 function:  0.58*x1**2+0.34*x1+sin(x1+0.29)\n",
            " ---> GPT2 Test Error: 12.23831\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.08759\n",
            "Genetic Model function:  div(X0, 0.479)\n",
            " ---> GP Test Error: 2.31744\n",
            "Test case 558/1000.\n",
            "True equation: 2*x1+0.75\n",
            "GPT2 function:  2*x1+0.55\n",
            " ---> GPT2 Test Error: 0.04000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.20045\n",
            "Genetic Model function:  add(add(X0, X0), sin(0.858))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 559/1000.\n",
            "True equation: 0.72*sqrt(x1)\n",
            "GPT2 function:  0.72*sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00038\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.07516\n",
            "Genetic Model function:  sqrt(mul(X0, 0.519))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 560/1000.\n",
            "True equation: sin(sqrt(x1-0.36))\n",
            "GPT2 function:  sin(sqrt(x1-0.47))\n",
            " ---> GPT2 Test Error: 0.00014\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00330\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  sin(sqrt(add(X0, -0.345)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 561/1000.\n",
            "True equation: 2*x1*sin(x1)-1.03\n",
            "GPT2 function:  2*x1-0.13*sin(x1-0.32)\n",
            " ---> GPT2 Test Error: 231.40026\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 18.53624\n",
            "Genetic Model function:  mul(sin(X0), add(X0, mul(log(X0), sqrt(X0))))\n",
            " ---> GP Test Error: 0.06081\n",
            "Test case 562/1000.\n",
            "True equation: 0.78*sqrt(0.21*x1**2-x1-0.84)\n",
            "GPT2 function:  -0.24*x1+sqrt(x1+0.38)+0.03\n",
            " ---> GPT2 Test Error: 0.23148\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.31356\n",
            "Genetic Model function:  sqrt(sqrt(sqrt(X0)))\n",
            " ---> GP Test Error: 0.30078\n",
            "Test case 563/1000.\n",
            "True equation: sin(sqrt(x1-0.29))\n",
            "GPT2 function:  sin(sqrt(x1-0.39))\n",
            " ---> GPT2 Test Error: 0.00012\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.71815\n",
            "Genetic Model function:  sin(sqrt(add(X0, -0.265)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 564/1000.\n",
            "True equation: sin(0.79*x1**2)\n",
            "GPT2 function:  sin(0.79*x1**2-0.06*x1)\n",
            " ---> GPT2 Test Error: 0.03227\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 4.58092\n",
            "Genetic Model function:  sin(mul(mul(X0, X0), sin(sqrt(sqrt(0.662)))))\n",
            " ---> GP Test Error: 0.00531\n",
            "Test case 565/1000.\n",
            "True equation: sin(1.17*x1+0.99)\n",
            "GPT2 function:  sin(1.13*x1+0.91)\n",
            " ---> GPT2 Test Error: 0.02988\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 5.71712\n",
            "Genetic Model function:  sin(mul(exp(0.136), add(X0, 0.906)))\n",
            " ---> GP Test Error: 0.00146\n",
            "Test case 566/1000.\n",
            "True equation: x1**2-0.81*x1+0.74*sqrt(-x1)\n",
            "GPT2 function:  sqrt(x1)+0.9*x1**2-0.3*x1-0.25\n",
            " ---> GPT2 Test Error: 0.29775\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 62.78874\n",
            "Genetic Model function:  mul(mul(mul(0.924, X0), X0), 0.934)\n",
            " ---> GP Test Error: 0.98734\n",
            "Test case 567/1000.\n",
            "True equation: -0.13*x1**2+0.85*x1+0.27\n",
            "GPT2 function:  -0.24*x1**2+1.77*x1+0.23\n",
            " ---> GPT2 Test Error: 12955.62641\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 8181.19294\n",
            "Genetic Model function:  mul(sin(log(0.159)), mul(mul(X0, X0), X0))\n",
            " ---> GP Test Error: 8.13284\n",
            "Test case 568/1000.\n",
            "True equation: sqrt(sin(0.39*x1+0.67))\n",
            "GPT2 function:  sqrt(-sin(0.41*x1+0.66))\n",
            " ---> GPT2 Test Error: 0.00695\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.09465\n",
            "Genetic Model function:  sin(sqrt(add(sqrt(div(log(0.285), log(-0.183))), mul(mul(0.878, X0), sqrt(-0.566)))))\n",
            " ---> GP Test Error: 0.03672\n",
            "Test case 569/1000.\n",
            "True equation: 0.9*(x1+0.67)**(1/4)\n",
            "GPT2 function:  0.92*(x1+0.61)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00053\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.07341\n",
            "Genetic Model function:  sqrt(sqrt(add(0.216, sqrt(X0))))\n",
            " ---> GP Test Error: 0.01630\n",
            "Test case 570/1000.\n",
            "True equation: 0.61*sqrt(-x1-1.0)+sqrt(x1-0.25)\n",
            "GPT2 function:  sqrt(x1-0.21)+0.84*sqrt(x1+0.67)\n",
            " ---> GPT2 Test Error: 0.23102\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.15414\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  exp(sin(mul(0.541, X0)))\n",
            " ---> GP Test Error: 3.55832\n",
            "Test case 571/1000.\n",
            "<class 'TypeError'> \n",
            "\n",
            " Error: sin(3.1-0.1)3.194), EQ:sin(x1-0.1)x194)\n",
            "Not calculated\n",
            "Test case 572/1000.\n",
            "True equation: sqrt(2)*sqrt(x1-0.44)\n",
            "GPT2 function:  sqrt(2)*sqrt(x1-0.54)\n",
            " ---> GPT2 Test Error: 0.00118\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.02467\n",
            "Genetic Model function:  sqrt(add(add(X0, X0), -0.875))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 573/1000.\n",
            "True equation: sqrt(sin(x1-0.94))\n",
            "GPT2 function:  sqrt(sin(x1-0.94))\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.19288\n",
            "Genetic Model function:  sqrt(sin(add(X0, -0.960)))\n",
            " ---> GP Test Error: 0.00041\n",
            "Test case 574/1000.\n",
            "True equation: sqrt(x1+0.72)\n",
            "GPT2 function:  sqrt(x1+0.62)\n",
            " ---> GPT2 Test Error: 0.00044\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.38705\n",
            "Genetic Model function:  sqrt(mul(add(X0, 0.747), sqrt(-0.989)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 575/1000.\n",
            "True equation: 0.41*sqrt(x1**2-0.94*x1)\n",
            "GPT2 function:  0.47*sqrt(0.96*x1-1)\n",
            " ---> GPT2 Test Error: 0.71927\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.09325\n",
            "Genetic Model function:  mul(0.315, X0)\n",
            " ---> GP Test Error: 0.06223\n",
            "Test case 576/1000.\n",
            "True equation: 0.78*sqrt(x1)-0.57*x1**2+0.09*x1\n",
            "GPT2 function:  -0.39*x1**2-0.09*x1+0.97*sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 13.29807\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 40.66008\n",
            "Genetic Model function:  add(mul(log(X0), div(X0, -0.883)), mul(mul(sin(sin(X0)), 0.368), X0))\n",
            " ---> GP Test Error: 4.22257\n",
            "Test case 577/1000.\n",
            "True equation: 0.3*sqrt(x1)+0.23*x1**2+0.55*x1\n",
            "GPT2 function:  0.14*x1**2+x1-0.08\n",
            " ---> GPT2 Test Error: 0.59989\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 10.20173\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  mul(sqrt(sqrt(X0)), add(0.094, X0))\n",
            " ---> GP Test Error: 2.35450\n",
            "Test case 578/1000.\n",
            "True equation: sqrt(2)*sqrt(x1)\n",
            "GPT2 function:  sqrt(2)*sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00121\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00143\n",
            "Genetic Model function:  exp(log(sqrt(add(X0, X0))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 579/1000.\n",
            "True equation: 3.71*x1-1.59\n",
            "GPT2 function:  3.56*x1-2.06\n",
            " ---> GPT2 Test Error: 1.34157\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00005\n",
            "Genetic Model function:  mul(add(add(div(X0, 0.959), X0), log(X0)), sqrt(add(sqrt(X0), add(0.877, -0.837))))\n",
            " ---> GP Test Error: 0.66880\n",
            "Test case 580/1000.\n",
            "True equation: -0.29*x1**2-0.44*x1-0.49\n",
            "GPT2 function:  -0.29*x1**2-0.38*x1-0.44\n",
            " ---> GPT2 Test Error: 0.17885\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 6.85890\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  div(X0, -0.776)\n",
            " ---> GP Test Error: 11.17475\n",
            "Test case 581/1000.\n",
            "True equation: 0.72*sqrt(-x1**2)\n",
            "GPT2 function:  0.72*x1-0.07\n",
            " ---> GPT2 Test Error: 0.00668\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00007\n",
            "Genetic Model function:  mul(sqrt(sqrt(-0.272)), exp(log(X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 582/1000.\n",
            "True equation: -0.4*x1**(3/2)-0.68\n",
            "GPT2 function:  0.1-0.47*x1\n",
            " ---> GPT2 Test Error: 8.65116\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 3.22179\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  mul(-0.899, X0)\n",
            " ---> GP Test Error: 0.78942\n",
            "Test case 583/1000.\n",
            "True equation: sqrt(x1+0.39)\n",
            "GPT2 function:  sqrt(x1+0.29)\n",
            " ---> GPT2 Test Error: 0.00055\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.82452\n",
            "Genetic Model function:  sqrt(add(X0, 0.387))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 584/1000.\n",
            "True equation: sin(0.65*x1-0.2)\n",
            "GPT2 function:  sin(0.64*x1-0.26)\n",
            " ---> GPT2 Test Error: 0.00669\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.17535\n",
            "Genetic Model function:  sin(mul(0.512, X0))\n",
            " ---> GP Test Error: 0.14527\n",
            "Test case 585/1000.\n",
            "True equation: 0.19*x1**2-0.25*x1+0.04\n",
            "GPT2 function:  0.18*x1**2-0.09*x1+0.05\n",
            " ---> GPT2 Test Error: 0.26564\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.40179\n",
            "Genetic Model function:  sin(mul(mul(mul(X0, 0.117), X0), log(X0)))\n",
            " ---> GP Test Error: 11.17449\n",
            "Test case 586/1000.\n",
            "True equation: sin(2*x1-0.71)\n",
            "GPT2 function:  sin(2*x1-0.91)\n",
            " ---> GPT2 Test Error: 0.01960\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.25770\n",
            "Genetic Model function:  sin(add(X0, add(X0, -0.722)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 587/1000.\n",
            "True equation: sqrt(-sin(0.09*x1-0.8))\n",
            "GPT2 function:  0.85*sqrt(0.11*x1-1)\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00147\n",
            "Genetic Model function:  0.786\n",
            " ---> GP Test Error: 0.03779\n",
            "Test case 588/1000.\n",
            "True equation: 1.41*sqrt(x1-0.03)\n",
            "GPT2 function:  sqrt(2)*sqrt(x1-0.12)\n",
            " ---> GPT2 Test Error: 0.00028\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00280\n",
            "Genetic Model function:  sqrt(div(X0, 0.521))\n",
            " ---> GP Test Error: 0.00132\n",
            "Test case 589/1000.\n",
            "True equation: -0.63*x1**2+sin(x1-0.96)\n",
            "GPT2 function:  -0.47*x1**2+sin(x1-0.99)\n",
            " ---> GPT2 Test Error: 13.78582\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 44.22234\n",
            "Genetic Model function:  mul(exp(X0), -0.240)\n",
            " ---> GP Test Error: 774.90034\n",
            "Test case 590/1000.\n",
            "True equation: -0.6*x1**2*sin(x1+0.45)-0.1*x1+0.54\n",
            "GPT2 function:  x1**2+0.05*x1-0.16*sin(x1-0.84)\n",
            " ---> GPT2 Test Error: 311.95355\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 33.09212\n",
            "Genetic Model function:  mul(sqrt(X0), sin(sin(exp(add(0.183, sqrt(X0))))))\n",
            " ---> GP Test Error: 76.37020\n",
            "Test case 591/1000.\n",
            "True equation: 0.39*sqrt(-x1)+0.63*sqrt(0.61-x1)\n",
            "GPT2 function:  sqrt(x1)-sin(0.15*x1-0.23)\n",
            " ---> GPT2 Test Error: 0.16483\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00079\n",
            "Genetic Model function:  sqrt(add(X0, -0.352))\n",
            " ---> GP Test Error: 0.00134\n",
            "Test case 592/1000.\n",
            "True equation: -sin(sin(0.55*x1))\n",
            "GPT2 function:  -sin(sin(0.55*x1-0.07))\n",
            " ---> GPT2 Test Error: 0.00089\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.14384\n",
            "Genetic Model function:  sin(sin(mul(X0, -0.536)))\n",
            " ---> GP Test Error: 0.00094\n",
            "Test case 593/1000.\n",
            "True equation: sin(0.92*sqrt(x1))\n",
            "GPT2 function:  sin(0.94*sqrt(x1-0.1))\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.09933\n",
            "Genetic Model function:  sin(mul(0.933, sqrt(X0)))\n",
            " ---> GP Test Error: 0.00008\n",
            "Test case 594/1000.\n",
            "True equation: 0.8*sqrt(-x1**2-0.61*x1+0.59)\n",
            "GPT2 function:  0.83*sqrt(x1**2+0.11*x1-0.63)\n",
            " ---> GPT2 Test Error: 0.00329\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.04697\n",
            "Genetic Model function:  mul(X0, 0.850)\n",
            " ---> GP Test Error: 0.00459\n",
            "Test case 595/1000.\n",
            "True equation: sin(sqrt(x1+0.36))\n",
            "GPT2 function:  sin(sqrt(x1+0.26))\n",
            " ---> GPT2 Test Error: 0.00016\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.09646\n",
            "Genetic Model function:  sin(sqrt(add(0.357, X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 596/1000.\n",
            "True equation: -sin(0.54*x1)-sin(0.86*x1)\n",
            "GPT2 function:  -sin(0.64*x1)-sin(0.98*x1-0.12)\n",
            " ---> GPT2 Test Error: 0.26018\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.84295\n",
            "Genetic Model function:  div(sin(mul(X0, -0.730)), sqrt(sin(-0.287)))\n",
            " ---> GP Test Error: 0.17451\n",
            "Test case 597/1000.\n",
            "True equation: sin(0.79*x1-0.74)\n",
            "GPT2 function:  sin(0.79*x1-0.84)\n",
            " ---> GPT2 Test Error: 0.00523\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.92422\n",
            "Genetic Model function:  sin(mul(add(X0, -0.921), sin(0.892)))\n",
            " ---> GP Test Error: 0.00049\n",
            "Test case 598/1000.\n",
            "True equation: 0.99*(x1-0.77)**(1/4)\n",
            "GPT2 function:  0.98*(x1-0.85)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00056\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.53004\n",
            "Genetic Model function:  sqrt(sqrt(add(-0.799, X0)))\n",
            " ---> GP Test Error: 0.00009\n",
            "Test case 599/1000.\n",
            "True equation: 0.55-0.56*x1**2\n",
            "GPT2 function:  -0.58*x1**2+0.21*x1+0.04\n",
            " ---> GPT2 Test Error: 0.00456\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 70.55927\n",
            "Genetic Model function:  mul(mul(-0.616, X0), add(add(0.053, X0), -0.476))\n",
            " ---> GP Test Error: 0.44838\n",
            "Test case 600/1000.\n",
            "True equation: sin(x1-0.91)\n",
            "GPT2 function:  sin(x1-1.0)\n",
            " ---> GPT2 Test Error: 0.00443\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.29897\n",
            "Genetic Model function:  sin(add(-0.906, X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 601/1000.\n",
            "True equation: sin(2*x1+0.42)\n",
            "GPT2 function:  sin(2*x1+0.22)\n",
            " ---> GPT2 Test Error: 0.01949\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.93485\n",
            "Genetic Model function:  sin(add(exp(-0.845), add(X0, X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 602/1000.\n",
            "True equation: -0.59*x1+0.03*sqrt(-x1)\n",
            "GPT2 function:  -0.1*x1**(3/2)-0.1*x1+0.02\n",
            " ---> GPT2 Test Error: 0.02391\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.88347\n",
            "Genetic Model function:  mul(sqrt(X0), mul(X0, -0.151))\n",
            " ---> GP Test Error: 0.00452\n",
            "Test case 603/1000.\n",
            "True equation: -0.32*x1+sin(x1+0.32)-0.74\n",
            "GPT2 function:  -0.47*x1+sin(x1+0.82)-0.48\n",
            " ---> GPT2 Test Error: 0.12538\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.50467\n",
            "Genetic Model function:  mul(add(X0, -0.849), mul(-0.289, X0))\n",
            " ---> GP Test Error: 8.85687\n",
            "Test case 604/1000.\n",
            "<class 'TypeError'> \n",
            "\n",
            " Error: sin(3.1-0.1)3.112), EQ:sin(x1-0.1)x112)\n",
            "Not calculated\n",
            "Test case 605/1000.\n",
            "True equation: sqrt(x1-0.3)*sin(x1)\n",
            "GPT2 function:  sqrt(x1-0.4)*sin(0.98*x1-0.06)\n",
            " ---> GPT2 Test Error: 0.04397\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 3.79786\n",
            "Genetic Model function:  mul(sin(X0), sqrt(add(X0, -0.285)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 606/1000.\n",
            "True equation: 0.37*x1**2-0.05*x1-0.13*sin(x1)\n",
            "GPT2 function:  0.55*x1**2-0.68*x1+0.03*sin(x1)\n",
            " ---> GPT2 Test Error: 227.86599\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 18.68833\n",
            "Genetic Model function:  mul(sin(X0), mul(mul(X0, 0.386), add(X0, -0.403)))\n",
            " ---> GP Test Error: 0.00278\n",
            "Test case 607/1000.\n",
            "True equation: sqrt(sin(0.3*x1-0.13))\n",
            "GPT2 function:  0.52*sqrt(0.53-x1)\n",
            " ---> GPT2 Test Error: 0.01160\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.38438\n",
            "Genetic Model function:  sin(sin(mul(0.432, X0)))\n",
            " ---> GP Test Error: 0.06189\n",
            "Test case 608/1000.\n",
            "True equation: 0.36*x1-0.86\n",
            "GPT2 function:  0.36*x1**2-1.*(x1-0.93)-0.12\n",
            " ---> GPT2 Test Error: 1.08799\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 27.22990\n",
            "Genetic Model function:  exp(mul(div(sin(X0), mul(X0, -0.256)), sin(X0)))\n",
            " ---> GP Test Error: 24.11510\n",
            "Test case 609/1000.\n",
            "True equation: 2.19*x1-0.08\n",
            "GPT2 function:  2.16*x1-0.32\n",
            " ---> GPT2 Test Error: 0.15687\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 15.44419\n",
            "Genetic Model function:  div(X0, 0.464)\n",
            " ---> GP Test Error: 0.00871\n",
            "Test case 610/1000.\n",
            "True equation: 0.11*x1**2+0.54*x1+sqrt(x1-0.33)\n",
            "GPT2 function:  x1+sqrt(x1-0.38)-0.17\n",
            " ---> GPT2 Test Error: 0.50728\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.43739\n",
            "Genetic Model function:  mul(exp(0.358), X0)\n",
            " ---> GP Test Error: 0.28453\n",
            "Test case 611/1000.\n",
            "True equation: sqrt(sin(x1+0.98))\n",
            "GPT2 function:  sqrt(sin(x1+0.88))\n",
            " ---> GPT2 Test Error: 0.00779\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.32185\n",
            "Genetic Model function:  sqrt(sin(add(X0, sqrt(0.944))))\n",
            " ---> GP Test Error: 0.00015\n",
            "Test case 612/1000.\n",
            "True equation: 2.9*x1+0.07\n",
            "GPT2 function:  2.88*x1-0.23\n",
            " ---> GPT2 Test Error: 0.14546\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.09478\n",
            "Genetic Model function:  div(X0, div(-0.319, -0.939))\n",
            " ---> GP Test Error: 0.02235\n",
            "Test case 613/1000.\n",
            "True equation: 0.9*x1\n",
            "GPT2 function:  1.27*x1-0.06\n",
            " ---> GPT2 Test Error: 0.18243\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.46496\n",
            "Genetic Model function:  add(-0.070, X0)\n",
            " ---> GP Test Error: 0.91698\n",
            "Test case 614/1000.\n",
            "True equation: 1.55*x1-0.34\n",
            "GPT2 function:  1.55*x1-0.48\n",
            " ---> GPT2 Test Error: 0.02348\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.05315\n",
            "Genetic Model function:  div(add(-0.143, X0), sin(0.731))\n",
            " ---> GP Test Error: 0.01872\n",
            "Test case 615/1000.\n",
            "True equation: -0.8*x1**2-0.51*x1+sqrt(x1-0.76)-0.02\n",
            "GPT2 function:  -0.71*x1**2-0.21*x1+0.91*sqrt(0.77-x1)\n",
            " ---> GPT2 Test Error: 11.31998\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 114.66726\n",
            "Genetic Model function:  mul(-0.799, mul(X0, X0))\n",
            " ---> GP Test Error: 0.31373\n",
            "Test case 616/1000.\n",
            "True equation: 1.83*x1\n",
            "GPT2 function:  1.82*x1-0.17\n",
            " ---> GPT2 Test Error: 0.05302\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.31782\n",
            "Genetic Model function:  div(X0, 0.545)\n",
            " ---> GP Test Error: 0.00013\n",
            "Test case 617/1000.\n",
            "True equation: -sin(0.9*x1)\n",
            "GPT2 function:  -sin(0.9*x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00464\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.09583\n",
            "Genetic Model function:  sin(mul(log(log(sin(-0.725))), X0))\n",
            " ---> GP Test Error: 0.00084\n",
            "Test case 618/1000.\n",
            "True equation: 0.49*sqrt(-x1**2)\n",
            "GPT2 function:  0.5*sqrt(x1)*sqrt(x1-0.08)\n",
            " ---> GPT2 Test Error: 0.00006\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.64243\n",
            "Genetic Model function:  log(sqrt(exp(X0)))\n",
            " ---> GP Test Error: 0.00068\n",
            "Test case 619/1000.\n",
            "True equation: 0.51*x1**2-0.35*x1\n",
            "GPT2 function:  0.51*x1**2-0.78*x1+0.07\n",
            " ---> GPT2 Test Error: 4.10261\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 17.21428\n",
            "Genetic Model function:  mul(add(-0.676, X0), mul(0.519, X0))\n",
            " ---> GP Test Error: 0.00940\n",
            "Test case 620/1000.\n",
            "True equation: sqrt(x1-0.72)\n",
            "GPT2 function:  sqrt(x1-0.82)\n",
            " ---> GPT2 Test Error: 0.00070\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.03939\n",
            "Genetic Model function:  sqrt(add(sin(-0.813), X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 621/1000.\n",
            "True equation: sqrt(x1-0.67)\n",
            "GPT2 function:  sqrt(x1-0.77)\n",
            " ---> GPT2 Test Error: 0.00074\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.06367\n",
            "Genetic Model function:  sqrt(add(-0.661, X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 622/1000.\n",
            "True equation: 2.62*x1-0.6\n",
            "GPT2 function:  0.81*x1**2+0.81*x1+sin(x1-0.86)\n",
            " ---> GPT2 Test Error: 3.63057\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 21.38391\n",
            "Genetic Model function:  add(add(sin(sin(X0)), add(-0.264, X0)), add(-0.431, mul(X0, X0)))\n",
            " ---> GP Test Error: 8.11005\n",
            "Test case 623/1000.\n",
            "True equation: 0.37*x1**3+0.49*x1\n",
            "GPT2 function:  0.48*x1**2+0.81*x1\n",
            " ---> GPT2 Test Error: 1831.66060\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 596.46558\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  mul(mul(X0, add(-0.071, X0)), sqrt(X0))\n",
            " ---> GP Test Error: 41.50707\n",
            "Test case 624/1000.\n",
            "True equation: -0.29*x1\n",
            "GPT2 function:  -0.32*x1-0.02\n",
            " ---> GPT2 Test Error: 0.01869\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.14552\n",
            "Genetic Model function:  div(div(mul(-0.197, X0), sin(0.752)), exp(sin(-0.023)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 625/1000.\n",
            "True equation: 0.23*x1**2+0.85*x1\n",
            "GPT2 function:  0.13*x1**2+0.72*x1-0.06\n",
            " ---> GPT2 Test Error: 8.69390\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 5.13741\n",
            "Genetic Model function:  mul(X0, sqrt(sqrt(div(X0, -0.671))))\n",
            " ---> GP Test Error: 2.70275\n",
            "Test case 626/1000.\n",
            "True equation: -0.57*x1**3\n",
            "GPT2 function:  -0.23*x1**2+0.23*x1\n",
            " ---> GPT2 Test Error: 3975.58093\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2037.38767\n",
            "Genetic Model function:  mul(mul(add(0.329, X0), -0.503), mul(X0, X0))\n",
            " ---> GP Test Error: 16.46050\n",
            "Test case 627/1000.\n",
            "True equation: -0.1*x1*sqrt(1-0.93*x1)-0.7\n",
            "GPT2 function:  -0.09*x1**2-0.41*x1+sin(0.2*x1-0.76)\n",
            " ---> GPT2 Test Error: 2.82773\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.04388\n",
            "Genetic Model function:  mul(-0.416, X0)\n",
            " ---> GP Test Error: 0.02433\n",
            "Test case 628/1000.\n",
            "True equation: sqrt(x1)+0.61*x1**2+0.08*x1-0.49\n",
            "GPT2 function:  0.53*x1**2+0.88*x1-0.65\n",
            " ---> GPT2 Test Error: 0.21275\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 95.25890\n",
            "Genetic Model function:  add(-0.442, sqrt(mul(exp(X0), X0)))\n",
            " ---> GP Test Error: 112.12372\n",
            "Test case 629/1000.\n",
            "True equation: 0.58*x1+sin(x1+0.54)-0.25\n",
            "GPT2 function:  0.34*x1+sin(x1+0.12)\n",
            " ---> GPT2 Test Error: 1.07268\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.41505\n",
            "Genetic Model function:  add(exp(-0.398), sin(sin(add(-0.215, X0))))\n",
            " ---> GP Test Error: 3.74804\n",
            "Test case 630/1000.\n",
            "True equation: sqrt(x1**2+0.27*x1)\n",
            "GPT2 function:  sqrt(x1**2+0.08*x1-0.06)\n",
            " ---> GPT2 Test Error: 0.00974\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.72184\n",
            "Genetic Model function:  sqrt(exp(log(add(mul(X0, X0), mul(0.282, X0)))))\n",
            " ---> GP Test Error: 0.00006\n",
            "Test case 631/1000.\n",
            "True equation: 0.94*sqrt(x1)+1.18*x1-0.4\n",
            "GPT2 function:  0.4*sqrt(x1)+1.17*x1-0.61\n",
            " ---> GPT2 Test Error: 2.02341\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.11329\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  add(sqrt(div(X0, 0.516)), add(X0, -0.649))\n",
            " ---> GP Test Error: 0.01967\n",
            "Test case 632/1000.\n",
            "True equation: 0.86*sqrt(-0.92*x1-1)\n",
            "GPT2 function:  0.85*sqrt(x1+0.96)\n",
            " ---> GPT2 Test Error: 0.00128\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.04391\n",
            "Genetic Model function:  sqrt(exp(mul(X0, 0.368)))\n",
            " ---> GP Test Error: 0.19740\n",
            "Test case 633/1000.\n",
            "True equation: sin(x1**2+0.15*x1-0.73)\n",
            "GPT2 function:  -sin(-x1**2+0.18*x1+0.72)\n",
            " ---> GPT2 Test Error: 0.94845\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.51383\n",
            "Genetic Model function:  sin(add(mul(X0, X0), -0.523))\n",
            " ---> GP Test Error: 0.11460\n",
            "Test case 634/1000.\n",
            "True equation: sqrt(x1**2-0.82*x1)\n",
            "GPT2 function:  sqrt(x1**2-0.96*x1+0.06)\n",
            " ---> GPT2 Test Error: 0.00468\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 3.22350\n",
            "Genetic Model function:  mul(sqrt(X0), sqrt(add(X0, -0.820)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 635/1000.\n",
            "True equation: 0.87*sqrt(x1**2)\n",
            "GPT2 function:  0.87*sqrt(x1**2-0.1*x1)\n",
            " ---> GPT2 Test Error: 0.00240\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00013\n",
            "Genetic Model function:  exp(log(log(exp(mul(div(0.876, X0), mul(X0, X0))))))\n",
            " ---> GP Test Error: 0.00052\n",
            "Test case 636/1000.\n",
            "True equation: sin(sin(x1))\n",
            "GPT2 function:  sin(sin(x1-0.1))\n",
            " ---> GPT2 Test Error: 0.00366\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.10008\n",
            "Genetic Model function:  sin(sin(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 637/1000.\n",
            "True equation: sin(sin(0.76*x1-0.51))\n",
            "GPT2 function:  sin(sin(0.72*x1-0.58))\n",
            " ---> GPT2 Test Error: 0.03203\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.45736\n",
            "Genetic Model function:  sin(log(add(X0, 0.332)))\n",
            " ---> GP Test Error: 0.96404\n",
            "Test case 638/1000.\n",
            "True equation: 0.46*x1*sin(0.17*x1)+0.6\n",
            "GPT2 function:  0.18*x1**2+0.02*x1\n",
            " ---> GPT2 Test Error: 5.18648\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.20390\n",
            "Genetic Model function:  mul(0.257, X0)\n",
            " ---> GP Test Error: 0.57654\n",
            "Test case 639/1000.\n",
            "True equation: 0.24*sqrt(-x1)\n",
            "GPT2 function:  0.24*sqrt(-x1)-sin(0.09*x1)\n",
            " ---> GPT2 Test Error: 0.17034\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00014\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  log(sqrt(sqrt(exp(log(exp(sqrt(X0)))))))\n",
            " ---> GP Test Error: 0.00015\n",
            "Test case 640/1000.\n",
            "True equation: x1\n",
            "GPT2 function:  x1-0.1\n",
            " ---> GPT2 Test Error: 0.01000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 3.26582\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  sqrt(mul(X0, X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 641/1000.\n",
            "True equation: 0.48*sqrt(-x1-0.78)\n",
            "GPT2 function:  0.49*sqrt(-x1-0.65)\n",
            " ---> GPT2 Test Error: 0.00013\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00213\n",
            "Genetic Model function:  sqrt(sqrt(mul(X0, -0.209)))\n",
            " ---> GP Test Error: 0.01602\n",
            "Test case 642/1000.\n",
            "True equation: x1+0.78*sqrt(-0.99*x1-1)\n",
            "GPT2 function:  1.23*x1+0.65\n",
            " ---> GPT2 Test Error: 0.02183\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 14.51430\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  add(0.775, div(X0, 0.775))\n",
            " ---> GP Test Error: 0.07932\n",
            "Test case 643/1000.\n",
            "True equation: sin(1.75*x1-0.12)\n",
            "GPT2 function:  sin(1.75*x1-0.29)\n",
            " ---> GPT2 Test Error: 0.01894\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.40518\n",
            "Genetic Model function:  sin(div(X0, 0.603))\n",
            " ---> GP Test Error: 0.06253\n",
            "Test case 644/1000.\n",
            "True equation: -sin(1.0*x1+0.86)\n",
            "GPT2 function:  -sin(x1+0.66)\n",
            " ---> GPT2 Test Error: 0.02041\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.48527\n",
            "Genetic Model function:  sin(mul(exp(sqrt(X0)), sin(log(-0.464))))\n",
            " ---> GP Test Error: 0.19765\n",
            "Test case 645/1000.\n",
            "True equation: 0.68*sqrt(x1)\n",
            "GPT2 function:  0.67*sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00075\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.03434\n",
            "Genetic Model function:  sqrt(mul(-0.454, X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 646/1000.\n",
            "True equation: 0.83*sqrt(0.26-x1)+sin(0.24*x1+0.12)\n",
            "GPT2 function:  0.16*x1+sqrt(x1-0.39)\n",
            " ---> GPT2 Test Error: 0.02707\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00906\n",
            "Genetic Model function:  sqrt(add(0.395, div(X0, -0.628)))\n",
            " ---> GP Test Error: 0.00149\n",
            "Test case 647/1000.\n",
            "True equation: (x1-0.37)**(1/4)\n",
            "GPT2 function:  (x1-0.47)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00008\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.02603\n",
            "Genetic Model function:  sqrt(sqrt(add(-0.358, X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 648/1000.\n",
            "True equation: 1.06*x1+0.09\n",
            "GPT2 function:  1.05*x1-0.01\n",
            " ---> GPT2 Test Error: 0.01850\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00005\n",
            "Genetic Model function:  div(X0, 0.911)\n",
            " ---> GP Test Error: 0.00945\n",
            "Test case 649/1000.\n",
            "True equation: 0.95*(-x1)**(1/4)\n",
            "GPT2 function:  0.95*(-x1)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.01367\n",
            "Genetic Model function:  sqrt(mul(sqrt(X0), sqrt(-0.812)))\n",
            " ---> GP Test Error: 0.00006\n",
            "Test case 650/1000.\n",
            "True equation: 0.7*x1*sqrt(0.52-x1)\n",
            "GPT2 function:  0.7*x1*sqrt(x1-0.62)-0.04\n",
            " ---> GPT2 Test Error: 0.01332\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.12172\n",
            "Genetic Model function:  div(sin(sin(mul(0.354, X0))), div(0.708, X0))\n",
            " ---> GP Test Error: 2.59213\n",
            "Test case 651/1000.\n",
            "True equation: 0.8*x1*sin(0.6*x1+0.78)-0.31\n",
            "GPT2 function:  0.69*sqrt(-x1-0.37)*sin(0.78*x1-0.47)\n",
            " ---> GPT2 Test Error: 2.58586\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 9.01433\n",
            "Genetic Model function:  mul(sin(sin(add(X0, -0.533))), sqrt(X0))\n",
            " ---> GP Test Error: 1.02953\n",
            "Test case 652/1000.\n",
            "True equation: sqrt(x1)+2*x1\n",
            "GPT2 function:  sqrt(x1)+2*x1-0.36\n",
            " ---> GPT2 Test Error: 0.12945\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 62.42942\n",
            "Genetic Model function:  add(add(X0, X0), sqrt(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 653/1000.\n",
            "True equation: 0.96*(-x1-0.71)**(1/4)\n",
            "GPT2 function:  0.94*(x1+0.39)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00269\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.01023\n",
            "Genetic Model function:  sqrt(sqrt(mul(add(X0, 0.581), log(log(log(0.514))))))\n",
            " ---> GP Test Error: 0.00020\n",
            "Test case 654/1000.\n",
            "True equation: 0.05*x1**(3/2)+0.39*x1**2\n",
            "GPT2 function:  0.29*x1**2*sqrt(-x1)-0.03*x1\n",
            " ---> GPT2 Test Error: 1.63346\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 27.70121\n",
            "Genetic Model function:  mul(add(X0, -0.614), mul(0.575, X0))\n",
            " ---> GP Test Error: 4.58523\n",
            "Test case 655/1000.\n",
            "True equation: x1+sin(x1)\n",
            "GPT2 function:  x1+sin(x1-0.19)\n",
            " ---> GPT2 Test Error: 0.01750\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.30182\n",
            "Genetic Model function:  add(X0, mul(sin(X0), div(X0, X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 656/1000.\n",
            "True equation: 1.37*x1+0.49\n",
            "GPT2 function:  1.36*x1+0.34\n",
            " ---> GPT2 Test Error: 0.03256\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 5.01015\n",
            "Genetic Model function:  add(log(add(sqrt(exp(X0)), 0.675)), X0)\n",
            " ---> GP Test Error: 0.04337\n",
            "Test case 657/1000.\n",
            "True equation: 1.37*sqrt(x1-0.27)\n",
            "GPT2 function:  1.37*sqrt(x1-0.37)\n",
            " ---> GPT2 Test Error: 0.00147\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.02380\n",
            "Genetic Model function:  sqrt(div(add(X0, -0.233), -0.544))\n",
            " ---> GP Test Error: 0.00045\n",
            "Test case 658/1000.\n",
            "True equation: sin(0.18*x1)\n",
            "GPT2 function:  0.18*sqrt(x1**2-0.33*x1)\n",
            " ---> GPT2 Test Error: 0.00563\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.01641\n",
            "Genetic Model function:  sin(sin(sqrt(mul(mul(X0, -0.145), mul(X0, 0.236)))))\n",
            " ---> GP Test Error: 0.00512\n",
            "Test case 659/1000.\n",
            "True equation: sqrt(sin(x1))\n",
            "GPT2 function:  sqrt(sin(x1-0.1))\n",
            " ---> GPT2 Test Error: 0.00409\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.02672\n",
            "Genetic Model function:  sqrt(sin(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 660/1000.\n",
            "True equation: x1**2+0.27*x1+sin(x1-0.26)\n",
            "GPT2 function:  x1**2+sin(x1-0.37)\n",
            " ---> GPT2 Test Error: 1.52872\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 54.98378\n",
            "Genetic Model function:  mul(sqrt(X0), add(X0, mul(X0, 0.950)))\n",
            " ---> GP Test Error: 14.82626\n",
            "Test case 661/1000.\n",
            "True equation: (x1+0.03)**(1/4)\n",
            "GPT2 function:  (x1-0.07)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00008\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.09634\n",
            "Genetic Model function:  sqrt(sqrt(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 662/1000.\n",
            "True equation: sin(sqrt(x1))\n",
            "GPT2 function:  sin(sqrt(x1-0.1))\n",
            " ---> GPT2 Test Error: 0.00016\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.01147\n",
            "Genetic Model function:  sin(log(exp(log(exp(sqrt(X0))))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 663/1000.\n",
            "True equation: -0.53*x1**2+0.42*x1\n",
            "GPT2 function:  -0.5*x1**2+0.61*x1-0.05\n",
            " ---> GPT2 Test Error: 2.08284\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 28.33216\n",
            "Genetic Model function:  mul(mul(X0, -0.564), add(X0, -0.907))\n",
            " ---> GP Test Error: 0.18992\n",
            "Test case 664/1000.\n",
            "True equation: -1.33*x1\n",
            "GPT2 function:  0.13-1.33*x1\n",
            " ---> GPT2 Test Error: 0.01819\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.46148\n",
            "Genetic Model function:  div(X0, -0.754)\n",
            " ---> GP Test Error: 0.00044\n",
            "Test case 665/1000.\n",
            "True equation: sin(0.74*sqrt(-x1))\n",
            "GPT2 function:  sin(0.74*sqrt(x1-0.1))\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.05664\n",
            "Genetic Model function:  sin(sqrt(mul(-0.565, X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 666/1000.\n",
            "True equation: -1.0*x1+0.1*sqrt(-x1)\n",
            "GPT2 function:  -0.96*x1+0.12*sqrt(-x1)\n",
            " ---> GPT2 Test Error: 0.04987\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.34897\n",
            "Genetic Model function:  mul(X0, -0.926)\n",
            " ---> GP Test Error: 0.01624\n",
            "Test case 667/1000.\n",
            "True equation: sin(sqrt(x1))\n",
            "GPT2 function:  sin(sqrt(x1-0.1))\n",
            " ---> GPT2 Test Error: 0.00016\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.07951\n",
            "Genetic Model function:  sin(sqrt(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 668/1000.\n",
            "True equation: sqrt(sin(x1+0.7))\n",
            "GPT2 function:  sqrt(sin(x1+0.6))\n",
            " ---> GPT2 Test Error: 0.00546\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.82564\n",
            "Genetic Model function:  sqrt(sin(add(0.694, X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 669/1000.\n",
            "True equation: sqrt(2)*sqrt(x1+0.26)\n",
            "GPT2 function:  sqrt(2)*sqrt(x1+0.16)\n",
            " ---> GPT2 Test Error: 0.00103\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.07397\n",
            "Genetic Model function:  sqrt(add(add(X0, X0), sin(0.556)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 670/1000.\n",
            "True equation: 0.27*x1+0.75*sqrt(0.64*x1+1)\n",
            "GPT2 function:  0.16*x1+0.67*sqrt(0.88*x1+1)\n",
            " ---> GPT2 Test Error: 0.24012\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.01081\n",
            "Genetic Model function:  sqrt(sqrt(add(-0.654, exp(X0))))\n",
            " ---> GP Test Error: 0.35776\n",
            "Test case 671/1000.\n",
            "True equation: x1**2+0.95*x1-0.83\n",
            "GPT2 function:  x1**2+0.64*x1-0.91\n",
            " ---> GPT2 Test Error: 2.23542\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 94.02788\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  add(add(-0.892, X0), mul(X0, X0))\n",
            " ---> GP Test Error: 0.03607\n",
            "Test case 672/1000.\n",
            "True equation: 2*x1**2-0.39\n",
            "GPT2 function:  2*x1**2-0.47*x1\n",
            " ---> GPT2 Test Error: 0.12845\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 277.34437\n",
            "Genetic Model function:  add(div(mul(X0, X0), 0.536), -0.204)\n",
            " ---> GP Test Error: 2.11699\n",
            "Test case 673/1000.\n",
            "True equation: -0.16*x1**2*sqrt(x1+0.95)\n",
            "GPT2 function:  0.13*x1**(3/2)-0.12*x1**2\n",
            " ---> GPT2 Test Error: 54.69657\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 30.39729\n",
            "Genetic Model function:  mul(mul(X0, X0), -0.283)\n",
            " ---> GP Test Error: 5.74028\n",
            "Test case 674/1000.\n",
            "True equation: sqrt(x1+0.45)\n",
            "GPT2 function:  sqrt(x1+0.35)\n",
            " ---> GPT2 Test Error: 0.00056\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.05026\n",
            "Genetic Model function:  sqrt(add(exp(add(-0.245, 0.257)), add(add(-0.052, X0), div(-0.496, 0.962))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 675/1000.\n",
            "True equation: sin(0.06*x1)\n",
            "GPT2 function:  0.05*x1\n",
            " ---> GPT2 Test Error: 0.00111\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00482\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  mul(mul(0.752, 0.039), add(X0, X0))\n",
            " ---> GP Test Error: 0.00006\n",
            "Test case 676/1000.\n",
            "True equation: sqrt(sin(x1-0.87))\n",
            "GPT2 function:  sqrt(sin(x1-0.97))\n",
            " ---> GPT2 Test Error: 0.00602\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.09782\n",
            "Genetic Model function:  sqrt(sin(add(-0.882, X0)))\n",
            " ---> GP Test Error: 0.00012\n",
            "Test case 677/1000.\n",
            "True equation: -0.91*x1**2-0.43*x1+sin(x1)+0.43\n",
            "GPT2 function:  -0.95*x1**2+sin(0.77*x1+0.39)\n",
            " ---> GPT2 Test Error: 0.74482\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 73.90189\n",
            "Genetic Model function:  add(sin(0.527), mul(sin(mul(X0, -0.582)), mul(X0, X0)))\n",
            " ---> GP Test Error: 481.40929\n",
            "Test case 678/1000.\n",
            "True equation: 0.12*x1**2+1.17*x1-0.38\n",
            "GPT2 function:  -0.1*x1**2*sin(x1+0.49)+0.58*x1-0.61\n",
            " ---> GPT2 Test Error: 36.02593\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 9.11723\n",
            "Genetic Model function:  0.045\n",
            " ---> GP Test Error: 9.89381\n",
            "Test case 679/1000.\n",
            "True equation: 2*x1*sin(x1)\n",
            "GPT2 function:  2*x1*sin(x1-0.07)\n",
            " ---> GPT2 Test Error: 0.18714\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 63.63130\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  mul(add(X0, X0), sin(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 680/1000.\n",
            "True equation: 0.24*x1**2-0.66\n",
            "GPT2 function:  0.72*x1-0.81*sin(0.31*x1-0.13)\n",
            " ---> GPT2 Test Error: 5.19211\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.45201\n",
            "Genetic Model function:  mul(mul(mul(X0, 0.376), add(X0, -0.604)), exp(-0.474))\n",
            " ---> GP Test Error: 0.00815\n",
            "Test case 681/1000.\n",
            "True equation: x1-sin(0.81*x1+0.99)\n",
            "GPT2 function:  0.23*x1**2+0.62*x1-0.91\n",
            " ---> GPT2 Test Error: 4.55329\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.16444\n",
            "Genetic Model function:  mul(log(X0), X0)\n",
            " ---> GP Test Error: 4.43102\n",
            "Test case 682/1000.\n",
            "True equation: -0.25*x1\n",
            "GPT2 function:  0\n",
            " ---> GPT2 Test Error: 0.01388\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.08834\n",
            "Genetic Model function:  log(div(X0, X0))\n",
            " ---> GP Test Error: 0.01388\n",
            "Test case 683/1000.\n",
            "True equation: sin(0.87*sqrt(x1-0.85))\n",
            "GPT2 function:  sin(0.83*sqrt(0.95-x1))\n",
            " ---> GPT2 Test Error: 0.00046\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.08546\n",
            "Genetic Model function:  sin(sqrt(mul(-0.762, add(X0, -0.852))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 684/1000.\n",
            "True equation: sin(sin(x1+0.24))\n",
            "GPT2 function:  sin(sin(x1+0.14))\n",
            " ---> GPT2 Test Error: 0.00336\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.54293\n",
            "Genetic Model function:  sin(sin(add(add(0.681, sqrt(sin(-0.126))), add(-0.791, X0))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 685/1000.\n",
            "True equation: 0.73*x1+0.16*sin(x1-0.16)\n",
            "GPT2 function:  0.9*x1-0.22*sin(0.98*x1)\n",
            " ---> GPT2 Test Error: 47.23167\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 10.22846\n",
            "Genetic Model function:  mul(X0, sin(sin(X0)))\n",
            " ---> GP Test Error: 0.26527\n",
            "Test case 686/1000.\n",
            "True equation: 0.64*x1**2+0.66*x1+0.55\n",
            "GPT2 function:  0.71*x1**2+0.74*x1+0.46\n",
            " ---> GPT2 Test Error: 3.31851\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 15.82588\n",
            "Genetic Model function:  add(mul(X0, X0), sin(sin(add(X0, 0.659))))\n",
            " ---> GP Test Error: 19.56315\n",
            "Test case 687/1000.\n",
            "True equation: 0.13*x1**2+1.02*x1\n",
            "GPT2 function:  0.27*x1**2+2*x1\n",
            " ---> GPT2 Test Error: 6569.75950\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 935.74493\n",
            "Genetic Model function:  mul(mul(X0, X0), log(div(exp(-0.672), X0)))\n",
            " ---> GP Test Error: 189.68443\n",
            "Test case 688/1000.\n",
            "True equation: -0.74*x1**2-0.85*x1-0.19\n",
            "GPT2 function:  -0.71*x1**2-0.71*x1-0.12\n",
            " ---> GPT2 Test Error: 1.70744\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 80.26097\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  mul(log(log(-0.661)), add(mul(X0, X0), sqrt(X0)))\n",
            " ---> GP Test Error: 1.25281\n",
            "Test case 689/1000.\n",
            "True equation: 0.45*sqrt(-x1**2)\n",
            "GPT2 function:  0.46*sqrt(x1)*sqrt(x1-0.08)\n",
            " ---> GPT2 Test Error: 0.00062\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.12143\n",
            "Genetic Model function:  sqrt(mul(sin(mul(X0, -0.210)), log(exp(X0))))\n",
            " ---> GP Test Error: 0.02761\n",
            "Test case 690/1000.\n",
            "True equation: sin(1.62*x1+0.08)\n",
            "GPT2 function:  sin(1.6*x1-0.06)\n",
            " ---> GPT2 Test Error: 0.03221\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 13.41432\n",
            "Genetic Model function:  sin(div(X0, 0.591))\n",
            " ---> GP Test Error: 0.03605\n",
            "Test case 691/1000.\n",
            "True equation: 2*sqrt(x1)\n",
            "GPT2 function:  sqrt(x1)+sqrt(x1-0.3)\n",
            " ---> GPT2 Test Error: 0.00537\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.14757\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  add(sqrt(X0), sqrt(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 692/1000.\n",
            "True equation: 0.56*sqrt(x1)\n",
            "GPT2 function:  0.72*sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.11031\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00260\n",
            "Genetic Model function:  sqrt(mul(mul(0.492, X0), exp(mul(-0.705, 0.668))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 693/1000.\n",
            "True equation: 0.03*x1+0.68\n",
            "GPT2 function:  0.65*x1**2-0.28*x1-0.09\n",
            " ---> GPT2 Test Error: 0.99719\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 29.42014\n",
            "Genetic Model function:  mul(add(-0.166, X0), mul(0.645, X0))\n",
            " ---> GP Test Error: 0.05359\n",
            "Test case 694/1000.\n",
            "True equation: 0.73*sqrt(x1+0.22)\n",
            "GPT2 function:  0.73*sqrt(x1+0.13)\n",
            " ---> GPT2 Test Error: 0.00054\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.13158\n",
            "Genetic Model function:  sqrt(div(add(0.240, X0), exp(0.627)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 695/1000.\n",
            "True equation: x1**2+x1-0.37\n",
            "GPT2 function:  x1**2+0.55*x1-0.43\n",
            " ---> GPT2 Test Error: 4.59326\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 39.89104\n",
            "Genetic Model function:  add(add(X0, add(-0.515, 0.820)), add(mul(X0, X0), mul(-0.730, 0.912)))\n",
            " ---> GP Test Error: 0.00008\n",
            "Test case 696/1000.\n",
            "True equation: sin(sin(x1-0.59))\n",
            "GPT2 function:  sin(sin(x1-0.69))\n",
            " ---> GPT2 Test Error: 0.00399\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.95375\n",
            "Genetic Model function:  sin(sin(add(X0, -0.581)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 697/1000.\n",
            "True equation: -0.53*x1**3-0.82*x1**2+0.74*x1\n",
            "GPT2 function:  -1.06*x1**3+0.17*x1\n",
            " ---> GPT2 Test Error: 286615.83160\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 304463.63992\n",
            "Genetic Model function:  mul(div(add(exp(X0), sin(log(mul(0.288, X0)))), div(-0.721, div(X0, 0.662))), sin(sin(mul(0.661, X0))))\n",
            " ---> GP Test Error: 2826502.15702\n",
            "Test case 698/1000.\n",
            "True equation: sqrt(x1)+0.38*x1**2+0.26*x1+0.02\n",
            "GPT2 function:  0.72*sqrt(x1)+x1-0.39\n",
            " ---> GPT2 Test Error: 37.91456\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 16.30871\n",
            "Genetic Model function:  sqrt(mul(mul(add(X0, 0.510), sqrt(X0)), exp(mul(X0, 0.589))))\n",
            " ---> GP Test Error: 6.89870\n",
            "Test case 699/1000.\n",
            "True equation: 0.54*x1\n",
            "GPT2 function:  0.82*x1**2-0.71*x1+0.06\n",
            " ---> GPT2 Test Error: 8.80973\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 180.98797\n",
            "Genetic Model function:  mul(mul(X0, 0.948), add(X0, -0.577))\n",
            " ---> GP Test Error: 0.45013\n",
            "Test case 700/1000.\n",
            "True equation: sqrt(x1+0.13)+sin(x1)\n",
            "GPT2 function:  sqrt(x1)+sin(x1-0.04)\n",
            " ---> GPT2 Test Error: 0.00128\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.21546\n",
            "Genetic Model function:  add(sin(X0), sqrt(add(0.235, X0)))\n",
            " ---> GP Test Error: 0.00057\n",
            "Test case 701/1000.\n",
            "True equation: -0.75*x1**2-0.38*x1+0.13*sqrt(1-0.88*x1)\n",
            "GPT2 function:  -0.59*x1**2*sqrt(x1-0.61)-0.24*x1+0.15\n",
            " ---> GPT2 Test Error: 3.31166\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 126.71287\n",
            "Genetic Model function:  mul(mul(X0, X0), mul(-0.295, X0))\n",
            " ---> GP Test Error: 54.13170\n",
            "Test case 702/1000.\n",
            "True equation: (x1+0.59)**(1/4)\n",
            "GPT2 function:  (x1+0.49)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00006\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.02042\n",
            "Genetic Model function:  sqrt(sqrt(add(sqrt(sin(log(0.063))), X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 703/1000.\n",
            "True equation: sin(sqrt(x1+0.54))\n",
            "GPT2 function:  sin(sqrt(x1+0.45))\n",
            " ---> GPT2 Test Error: 0.00015\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.40477\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  sqrt(sin(sqrt(add(X0, 0.206))))\n",
            " ---> GP Test Error: 0.02061\n",
            "Test case 704/1000.\n",
            "True equation: sqrt(x1+0.64)\n",
            "GPT2 function:  sqrt(x1+0.54)\n",
            " ---> GPT2 Test Error: 0.00056\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.02573\n",
            "Genetic Model function:  sqrt(add(X0, 0.643))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 705/1000.\n",
            "True equation: 0.32*x1**2+x1\n",
            "GPT2 function:  sqrt(x1)+0.36*x1**2-0.27*x1-0.18\n",
            " ---> GPT2 Test Error: 8.67066\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 30.31031\n",
            "Genetic Model function:  mul(add(X0, 0.313), sqrt(X0))\n",
            " ---> GP Test Error: 0.97331\n",
            "Test case 706/1000.\n",
            "True equation: sin(0.8*x1+0.63)\n",
            "GPT2 function:  sin(0.81*x1+0.54)\n",
            " ---> GPT2 Test Error: 0.00124\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.07360\n",
            "Genetic Model function:  sqrt(sin(add(0.379, X0)))\n",
            " ---> GP Test Error: 2.34616\n",
            "Test case 707/1000.\n",
            "True equation: sin(0.39*x1**2-0.09*x1)\n",
            "GPT2 function:  sin(0.39*x1**2-0.1*x1)\n",
            " ---> GPT2 Test Error: 0.01285\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 7.99381\n",
            "Genetic Model function:  sin(mul(mul(X0, 0.359), X0))\n",
            " ---> GP Test Error: 0.09248\n",
            "Test case 708/1000.\n",
            "True equation: sqrt(x1+0.28)\n",
            "GPT2 function:  sqrt(x1+0.18)\n",
            " ---> GPT2 Test Error: 0.00061\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.17659\n",
            "Genetic Model function:  sqrt(add(0.132, add(0.132, X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 709/1000.\n",
            "True equation: -sin(1.93*x1-0.16)\n",
            "GPT2 function:  -sin(1.85*x1-0.33)\n",
            " ---> GPT2 Test Error: 0.14527\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.45302\n",
            "Genetic Model function:  sin(div(X0, -0.546))\n",
            " ---> GP Test Error: 0.04342\n",
            "Test case 710/1000.\n",
            "True equation: (x1-0.76)**(1/4)\n",
            "GPT2 function:  (x1-0.86)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00010\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.17868\n",
            "Genetic Model function:  sqrt(sqrt(add(X0, -0.753)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 711/1000.\n",
            "True equation: sin(0.59*sqrt(x1))\n",
            "GPT2 function:  sin(0.61*sqrt(x1-0.1))\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.19074\n",
            "Genetic Model function:  sin(sqrt(log(sqrt(exp(add(mul(-0.308, X0), X0))))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 712/1000.\n",
            "True equation: 1.04*x1\n",
            "GPT2 function:  1.03*x1-0.1\n",
            " ---> GPT2 Test Error: 0.01991\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.70037\n",
            "Genetic Model function:  div(X0, 0.966)\n",
            " ---> GP Test Error: 0.00027\n",
            "Test case 713/1000.\n",
            "True equation: 0.5*x1**2-0.61*x1*sin(0.38*x1)\n",
            "GPT2 function:  0.49*x1**2*sin(0.4*x1-0.89)-0.02*x1\n",
            " ---> GPT2 Test Error: 7.24861\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 32.40094\n",
            "Genetic Model function:  mul(mul(X0, mul(0.458, X0)), log(add(exp(sin(-0.663)), div(mul(X0, -0.939), log(-0.093)))))\n",
            " ---> GP Test Error: 6.28264\n",
            "Test case 714/1000.\n",
            "True equation: sin(x1-0.78)\n",
            "GPT2 function:  sin(x1-0.88)\n",
            " ---> GPT2 Test Error: 0.00464\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.93536\n",
            "Genetic Model function:  sin(log(mul(mul(log(mul(log(sqrt(-0.213)), sqrt(sin(-0.400)))), sqrt(sin(-0.400))), exp(X0))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 715/1000.\n",
            "True equation: sqrt(x1-0.36)-sin(0.27*x1)\n",
            "GPT2 function:  0.72*(x1-0.43)**(1/4)\n",
            " ---> GPT2 Test Error: 0.01616\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.07497\n",
            "Genetic Model function:  sqrt(mul(X0, -0.281))\n",
            " ---> GP Test Error: 0.00122\n",
            "Test case 716/1000.\n",
            "True equation: 0.76*x1**2*sqrt(x1-0.81)\n",
            "GPT2 function:  0.76*x1**2*sqrt(x1-0.99)\n",
            " ---> GPT2 Test Error: 0.63587\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 743.12272\n",
            "Genetic Model function:  mul(mul(0.384, X0), add(0.231, mul(X0, X0)))\n",
            " ---> GP Test Error: 97.56591\n",
            "Test case 717/1000.\n",
            "True equation: -sin(sin(0.92*x1))\n",
            "GPT2 function:  -sin(sin(0.94*x1-0.1))\n",
            " ---> GPT2 Test Error: 0.00016\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.46491\n",
            "Genetic Model function:  sin(sin(mul(X0, -0.938)))\n",
            " ---> GP Test Error: 0.00256\n",
            "Test case 718/1000.\n",
            "True equation: sin(x1)**2\n",
            "GPT2 function:  sin(0.93*x1)*sin(x1-0.06)\n",
            " ---> GPT2 Test Error: 0.01827\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.73109\n",
            "Genetic Model function:  mul(sin(X0), sin(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 719/1000.\n",
            "True equation: sqrt(sin(x1))\n",
            "GPT2 function:  sqrt(sin(x1-0.1))\n",
            " ---> GPT2 Test Error: 0.00409\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.05387\n",
            "Genetic Model function:  sqrt(sin(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 720/1000.\n",
            "True equation: 0.14*x1**2*sin(0.78*x1)\n",
            "GPT2 function:  0.13*x1**2*sin(0.68*x1)\n",
            " ---> GPT2 Test Error: 1.36471\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 15.26708\n",
            "Genetic Model function:  mul(X0, mul(0.121, X0))\n",
            " ---> GP Test Error: 24.98092\n",
            "Test case 721/1000.\n",
            "True equation: sin(x1-0.3)\n",
            "GPT2 function:  sin(x1-0.4)\n",
            " ---> GPT2 Test Error: 0.00506\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.80945\n",
            "Genetic Model function:  sin(add(sin(-0.318), X0))\n",
            " ---> GP Test Error: 0.00011\n",
            "Test case 722/1000.\n",
            "True equation: 1.84*x1+0.53\n",
            "GPT2 function:  1.83*x1+0.36\n",
            " ---> GPT2 Test Error: 0.04653\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.08873\n",
            "Genetic Model function:  mul(add(X0, 0.322), div(0.378, 0.209))\n",
            " ---> GP Test Error: 0.01074\n",
            "Test case 723/1000.\n",
            "True equation: -0.3*x1**4+0.22*x1\n",
            "GPT2 function:  0.28*x1**3+x1**2\n",
            " ---> GPT2 Test Error: 49123.27918\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 12709.64442\n",
            "Genetic Model function:  mul(mul(mul(div(add(X0, -0.905), log(-0.430)), X0), X0), sin(mul(X0, 0.330)))\n",
            " ---> GP Test Error: 3316.65843\n",
            "Test case 724/1000.\n",
            "True equation: -0.51*x1**2*sin(0.5*x1)-0.46*x1\n",
            "GPT2 function:  -0.58*x1**2+0.07*x1*sin(0.7*x1+0.34)\n",
            " ---> GPT2 Test Error: 52.78910\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 22.24599\n",
            "Genetic Model function:  mul(mul(-0.361, X0), add(add(-0.533, X0), X0))\n",
            " ---> GP Test Error: 85.07100\n",
            "Test case 725/1000.\n",
            "True equation: -0.67*x1**2-1.39*x1-0.47\n",
            "GPT2 function:  -0.61*sqrt(x1)-1.59*x1**2-1.01*x1-0.12\n",
            " ---> GPT2 Test Error: 404.63122\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 69.85458\n",
            "Genetic Model function:  div(sqrt(X0), div(-0.604, add(X0, 0.542)))\n",
            " ---> GP Test Error: 12.70901\n",
            "Test case 726/1000.\n",
            "True equation: 0.81*x1**2*sqrt(-x1)\n",
            "GPT2 function:  0.66*x1**(5/2)\n",
            " ---> GPT2 Test Error: 59.00279\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 545.94882\n",
            "Genetic Model function:  mul(mul(X0, X0), sqrt(mul(X0, sin(sin(0.799)))))\n",
            " ---> GP Test Error: 0.01198\n",
            "Test case 727/1000.\n",
            "True equation: sqrt(sin(0.08*x1-0.26))\n",
            "GPT2 function:  0.5*sqrt(0.26*x1-1)\n",
            " ---> GPT2 Test Error: 0.00949\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.02846\n",
            "Genetic Model function:  0.377\n",
            " ---> GP Test Error: 0.02225\n",
            "Test case 728/1000.\n",
            "True equation: -sin(0.29*x1)\n",
            "GPT2 function:  -sin(0.28*x1-0.63)*sin(0.4*x1-0.04)\n",
            " ---> GPT2 Test Error: 0.17359\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.05856\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  mul(exp(mul(sqrt(-0.069), sin(add(-0.693, -0.209)))), sin(mul(-0.366, X0)))\n",
            " ---> GP Test Error: 0.03509\n",
            "Test case 729/1000.\n",
            "True equation: 1.02*x1\n",
            "GPT2 function:  1.03*x1-0.1\n",
            " ---> GPT2 Test Error: 0.00135\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.74966\n",
            "Genetic Model function:  div(mul(add(X0, X0), sin(0.435)), sqrt(add(0.700, -0.018)))\n",
            " ---> GP Test Error: 0.00063\n",
            "Test case 730/1000.\n",
            "True equation: 0.84*sqrt(0.53-x1)\n",
            "GPT2 function:  0.82*sqrt(x1-0.63)\n",
            " ---> GPT2 Test Error: 0.00307\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.39278\n",
            "Genetic Model function:  log(add(X0, 0.777))\n",
            " ---> GP Test Error: 0.00041\n",
            "Test case 731/1000.\n",
            "True equation: sqrt(sin(x1+0.22))\n",
            "GPT2 function:  sqrt(sin(x1+0.12))\n",
            " ---> GPT2 Test Error: 0.00390\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.73618\n",
            "Genetic Model function:  sqrt(sin(add(0.235, X0)))\n",
            " ---> GP Test Error: 0.00010\n",
            "Test case 732/1000.\n",
            "True equation: x1\n",
            "GPT2 function:  x1-0.1\n",
            " ---> GPT2 Test Error: 0.01000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.66180\n",
            "Genetic Model function:  sqrt(mul(X0, X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 733/1000.\n",
            "True equation: 0.26*sqrt(-x1-0.96)*sqrt(-0.95*x1-1)\n",
            "GPT2 function:  0.04*x1*sqrt(0.35*x1+1)+0.37\n",
            " ---> GPT2 Test Error: 0.52440\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.02510\n",
            "Genetic Model function:  sqrt(mul(0.285, X0))\n",
            " ---> GP Test Error: 0.06962\n",
            "Test case 734/1000.\n",
            "True equation: 0.5*x1+0.36\n",
            "GPT2 function:  0.47*x1+0.3\n",
            " ---> GPT2 Test Error: 0.03379\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.23119\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  sqrt(add(-0.159, X0))\n",
            " ---> GP Test Error: 0.33580\n",
            "Test case 735/1000.\n",
            "True equation: 0.56*sqrt(0.86-x1)\n",
            "GPT2 function:  0.59*sqrt(x1-0.97)\n",
            " ---> GPT2 Test Error: 0.00147\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.03389\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  mul(sqrt(log(-0.733)), sqrt(add(X0, -0.877)))\n",
            " ---> GP Test Error: 0.00011\n",
            "Test case 736/1000.\n",
            "True equation: 1.4*x1*sqrt(-x1)+0.78\n",
            "GPT2 function:  0.51*x1**2+0.93*x1+0.89*sqrt(-x1)-0.24\n",
            " ---> GPT2 Test Error: 3.28157\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 11.55527\n",
            "Genetic Model function:  mul(sqrt(X0), exp(sqrt(add(-0.444, X0))))\n",
            " ---> GP Test Error: 2.78978\n",
            "Test case 737/1000.\n",
            "True equation: 0.94*x1\n",
            "GPT2 function:  0.93*sqrt(-x1**2+0.1*x1)\n",
            " ---> GPT2 Test Error: 0.00511\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.04823\n",
            "Genetic Model function:  mul(X0, 0.932)\n",
            " ---> GP Test Error: 0.00023\n",
            "Test case 738/1000.\n",
            "True equation: sqrt(x1+0.35)-sin(0.04*x1+0.64)\n",
            "GPT2 function:  0.91*sqrt(x1)-0.1\n",
            " ---> GPT2 Test Error: 0.14020\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00046\n",
            "Genetic Model function:  sin(mul(0.529, X0))\n",
            " ---> GP Test Error: 0.97715\n",
            "Test case 739/1000.\n",
            "True equation: 0.19*x1**3-0.77*x1**2-0.43*x1\n",
            "GPT2 function:  0.34*x1**3+x1**2\n",
            " ---> GPT2 Test Error: 106300.01854\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 107535.97933\n",
            "Genetic Model function:  mul(add(add(exp(X0), mul(add(sin(X0), div(log(X0), sqrt(0.752))), log(sqrt(X0)))), log(-0.215)), X0)\n",
            " ---> GP Test Error: 346364.96755\n",
            "Test case 740/1000.\n",
            "True equation: -sin(0.06*x1)\n",
            "GPT2 function:  -sin(0.06*x1-0.02)\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.35874\n",
            "Genetic Model function:  mul(add(mul(sqrt(mul(X0, X0)), sin(exp(0.367))), mul(add(log(-0.481), div(0.694, X0)), mul(sin(X0), sqrt(0.168)))), log(log(sqrt(mul(0.416, -0.366)))))\n",
            " ---> GP Test Error: 0.00063\n",
            "Test case 741/1000.\n",
            "True equation: sin(0.84*x1)\n",
            "GPT2 function:  sin(0.84*x1-0.09)\n",
            " ---> GPT2 Test Error: 0.00538\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.63545\n",
            "Genetic Model function:  sin(mul(0.843, X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 742/1000.\n",
            "True equation: -0.27*x1**2\n",
            "GPT2 function:  -0.27*x1**2+0.08*x1\n",
            " ---> GPT2 Test Error: 0.11768\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 29.73938\n",
            "Genetic Model function:  mul(mul(X0, log(0.618)), sqrt(mul(log(sin(log(sin(-0.453)))), mul(X0, X0))))\n",
            " ---> GP Test Error: 0.00380\n",
            "Test case 743/1000.\n",
            "True equation: sin(0.74*x1+0.64)\n",
            "GPT2 function:  sin(0.74*x1+0.57)\n",
            " ---> GPT2 Test Error: 0.00253\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.04513\n",
            "Genetic Model function:  sqrt(sin(add(X0, 0.298)))\n",
            " ---> GP Test Error: 2.14721\n",
            "Test case 744/1000.\n",
            "True equation: x1-0.8\n",
            "GPT2 function:  x1-0.9\n",
            " ---> GPT2 Test Error: 0.01000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.61757\n",
            "Genetic Model function:  log(div(exp(X0), add(log(-0.258), -0.866)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 745/1000.\n",
            "True equation: 0.94*x1**2+0.32*x1-1.01\n",
            "GPT2 function:  x1**2+0.28*x1-1.01\n",
            " ---> GPT2 Test Error: 1.46035\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 171.99214\n",
            "Genetic Model function:  add(mul(X0, add(0.078, X0)), sin(-0.958))\n",
            " ---> GP Test Error: 0.23152\n",
            "Test case 746/1000.\n",
            "True equation: x1**2\n",
            "GPT2 function:  x1**2-0.02*x1\n",
            " ---> GPT2 Test Error: 0.00858\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 87.07615\n",
            "Genetic Model function:  mul(mul(X0, X0), div(X0, X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 747/1000.\n",
            "True equation: sin(0.26*sqrt(1-0.34*x1))\n",
            "GPT2 function:  -sin(0.07*x1-0.27)\n",
            " ---> GPT2 Test Error: 0.06583\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.24722\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  div(sqrt(mul(-0.753, X0)), add(div(X0, 0.973), exp(X0)))\n",
            " ---> GP Test Error: 0.02979\n",
            "Test case 748/1000.\n",
            "True equation: sqrt(x1)+sin(0.57*x1-0.85)\n",
            "GPT2 function:  sqrt(x1)+0.46*x1-0.99\n",
            " ---> GPT2 Test Error: 0.29434\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 3.94114\n",
            "Genetic Model function:  add(-0.302, X0)\n",
            " ---> GP Test Error: 2.14095\n",
            "Test case 749/1000.\n",
            "True equation: sin(0.48*x1**2)\n",
            "GPT2 function:  sin(0.47*x1**2-0.02*x1)\n",
            " ---> GPT2 Test Error: 0.04360\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 20.80952\n",
            "Genetic Model function:  sin(div(mul(X0, X0), exp(0.744)))\n",
            " ---> GP Test Error: 0.00340\n",
            "Test case 750/1000.\n",
            "True equation: -sin(0.03*x1)\n",
            "GPT2 function:  -sin(0.03*x1-0.02)\n",
            " ---> GPT2 Test Error: 0.00103\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00357\n",
            "Genetic Model function:  mul(mul(-0.425, X0), log(log(log(mul(-0.397, -0.137)))))\n",
            " ---> GP Test Error: 0.00045\n",
            "Test case 751/1000.\n",
            "True equation: sin(sin(0.29*x1))\n",
            "GPT2 function:  sin(sin(0.28*x1-0.03))\n",
            " ---> GPT2 Test Error: 0.00026\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00191\n",
            "Genetic Model function:  log(exp(sin(sin(mul(0.299, X0)))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 752/1000.\n",
            "True equation: sin(2*x1+0.18)\n",
            "GPT2 function:  sin(2*x1-0.02)\n",
            " ---> GPT2 Test Error: 0.01962\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.05446\n",
            "Genetic Model function:  sin(add(add(0.153, X0), add(0.040, X0)))\n",
            " ---> GP Test Error: 0.00006\n",
            "Test case 753/1000.\n",
            "True equation: 0.97*sqrt(1-0.37*x1)\n",
            "GPT2 function:  0.98*sqrt(0.35*x1-1)\n",
            " ---> GPT2 Test Error: 0.00352\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.68820\n",
            "Genetic Model function:  sin(sqrt(log(log(mul(-0.140, X0)))))\n",
            " ---> GP Test Error: 0.00273\n",
            "Test case 754/1000.\n",
            "True equation: 0.47*sqrt(1-0.07*x1)*sqrt(-x1-0.38)\n",
            "GPT2 function:  sin(0.49*sqrt(x1+0.33))\n",
            " ---> GPT2 Test Error: 0.00044\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.06980\n",
            "Genetic Model function:  sqrt(sqrt(mul(0.100, X0)))\n",
            " ---> GP Test Error: 0.00160\n",
            "Test case 755/1000.\n",
            "True equation: -0.31*x1**2+0.47*x1\n",
            "GPT2 function:  -0.51*x1**2*sin(0.48*x1-0.7)-0.05*x1\n",
            " ---> GPT2 Test Error: 25.78950\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 178.97473\n",
            "Genetic Model function:  mul(log(X0), add(sin(X0), mul(X0, -0.669)))\n",
            " ---> GP Test Error: 91.55352\n",
            "Test case 756/1000.\n",
            "True equation: sqrt(x1-0.44)\n",
            "GPT2 function:  sqrt(x1-0.54)\n",
            " ---> GPT2 Test Error: 0.00070\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.04714\n",
            "Genetic Model function:  sqrt(add(X0, -0.438))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 757/1000.\n",
            "True equation: sqrt(2)*sqrt(x1-0.4)\n",
            "GPT2 function:  sqrt(2)*sqrt(x1-0.5)\n",
            " ---> GPT2 Test Error: 0.00137\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.07296\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  sqrt(add(X0, add(add(-0.423, -0.365), X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 758/1000.\n",
            "True equation: sin(0.12*x1**2)\n",
            "GPT2 function:  sin(0.11*x1**2)\n",
            " ---> GPT2 Test Error: 0.04730\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.79822\n",
            "Genetic Model function:  mul(mul(0.331, X0), sin(mul(X0, 0.397)))\n",
            " ---> GP Test Error: 1.70478\n",
            "Test case 759/1000.\n",
            "True equation: 0.89*sqrt(x1+0.78)\n",
            "GPT2 function:  0.88*sqrt(x1+0.69)\n",
            " ---> GPT2 Test Error: 0.00281\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.19259\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  sqrt(log(add(sqrt(add(X0, 0.830)), exp(X0))))\n",
            " ---> GP Test Error: 0.00593\n",
            "Test case 760/1000.\n",
            "True equation: sqrt(x1**2+0.53*x1)\n",
            "GPT2 function:  sqrt(x1**2+0.36*x1-0.06)\n",
            " ---> GPT2 Test Error: 0.00813\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00574\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  div(add(X0, 0.211), 0.983)\n",
            " ---> GP Test Error: 0.00123\n",
            "Test case 761/1000.\n",
            "True equation: sin(0.87*sqrt(x1-0.85))\n",
            "GPT2 function:  sin(0.94*sqrt(0.95-x1))\n",
            " ---> GPT2 Test Error: 0.00093\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.29649\n",
            "Genetic Model function:  sin(sin(sqrt(add(-0.867, X0))))\n",
            " ---> GP Test Error: 0.03423\n",
            "Test case 762/1000.\n",
            "True equation: sin(sqrt(x1+0.02))\n",
            "GPT2 function:  sin(sqrt(x1-0.08))\n",
            " ---> GPT2 Test Error: 0.00014\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.03601\n",
            "Genetic Model function:  sin(sqrt(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 763/1000.\n",
            "True equation: -0.53*x1**4-0.01*x1+0.15\n",
            "GPT2 function:  0.2*x1**3-0.66*x1**2\n",
            " ---> GPT2 Test Error: 115956.07384\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 89357.07393\n",
            "Genetic Model function:  mul(mul(mul(add(X0, -0.014), -0.517), mul(X0, X0)), X0)\n",
            " ---> GP Test Error: 22.95034\n",
            "Test case 764/1000.\n",
            "True equation: sqrt(x1-0.41)+sin(x1)\n",
            "GPT2 function:  sqrt(x1-0.41)+sin(x1)\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.37238\n",
            "Genetic Model function:  add(sin(X0), sqrt(add(X0, -0.424)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 765/1000.\n",
            "True equation: x1*sin(x1-0.73)\n",
            "GPT2 function:  x1*sin(x1-0.75)-0.08\n",
            " ---> GPT2 Test Error: 0.00351\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 29.98743\n",
            "Genetic Model function:  add(-0.423, X0)\n",
            " ---> GP Test Error: 54.82950\n",
            "Test case 766/1000.\n",
            "True equation: 0.26*x1**2+0.99*x1-0.2\n",
            "GPT2 function:  0.91*x1*sqrt(-x1-0.05)-0.34\n",
            " ---> GPT2 Test Error: 1.59830\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 3.25966\n",
            "Genetic Model function:  mul(sqrt(X0), X0)\n",
            " ---> GP Test Error: 0.02411\n",
            "Test case 767/1000.\n",
            "True equation: 0.32*x1**4-0.28*x1+0.03\n",
            "GPT2 function:  0.25*x1**4\n",
            " ---> GPT2 Test Error: 5032.68141\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 32951.13980\n",
            "Genetic Model function:  mul(mul(X0, X0), sqrt(mul(mul(sqrt(X0), add(-0.886, X0)), X0)))\n",
            " ---> GP Test Error: 4423.81168\n",
            "Test case 768/1000.\n",
            "True equation: 0.92*sqrt(-0.18*x1**2+0.95*x1+1)\n",
            "GPT2 function:  0.89*sqrt(0.71*x1+1)\n",
            " ---> GPT2 Test Error: 0.59227\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.09445\n",
            "Genetic Model function:  exp(sqrt(mul(-0.043, X0)))\n",
            " ---> GP Test Error: 0.25118\n",
            "Test case 769/1000.\n",
            "True equation: x1**(3/2)-0.76\n",
            "GPT2 function:  1.1*x1-0.13*sqrt(x1-0.82)\n",
            " ---> GPT2 Test Error: 14.85468\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 34.09222\n",
            "Genetic Model function:  add(mul(mul(X0, 0.477), X0), -0.244)\n",
            " ---> GP Test Error: 4.53420\n",
            "Test case 770/1000.\n",
            "True equation: 0.73*sqrt(x1)\n",
            "GPT2 function:  0.74*sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00006\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.07930\n",
            "Genetic Model function:  sqrt(mul(X0, -0.526))\n",
            " ---> GP Test Error: 0.00006\n",
            "Test case 771/1000.\n",
            "True equation: x1**(1/4)\n",
            "GPT2 function:  (x1-0.1)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00010\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.04285\n",
            "Genetic Model function:  sqrt(sqrt(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 772/1000.\n",
            "True equation: 0.28*sqrt(-x1**2+0.5*x1)\n",
            "GPT2 function:  0.29*sqrt(x1**2-0.5*x1+0.1)\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00017\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  mul(0.262, X0)\n",
            " ---> GP Test Error: 0.00369\n",
            "Test case 773/1000.\n",
            "True equation: 2.28*x1-0.98\n",
            "GPT2 function:  2.27*x1-1.18\n",
            " ---> GPT2 Test Error: 0.06939\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.22255\n",
            "Genetic Model function:  mul(add(X0, -0.469), add(exp(0.290), 0.998))\n",
            " ---> GP Test Error: 0.01492\n",
            "Test case 774/1000.\n",
            "True equation: 2*x1\n",
            "GPT2 function:  2*x1-0.2\n",
            " ---> GPT2 Test Error: 0.04000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.06251\n",
            "Genetic Model function:  exp(log(add(X0, X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 775/1000.\n",
            "True equation: 2*x1\n",
            "GPT2 function:  2*x1-0.2\n",
            " ---> GPT2 Test Error: 0.04000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.58491\n",
            "Genetic Model function:  mul(add(X0, X0), div(X0, X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 776/1000.\n",
            "True equation: 0.74*x1**3\n",
            "GPT2 function:  -0.03*x1**2+0.93*x1\n",
            " ---> GPT2 Test Error: 7114.60835\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2030.71060\n",
            "Genetic Model function:  mul(div(X0, 0.665), mul(mul(X0, X0), sqrt(-0.243)))\n",
            " ---> GP Test Error: 0.00858\n",
            "Test case 777/1000.\n",
            "True equation: sin(sin(x1))\n",
            "GPT2 function:  sin(sin(x1-0.1))\n",
            " ---> GPT2 Test Error: 0.00366\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.27589\n",
            "Genetic Model function:  sin(sin(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 778/1000.\n",
            "True equation: 1.84*x1*sqrt(x1-0.8)+1.14\n",
            "GPT2 function:  2*x1*sqrt(x1-0.98)+0.82\n",
            " ---> GPT2 Test Error: 0.04982\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 51.93500\n",
            "Genetic Model function:  add(sqrt(sqrt(log(add(0.178, X0)))), mul(X0, X0))\n",
            " ---> GP Test Error: 25.07148\n",
            "Test case 779/1000.\n",
            "True equation: -0.25*x1**2+1.87*x1+0.04\n",
            "GPT2 function:  x1+sin(0.78*x1)-0.12\n",
            " ---> GPT2 Test Error: 1.56086\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.17761\n",
            "Genetic Model function:  add(X0, sin(sin(sin(mul(X0, 0.920)))))\n",
            " ---> GP Test Error: 1.98310\n",
            "Test case 780/1000.\n",
            "True equation: sqrt(x1)\n",
            "GPT2 function:  sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00057\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00070\n",
            "Genetic Model function:  sqrt(log(exp(X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 781/1000.\n",
            "True equation: 0.09*x1-0.21*sin(0.85*x1)\n",
            "GPT2 function:  -0.22*x1-0.33*sin(0.24*x1-0.02)\n",
            " ---> GPT2 Test Error: 2.94704\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.57485\n",
            "Genetic Model function:  mul(X0, -0.180)\n",
            " ---> GP Test Error: 1.58099\n",
            "Test case 782/1000.\n",
            "True equation: x1**2+x1+0.76\n",
            "GPT2 function:  x1**2+0.78*x1-sin(0.01*x1-0.74)\n",
            " ---> GPT2 Test Error: 1.29553\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 116.16947\n",
            "Genetic Model function:  add(mul(X0, X0), add(X0, 0.753))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 783/1000.\n",
            "True equation: -0.08*x1**2+0.93*x1-0.58\n",
            "GPT2 function:  -0.14*x1**2+0.9*x1-0.67\n",
            " ---> GPT2 Test Error: 2.64682\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.97035\n",
            "Genetic Model function:  mul(add(-0.665, X0), 0.710)\n",
            " ---> GP Test Error: 0.81151\n",
            "Test case 784/1000.\n",
            "True equation: sin(x1-0.89)*sin(x1+0.95)\n",
            "GPT2 function:  -0.01*x1+sin(x1-0.53)-0.12\n",
            " ---> GPT2 Test Error: 0.90916\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.44554\n",
            "Genetic Model function:  add(-0.789, sin(X0))\n",
            " ---> GP Test Error: 2.19606\n",
            "Test case 785/1000.\n",
            "True equation: -0.81*x1**2-0.08\n",
            "GPT2 function:  -0.9*x1**2+0.06*x1\n",
            " ---> GPT2 Test Error: 1.29849\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 78.82036\n",
            "Genetic Model function:  mul(mul(X0, X0), -0.866)\n",
            " ---> GP Test Error: 0.40700\n",
            "Test case 786/1000.\n",
            "True equation: 0.04*x1+0.41\n",
            "GPT2 function:  0.37*sqrt(0.29*x1+1)\n",
            " ---> GPT2 Test Error: 0.00017\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.20267\n",
            "Genetic Model function:  0.461\n",
            " ---> GP Test Error: 0.01400\n",
            "Test case 787/1000.\n",
            "True equation: sin(0.43*x1-0.1)\n",
            "GPT2 function:  sin(0.44*x1-0.13)\n",
            " ---> GPT2 Test Error: 0.00011\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.56232\n",
            "Genetic Model function:  mul(X0, 0.335)\n",
            " ---> GP Test Error: 0.55531\n",
            "Test case 788/1000.\n",
            "True equation: 0.67*sqrt(0.67*x1+1)\n",
            "GPT2 function:  0.66*sqrt(-0.67*x1-1)\n",
            " ---> GPT2 Test Error: 0.00073\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00085\n",
            "Genetic Model function:  sqrt(sqrt(mul(X0, 0.608)))\n",
            " ---> GP Test Error: 0.00570\n",
            "Test case 789/1000.\n",
            "True equation: 0.37*x1*sqrt(-x1)+0.47\n",
            "GPT2 function:  x1-sin(0.37*x1)-0.04\n",
            " ---> GPT2 Test Error: 0.19993\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.15424\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  mul(sqrt(sqrt(X0)), mul(0.547, X0))\n",
            " ---> GP Test Error: 0.14498\n",
            "Test case 790/1000.\n",
            "<class 'TypeError'> \n",
            "\n",
            " Error: sin(3.1-0.1)3.194), EQ:sin(x1-0.1)x194)\n",
            "Not calculated\n",
            "Test case 791/1000.\n",
            "True equation: 0.57*x1**3-0.86*x1-0.25\n",
            "GPT2 function:  -1.48*x1*sin(0.95*x1+0.09)\n",
            " ---> GPT2 Test Error: 835.53846\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 832.98609\n",
            "Genetic Model function:  mul(sin(X0), div(sin(X0), -0.513))\n",
            " ---> GP Test Error: 1180.69535\n",
            "Test case 792/1000.\n",
            "True equation: 1.19*x1**2+1.61*x1\n",
            "GPT2 function:  x1**2+1.52*x1-0.12\n",
            " ---> GPT2 Test Error: 24.57576\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 194.92383\n",
            "Genetic Model function:  add(mul(X0, X0), add(X0, X0))\n",
            " ---> GP Test Error: 7.11869\n",
            "Test case 793/1000.\n",
            "True equation: -0.61*x1\n",
            "GPT2 function:  0.04-0.65*x1\n",
            " ---> GPT2 Test Error: 0.01530\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.94331\n",
            "Genetic Model function:  mul(exp(-0.638), div(X0, -0.863))\n",
            " ---> GP Test Error: 0.00015\n",
            "Test case 794/1000.\n",
            "True equation: sqrt(x1)-0.07*x1\n",
            "GPT2 function:  0.93*sqrt(0.1-x1)\n",
            " ---> GPT2 Test Error: 0.02763\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.03090\n",
            "Genetic Model function:  add(sqrt(X0), mul(-0.069, X0))\n",
            " ---> GP Test Error: 0.00030\n",
            "Test case 795/1000.\n",
            "True equation: 2*x1-0.92\n",
            "GPT2 function:  2*x1-1.12\n",
            " ---> GPT2 Test Error: 0.04000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.60096\n",
            "Genetic Model function:  add(add(-0.122, X0), add(-0.796, X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 796/1000.\n",
            "True equation: 2.87*x1+0.22\n",
            "GPT2 function:  2.86*x1-0.07\n",
            " ---> GPT2 Test Error: 0.10265\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.66942\n",
            "Genetic Model function:  add(div(X0, 0.515), add(0.089, X0))\n",
            " ---> GP Test Error: 0.05218\n",
            "Test case 797/1000.\n",
            "True equation: x1**(3/2)\n",
            "GPT2 function:  x1*sqrt(x1-0.1)-0.06\n",
            " ---> GPT2 Test Error: 0.02824\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.55242\n",
            "Genetic Model function:  sqrt(mul(X0, mul(X0, X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 798/1000.\n",
            "True equation: -sin(0.96*x1**2-0.08*x1)\n",
            "GPT2 function:  -sin(0.95*x1**2-0.15*x1)\n",
            " ---> GPT2 Test Error: 0.21175\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 4.79670\n",
            "Genetic Model function:  sin(div(mul(mul(X0, X0), 0.391), sin(-0.437)))\n",
            " ---> GP Test Error: 0.15216\n",
            "Test case 799/1000.\n",
            "True equation: 0.58*x1**2+0.04*x1+sin(x1-0.54)\n",
            "GPT2 function:  0.39*x1**2+0.47*x1+sin(0.85*x1-0.65)\n",
            " ---> GPT2 Test Error: 4.41189\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 25.40004\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  mul(div(X0, 0.857), sqrt(X0))\n",
            " ---> GP Test Error: 1.43163\n",
            "Test case 800/1000.\n",
            "True equation: sin(0.76*x1)\n",
            "GPT2 function:  sin(0.76*x1-0.06)\n",
            " ---> GPT2 Test Error: 0.00192\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 3.88888\n",
            "Genetic Model function:  sin(mul(0.767, X0))\n",
            " ---> GP Test Error: 0.00088\n",
            "Test case 801/1000.\n",
            "<class 'TypeError'> \n",
            "\n",
            " Error: 0.97*sqrt(3.1)-0.1)**(1), EQ:0.97*sqrt(x1)-0.1)**(1)\n",
            "Not calculated\n",
            "Test case 802/1000.\n",
            "True equation: sin(x1-0.89)*sin(x1+0.74)\n",
            "GPT2 function:  sin(x1-0.96)*sin(x1+0.67)\n",
            " ---> GPT2 Test Error: 0.00255\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 4.19111\n",
            "Genetic Model function:  add(sin(X0), -0.662)\n",
            " ---> GP Test Error: 2.13019\n",
            "Test case 803/1000.\n",
            "True equation: 0.95*sqrt(x1-0.12)\n",
            "GPT2 function:  0.96*sqrt(0.22-x1)\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00748\n",
            "Genetic Model function:  sqrt(mul(-0.913, add(-0.152, X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 804/1000.\n",
            "True equation: x1**(3/2)\n",
            "GPT2 function:  x1*sqrt(x1-0.1)-0.08\n",
            " ---> GPT2 Test Error: 0.03535\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 7.68367\n",
            "Genetic Model function:  mul(sqrt(X0), X0)\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 805/1000.\n",
            "True equation: sqrt(-sin(0.24*x1-0.59))\n",
            "GPT2 function:  sqrt(sin(0.21*x1-0.67))\n",
            " ---> GPT2 Test Error: 0.03895\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.12101\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  sin(exp(mul(-0.519, X0)))\n",
            " ---> GP Test Error: 0.36427\n",
            "Test case 806/1000.\n",
            "True equation: 1.26*sqrt(x1-0.44)\n",
            "GPT2 function:  1.27*sqrt(0.54-x1)\n",
            " ---> GPT2 Test Error: 0.00029\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.91673\n",
            "Genetic Model function:  sqrt(add(add(-0.999, X0), sqrt(X0)))\n",
            " ---> GP Test Error: 0.03198\n",
            "Test case 807/1000.\n",
            "True equation: x1\n",
            "GPT2 function:  x1-0.1\n",
            " ---> GPT2 Test Error: 0.01000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00575\n",
            "Genetic Model function:  sqrt(mul(X0, X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 808/1000.\n",
            "True equation: -sin(0.22*x1)\n",
            "GPT2 function:  -0.24*x1+0.03*sqrt(-x1)\n",
            " ---> GPT2 Test Error: 0.04698\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.04922\n",
            "Genetic Model function:  mul(X0, sin(add(-0.540, 0.328)))\n",
            " ---> GP Test Error: 0.02209\n",
            "Test case 809/1000.\n",
            "True equation: -1.25*x1*sin(0.6*x1-0.56)\n",
            "GPT2 function:  -0.69*x1**2+x1+0.06*sqrt(x1-0.74)\n",
            " ---> GPT2 Test Error: 69.48164\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 5.01936\n",
            "Genetic Model function:  mul(div(X0, -0.935), log(X0))\n",
            " ---> GP Test Error: 23.34086\n",
            "Test case 810/1000.\n",
            "True equation: sin(0.42*sqrt(x1))\n",
            "GPT2 function:  sin(0.42*sqrt(x1-0.1))\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.01771\n",
            "Genetic Model function:  log(exp(sin(sqrt(mul(sqrt(sin(sqrt(sqrt(0.050)))), mul(X0, -0.260))))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 811/1000.\n",
            "True equation: sin(sin(x1+0.16))\n",
            "GPT2 function:  sin(sin(x1+0.06))\n",
            " ---> GPT2 Test Error: 0.00384\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.41432\n",
            "Genetic Model function:  sin(sin(add(X0, 0.156)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 812/1000.\n",
            "True equation: 1.73*x1-1.23\n",
            "GPT2 function:  1.74*x1-1.42\n",
            " ---> GPT2 Test Error: 0.01915\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.74278\n",
            "Genetic Model function:  add(log(sqrt(exp(-0.696))), add(div(X0, 0.576), log(0.408)))\n",
            " ---> GP Test Error: 0.00068\n",
            "Test case 813/1000.\n",
            "True equation: 0.5*x1+0.51*sin(0.08*x1)\n",
            "GPT2 function:  -0.39*x1+0.5*sin(0.05*x1)\n",
            " ---> GPT2 Test Error: 7.38582\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.72391\n",
            "Genetic Model function:  mul(sin(sqrt(mul(X0, 0.094))), mul(0.298, X0))\n",
            " ---> GP Test Error: 0.03255\n",
            "Test case 814/1000.\n",
            "True equation: 0.94*(-x1)**(1/4)\n",
            "GPT2 function:  0.94*(-x1-0.1)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.02440\n",
            "Genetic Model function:  sqrt(mul(sqrt(X0), sqrt(-0.786)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 815/1000.\n",
            "True equation: sqrt(sin(x1))\n",
            "GPT2 function:  sqrt(sin(x1-0.1))\n",
            " ---> GPT2 Test Error: 0.00409\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.19868\n",
            "Genetic Model function:  sqrt(sin(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 816/1000.\n",
            "True equation: sqrt(x1)+sqrt(x1-0.21)\n",
            "GPT2 function:  sqrt(x1)+sqrt(x1-0.21)\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.17995\n",
            "Genetic Model function:  add(sqrt(X0), sqrt(add(-0.229, X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 817/1000.\n",
            "True equation: 1.36*sqrt(x1)\n",
            "GPT2 function:  1.36*sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00062\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.07795\n",
            "Genetic Model function:  log(exp(sqrt(div(X0, 0.545))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 818/1000.\n",
            "True equation: x1**2+0.41*x1\n",
            "GPT2 function:  0.22*x1**2-0.92\n",
            " ---> GPT2 Test Error: 216.30079\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 127.18137\n",
            "Genetic Model function:  mul(mul(X0, add(mul(mul(X0, X0), sqrt(-0.164)), mul(log(add(-0.570, X0)), sin(0.036)))), sqrt(-0.164))\n",
            " ---> GP Test Error: 0.44519\n",
            "Test case 819/1000.\n",
            "True equation: sqrt(sin(x1))\n",
            "GPT2 function:  sqrt(sin(x1-0.1))\n",
            " ---> GPT2 Test Error: 0.00409\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.51662\n",
            "Genetic Model function:  sqrt(mul(div(X0, X0), sin(X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 820/1000.\n",
            "True equation: x1**2-0.21*x1+sqrt(x1+0.3)-0.62\n",
            "GPT2 function:  x1**2-0.18*x1+sin(0.43*x1-0.14)\n",
            " ---> GPT2 Test Error: 0.38042\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 255.27864\n",
            "Genetic Model function:  add(mul(X0, 0.252), mul(X0, X0))\n",
            " ---> GP Test Error: 0.29692\n",
            "Test case 821/1000.\n",
            "True equation: 0.84*sqrt(0.09*x1-1)\n",
            "GPT2 function:  sin(0.99*sqrt(0.12*x1-1))\n",
            " ---> GPT2 Test Error: 0.00164\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.47171\n",
            "Genetic Model function:  sin(exp(mul(X0, -0.073)))\n",
            " ---> GP Test Error: 0.00014\n",
            "Test case 822/1000.\n",
            "True equation: sin(x1-0.76)\n",
            "GPT2 function:  sin(x1-0.86)\n",
            " ---> GPT2 Test Error: 0.00505\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.69804\n",
            "Genetic Model function:  add(sin(add(-0.774, X0)), log(exp(0.004)))\n",
            " ---> GP Test Error: 0.00018\n",
            "Test case 823/1000.\n",
            "True equation: 0.68\n",
            "GPT2 function:  sin(0.76*sqrt(0.04*x1-1))\n",
            " ---> GPT2 Test Error: 0.00060\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00031\n",
            "Genetic Model function:  sin(sin(sqrt(add(0.732, -0.024))))\n",
            " ---> GP Test Error: 0.00046\n",
            "Test case 824/1000.\n",
            "True equation: 0.96*sqrt(-x1)\n",
            "GPT2 function:  0.96*sqrt(0.1-x1)\n",
            " ---> GPT2 Test Error: 0.00024\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.02612\n",
            "Genetic Model function:  mul(exp(-0.049), sqrt(X0))\n",
            " ---> GP Test Error: 0.00007\n",
            "Test case 825/1000.\n",
            "True equation: 1.31*x1-0.8\n",
            "GPT2 function:  1.31*x1-0.9\n",
            " ---> GPT2 Test Error: 0.00710\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.54008\n",
            "Genetic Model function:  mul(exp(0.226), add(X0, -0.567))\n",
            " ---> GP Test Error: 0.02590\n",
            "Test case 826/1000.\n",
            "True equation: -sin(0.93*x1**2)\n",
            "GPT2 function:  -sin(0.93*x1**2-0.1*x1)\n",
            " ---> GPT2 Test Error: 0.07805\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 41.64553\n",
            "Genetic Model function:  sin(mul(-0.468, exp(add(log(X0), log(add(sin(mul(-0.057, 0.846)), add(X0, X0)))))))\n",
            " ---> GP Test Error: 0.00489\n",
            "Test case 827/1000.\n",
            "True equation: sqrt(x1**2+0.81*x1)\n",
            "GPT2 function:  sqrt(x1**2+0.84*x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.92887\n",
            "Genetic Model function:  sqrt(add(sqrt(div(mul(X0, X0), log(0.210))), mul(X0, X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 828/1000.\n",
            "True equation: 0.38*x1+sin(0.35*x1)\n",
            "GPT2 function:  0.35*x1+sin(0.4*x1)-0.06\n",
            " ---> GPT2 Test Error: 0.06586\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.24069\n",
            "Genetic Model function:  mul(0.691, X0)\n",
            " ---> GP Test Error: 0.29355\n",
            "Test case 829/1000.\n",
            "True equation: sin(0.37*x1)\n",
            "GPT2 function:  sin(0.37*x1-0.02)\n",
            " ---> GPT2 Test Error: 0.00015\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.13709\n",
            "Genetic Model function:  sin(mul(mul(0.602, X0), 0.620))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 830/1000.\n",
            "True equation: sqrt(x1+0.05)\n",
            "GPT2 function:  sqrt(x1-0.05)\n",
            " ---> GPT2 Test Error: 0.00057\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.20725\n",
            "Genetic Model function:  sqrt(add(X0, 0.041))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 831/1000.\n",
            "True equation: sqrt(sin(x1))\n",
            "GPT2 function:  sqrt(sin(x1-0.1))\n",
            " ---> GPT2 Test Error: 0.00409\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.16005\n",
            "Genetic Model function:  sqrt(sin(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 832/1000.\n",
            "True equation: sqrt(x1+0.8)\n",
            "GPT2 function:  sqrt(x1+0.7)\n",
            " ---> GPT2 Test Error: 0.00047\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.90473\n",
            "Genetic Model function:  add(sin(mul(0.135, -0.403)), sqrt(add(0.967, X0)))\n",
            " ---> GP Test Error: 0.00035\n",
            "Test case 833/1000.\n",
            "True equation: 2*x1+0.98*sqrt(-x1)\n",
            "GPT2 function:  sqrt(x1)+sqrt(x1-0.27)\n",
            " ---> GPT2 Test Error: 51.18951\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.93423\n",
            "Genetic Model function:  add(sqrt(X0), div(X0, 0.505))\n",
            " ---> GP Test Error: 0.00245\n",
            "Test case 834/1000.\n",
            "True equation: 1.92*x1+sin(0.36*x1-0.46)-0.35\n",
            "GPT2 function:  2.25*x1-0.97\n",
            " ---> GPT2 Test Error: 0.03271\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.11079\n",
            "Genetic Model function:  add(add(-0.108, X0), div(add(-0.546, X0), sin(sqrt(0.831))))\n",
            " ---> GP Test Error: 0.10271\n",
            "Test case 835/1000.\n",
            "True equation: 0.29*x1\n",
            "GPT2 function:  0.27*sqrt(x1**2-0.1*x1)\n",
            " ---> GPT2 Test Error: 0.00962\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00046\n",
            "Genetic Model function:  mul(add(mul(0.074, X0), add(X0, X0)), add(add(-0.246, -0.278), sin(0.722)))\n",
            " ---> GP Test Error: 0.00023\n",
            "Test case 836/1000.\n",
            "True equation: 0.07*x1*sin(x1)-1.17\n",
            "GPT2 function:  -sin(1.03*x1-0.1)\n",
            " ---> GPT2 Test Error: 0.01264\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.74472\n",
            "Genetic Model function:  sin(div(X0, -0.996))\n",
            " ---> GP Test Error: 0.01475\n",
            "Test case 837/1000.\n",
            "True equation: x1+0.18*sqrt(-x1)\n",
            "GPT2 function:  0.72*x1**(3/2)-0.07\n",
            " ---> GPT2 Test Error: 0.03654\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 3.64768\n",
            "Genetic Model function:  mul(sqrt(add(0.233, X0)), mul(X0, 0.747))\n",
            " ---> GP Test Error: 0.12671\n",
            "Test case 838/1000.\n",
            "True equation: 0.74*sqrt(0.19*x1+1)+sin(0.68*x1+0.59)\n",
            "GPT2 function:  0.82*sqrt(x1+0.25)+0.91*sqrt(1-0.96*x1)\n",
            " ---> GPT2 Test Error: 8.76799\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.67652\n",
            "Genetic Model function:  sqrt(add(exp(sin(X0)), 0.846))\n",
            " ---> GP Test Error: 0.48758\n",
            "Test case 839/1000.\n",
            "True equation: -0.29*x1**2-0.5*x1*sqrt(x1-0.51)\n",
            "GPT2 function:  -0.81*x1**2+0.72*x1-0.03\n",
            " ---> GPT2 Test Error: 13.10130\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 92.06424\n",
            "Genetic Model function:  mul(X0, mul(-0.684, X0))\n",
            " ---> GP Test Error: 11.11703\n",
            "Test case 840/1000.\n",
            "True equation: sin(sqrt(x1))\n",
            "GPT2 function:  sin(sqrt(x1-0.1))\n",
            " ---> GPT2 Test Error: 0.00016\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.45795\n",
            "Genetic Model function:  sin(sqrt(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 841/1000.\n",
            "True equation: sin(x1**2+0.12*x1)\n",
            "GPT2 function:  sin(x1**2-0.06*x1)\n",
            " ---> GPT2 Test Error: 0.31826\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 4.54932\n",
            "Genetic Model function:  sin(div(mul(X0, X0), 0.955))\n",
            " ---> GP Test Error: 0.13414\n",
            "Test case 842/1000.\n",
            "True equation: 2*sqrt(x1)\n",
            "GPT2 function:  sqrt(x1)+sqrt(x1-0.3)\n",
            " ---> GPT2 Test Error: 0.00537\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.32424\n",
            "Genetic Model function:  add(sqrt(X0), sqrt(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 843/1000.\n",
            "True equation: x1+0.08*sqrt(-x1)\n",
            "GPT2 function:  0.47*x1*sqrt(-x1)-0.1\n",
            " ---> GPT2 Test Error: 0.01358\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.04900\n",
            "Genetic Model function:  add(mul(sqrt(X0), -0.403), X0)\n",
            " ---> GP Test Error: 1.12859\n",
            "Test case 844/1000.\n",
            "True equation: 0.07*x1**2-1.28*x1+0.24\n",
            "GPT2 function:  0.45-0.75*x1\n",
            " ---> GPT2 Test Error: 1.12952\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.09664\n",
            "Genetic Model function:  mul(-0.993, X0)\n",
            " ---> GP Test Error: 0.35583\n",
            "Test case 845/1000.\n",
            "True equation: 0.25*sqrt(x1)+2*x1\n",
            "GPT2 function:  x1**2+0.52*x1+sin(x1-0.09)\n",
            " ---> GPT2 Test Error: 16.00399\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 42.33933\n",
            "Genetic Model function:  mul(add(X0, add(X0, 0.239)), sqrt(X0))\n",
            " ---> GP Test Error: 0.00036\n",
            "Test case 846/1000.\n",
            "True equation: -0.24*x1**4+0.8*x1\n",
            "GPT2 function:  0.28*x1**3-0.15*x1**2\n",
            " ---> GPT2 Test Error: 23052.52945\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 13657.98462\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  mul(mul(mul(mul(-0.770, 0.072), add(X0, 0.867)), mul(add(X0, X0), mul(X0, X0))), log(X0))\n",
            " ---> GP Test Error: 251.16489\n",
            "Test case 847/1000.\n",
            "True equation: x1**(1/4)\n",
            "GPT2 function:  (x1-0.1)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00010\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.22743\n",
            "Genetic Model function:  sqrt(sqrt(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 848/1000.\n",
            "True equation: sin(0.18*x1-0.38)\n",
            "GPT2 function:  0.17*x1-0.38\n",
            " ---> GPT2 Test Error: 0.00128\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.05360\n",
            "Genetic Model function:  div(-0.429, exp(X0))\n",
            " ---> GP Test Error: 0.20766\n",
            "Test case 849/1000.\n",
            "True equation: 1.36*x1**2-0.35*x1\n",
            "GPT2 function:  1.37*x1**2-0.47*x1+0.04\n",
            " ---> GPT2 Test Error: 0.13118\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 270.33637\n",
            "Genetic Model function:  mul(sqrt(sqrt(X0)), mul(X0, X0))\n",
            " ---> GP Test Error: 23.74396\n",
            "Test case 850/1000.\n",
            "True equation: -0.08*x1-sin(0.75*x1)\n",
            "GPT2 function:  -0.9*sqrt(x1-0.11)*sin(0.76*x1-0.12)\n",
            " ---> GPT2 Test Error: 0.64114\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.04063\n",
            "Genetic Model function:  mul(sin(mul(-0.699, X0)), sqrt(log(0.253)))\n",
            " ---> GP Test Error: 0.04977\n",
            "Test case 851/1000.\n",
            "True equation: sqrt(-sin(0.68*x1-1.0))\n",
            "GPT2 function:  sqrt(sin(0.65*x1-0.98))\n",
            " ---> GPT2 Test Error: 0.00444\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.23780\n",
            "Genetic Model function:  sin(sin(exp(sin(X0))))\n",
            " ---> GP Test Error: 0.18257\n",
            "Test case 852/1000.\n",
            "True equation: sin(sqrt(x1+0.34))\n",
            "GPT2 function:  sin(sqrt(x1+0.24))\n",
            " ---> GPT2 Test Error: 0.00020\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.04534\n",
            "Genetic Model function:  sqrt(log(exp(sin(sqrt(X0)))))\n",
            " ---> GP Test Error: 0.01769\n",
            "Test case 853/1000.\n",
            "True equation: 1.0*x1+0.51\n",
            "GPT2 function:  x1+0.4\n",
            " ---> GPT2 Test Error: 0.00968\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.75735\n",
            "Genetic Model function:  add(0.505, X0)\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 854/1000.\n",
            "True equation: 0.53*sqrt(-0.14*x1-1)\n",
            "GPT2 function:  0.54*sqrt(0.1*x1+1)\n",
            " ---> GPT2 Test Error: 0.00063\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.12817\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  0.580\n",
            " ---> GP Test Error: 0.00973\n",
            "Test case 855/1000.\n",
            "True equation: -sin(0.51*x1**2)\n",
            "GPT2 function:  -sin(0.51*x1**2-0.08*x1)\n",
            " ---> GPT2 Test Error: 0.08766\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.37769\n",
            "Genetic Model function:  sin(mul(mul(X0, X0), sin(-0.537)))\n",
            " ---> GP Test Error: 0.00032\n",
            "Test case 856/1000.\n",
            "True equation: sqrt(x1-0.25)\n",
            "GPT2 function:  sqrt(x1-0.35)\n",
            " ---> GPT2 Test Error: 0.00068\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.02035\n",
            "Genetic Model function:  sqrt(add(-0.233, X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 857/1000.\n",
            "True equation: 0.29*x1**2-0.92*x1*sin(x1+0.46)\n",
            "GPT2 function:  0.01*x1-1.05*sin(x1-0.09)\n",
            " ---> GPT2 Test Error: 4.24398\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.64032\n",
            "Genetic Model function:  mul(-0.653, sin(div(X0, 0.852)))\n",
            " ---> GP Test Error: 2.63681\n",
            "Test case 858/1000.\n",
            "True equation: sqrt(-sin(0.72*x1+0.93))\n",
            "GPT2 function:  sqrt(sin(0.7*x1+0.87))\n",
            " ---> GPT2 Test Error: 0.00663\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.33769\n",
            "Genetic Model function:  sin(exp(sqrt(mul(X0, -0.312))))\n",
            " ---> GP Test Error: 1.23304\n",
            "Test case 859/1000.\n",
            "True equation: sin(x1)+sin(x1+0.75)\n",
            "GPT2 function:  sin(x1)+sin(x1+0.52)\n",
            " ---> GPT2 Test Error: 0.02603\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 3.67914\n",
            "Genetic Model function:  add(sin(add(X0, 0.756)), sin(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 860/1000.\n",
            "True equation: x1+sin(x1+0.36)\n",
            "GPT2 function:  0.94*x1+sin(x1+0.19)\n",
            " ---> GPT2 Test Error: 0.11095\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.91395\n",
            "Genetic Model function:  mul(sin(sqrt(X0)), exp(sin(sqrt(log(div(div(0.862, -0.892), exp(X0)))))))\n",
            " ---> GP Test Error: 5.97322\n",
            "Test case 861/1000.\n",
            "True equation: sin(sqrt(x1-0.2))\n",
            "GPT2 function:  sin(sqrt(x1-0.3))\n",
            " ---> GPT2 Test Error: 0.00014\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.32069\n",
            "Genetic Model function:  sin(sqrt(add(-0.231, X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 862/1000.\n",
            "True equation: -0.25*x1**2+0.43*x1+0.53\n",
            "GPT2 function:  -0.23*x1**2+0.17*x1+0.47\n",
            " ---> GPT2 Test Error: 0.83820\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 4.28349\n",
            "Genetic Model function:  sin(sin(sin(add(0.592, X0))))\n",
            " ---> GP Test Error: 8.59768\n",
            "Test case 863/1000.\n",
            "True equation: sin(sin(0.62*x1))\n",
            "GPT2 function:  sin(sin(0.62*x1-0.06))\n",
            " ---> GPT2 Test Error: 0.00229\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.62127\n",
            "Genetic Model function:  sin(sin(mul(0.627, X0)))\n",
            " ---> GP Test Error: 0.00065\n",
            "Test case 864/1000.\n",
            "True equation: sqrt(2)*sqrt(x1+0.34)\n",
            "GPT2 function:  sqrt(2)*sqrt(x1+0.25)\n",
            " ---> GPT2 Test Error: 0.00103\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.09693\n",
            "Genetic Model function:  sqrt(add(X0, add(X0, 0.659)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 865/1000.\n",
            "True equation: 0.42-0.93*x1\n",
            "GPT2 function:  0.49-0.93*x1\n",
            " ---> GPT2 Test Error: 0.00470\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00005\n",
            "Genetic Model function:  mul(-0.931, add(-0.449, X0))\n",
            " ---> GP Test Error: 0.00007\n",
            "Test case 866/1000.\n",
            "True equation: 0.27*x1+0.38\n",
            "GPT2 function:  0.31*x1+0.33\n",
            " ---> GPT2 Test Error: 0.02013\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00005\n",
            "Genetic Model function:  sqrt(mul(0.435, X0))\n",
            " ---> GP Test Error: 0.05093\n",
            "Test case 867/1000.\n",
            "True equation: -sin(sin(0.63*x1))\n",
            "GPT2 function:  -sin(sin(0.61*x1-0.07))\n",
            " ---> GPT2 Test Error: 0.01954\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.15918\n",
            "Genetic Model function:  sin(sin(mul(-0.632, X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 868/1000.\n",
            "True equation: 0.59*x1+sin(x1)-0.6\n",
            "GPT2 function:  0.34*x1+sin(x1-0.53)-0.18\n",
            " ---> GPT2 Test Error: 0.62271\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.35154\n",
            "Genetic Model function:  mul(sin(mul(X0, 0.771)), sqrt(X0))\n",
            " ---> GP Test Error: 7.18682\n",
            "Test case 869/1000.\n",
            "True equation: -sin(0.4*x1-0.71)\n",
            "GPT2 function:  -sin(0.37*x1-0.74)\n",
            " ---> GPT2 Test Error: 0.00515\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.08559\n",
            "Genetic Model function:  sin(div(add(mul(-0.204, X0), add(0.090, 0.282)), exp(-0.634)))\n",
            " ---> GP Test Error: 0.00025\n",
            "Test case 870/1000.\n",
            "True equation: sin(0.27*sqrt(-x1))\n",
            "GPT2 function:  sin(0.27*sqrt(x1-0.1))\n",
            " ---> GPT2 Test Error: 0.00006\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.01102\n",
            "Genetic Model function:  sqrt(sin(sin(mul(-0.066, X0))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 871/1000.\n",
            "True equation: -0.4*x1**2*sin(0.45*x1)\n",
            "GPT2 function:  -0.28*x1**2*sqrt(x1-0.2)\n",
            " ---> GPT2 Test Error: 69.55511\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.75400\n",
            "Genetic Model function:  mul(add(-0.859, X0), mul(X0, -0.549))\n",
            " ---> GP Test Error: 20.94154\n",
            "Test case 872/1000.\n",
            "True equation: 0.09*x1-0.81\n",
            "GPT2 function:  sin(0.11*x1-0.97)\n",
            " ---> GPT2 Test Error: 0.00458\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.16898\n",
            "Genetic Model function:  -0.667\n",
            " ---> GP Test Error: 0.08690\n",
            "Test case 873/1000.\n",
            "True equation: 1.16*x1**2+0.29\n",
            "GPT2 function:  0.95*x1**2+0.37\n",
            " ---> GPT2 Test Error: 5268.88259\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2169.34151\n",
            "Genetic Model function:  mul(add(mul(add(X0, 0.675), mul(X0, 0.710)), exp(-0.975)), X0)\n",
            " ---> GP Test Error: 4.44464\n",
            "Test case 874/1000.\n",
            "True equation: 0.32*x1+0.2*sqrt(1-0.16*x1)\n",
            "GPT2 function:  sin(sin(0.25*x1+0.2))\n",
            " ---> GPT2 Test Error: 0.03303\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.15991\n",
            "Genetic Model function:  mul(sqrt(-0.188), sqrt(X0))\n",
            " ---> GP Test Error: 0.09090\n",
            "Test case 875/1000.\n",
            "True equation: 0.02*x1+0.72*sqrt(-x1)-0.84\n",
            "GPT2 function:  0.52*x1-0.92\n",
            " ---> GPT2 Test Error: 0.49436\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.16895\n",
            "Genetic Model function:  sin(log(add(-0.114, sqrt(X0))))\n",
            " ---> GP Test Error: 0.03567\n",
            "Test case 876/1000.\n",
            "True equation: x1**2-0.59*x1+sqrt(x1+0.34)\n",
            "GPT2 function:  x1**2-0.76*x1+0.85*sqrt(-x1)+0.34\n",
            " ---> GPT2 Test Error: 0.72451\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 67.65228\n",
            "Genetic Model function:  add(div(add(X0, 0.561), exp(X0)), mul(X0, X0))\n",
            " ---> GP Test Error: 0.37235\n",
            "Test case 877/1000.\n",
            "True equation: 2*x1+0.48*sqrt(0.44-x1)\n",
            "GPT2 function:  1.07*x1*sqrt(x1-0.54)+0.39\n",
            " ---> GPT2 Test Error: 0.63554\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 23.23332\n",
            "Genetic Model function:  mul(sqrt(div(X0, -0.744)), X0)\n",
            " ---> GP Test Error: 0.14279\n",
            "Test case 878/1000.\n",
            "True equation: 1.52*sqrt(x1)\n",
            "GPT2 function:  1.62*sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.03215\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.13093\n",
            "Genetic Model function:  mul(add(sqrt(log(0.527)), sqrt(exp(-0.671))), sqrt(log(exp(X0))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 879/1000.\n",
            "True equation: x1+sqrt(x1+0.33)\n",
            "GPT2 function:  x1+sqrt(x1+0.35)-0.13\n",
            " ---> GPT2 Test Error: 0.01610\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.81893\n",
            "Genetic Model function:  add(X0, sqrt(add(sin(log(-0.030)), X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 880/1000.\n",
            "True equation: 0.98*(-0.56*x1-1)**(1/4)\n",
            "GPT2 function:  0.95*(0.59*x1+1)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00107\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.01540\n",
            "Genetic Model function:  sqrt(exp(sin(log(exp(mul(sin(0.926), mul(X0, 0.204)))))))\n",
            " ---> GP Test Error: 0.00348\n",
            "Test case 881/1000.\n",
            "True equation: sqrt(sin(0.24*x1+0.5))\n",
            "GPT2 function:  sin(0.19*x1+0.73)\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.02985\n",
            "Genetic Model function:  sin(sqrt(sqrt(X0)))\n",
            " ---> GP Test Error: 0.00018\n",
            "Test case 882/1000.\n",
            "<class 'TypeError'> \n",
            "\n",
            " Error: sin(3.1-0.1)3.1), EQ:sin(x1-0.1)x1)\n",
            "Not calculated\n",
            "Test case 883/1000.\n",
            "True equation: x1\n",
            "GPT2 function:  x1-0.1\n",
            " ---> GPT2 Test Error: 0.01000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00005\n",
            "Genetic Model function:  sqrt(mul(X0, X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 884/1000.\n",
            "True equation: x1**2+0.18*x1+0.94*sqrt(-x1)\n",
            "GPT2 function:  sqrt(x1)+x1**2+0.2\n",
            " ---> GPT2 Test Error: 0.24709\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 79.56167\n",
            "Genetic Model function:  add(mul(add(0.128, X0), X0), sqrt(X0))\n",
            " ---> GP Test Error: 0.00973\n",
            "Test case 885/1000.\n",
            "True equation: sqrt(x1)\n",
            "GPT2 function:  sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00057\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.24094\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  exp(log(sqrt(X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 886/1000.\n",
            "True equation: sin(0.43*x1-0.83)\n",
            "GPT2 function:  sin(0.39*x1-0.88)\n",
            " ---> GPT2 Test Error: 0.01196\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.02394\n",
            "Genetic Model function:  sin(add(sin(-0.953), mul(X0, 0.411)))\n",
            " ---> GP Test Error: 0.00047\n",
            "Test case 887/1000.\n",
            "True equation: sin(sin(0.22*x1))\n",
            "GPT2 function:  0.9*sqrt(0.09-x1)*sin(0.09*x1)\n",
            " ---> GPT2 Test Error: 0.02057\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.06231\n",
            "Genetic Model function:  sin(mul(X0, 0.211))\n",
            " ---> GP Test Error: 0.00708\n",
            "Test case 888/1000.\n",
            "True equation: sin(x1**2+0.84*x1)\n",
            "GPT2 function:  sin(x1**2+0.59*x1-0.06)\n",
            " ---> GPT2 Test Error: 0.64000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.48448\n",
            "Genetic Model function:  sin(add(mul(mul(X0, 0.921), 0.921), mul(X0, X0)))\n",
            " ---> GP Test Error: 0.00134\n",
            "Test case 889/1000.\n",
            "True equation: 0.32*sqrt(0.5*x1**2-x1)\n",
            "GPT2 function:  0.48*sqrt(1-0.1*x1)*sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.03528\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00646\n",
            "Genetic Model function:  0.214\n",
            " ---> GP Test Error: 0.30218\n",
            "Test case 890/1000.\n",
            "True equation: 1.2*x1+0.41\n",
            "GPT2 function:  1.18*x1+0.28\n",
            " ---> GPT2 Test Error: 0.04061\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 15.19297\n",
            "Genetic Model function:  add(0.434, div(X0, 0.844))\n",
            " ---> GP Test Error: 0.00070\n",
            "Test case 891/1000.\n",
            "True equation: sin(sin(x1+0.55))\n",
            "GPT2 function:  sin(sin(x1+0.45))\n",
            " ---> GPT2 Test Error: 0.00393\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.92876\n",
            "Genetic Model function:  sin(sin(add(exp(-0.680), add(0.039, X0))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 892/1000.\n",
            "True equation: 3*x1+1.23\n",
            "GPT2 function:  3*x1+0.92\n",
            " ---> GPT2 Test Error: 0.09000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.04287\n",
            "Genetic Model function:  add(sqrt(exp(0.440)), div(X0, 0.335))\n",
            " ---> GP Test Error: 0.00297\n",
            "Test case 893/1000.\n",
            "True equation: -0.43*x1**2-sin(0.25*x1-0.67)\n",
            "GPT2 function:  -0.39*x1**2-0.09*x1+0.66\n",
            " ---> GPT2 Test Error: 2.34926\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 86.31589\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  mul(div(X0, -0.867), log(X0))\n",
            " ---> GP Test Error: 3.55081\n",
            "Test case 894/1000.\n",
            "True equation: sqrt(x1)+x1\n",
            "GPT2 function:  sqrt(x1)+x1-0.39\n",
            " ---> GPT2 Test Error: 0.15194\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.03763\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  add(sqrt(X0), exp(log(X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 895/1000.\n",
            "True equation: sin(0.18*x1**2+0.58*x1+0.08)\n",
            "GPT2 function:  sin(0.25*x1**2+0.63*x1+0.02)\n",
            " ---> GPT2 Test Error: 0.98904\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 5.59446\n",
            "Genetic Model function:  sin(X0)\n",
            " ---> GP Test Error: 1.13278\n",
            "Test case 896/1000.\n",
            "True equation: -0.25*x1**2+0.67*x1+0.47\n",
            "GPT2 function:  0.9*sqrt(0.17*x1**2+x1+0.23)\n",
            " ---> GPT2 Test Error: 21.91268\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.97254\n",
            "Genetic Model function:  sqrt(sin(sin(add(0.197, X0))))\n",
            " ---> GP Test Error: 8.13698\n",
            "Test case 897/1000.\n",
            "True equation: x1+0.59\n",
            "GPT2 function:  x1+0.49\n",
            " ---> GPT2 Test Error: 0.01000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.57709\n",
            "Genetic Model function:  add(X0, 0.586)\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 898/1000.\n",
            "True equation: 2*x1+0.84\n",
            "GPT2 function:  2*x1+0.64\n",
            " ---> GPT2 Test Error: 0.04000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00355\n",
            "Genetic Model function:  add(add(add(X0, X0), mul(-0.178, -0.657)), add(0.470, 0.249))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 899/1000.\n",
            "<class 'TypeError'> \n",
            "\n",
            " Error: sin(3.1-0.1)3.1), EQ:sin(x1-0.1)x1)\n",
            "Not calculated\n",
            "Test case 900/1000.\n",
            "True equation: sin(2*x1+0.72)\n",
            "GPT2 function:  sin(2*x1+0.52)\n",
            " ---> GPT2 Test Error: 0.01937\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 13.48814\n",
            "Genetic Model function:  sin(add(exp(log(add(X0, X0))), sqrt(sqrt(div(add(0.158, 0.399), exp(0.735))))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 901/1000.\n",
            "True equation: -sin(sin(0.05*x1+0.64))\n",
            "GPT2 function:  -sin(sin(0.06*x1+0.64))\n",
            " ---> GPT2 Test Error: 0.00020\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00094\n",
            "Genetic Model function:  -0.611\n",
            " ---> GP Test Error: 0.00767\n",
            "Test case 902/1000.\n",
            "True equation: 0.86*sqrt(0.88*x1+1)\n",
            "GPT2 function:  0.86*sqrt(-x1-0.96)\n",
            " ---> GPT2 Test Error: 0.00933\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.01532\n",
            "Genetic Model function:  log(add(add(X0, -0.353), exp(0.941)))\n",
            " ---> GP Test Error: 0.00052\n",
            "Test case 903/1000.\n",
            "True equation: x1**2-0.68*x1\n",
            "GPT2 function:  1.03*x1-0.05\n",
            " ---> GPT2 Test Error: 229.95671\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 36.57477\n",
            "Genetic Model function:  mul(mul(0.994, X0), add(X0, -0.666))\n",
            " ---> GP Test Error: 0.00581\n",
            "Test case 904/1000.\n",
            "True equation: 0.05*x1**2\n",
            "GPT2 function:  0.04*x1**2\n",
            " ---> GPT2 Test Error: 0.01492\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.17952\n",
            "Genetic Model function:  mul(mul(add(X0, -0.350), 0.051), X0)\n",
            " ---> GP Test Error: 0.00349\n",
            "Test case 905/1000.\n",
            "True equation: -sin(0.26*x1**2)\n",
            "GPT2 function:  -sin(0.23*x1**2-0.04*x1)\n",
            " ---> GPT2 Test Error: 0.32171\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.29569\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  sin(mul(X0, mul(X0, -0.256)))\n",
            " ---> GP Test Error: 0.00426\n",
            "Test case 906/1000.\n",
            "True equation: sqrt(sin(x1+0.47))\n",
            "GPT2 function:  sqrt(sin(x1+0.37))\n",
            " ---> GPT2 Test Error: 0.00541\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.21018\n",
            "Genetic Model function:  sqrt(sin(add(add(X0, mul(-0.681, -0.468)), 0.138)))\n",
            " ---> GP Test Error: 0.00012\n",
            "Test case 907/1000.\n",
            "True equation: 0.43-0.13*x1\n",
            "GPT2 function:  -sin(0.14*x1-0.45)\n",
            " ---> GPT2 Test Error: 0.00139\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00005\n",
            "Genetic Model function:  div(sqrt(sqrt(div(log(-0.808), div(X0, X0)))), sqrt(exp(sqrt(exp(X0)))))\n",
            " ---> GP Test Error: 0.03684\n",
            "Test case 908/1000.\n",
            "True equation: x1**2-0.16*x1-0.1\n",
            "GPT2 function:  x1**2-0.39*x1-0.09\n",
            " ---> GPT2 Test Error: 1.14495\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 124.00591\n",
            "Genetic Model function:  mul(X0, add(add(-0.077, X0), -0.133))\n",
            " ---> GP Test Error: 0.02136\n",
            "Test case 909/1000.\n",
            "True equation: 0.49*x1+sin(0.82*x1)\n",
            "GPT2 function:  0.22*x1**2+sin(x1-0.09)\n",
            " ---> GPT2 Test Error: 7.88973\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.09992\n",
            "Genetic Model function:  log(log(exp(add(mul(0.610, X0), exp(X0)))))\n",
            " ---> GP Test Error: 0.18308\n",
            "Test case 910/1000.\n",
            "True equation: 0.8*x1**2\n",
            "GPT2 function:  0.7*x1**2-0.04*x1\n",
            " ---> GPT2 Test Error: 0.28567\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 19.40872\n",
            "Genetic Model function:  div(mul(X0, X0), exp(0.277))\n",
            " ---> GP Test Error: 3.06711\n",
            "Test case 911/1000.\n",
            "True equation: sin(0.56*x1+0.45)\n",
            "GPT2 function:  sin(0.58*x1+0.39)\n",
            " ---> GPT2 Test Error: 0.00156\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.16777\n",
            "Genetic Model function:  sin(sqrt(X0))\n",
            " ---> GP Test Error: 0.60512\n",
            "Test case 912/1000.\n",
            "True equation: 0.87*x1+0.72\n",
            "GPT2 function:  0.86*x1+0.62\n",
            " ---> GPT2 Test Error: 0.02435\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.22302\n",
            "Genetic Model function:  add(sqrt(0.560), mul(0.859, X0))\n",
            " ---> GP Test Error: 0.00129\n",
            "Test case 913/1000.\n",
            "True equation: sqrt(x1)\n",
            "GPT2 function:  sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00057\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.07295\n",
            "Genetic Model function:  sqrt(log(exp(X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 914/1000.\n",
            "True equation: sin(2*x1-0.59)\n",
            "GPT2 function:  sin(2*x1-0.79)\n",
            " ---> GPT2 Test Error: 0.01939\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.27236\n",
            "Genetic Model function:  sin(add(add(X0, -0.602), X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 915/1000.\n",
            "True equation: x1+sin(x1+0.23)\n",
            "GPT2 function:  0.84*x1+sin(x1+0.03)\n",
            " ---> GPT2 Test Error: 0.59726\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.21055\n",
            "Genetic Model function:  add(sin(add(add(0.102, X0), 0.136)), X0)\n",
            " ---> GP Test Error: 0.00009\n",
            "Test case 916/1000.\n",
            "True equation: -0.07*x1**(3/2)-0.95\n",
            "GPT2 function:  0.13-0.37*x1\n",
            " ---> GPT2 Test Error: 0.02318\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00017\n",
            "Genetic Model function:  sin(mul(X0, -0.526))\n",
            " ---> GP Test Error: 1.57475\n",
            "Test case 917/1000.\n",
            "<class 'TypeError'> \n",
            "\n",
            " Error: sin(3.1-0.1)3.1), EQ:sin(x1-0.1)x1)\n",
            "Not calculated\n",
            "Test case 918/1000.\n",
            "True equation: 0.91*sqrt(0.91*x1**2+x1+0.04)\n",
            "GPT2 function:  0.88*sqrt(x1**2+0.87*x1-0.05)\n",
            " ---> GPT2 Test Error: 0.00117\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 4.21106\n",
            "Genetic Model function:  add(0.203, X0)\n",
            " ---> GP Test Error: 0.13851\n",
            "Test case 919/1000.\n",
            "True equation: 0.38*x1**2+0.29*x1\n",
            "GPT2 function:  0.36*x1**2+0.37*x1-0.02\n",
            " ---> GPT2 Test Error: 0.01328\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 14.33903\n",
            "Genetic Model function:  mul(mul(X0, 0.728), sqrt(mul(mul(X0, 0.736), sqrt(X0))))\n",
            " ---> GP Test Error: 0.25461\n",
            "Test case 920/1000.\n",
            "True equation: 0.93*sqrt(x1-0.11)\n",
            "GPT2 function:  0.93*sqrt(x1-0.19)\n",
            " ---> GPT2 Test Error: 0.00065\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.02839\n",
            "Genetic Model function:  mul(0.905, sqrt(X0))\n",
            " ---> GP Test Error: 0.00130\n",
            "Test case 921/1000.\n",
            "True equation: sqrt(x1)\n",
            "GPT2 function:  sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00057\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.02600\n",
            "Genetic Model function:  div(sqrt(X0), div(X0, X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 922/1000.\n",
            "True equation: 0.74*sqrt(-x1)\n",
            "GPT2 function:  0.75*sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.03699\n",
            "Genetic Model function:  sqrt(mul(sqrt(add(mul(0.261, -0.656), exp(0.382))), log(sqrt(exp(X0)))))\n",
            " ---> GP Test Error: 0.00045\n",
            "Test case 923/1000.\n",
            "True equation: -sin(0.24*x1-0.14)\n",
            "GPT2 function:  -sin(0.25*x1-0.19)\n",
            " ---> GPT2 Test Error: 0.00008\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.09232\n",
            "Genetic Model function:  mul(-0.173, X0)\n",
            " ---> GP Test Error: 0.00134\n",
            "Test case 924/1000.\n",
            "True equation: 0.95*x1+sin(x1)-0.58\n",
            "GPT2 function:  x1+sin(x1)-0.76\n",
            " ---> GPT2 Test Error: 0.00402\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.91798\n",
            "Genetic Model function:  add(sin(add(X0, 0.036)), add(-0.662, X0))\n",
            " ---> GP Test Error: 0.02454\n",
            "Test case 925/1000.\n",
            "True equation: 0.32*x1**2*sin(0.54*x1)-0.12*x1\n",
            "GPT2 function:  0.38*x1**2-0.22\n",
            " ---> GPT2 Test Error: 43.08562\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.86026\n",
            "Genetic Model function:  mul(mul(X0, 0.382), add(X0, -0.815))\n",
            " ---> GP Test Error: 30.53832\n",
            "Test case 926/1000.\n",
            "True equation: 1.2*x1-0.31\n",
            "GPT2 function:  x1+sin(0.2*x1-0.44)\n",
            " ---> GPT2 Test Error: 0.02968\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00016\n",
            "Genetic Model function:  div(X0, 0.945)\n",
            " ---> GP Test Error: 0.14144\n",
            "Test case 927/1000.\n",
            "True equation: sin(2*x1)\n",
            "GPT2 function:  sin(2*x1-0.2)\n",
            " ---> GPT2 Test Error: 0.01955\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.82570\n",
            "Genetic Model function:  log(exp(sin(add(X0, X0))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 928/1000.\n",
            "True equation: 0.82*sqrt(-0.44*x1-1)\n",
            "GPT2 function:  0.81*sqrt(0.55*x1+1)\n",
            " ---> GPT2 Test Error: 0.00686\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.04738\n",
            "Genetic Model function:  sqrt(sqrt(mul(exp(sqrt(div(X0, 0.704))), log(sqrt(exp(-0.594))))))\n",
            " ---> GP Test Error: 0.00151\n",
            "Test case 929/1000.\n",
            "True equation: -sin(0.89*x1)\n",
            "GPT2 function:  -sin(0.88*x1-0.1)\n",
            " ---> GPT2 Test Error: 0.01079\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.65533\n",
            "Genetic Model function:  sin(mul(-0.896, X0))\n",
            " ---> GP Test Error: 0.00013\n",
            "Test case 930/1000.\n",
            "True equation: -sin(sin(0.44*x1-0.6))\n",
            "GPT2 function:  -sin(0.41*x1-0.61)\n",
            " ---> GPT2 Test Error: 0.01496\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.15414\n",
            "Genetic Model function:  add(0.561, mul(-0.406, X0))\n",
            " ---> GP Test Error: 0.34619\n",
            "Test case 931/1000.\n",
            "True equation: 1.3*sqrt(x1+0.07)\n",
            "GPT2 function:  1.31*sqrt(x1-0.05)\n",
            " ---> GPT2 Test Error: 0.00037\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.21978\n",
            "Genetic Model function:  sqrt(div(X0, 0.574))\n",
            " ---> GP Test Error: 0.00040\n",
            "Test case 932/1000.\n",
            "True equation: 0.2*x1+sqrt(x1-0.14)+0.34\n",
            "GPT2 function:  sqrt(x1)+0.3*x1+0.39\n",
            " ---> GPT2 Test Error: 0.31752\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.03152\n",
            "Genetic Model function:  sqrt(div(X0, 0.452))\n",
            " ---> GP Test Error: 0.03232\n",
            "Test case 933/1000.\n",
            "True equation: 0.56*(-0.12*x1-1)**(1/4)\n",
            "GPT2 function:  sin(0.61*sqrt(0.05*x1+1))\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00062\n",
            "Genetic Model function:  0.581\n",
            " ---> GP Test Error: 0.00166\n",
            "Test case 934/1000.\n",
            "True equation: x1+sin(x1-0.76)\n",
            "GPT2 function:  x1+sin(x1-0.97)\n",
            " ---> GPT2 Test Error: 0.02311\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.39496\n",
            "Genetic Model function:  add(sin(add(X0, -0.768)), sqrt(mul(X0, X0)))\n",
            " ---> GP Test Error: 0.00007\n",
            "Test case 935/1000.\n",
            "True equation: sin(0.08*x1)\n",
            "GPT2 function:  0.08*x1\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.08110\n",
            "Genetic Model function:  sin(mul(0.086, X0))\n",
            " ---> GP Test Error: 0.00010\n",
            "Test case 936/1000.\n",
            "True equation: 1.46*x1*sqrt(-x1)\n",
            "GPT2 function:  1.5*x1**(3/2)-0.12\n",
            " ---> GPT2 Test Error: 0.10404\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 14.41675\n",
            "Genetic Model function:  mul(mul(sqrt(X0), add(sqrt(0.533), sqrt(0.533))), exp(log(X0)))\n",
            " ---> GP Test Error: 0.00102\n",
            "Test case 937/1000.\n",
            "True equation: 0.95*(x1-0.81)**(1/4)\n",
            "GPT2 function:  0.96*(x1-0.92)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00012\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.15749\n",
            "Genetic Model function:  sqrt(sqrt(add(-0.848, X0)))\n",
            " ---> GP Test Error: 0.00522\n",
            "Test case 938/1000.\n",
            "True equation: sin(sin(x1+0.58))\n",
            "GPT2 function:  sin(sin(x1+0.48))\n",
            " ---> GPT2 Test Error: 0.00355\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.15410\n",
            "Genetic Model function:  sin(sin(add(sin(sqrt(0.380)), X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 939/1000.\n",
            "True equation: sqrt(x1)*sqrt(x1-0.11)\n",
            "GPT2 function:  sqrt(x1**2-0.1*x1)\n",
            " ---> GPT2 Test Error: 0.00009\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.35303\n",
            "Genetic Model function:  add(log(0.752), add(X0, 0.228))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 940/1000.\n",
            "<class 'TypeError'> \n",
            "\n",
            " Error: sin(3.1-0.1)3.1+0.1), EQ:sin(x1-0.1)x1+0.1)\n",
            "Not calculated\n",
            "Test case 941/1000.\n",
            "True equation: 1.08*sqrt(x1)\n",
            "GPT2 function:  1.08*sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00056\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.01496\n",
            "Genetic Model function:  sqrt(div(X0, -0.847))\n",
            " ---> GP Test Error: 0.00027\n",
            "Test case 942/1000.\n",
            "True equation: sqrt(x1)\n",
            "GPT2 function:  sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00057\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00523\n",
            "Genetic Model function:  sqrt(log(mul(div(X0, X0), exp(X0))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 943/1000.\n",
            "True equation: 0.21*x1**2+0.34*x1+0.13\n",
            "GPT2 function:  0.2*x1**2+0.29*x1+0.1\n",
            " ---> GPT2 Test Error: 0.16296\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 8.52325\n",
            "Genetic Model function:  exp(log(add(-0.267, X0)))\n",
            " ---> GP Test Error: 4.44052\n",
            "Test case 944/1000.\n",
            "<class 'TypeError'> \n",
            "\n",
            " Error: sin(3.1-0.1)3.1), EQ:sin(x1-0.1)x1)\n",
            "Not calculated\n",
            "Test case 945/1000.\n",
            "True equation: 0.95*sqrt(0.63*x1**2+x1-0.01)\n",
            "GPT2 function:  0.44*x1+sqrt(x1-0.11)\n",
            " ---> GPT2 Test Error: 0.01964\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.03272\n",
            "Genetic Model function:  mul(add(X0, 0.358), 0.847)\n",
            " ---> GP Test Error: 0.03778\n",
            "Test case 946/1000.\n",
            "True equation: 0.96*sqrt(x1**2)\n",
            "GPT2 function:  0.95*x1-0.1\n",
            " ---> GPT2 Test Error: 0.02419\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00010\n",
            "Genetic Model function:  mul(X0, 0.959)\n",
            " ---> GP Test Error: 0.00020\n",
            "Test case 947/1000.\n",
            "True equation: sin(0.89*x1)*sin(x1)\n",
            "GPT2 function:  sin(0.83*x1)*sin(x1-0.06)\n",
            " ---> GPT2 Test Error: 0.01375\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 3.77131\n",
            "Genetic Model function:  mul(sin(X0), sin(mul(0.867, X0)))\n",
            " ---> GP Test Error: 0.00114\n",
            "Test case 948/1000.\n",
            "True equation: -0.97*x1**2-0.78*x1+sqrt(x1+0.86)\n",
            "GPT2 function:  -0.89*x1**2-0.31*x1+0.94*sqrt(-0.83*x1-1)\n",
            " ---> GPT2 Test Error: 14.02630\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 120.10301\n",
            "Genetic Model function:  div(add(mul(X0, X0), -0.641), -0.902)\n",
            " ---> GP Test Error: 1.41933\n",
            "Test case 949/1000.\n",
            "True equation: 0.69*x1**2-0.66*x1\n",
            "GPT2 function:  0.49*x1**2-0.45*x1\n",
            " ---> GPT2 Test Error: 3448.47511\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 754.52375\n",
            "Genetic Model function:  mul(exp(-0.822), mul(mul(-0.862, X0), add(mul(X0, X0), -0.982)))\n",
            " ---> GP Test Error: 41.79531\n",
            "Test case 950/1000.\n",
            "True equation: 0.95*sqrt(x1)+0.43*x1-0.75\n",
            "GPT2 function:  sqrt(x1)+0.41*x1-0.97\n",
            " ---> GPT2 Test Error: 0.05348\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.62360\n",
            "Genetic Model function:  mul(0.861, add(X0, -0.291))\n",
            " ---> GP Test Error: 0.20430\n",
            "Test case 951/1000.\n",
            "True equation: x1-0.65\n",
            "GPT2 function:  x1-0.75\n",
            " ---> GPT2 Test Error: 0.01000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00054\n",
            "Genetic Model function:  div(add(X0, -0.645), div(X0, X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 952/1000.\n",
            "True equation: x1\n",
            "GPT2 function:  x1-0.1\n",
            " ---> GPT2 Test Error: 0.01000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00005\n",
            "Genetic Model function:  sqrt(mul(X0, X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 953/1000.\n",
            "True equation: sin(sin(x1))\n",
            "GPT2 function:  sin(sin(x1-0.1))\n",
            " ---> GPT2 Test Error: 0.00366\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.50193\n",
            "Genetic Model function:  sin(sin(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 954/1000.\n",
            "True equation: 2*x1-1.72\n",
            "GPT2 function:  2*x1-1.92\n",
            " ---> GPT2 Test Error: 0.04000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.72338\n",
            "Genetic Model function:  add(add(X0, -0.983), add(X0, -0.735))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 955/1000.\n",
            "True equation: sqrt(2)*sqrt(x1)\n",
            "GPT2 function:  sqrt(2)*sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00121\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.07336\n",
            "Genetic Model function:  sqrt(add(X0, X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 956/1000.\n",
            "True equation: 1.3*x1+0.26*sqrt(-x1)-0.24\n",
            "GPT2 function:  1.36*x1-0.43\n",
            " ---> GPT2 Test Error: 0.19983\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.14439\n",
            "Genetic Model function:  div(X0, 0.743)\n",
            " ---> GP Test Error: 0.00737\n",
            "Test case 957/1000.\n",
            "<class 'TypeError'> \n",
            "\n",
            " Error: sin(3.1-0.1)3.1), EQ:sin(x1-0.1)x1)\n",
            "Not calculated\n",
            "Test case 958/1000.\n",
            "True equation: 2*x1-0.27\n",
            "GPT2 function:  2*x1-0.47\n",
            " ---> GPT2 Test Error: 0.04000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00013\n",
            "Genetic Model function:  add(mul(sqrt(-0.966), -0.265), add(X0, X0))\n",
            " ---> GP Test Error: 0.00009\n",
            "Test case 959/1000.\n",
            "<class 'TypeError'> \n",
            "\n",
            " Error: sin(3.1-0.1)3.1), EQ:sin(x1-0.1)x1)\n",
            "Not calculated\n",
            "Test case 960/1000.\n",
            "True equation: 0.33*sqrt(0.36*x1**2-x1)\n",
            "GPT2 function:  0.3*sqrt(0.04*x1**2-x1+0.08)\n",
            " ---> GPT2 Test Error: 0.02424\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.50750\n",
            "Genetic Model function:  0.236\n",
            " ---> GP Test Error: 0.14494\n",
            "Test case 961/1000.\n",
            "True equation: 0.23-2.32*x1\n",
            "GPT2 function:  -2.16*x1**2-0.41\n",
            " ---> GPT2 Test Error: 294.72951\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 159.68539\n",
            "Genetic Model function:  div(sqrt(X0), sin(sin(sin(sin(mul(div(-0.781, X0), sin(0.458)))))))\n",
            " ---> GP Test Error: 10.17027\n",
            "Test case 962/1000.\n",
            "True equation: sin(1.6*x1)\n",
            "GPT2 function:  sin(1.58*x1-0.13)\n",
            " ---> GPT2 Test Error: 0.03049\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 4.56895\n",
            "Genetic Model function:  sin(add(mul(-0.394, X0), add(X0, X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 963/1000.\n",
            "True equation: 1.85*x1+0.33*sqrt(1-0.88*x1)\n",
            "GPT2 function:  1.89*x1*sqrt(-0.42*x1-1)+0.19\n",
            " ---> GPT2 Test Error: 0.83451\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 87.25627\n",
            "Genetic Model function:  sqrt(mul(add(sin(add(X0, 0.663)), mul(X0, X0)), mul(log(X0), add(X0, X0))))\n",
            " ---> GP Test Error: 5.71129\n",
            "Test case 964/1000.\n",
            "True equation: 0.33*x1\n",
            "GPT2 function:  0.36*sqrt(x1**2-0.03*x1)\n",
            " ---> GPT2 Test Error: 0.01243\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00007\n",
            "Genetic Model function:  sqrt(mul(mul(-0.621, X0), mul(0.175, X0)))\n",
            " ---> GP Test Error: 0.00063\n",
            "Test case 965/1000.\n",
            "True equation: 0.95*sqrt(0.55*x1+1)+sin(x1)\n",
            "GPT2 function:  0.55*x1+sin(x1+0.08)+0.77\n",
            " ---> GPT2 Test Error: 2.38592\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.60178\n",
            "Genetic Model function:  exp(sin(sin(mul(X0, 0.888))))\n",
            " ---> GP Test Error: 0.30006\n",
            "Test case 966/1000.\n",
            "True equation: sin(2*x1+0.09)\n",
            "GPT2 function:  sin(2*x1-0.11)\n",
            " ---> GPT2 Test Error: 0.01876\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.64379\n",
            "Genetic Model function:  sin(add(X0, X0))\n",
            " ---> GP Test Error: 0.00370\n",
            "Test case 967/1000.\n",
            "True equation: 1.32*x1\n",
            "GPT2 function:  1.34*x1-0.12\n",
            " ---> GPT2 Test Error: 0.00114\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.13677\n",
            "Genetic Model function:  div(mul(div(X0, 0.931), div(X0, X0)), sqrt(sin(exp(-0.316))))\n",
            " ---> GP Test Error: 0.00034\n",
            "Test case 968/1000.\n",
            "True equation: -0.85*x1**3\n",
            "GPT2 function:  -0.81*x1**3-0.18\n",
            " ---> GPT2 Test Error: 25.09365\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2813.29827\n",
            "Genetic Model function:  mul(mul(X0, X0), mul(-0.855, X0))\n",
            " ---> GP Test Error: 0.01938\n",
            "Test case 969/1000.\n",
            "True equation: 1.25*sqrt(x1+0.5)\n",
            "GPT2 function:  1.25*sqrt(x1+0.41)\n",
            " ---> GPT2 Test Error: 0.00070\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.04341\n",
            "Genetic Model function:  add(0.553, sqrt(X0))\n",
            " ---> GP Test Error: 0.01669\n",
            "Test case 970/1000.\n",
            "True equation: 0.06*x1**2+0.77*x1+0.16\n",
            "GPT2 function:  0.58*x1**2+0.24*x1+0.03\n",
            " ---> GPT2 Test Error: 7.21639\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 61.81065\n",
            "Genetic Model function:  mul(0.689, mul(X0, X0))\n",
            " ---> GP Test Error: 1.79765\n",
            "Test case 971/1000.\n",
            "True equation: 0.88*x1*sqrt(x1+0.22)\n",
            "GPT2 function:  0.9*x1*sqrt(-x1)-0.1\n",
            " ---> GPT2 Test Error: 0.01494\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 8.05525\n",
            "Genetic Model function:  exp(mul(log(X0), exp(0.344)))\n",
            " ---> GP Test Error: 0.12957\n",
            "Test case 972/1000.\n",
            "True equation: sqrt(sin(x1+0.94))\n",
            "GPT2 function:  sqrt(sin(x1+0.84))\n",
            " ---> GPT2 Test Error: 0.00476\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.50858\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  sqrt(sin(add(X0, sin(div(div(-0.996, -0.705), sqrt(0.577))))))\n",
            " ---> GP Test Error: 0.00016\n",
            "Test case 973/1000.\n",
            "True equation: sin(0.55*x1**2+0.36*x1)\n",
            "GPT2 function:  sin(0.55*x1**2+0.04*x1-0.02)\n",
            " ---> GPT2 Test Error: 0.89788\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 15.87205\n",
            "Genetic Model function:  sin(mul(X0, sin(mul(X0, add(0.543, 0.939)))))\n",
            " ---> GP Test Error: 0.88929\n",
            "Test case 974/1000.\n",
            "True equation: 1.46*x1-0.4\n",
            "GPT2 function:  1.5*x1-0.55\n",
            " ---> GPT2 Test Error: 0.00113\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 2.07388\n",
            "Genetic Model function:  add(sqrt(X0), add(-0.905, X0))\n",
            " ---> GP Test Error: 0.28446\n",
            "Test case 975/1000.\n",
            "True equation: sin(0.77*x1+0.53)\n",
            "GPT2 function:  sin(0.81*x1+0.45)\n",
            " ---> GPT2 Test Error: 0.00181\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.16067\n",
            "Genetic Model function:  sqrt(sin(add(0.217, X0)))\n",
            " ---> GP Test Error: 2.22300\n",
            "Test case 976/1000.\n",
            "True equation: sin(0.62*sqrt(-x1))\n",
            "GPT2 function:  sin(0.62*sqrt(x1-0.11))\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.02361\n",
            "Genetic Model function:  sin(div(sqrt(X0), exp(0.496)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 977/1000.\n",
            "True equation: sin(sqrt(x1-0.2))\n",
            "GPT2 function:  sin(sqrt(x1-0.3))\n",
            " ---> GPT2 Test Error: 0.00014\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.26636\n",
            "Genetic Model function:  sin(sqrt(add(-0.191, X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 978/1000.\n",
            "True equation: -sin(0.27*x1**2+0.37*x1+0.08)\n",
            "GPT2 function:  -sin(0.26*x1**2+0.26*x1+0.04)\n",
            " ---> GPT2 Test Error: 0.32379\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.54910\n",
            "Genetic Model function:  sin(mul(mul(-0.647, X0), sqrt(add(X0, 0.378))))\n",
            " ---> GP Test Error: 0.55365\n",
            "Test case 979/1000.\n",
            "True equation: x1\n",
            "GPT2 function:  x1-0.1\n",
            " ---> GPT2 Test Error: 0.01000\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.09711\n",
            "Genetic Model function:  sqrt(div(mul(X0, X0), div(X0, X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 980/1000.\n",
            "True equation: 0.22*sqrt(-x1)\n",
            "GPT2 function:  sqrt(sin(0.05*x1-0.02))\n",
            " ---> GPT2 Test Error: 0.00193\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.04560\n",
            "Genetic Model function:  sqrt(mul(mul(-0.365, X0), log(-0.866)))\n",
            " ---> GP Test Error: 0.00009\n",
            "Test case 981/1000.\n",
            "True equation: 0.11*x1**3-0.1\n",
            "GPT2 function:  0.12*x1**3+0.12*x1\n",
            " ---> GPT2 Test Error: 0.24096\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 92.73036\n",
            "Genetic Model function:  mul(add(X0, -0.694), mul(X0, 0.506))\n",
            " ---> GP Test Error: 28.73317\n",
            "Test case 982/1000.\n",
            "<class 'TypeError'> \n",
            "\n",
            " Error: sin(3.1-0.1)3.1), EQ:sin(x1-0.1)x1)\n",
            "Not calculated\n",
            "Test case 983/1000.\n",
            "True equation: 0.93*x1-1.15\n",
            "GPT2 function:  0.6*x1-1.22\n",
            " ---> GPT2 Test Error: 2.52412\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.01019\n",
            "Genetic Model function:  mul(sqrt(-0.842), add(add(X0, -0.854), -0.385))\n",
            " ---> GP Test Error: 0.00123\n",
            "Test case 984/1000.\n",
            "True equation: 0.36*x1-0.51\n",
            "GPT2 function:  sin(0.38*x1-0.58)\n",
            " ---> GPT2 Test Error: 0.11312\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.54574\n",
            "Genetic Model function:  add(-0.498, mul(X0, 0.356))\n",
            " ---> GP Test Error: 0.00046\n",
            "Test case 985/1000.\n",
            "True equation: sqrt(x1)\n",
            "GPT2 function:  sqrt(x1-0.1)\n",
            " ---> GPT2 Test Error: 0.00057\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 1.44485\n",
            "Genetic Model function:  sqrt(exp(log(X0)))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 986/1000.\n",
            "True equation: 1.04*x1-0.58\n",
            "GPT2 function:  1.04*x1-0.69\n",
            " ---> GPT2 Test Error: 0.01623\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 3.61203\n",
            "Genetic Model function:  add(-0.511, X0)\n",
            " ---> GP Test Error: 0.01839\n",
            "Test case 987/1000.\n",
            "True equation: 0.15*x1**2-sin(0.31*x1+0.83)\n",
            "GPT2 function:  0.06*x1**2+0.17*x1-0.81\n",
            " ---> GPT2 Test Error: 1.80165\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 7.22586\n",
            "Genetic Model function:  sin(sin(sin(add(mul(X0, 0.739), log(0.146)))))\n",
            " ---> GP Test Error: 4.72732\n",
            "Test case 988/1000.\n",
            "True equation: 0.69*sqrt(0.26*x1-1)+0.83*sqrt(0.83*x1-1)\n",
            "GPT2 function:  sqrt(x1-0.68)-sin(0.12*x1-0.68)\n",
            " ---> GPT2 Test Error: 0.20228\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.06219\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  exp(0.181)\n",
            " ---> GP Test Error: 0.31062\n",
            "Test case 989/1000.\n",
            "True equation: 1.0*sqrt(0.99*x1**2+x1+0.14)\n",
            "GPT2 function:  sqrt(x1**2+0.85*x1+0.05)\n",
            " ---> GPT2 Test Error: 0.00618\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.05467\n",
            "Genetic Model function:  add(X0, 0.478)\n",
            " ---> GP Test Error: 0.00015\n",
            "Test case 990/1000.\n",
            "True equation: 0.96*sqrt(0.43*x1+1)\n",
            "GPT2 function:  0.92*sqrt(0.48*x1+1)\n",
            " ---> GPT2 Test Error: 0.00033\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.02481\n",
            "Genetic Model function:  sqrt(sqrt(add(0.821, X0)))\n",
            " ---> GP Test Error: 0.02077\n",
            "Test case 991/1000.\n",
            "True equation: sin(0.4*x1-0.59)\n",
            "GPT2 function:  sin(0.42*x1-0.64)\n",
            " ---> GPT2 Test Error: 0.00005\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00934\n",
            "Genetic Model function:  sin(log(sqrt(add(X0, -0.314))))\n",
            " ---> GP Test Error: 0.06185\n",
            "Test case 992/1000.\n",
            "True equation: sin(x1+0.24)\n",
            "GPT2 function:  sin(x1+0.14)\n",
            " ---> GPT2 Test Error: 0.00432\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.87084\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gplearn/functions.py:127: RuntimeWarning: overflow encountered in true_divide\n",
            "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Genetic Model function:  log(exp(sin(add(0.243, X0))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 993/1000.\n",
            "True equation: sin(0.25*x1+0.16)\n",
            "GPT2 function:  0.2*x1+0.14\n",
            " ---> GPT2 Test Error: 0.02545\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.06177\n",
            "Genetic Model function:  sqrt(mul(-0.188, X0))\n",
            " ---> GP Test Error: 0.00189\n",
            "Test case 994/1000.\n",
            "True equation: (x1+0.8)**(1/4)\n",
            "GPT2 function:  (x1+0.7)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00006\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.05216\n",
            "Genetic Model function:  sqrt(sqrt(add(sqrt(log(-0.499)), add(X0, -0.039))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 995/1000.\n",
            "True equation: x1**(1/4)\n",
            "GPT2 function:  (x1-0.1)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00010\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.03146\n",
            "Genetic Model function:  sqrt(sqrt(X0))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 996/1000.\n",
            "True equation: (x1+0.46)**(1/4)\n",
            "GPT2 function:  (x1+0.36)**(1/4)\n",
            " ---> GPT2 Test Error: 0.00006\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.84568\n",
            "Genetic Model function:  sqrt(sqrt(log(exp(add(0.438, X0)))))\n",
            " ---> GP Test Error: 0.00005\n",
            "Test case 997/1000.\n",
            "True equation: sin(0.97*sqrt(1-0.05*x1))\n",
            "GPT2 function:  0.82*sqrt(0.03*x1-1)\n",
            " ---> GPT2 Test Error: 0.00012\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.00024\n",
            "Genetic Model function:  0.800\n",
            " ---> GP Test Error: 0.00256\n",
            "Test case 998/1000.\n",
            "True equation: sqrt(sin(0.3*x1+0.87))\n",
            "GPT2 function:  sqrt(-sin(0.3*x1+0.82))\n",
            " ---> GPT2 Test Error: 0.00050\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.25655\n",
            "Genetic Model function:  0.982\n",
            " ---> GP Test Error: 0.02291\n",
            "Test case 999/1000.\n",
            "True equation: sin(0.02*x1**2+0.93*x1)\n",
            "GPT2 function:  sin(0.94*x1-0.09)\n",
            " ---> GPT2 Test Error: 0.06774\n",
            "MLP Model function:  (neural black box)\n",
            " ---> MLP Test Error: 0.84963\n",
            "Genetic Model function:  sin(mul(X0, 0.969))\n",
            " ---> GP Test Error: 0.01793\n",
            "\n",
            "26 of 1000 equations have wrong structures!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_eb42a50b-35e5-4d86-b1c9-d92edca4254b\", \"Test-var_GPT2.out\", 185465)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-zLp6BpJgVL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 886
        },
        "outputId": "60ee8589-efc4-42c3-859e-e7af65b42705"
      },
      "source": [
        "# plot the error frequency for model comparison\n",
        "from matplotlib import pyplot as plt\n",
        "num_eqns = len(resultDict[fName]['GPT2'])\n",
        "num_vars = 1\n",
        "\n",
        "models = list(resultDict[fName].keys())\n",
        "lists_of_error_scores = [resultDict[fName][key] for key in models]\n",
        "linestyles = [\"-\",\"dashdot\",\"dotted\",\"--\"]\n",
        "\n",
        "y, x, _ = plt.hist([np.log(e) for e in lists_of_error_scores],\n",
        "                   label=models,\n",
        "                   cumulative=True, \n",
        "                   histtype=\"step\", \n",
        "                   bins=2000, \n",
        "                   density=\"true\")\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "for idx, model in enumerate(models): \n",
        "  plt.plot(x[:-1], \n",
        "           y[idx] * 100, \n",
        "           linestyle=linestyles[idx], \n",
        "           label=model)\n",
        "\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.title(\"{} equations of {} variables\".format(num_eqns, num_vars))\n",
        "plt.xlabel(\"Log of error\")\n",
        "plt.ylabel(\"Frequency Percentage\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Frequency Percentage')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBG1ANnFPRun"
      },
      "source": [
        "# Test case 1/200.\n",
        "# sin(3.98*x1-sin(2.57*x1+3.31)+3.7)\n",
        "# MLP: 16.60112825016495\n",
        "# (neural black box)\n",
        "# GP: 0.343221433055544\n",
        "# sin(mul(add(0.705, 0.487), mul(X0, X0)))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OdM8k1ikDbx"
      },
      "source": [
        "# # convert mseRes to something useful for the plot\n",
        "# import pandas as pd\n",
        "# df = pd.DataFrame(columns=['RMSE', 'SRC'])\n",
        "# for key in resultDict:\n",
        "#   tempSrc = pd.Series([key for i in range(len(resultDict[key]))], name='SRC')\n",
        "#   tempMSE = pd.Series(resultDict[key], name='RMSE')\n",
        "#   temp = pd.concat((tempSrc, tempMSE), axis=1)\n",
        "#   df = df.append(temp)\n",
        "# df['index'] = df.index"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12fqctULNrIu"
      },
      "source": [
        "# x = [_ for _ in range(6)]\n",
        "# y = [_ for _ in range(6)]\n",
        "# num_eqns = [0]\n",
        "\n",
        "# for num_vars in range(1, 6):\n",
        "\n",
        "#     input_file = open(\"output_{}var.txt\".format(num_vars), \"r\")\n",
        "#     input_lines = input_file.readlines()\n",
        "#     input_file.close()\n",
        "\n",
        "#     gp_errs = []\n",
        "#     mlp_errs = []\n",
        "#     sfl_errs= []\n",
        "#     num_less_than_0_1 = [0, 0, 0]\n",
        "#     num_less_than_0_01 = [0, 0, 0]\n",
        "#     num_less_than_0_5= [0, 0, 0]\n",
        "#     num_less_than_1= [0, 0, 0]\n",
        "\n",
        "\n",
        "#     new_input_lines = []\n",
        "#     for i in range(len(input_lines)-1):\n",
        "#         if \"Test case\" in input_lines[i] and \"Test case\" in input_lines[i+1]:\n",
        "#             continue\n",
        "#         new_input_lines.append(input_lines[i].strip())\n",
        "\n",
        "#     num_tests2 = int(len(new_input_lines)/7.0 + 0.5)\n",
        "#     print(\"{} tests\".format(num_tests2))\n",
        "\n",
        "\n",
        "#     for i in range(0, len(new_input_lines), 7):\n",
        "#         # for line in new_input_lines[i:i+7]:\n",
        "#         #     print(line)\n",
        "\n",
        "#         eqn_index = int(new_input_lines[i].split(\"/\")[0][10:].strip())\n",
        "#         eqn_str = new_input_lines[i+1].strip()\n",
        "#         mlp_err = min(np.exp(15), float(new_input_lines[i+2].split()[1]))\n",
        "#         gp_err = min(np.exp(15), float(new_input_lines[i+4].split()[1]))\n",
        "\n",
        "#         gp_errs.append(gp_err)\n",
        "#         mlp_errs.append(mlp_err)\n",
        "\n",
        "#         if gp_err < 1:\n",
        "#             num_less_than_1[0] += 1./num_tests2\n",
        "#             if gp_err < 0.5:\n",
        "#                 num_less_than_0_5[0] += 1./num_tests2\n",
        "#                 if gp_err < 0.1:\n",
        "#                     num_less_than_0_1[0] += 1./num_tests2\n",
        "#                     if gp_err < 0.01:\n",
        "#                         num_less_than_0_01[0] += 1./num_tests2\n",
        "\n",
        "#         if mlp_err < 1:\n",
        "#             num_less_than_1[1] += 1./num_tests2\n",
        "#             if mlp_err < 0.5:\n",
        "#                 num_less_than_0_5[1] += 1./num_tests2\n",
        "#                 if mlp_err < 0.1:\n",
        "#                     num_less_than_0_1[1] += 1./num_tests2\n",
        "#                     if mlp_err < 0.01:\n",
        "#                         num_less_than_0_01[1] += 1./num_tests2\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8iUcrAgNEvW"
      },
      "source": [
        "# lists_of_error_scores = [gp_errs, mlp_errs]\n",
        "# model_names = [\"GP\", \"MLP\"]\n",
        "\n",
        "# y[num_vars], x[num_vars], _ = plt.hist([np.log(errors_i) for errors_i in lists_of_error_scores],\n",
        "#                                   label=[model_name for model_name in model_names],\n",
        "#                                   cumulative=True, histtype=\"step\", bins=num_tests2, density=\"true\")\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hx7mS0nrNSUd"
      },
      "source": [
        "# plt.figure(figsize=(15, 10))\n",
        "# for num_vars in range(1, 6):\n",
        "#     plt.subplot(2, 3, num_vars)\n",
        "#     plt.plot(x[num_vars][:-1], y[num_vars][0]*100, linestyle=\"-\", label=\"GP\")\n",
        "#     plt.plot(x[num_vars][:-1], y[num_vars][1]*100, linestyle=\"--\", label=\"MLP\")\n",
        "\n",
        "\n",
        "#     plt.legend(loc=\"upper left\")\n",
        "#     plt.title(\"{} equations of {} variables\".format(num_eqns[num_vars], num_vars))\n",
        "#     plt.xlabel(\"Log of error\")\n",
        "#     plt.ylabel(\"Frequency\")\n",
        "\n",
        "# plt.savefig(\"images/hist_of_errors.png\")\n",
        "# plt.close()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVwBRdhnl2bq"
      },
      "source": [
        "# Plot the test code\n",
        "# import seaborn as sns\n",
        "# import matplotlib.pyplot as plt\n",
        "# plt.fill_between( x, y, color=\"skyblue\", alpha=0.2)\n",
        "# plt.plot(x, y, color=\"Slateblue\", alpha=0.6)\n",
        "# sns.kdeplot(\n",
        "#     data=df['RMSE'],\n",
        "#     shade=True, color=\"r\",\n",
        "#     cumulative=True)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnfygaUk0780"
      },
      "source": [
        "# Experiments: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_0kYnJpnikl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d9727bb0-3eff-4ae8-f2bd-9fa1e84924d8"
      },
      "source": [
        "# Experiment:\n",
        "'''\n",
        "# Showcase of interesting equations. Physics, Real Formula, very complicated looking curve (waves). \n",
        "cumulative experiment: \n",
        "'''"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# Showcase of interesting equations. Physics, Real Formula, very complicated looking curve (waves). \\ncumulative experiment: \\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    }
  ]
}