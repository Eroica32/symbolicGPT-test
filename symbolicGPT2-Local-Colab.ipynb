{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a4sQPcK9YNLC",
    "outputId": "6ec90c0f-072e-4c30-f1f8-02cd62dc76e6"
   },
   "outputs": [],
   "source": [
    "# install libraries and other requirements\n",
    "# !pip install -I tensorflow-gpu==2.3.1 &> tmp.log #1.15.2\n",
    "# !pip install tokenizers\n",
    "# !pip install wrapt_timeout_decorator \n",
    "# !pip install gplearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PlzbAbvgYUGm",
    "outputId": "44b7ec6b-f99c-4728-b174-f1fae131dcab"
   },
   "outputs": [],
   "source": [
    "# download weights and codes\n",
    "# import os\n",
    "# !git clone https://m5valipo:1ezHio5Rff6y-GET5drm@git.uwaterloo.ca/data-analytics-lab/symbolicgpt2.git\n",
    "# %cd symbolicgpt2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zO0SvIOvY16t",
    "outputId": "67b0060b-e47d-4805-b1b8-0581dec6c993"
   },
   "outputs": [],
   "source": [
    "# upload the latest weights for the model\n",
    "# !wget https://www.dropbox.com/s/2xee6ysificfszx/expSymbolic_Mesh_Simple_GPT2_256_base_model.ckpt-108000.data-00000-of-00001\n",
    "# !wget https://www.dropbox.com/s/75hf6b3qup9y1dh/expSymbolic_Mesh_Simple_GPT2_256_base_model.ckpt-108000.index\n",
    "# !wget https://www.dropbox.com/s/43qcil022vt9cnt/expSymbolic_Mesh_Simple_GPT2_256_base_model.ckpt-108000.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e7lFZQMRtZKZ",
    "outputId": "12083d0a-3d09-4ea9-c2bc-3973d8726fc1"
   },
   "outputs": [],
   "source": [
    "# update code, pull the recent changes\n",
    "# !git pull origin master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-PLwh7oEo4ot"
   },
   "outputs": [],
   "source": [
    "#!git reset --hard 3a4aed7c39cc33c6925ffdefea8c7ab7a164284d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XY0YoITHeGo0"
   },
   "outputs": [],
   "source": [
    "# # generate data given an equation\n",
    "# import numpy as np\n",
    "# decimals = 2\n",
    "# supportPoints = np.linspace(0.1,3.1,30)\n",
    "# supportPoints = [[np.round(p,decimals)] for p in supportPoints]\n",
    "# nv = 1\n",
    "# Y = []\n",
    "# for x in supportPoints:\n",
    "#   formula = np.exp(np.sin(x[0])) + x[0] * 1.3 + 0.1\n",
    "#   formula = formula\n",
    "#   Y.append(np.round(formula,2))\n",
    "# # use this input:\n",
    "# print('<SOS_X>{}<EOS_X><SOS_Y>{}<EOS_Y><SOS_EQ>'.format(str(supportPoints), str(Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5W6QmmThgzDy"
   },
   "outputs": [],
   "source": [
    "# # validate results\n",
    "# #sin(x1 + 1.49)\n",
    "# from scipy.spatial import distance\n",
    "# YPred = []\n",
    "# for x in supportPoints:\n",
    "#   formula = np.cos(x) + np.sin(x) + 1.08 #np.sin(x[0] + 1.56)\n",
    "#   formula = formula#[0]\n",
    "#   YPred.append(np.round(formula,2))\n",
    "# # use this input:\n",
    "# print('<SOS_X>{}<EOS_X><SOS_Y>{}<EOS_Y><SOS_EQ>'.format(str(supportPoints), str(YPred)))\n",
    "# print(distance.euclidean(Y,YPred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sv6_MLAo7UcE"
   },
   "outputs": [],
   "source": [
    "#cd symbolicgpt2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ldMWkMV3Y3h7"
   },
   "outputs": [],
   "source": [
    "# #@title #Inference\n",
    "# min_len = 0 #@param {type:\"number\", min:5, max:1024, step:1}\n",
    "# sample_num = 1 #@param {type:\"number\", min:1, max:50, step:1}\n",
    "# top_p = 0.7 #@param {type:\"number\", min:0, max:1}\n",
    "# model_type = 'large' #@param {type:\"string\"}\n",
    "# extraName = '' #'-finetune'\n",
    "# config_fn = 'configs/{}.json'.format(model_type) #'lm/configs/{}.json'.format(model_type) #@param {type:\"string\"}\n",
    "# ckpt_fn = './experimentsSymbolic_{}{}_model.ckpt-188000'.format(model_type, extraName) #@param {type:\"string\"}\n",
    "# filters = '' #@param {type:\"string\"} # text;\n",
    "# saveFlag = False #@param {type:\"boolean\"}from scripts import demodemo.wraper(top_p, config_fn, ckpt_fn, min_len, sample_num, saveFlag, filters)\n",
    "\n",
    "# #from scripts import demo\n",
    "# import demo\n",
    "# demo.wraper(top_p, config_fn, ckpt_fn, min_len, sample_num, saveFlag, filters, context='user')\n",
    "\n",
    "# # Some cool Example As Input:\n",
    "\n",
    "# # <SOS_X>[[0.1], [0.2], [0.31], [0.41], [0.51], [0.62], [0.72], [0.82], [0.93], [1.03], [1.13], [1.24], [1.34], [1.44], [1.55], [1.65], [1.76], [1.86], [1.96], [2.07], [2.17], [2.27], [2.38], [2.48], [2.58], [2.69], [2.79], [2.89], [3.0], [3.1]]<EOS_X><SOS_Y>[-2.54, -1.97, -1.6, -1.34, -1.12, -0.89, -0.67, -0.45, -0.18, 0.08, 0.38, 0.74, 1.12, 1.54, 2.06, 2.61, 3.29, 3.99, 4.78, 5.77, 6.79, 7.93, 9.37, 10.85, 12.51, 14.58, 16.71, 19.1, 22.07, 25.11]<EOS_Y><SOS_EQ>exp(x1)*log(x1)<EOS_EQ>\n",
    "# # <SOS_X>[[0.1], [0.2], [0.31], [0.41], [0.51], [0.62], [0.72], [0.82], [0.93], [1.03], [1.13], [1.24], [1.34], [1.44], [1.55], [1.65], [1.76], [1.86], [1.96], [2.07], [2.17], [2.27], [2.38], [2.48], [2.58], [2.69], [2.79], [2.89], [3.0], [3.1]]<EOS_X><SOS_Y>[-2.31, -1.61, -1.17, -0.89, -0.67, -0.48, -0.33, -0.2, -0.07, 0.03, 0.12, 0.22, 0.29, 0.36, 0.44, 0.5, 0.57, 0.62, 0.67, 0.73, 0.77, 0.82, 0.87, 0.91, 0.95, 0.99, 1.03, 1.06, 1.1, 1.13]<EOS_Y><SOS_EQ>log(x1)<EOS_EQ>\n",
    "# # <SOS_X>[[0.1], [0.2], [0.31], [0.41], [0.51], [0.62], [0.72], [0.82], [0.93], [1.03], [1.13], [1.24], [1.34], [1.44], [1.55], [1.65], [1.76], [1.86], [1.96], [2.07], [2.17], [2.27], [2.38], [2.48], [2.58], [2.69], [2.79], [2.89], [3.0], [3.1]]<EOS_X><SOS_Y>[-2.1, -1.21, -0.55, -0.07, 0.35, 0.76, 1.11, 1.44, 1.79, 2.09, 2.38, 2.7, 2.97, 3.24, 3.54, 3.8, 4.09, 4.34, 4.59, 4.87, 5.11, 5.36, 5.63, 5.87, 6.11, 6.37, 6.61, 6.84, 7.1, 7.33]<EOS_Y><SOS_EQ>2*x1 + log(x1)<EOS_EQ>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AtN25bVZl44J",
    "outputId": "c803ff1e-d6df-4d6e-ca45-698e71a408d6"
   },
   "outputs": [],
   "source": [
    "# load the test data\n",
    "# !wget https://www.dropbox.com/sh/5e5f5cfs4tfknst/AAC-bYCki_HSw0YPaNrM6_FBa\n",
    "# !unzip AAC-bYCki_HSw0YPaNrM6_FBa -d ./TestData/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "puaOnAlx9aPf"
   },
   "outputs": [],
   "source": [
    "# import demo\n",
    "# result = demo.wraper(top_p, config_fn, ckpt_fn, min_len, sample_num, saveFlag, filters, context=['<SOS_EQ>','<SOS_X>'])\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kHa5bq3__2Rg"
   },
   "outputs": [],
   "source": [
    "def cleanEquation(eq):\n",
    "  import re\n",
    "  eq = eq.replace('\\n','')\n",
    "  eq = re.sub(r'(?=)\\[.+?\\](?=)', '', eq) # remove anything between lists\n",
    "  eq = eq.replace(',','')\n",
    "  eq = eq.replace('<SOS_X>','')\n",
    "  eq = eq.replace('<EOS_X>','')\n",
    "  eq = eq.replace('<SOS_Y>','')\n",
    "  eq = eq.replace('<EOS_Y>','')\n",
    "  eq = eq.replace('<SOS_EQ>','')\n",
    "  eq = eq.replace('<EOS_EQ>','')\n",
    "  eq = eq.replace('<SOS_Skeleton>','')\n",
    "  eq = eq.replace('<EOS_Skeleton>','')\n",
    "  eq = eq.replace('[','')\n",
    "  eq = eq.replace(']','')\n",
    "  eq = eq.strip()\n",
    "  return eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "48YtMr2fIj_I"
   },
   "outputs": [],
   "source": [
    "# Mean square error\n",
    "def mse(y, y_hat):\n",
    "    y_hat = np.reshape(y_hat, [1, -1])[0]\n",
    "    y_gold = np.reshape(y, [1, -1])[0]\n",
    "    our_sum = 0\n",
    "    for i in range(len(y_gold)):\n",
    "        our_sum += (y_hat[i] - y_gold[i]) ** 2\n",
    "\n",
    "    return our_sum / len(y_gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pDqCmya4pto8",
    "outputId": "bdf10ddc-2179-4423-8ab6-1d90f8a10dfc"
   },
   "outputs": [],
   "source": [
    "# calculate test error, show the real performance using a metric\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "import demo\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# config\n",
    "show_found_eqns = True\n",
    "min_len = 0 #@param {type:\"number\", min:5, max:1024, step:1}\n",
    "sample_num = 1 #@param {type:\"number\", min:1, max:50, step:1}\n",
    "top_p = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
    "model_size = 'base' # @param [\"large\", \"base\", \"mega\"]\n",
    "model_type = 'GPT2' # @param [\"GPT2\", \"PT\"]\n",
    "extraName = '' #'-finetune' \n",
    "#'lm/configs/{}.json'.format(model_type) \n",
    "config_fn = 'configs/{}.json'.format(model_size) #@param {type:\"string\"}\n",
    "#ckpt_fn = './expSymbolic_{}_{}{}_model.ckpt-524000'.format(model_type, model_size, extraName) #@param {type:\"string\"}\n",
    "#ckpt_fn = './experimentsSymbolic_{}_model.ckpt-524000'.format(model_size) #@param {type:\"string\"}\n",
    "ckpt_fn = 'D:/experiments/symbolicGPT2/Mesh_Simple_GPT2_256/expSymbolic_Mesh_Simple_GPT2_256_base_model.ckpt-108000'\n",
    "filters = 'EQ' #@param {type:\"string\"} # text;\n",
    "saveFlag = False #@param {type:\"boolean\"}\n",
    "\n",
    "resultDict = {}\n",
    "threshold = 1e5 # to handle inf or very big points\n",
    "\n",
    "for fName in glob('D:/Datasets/Symbolic Dataset/Datasets/Mesh_Simple_GPT2/TestDataset/*.json'):\n",
    "  print('Processing {}'.format(fName))\n",
    "  \n",
    "  if 'little' in fName:# or '0_1_0_02022021_164747.json' in fName:# or '0_5_4_02022021_164747.json' in fName: # This one was only for the development testing\n",
    "    continue\n",
    "\n",
    "  # outputName = './{}-var_{}.out'.format(re.findall(\n",
    "  #                                   r'_\\d_', fName.split(\n",
    "  #                                   '.json')[0].split(\n",
    "  #                                   '/')[-1])[0].strip('_'),\n",
    "  #                                   model_type)\n",
    "  outputName = '{}-var_{}.out'.format(\n",
    "                            fName.split('.json')[0],\n",
    "                            #re.findall(r'\\d', fName)[0],\n",
    "                            model_type\n",
    "                          )\n",
    "\n",
    "  with open(fName, 'r', encoding=\"utf-8\") as f, open(outputName, 'w', encoding=\"utf-8\") as o:\n",
    "    resultDict[fName] = {'GPT2':[],\n",
    "                         'MLP':[],\n",
    "                         'GP':[]}\n",
    "\n",
    "    lines = f.readlines()\n",
    "    \n",
    "    # <SOS_X>{}<EOS_X>\n",
    "    context = ['<SOS_Y>{}<EOS_Y><SOS_EQ>'.format(\n",
    "        *(np.round(val,2).tolist() for key, val in json.loads(line).items(\n",
    "              ) if key == 'Y')) for line in lines]\n",
    "    print(context)\n",
    "    equations = demo.wraper(top_p, config_fn, ckpt_fn, min_len, sample_num, \n",
    "                            saveFlag, filters, context=context, \n",
    "                            modelType=model_type, max_num_points=30, \n",
    "                            max_num_vars=5)\n",
    "    \n",
    "    wrongEQCounter = 0\n",
    "    yPred = []\n",
    "    # compare results with other models\n",
    "    from gp_model import Genetic_Model\n",
    "    from mlp_model import MLP_Model\n",
    "\n",
    "    show_found_eqns = True\n",
    "    num_vars = 1\n",
    "    gpm = Genetic_Model()\n",
    "    mlp = MLP_Model()\n",
    "\n",
    "    for idx, line in tqdm(enumerate(lines)):\n",
    "      print(\"Test case {}/{}.\".format(idx, len(lines)))\n",
    "      \n",
    "      # TODO: don't skip infinities\n",
    "      if \"Infinity\" in line or \"NaN\" in line: #or i < 134:\n",
    "        print('infinity or nan in input!')\n",
    "        continue\n",
    "\n",
    "      data = json.loads(line) # 50000 samples in each file\n",
    "\n",
    "      # run the model\n",
    "      #TODO: calculate the model output\n",
    "      #context = ['<SOS_X>{}<EOS_X><SOS_Y>{}<EOS_Y><SOS_EQ>'.format(data['X'],data['Y'])]\n",
    "      #YPred = demo.wraper(top_p, config_fn, ckpt_fn, min_len, sample_num, saveFlag, filters, context=context)\n",
    "\n",
    "      # use Y as target labels\n",
    "      Y = data['YT']\n",
    "\n",
    "      # Evaluate YPred & Extract predicted equation\n",
    "      eq = equations[idx]\n",
    "      eq = cleanEquation(eq)\n",
    "      yPred = []      \n",
    "      YN = []\n",
    "      YPredN = []\n",
    "      try:\n",
    "        # replace vars with values\n",
    "        for xs in data['XT']:\n",
    "          eqTmp = eq + '' # copy eq\n",
    "          eqTmp = eqTmp.replace(' ','')\n",
    "          eqTmp = eqTmp.replace('\\n','')\n",
    "          for i,x in enumerate(xs):\n",
    "            #print('x{}'.format(i+1),x)\n",
    "            # replace xi with the value in the eq\n",
    "            eqTmp = eqTmp.replace('x{}'.format(i+1), str(x))\n",
    "            if ',' in eqTmp:\n",
    "              assert 'There is a , in the equation!'\n",
    "          eqEvaluated = eval(eqTmp)\n",
    "          eqEvaluated = 0 if np.isnan(eqEvaluated) else eqEvaluated\n",
    "          eqEvaluated = 10000 if np.isinf(eqEvaluated) else eqEvaluated\n",
    "          yPred.append(eqEvaluated)\n",
    "        \n",
    "        # ignore inf, or NAN\n",
    "        for i, v in enumerate(Y):\n",
    "          if v is not float('nan'): # v < threshold and \n",
    "            if Y[i] == np.inf:\n",
    "              YN.append(10000)\n",
    "            else:\n",
    "              YN.append(Y[i])\n",
    "\n",
    "            if yPred[i] == np.inf:\n",
    "              YPredN.append(10000)\n",
    "            else:\n",
    "              YPredN.append(yPred[i])\n",
    "      except Exception as e: #SyntaxError or AssertionError or NameError or TypeError:\n",
    "        print('{} \\n\\n Error: {}, EQ:{}'.format(TypeError, eqTmp, eq))\n",
    "        #TODO: Find a fair strategy, Resample/Ignore?!\n",
    "        #continue # ignore this sample\n",
    "        #yPred = np.zeros_like(Y) # no prediction\n",
    "        wrongEQCounter += 1\n",
    "\n",
    "      # ignore noisy samples with zero data on X & Y\n",
    "      if len(YN) == 0:\n",
    "        o.write('Test case {}/{}.\\n{}\\n{}: {}\\n{}\\n\\n'.format(\n",
    "          idx, len(lines),\n",
    "          data['EQ'],\n",
    "          model_type, \"Not calculated!\",\n",
    "          eq\n",
    "        ))\n",
    "        print('Not calculated')\n",
    "        continue\n",
    "\n",
    "      dict_line = eval(line)\n",
    "      print(\"True equation: {}\".format(dict_line[\"EQ\"]))\n",
    "\n",
    "      # calculate rmse between YPred and Y\n",
    "      #mseValue = np.log(mean_squared_error(YN,YPredN, squared=True))\n",
    "      model_err = mse(YN,YPredN)\n",
    "      test_err = max(np.exp(-10), model_err) \n",
    "\n",
    "      if show_found_eqns:\n",
    "          print(\"{} function:  {}\".format('GPT2', eq)[:550])\n",
    "\n",
    "      print(\" ---> {} Test Error: {:.5f}\".format('GPT2', test_err))\n",
    "\n",
    "      resultDict[fName]['GPT2'].append(test_err)\n",
    "      o.write('Test case {}/{}.\\n{}\\n{}: {}\\n{}'.format(\n",
    "          idx, len(lines),\n",
    "          data['EQ'],\n",
    "          model_type, test_err,\n",
    "          eq\n",
    "      ))\n",
    "\n",
    "      # tokenize to get input x, input y, and true eqn\n",
    "      train_data_x = dict_line[\"X\"]\n",
    "      train_data_y = dict_line[\"Y\"]\n",
    "      test_data_x = dict_line[\"XT\"]\n",
    "      test_data_y = dict_line[\"YT\"]\n",
    "      #print(\"{} training points, {} test points.\".format(len(train_data_x), len(test_data_x)))\n",
    "\n",
    "      # train MLP model\n",
    "      mlp.reset()\n",
    "      model_eqn, _, best_err = mlp.repeat_train(train_data_x, train_data_y,\n",
    "                                                test_x=test_data_x, test_y=test_data_y,                                     verbose=False)\n",
    "      if show_found_eqns:\n",
    "          print(\"{} function:  {}\".format(mlp.name, model_eqn)[:550])\n",
    "\n",
    "      # Test model on that equation\n",
    "      test_err = max(np.exp(-10), best_err)  # data_utils.test_from_formula(model_eqn, test_data_x, test_data_y)\n",
    "      print(\" ---> {} Test Error: {:.5f}\".format(mlp.short_name, test_err))\n",
    "\n",
    "      resultDict[fName]['MLP'].append(test_err)\n",
    "      o.write('\\n{}: {}\\n{}'.format('MLP', \n",
    "                                   test_err,\n",
    "                                   model_eqn))\n",
    "\n",
    "      # train GPL model\n",
    "      gpm.reset()\n",
    "      model_eqn, _, best_err = gpm.repeat_train(train_data_x, train_data_y,\n",
    "                                                test_x=test_data_x, test_y=test_data_y,\n",
    "                                                verbose=False)\n",
    "      if show_found_eqns:\n",
    "          print(\"{} function:  {}\".format(gpm.name, model_eqn)[:550])\n",
    "\n",
    "      # Test model on that equation\n",
    "      # test_err = model.test(test_data_x, test_data_y)\n",
    "      test_err = max(np.exp(-10), best_err)  # data_utils.test_from_formula(model_eqn, test_data_x, test_data_y)\n",
    "      print(\" ---> {} Test Error: {:.5f}\".format(gpm.short_name, test_err))\n",
    "\n",
    "      resultDict[fName]['GP'].append(test_err)\n",
    "      o.write('\\n{}: {}\\n{}'.format('GP', \n",
    "                                   test_err,\n",
    "                                   model_eqn))\n",
    "\n",
    "      # o.write('Test case {}/{}.\\n{}\\n{}: {}\\n{}\\n\\n'.format(\n",
    "      #     idx, len(lines),\n",
    "      #     data['Skeleton'],\n",
    "      #     model_type, mseValue,\n",
    "      #     eq\n",
    "      # ))\n",
    "\n",
    "      o.write('\\n\\n')\n",
    "\n",
    "    print('{} of {} equations have wrong structures!'.format(wrongEQCounter, len(lines)))\n",
    "    break # for now just use one test file\n",
    "  #from google.colab import files\n",
    "  #files.download(outputName) \n",
    "  # save dictionary\n",
    "  with open('data.json', 'w') as outfile:\n",
    "    json.dump(resultDict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q-zLp6BpJgVL"
   },
   "outputs": [],
   "source": [
    "# plot the error frequency for model comparison\n",
    "num_eqns = 1000\n",
    "num_vars = 1\n",
    "\n",
    "models = list(resultDict[fName].keys())\n",
    "lists_of_error_scores = [resultDict[fName][key] for key in models]\n",
    "linestyles = [\"-\",\"dashdot\",\"dotted\",\"--\"]\n",
    "\n",
    "y, x, _ = plt.hist([np.log(e) for e in lists_of_error_scores],\n",
    "                   label=models,\n",
    "                   cumulative=True, \n",
    "                   histtype=\"step\", \n",
    "                   bins=num_tests2, \n",
    "                   density=\"true\")\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for idx, model in enumerate(models): \n",
    "  plt.plot(x[:-1], \n",
    "           y[idx] * 100, \n",
    "           linestyle=linestyle[idx], \n",
    "           label=model)\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.title(\"{} equations of {} variables\".format(num_eqns, num_vars))\n",
    "plt.xlabel(\"Log of error\")\n",
    "plt.ylabel(\"Frequency Percentage\")\n",
    "\n",
    "plt.savefig('comparison.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DBG1ANnFPRun"
   },
   "outputs": [],
   "source": [
    "# Test case 1/200.\n",
    "# sin(3.98*x1-sin(2.57*x1+3.31)+3.7)\n",
    "# MLP: 16.60112825016495\n",
    "# (neural black box)\n",
    "# GP: 0.343221433055544\n",
    "# sin(mul(add(0.705, 0.487), mul(X0, X0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-OdM8k1ikDbx"
   },
   "outputs": [],
   "source": [
    "# # convert mseRes to something useful for the plot\n",
    "# import pandas as pd\n",
    "# df = pd.DataFrame(columns=['RMSE', 'SRC'])\n",
    "# for key in resultDict:\n",
    "#   tempSrc = pd.Series([key for i in range(len(resultDict[key]))], name='SRC')\n",
    "#   tempMSE = pd.Series(resultDict[key], name='RMSE')\n",
    "#   temp = pd.concat((tempSrc, tempMSE), axis=1)\n",
    "#   df = df.append(temp)\n",
    "# df['index'] = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "12fqctULNrIu"
   },
   "outputs": [],
   "source": [
    "# x = [_ for _ in range(6)]\n",
    "# y = [_ for _ in range(6)]\n",
    "# num_eqns = [0]\n",
    "\n",
    "# for num_vars in range(1, 6):\n",
    "\n",
    "#     input_file = open(\"output_{}var.txt\".format(num_vars), \"r\")\n",
    "#     input_lines = input_file.readlines()\n",
    "#     input_file.close()\n",
    "\n",
    "#     gp_errs = []\n",
    "#     mlp_errs = []\n",
    "#     sfl_errs= []\n",
    "#     num_less_than_0_1 = [0, 0, 0]\n",
    "#     num_less_than_0_01 = [0, 0, 0]\n",
    "#     num_less_than_0_5= [0, 0, 0]\n",
    "#     num_less_than_1= [0, 0, 0]\n",
    "\n",
    "\n",
    "#     new_input_lines = []\n",
    "#     for i in range(len(input_lines)-1):\n",
    "#         if \"Test case\" in input_lines[i] and \"Test case\" in input_lines[i+1]:\n",
    "#             continue\n",
    "#         new_input_lines.append(input_lines[i].strip())\n",
    "\n",
    "#     num_tests2 = int(len(new_input_lines)/7.0 + 0.5)\n",
    "#     print(\"{} tests\".format(num_tests2))\n",
    "\n",
    "\n",
    "#     for i in range(0, len(new_input_lines), 7):\n",
    "#         # for line in new_input_lines[i:i+7]:\n",
    "#         #     print(line)\n",
    "\n",
    "#         eqn_index = int(new_input_lines[i].split(\"/\")[0][10:].strip())\n",
    "#         eqn_str = new_input_lines[i+1].strip()\n",
    "#         mlp_err = min(np.exp(15), float(new_input_lines[i+2].split()[1]))\n",
    "#         gp_err = min(np.exp(15), float(new_input_lines[i+4].split()[1]))\n",
    "\n",
    "#         gp_errs.append(gp_err)\n",
    "#         mlp_errs.append(mlp_err)\n",
    "\n",
    "#         if gp_err < 1:\n",
    "#             num_less_than_1[0] += 1./num_tests2\n",
    "#             if gp_err < 0.5:\n",
    "#                 num_less_than_0_5[0] += 1./num_tests2\n",
    "#                 if gp_err < 0.1:\n",
    "#                     num_less_than_0_1[0] += 1./num_tests2\n",
    "#                     if gp_err < 0.01:\n",
    "#                         num_less_than_0_01[0] += 1./num_tests2\n",
    "\n",
    "#         if mlp_err < 1:\n",
    "#             num_less_than_1[1] += 1./num_tests2\n",
    "#             if mlp_err < 0.5:\n",
    "#                 num_less_than_0_5[1] += 1./num_tests2\n",
    "#                 if mlp_err < 0.1:\n",
    "#                     num_less_than_0_1[1] += 1./num_tests2\n",
    "#                     if mlp_err < 0.01:\n",
    "#                         num_less_than_0_01[1] += 1./num_tests2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v8iUcrAgNEvW"
   },
   "outputs": [],
   "source": [
    "# lists_of_error_scores = [gp_errs, mlp_errs]\n",
    "# model_names = [\"GP\", \"MLP\"]\n",
    "\n",
    "# y[num_vars], x[num_vars], _ = plt.hist([np.log(errors_i) for errors_i in lists_of_error_scores],\n",
    "#                                   label=[model_name for model_name in model_names],\n",
    "#                                   cumulative=True, histtype=\"step\", bins=num_tests2, density=\"true\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hx7mS0nrNSUd"
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15, 10))\n",
    "# for num_vars in range(1, 6):\n",
    "#     plt.subplot(2, 3, num_vars)\n",
    "#     plt.plot(x[num_vars][:-1], y[num_vars][0]*100, linestyle=\"-\", label=\"GP\")\n",
    "#     plt.plot(x[num_vars][:-1], y[num_vars][1]*100, linestyle=\"--\", label=\"MLP\")\n",
    "\n",
    "\n",
    "#     plt.legend(loc=\"upper left\")\n",
    "#     plt.title(\"{} equations of {} variables\".format(num_eqns[num_vars], num_vars))\n",
    "#     plt.xlabel(\"Log of error\")\n",
    "#     plt.ylabel(\"Frequency\")\n",
    "\n",
    "# plt.savefig(\"images/hist_of_errors.png\")\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pVwBRdhnl2bq"
   },
   "outputs": [],
   "source": [
    "# Plot the test code\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.fill_between( x, y, color=\"skyblue\", alpha=0.2)\n",
    "# plt.plot(x, y, color=\"Slateblue\", alpha=0.6)\n",
    "# sns.kdeplot(\n",
    "#     data=df['RMSE'],\n",
    "#     shade=True, color=\"r\",\n",
    "#     cumulative=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tnfygaUk0780"
   },
   "source": [
    "# Experiments: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t_0kYnJpnikl"
   },
   "outputs": [],
   "source": [
    "# Experiment:\n",
    "'''\n",
    "# Showcase of interesting equations. Physics, Real Formula, very complicated looking curve (waves). \n",
    "cumulative experiment: \n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "symbolicGPT2_1Var_Mine.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
